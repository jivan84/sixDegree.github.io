<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SixDegree</title>
  <subtitle>host by chenjin</subtitle>
  <link href="//atom.xml" rel="self"/>
  
  <link href="http://sixdegree.github.io/"/>
  <updated>2016-10-22T07:38:02.000Z</updated>
  <id>http://sixdegree.github.io/</id>
  
  <author>
    <name>Chen Jin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hadoop2.x Basic</title>
    <link href="http://sixdegree.github.io/2016/05/25/Hadoop2.x-Basic.html"/>
    <id>http://sixdegree.github.io/2016/05/25/Hadoop2.x-Basic.html</id>
    <published>2016-05-24T16:00:00.000Z</published>
    <updated>2016-10-22T07:38:02.000Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;Hadoop2.x HDFS HA &amp;amp; Federation;&lt;/li&gt;
&lt;li&gt;Hadoop2.x MapReduce on Yarn&lt;/li&gt;
&lt;/ol&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;Hadoop2中有两个重要的变更：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DFS的NameNode可以以集群的方式布署，增强了NameNodes的水平扩展能力和高可用性，分别是:HDFS Federation与HA；&lt;/li&gt;
&lt;li&gt;MapReduce将JobTracker中的资源管理及任务生命周期管理（包括定时触发及监控），拆分成两个独立的组件，并更名为YARN（Yet Another Resource Negotiator）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;HDFS&quot;&gt;&lt;a href=&quot;#HDFS&quot; class=&quot;headerlink&quot; title=&quot;HDFS&quot;&gt;&lt;/a&gt;HDFS&lt;/h2&gt;&lt;h3 id=&quot;1-x缺点&quot;&gt;&lt;a href=&quot;#1-x缺点&quot; class=&quot;headerlink&quot; title=&quot;1.x缺点&quot;&gt;&lt;/a&gt;1.x缺点&lt;/h3&gt;&lt;p&gt;Namenode problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Only One&lt;/li&gt;
&lt;li&gt;under great memory pressure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SecondaryNamenode problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It’s confusing name&lt;/li&gt;
&lt;li&gt;No up-to-date FSIMAGE file&lt;/li&gt;
&lt;li&gt;No automatic failover&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;2-x改进&quot;&gt;&lt;a href=&quot;#2-x改进&quot; class=&quot;headerlink&quot; title=&quot;2.x改进&quot;&gt;&lt;/a&gt;2.x改进&lt;/h3&gt;&lt;p&gt;Muti-Namenode （水平扩展和高可用）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Federation (different namespace)&lt;ul&gt;
&lt;li&gt;多个Namenode，一组Datanode&lt;/li&gt;
&lt;li&gt;使用不同的HDFS目录（即不同的namespace，互不影响）&lt;/li&gt;
&lt;li&gt;应用举例：不同Federation HDFS配置使用不同的Block大小以处理不同的需求&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;HA (same namespace)&lt;ul&gt;
&lt;li&gt;多个Namenode，一组Datanode&lt;/li&gt;
&lt;li&gt;使用相同的HDFS目录（即相同的namespace，只有一个Namenode负责读写）&lt;/li&gt;
&lt;li&gt;只有一个Namenode为Active，对外提供读写服务，其他为StandBy&lt;/li&gt;
&lt;li&gt;Active NN 一旦故障便自动切换到 standby NN（借助Zookeeper完成热切）&lt;/li&gt;
&lt;li&gt;系统通过JournalNodes守护进程使Standby和Active的Namenode保持元数据同步&lt;ul&gt;
&lt;li&gt;Active NN 将修改持久化（写）到JournalNodes&lt;/li&gt;
&lt;li&gt;StandBy NN 从JournalNodes读取修改信息，更新内部元数据&lt;/li&gt;
&lt;li&gt;JournalNodes是轻量级的进程（通过editlog持久化存储），需为奇数个&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;注意：Standby NN也执行namespace状态的checkpoints，所以不要再运行Secondary NN、CheckpointNode、BackupNode&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;2016-05-25-Hadoop2.x-Basic/hdfs.png&quot; alt=&quot;HDFS&quot;&gt;&lt;br&gt;(图片来自 &lt;a href=&quot;http://blog.csdn.net/jiewuyou&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/jiewuyou&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&quot;HDFS示例&quot;&gt;&lt;a href=&quot;#HDFS示例&quot; class=&quot;headerlink&quot; title=&quot;HDFS示例&quot;&gt;&lt;/a&gt;HDFS示例&lt;/h3&gt;&lt;p&gt;Nodes DNS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cluster1 namenode&lt;ul&gt;
&lt;li&gt;masterA.cls1&lt;/li&gt;
&lt;li&gt;masterB.cls1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cluster2 namenode&lt;ul&gt;
&lt;li&gt;masterA.cls2&lt;/li&gt;
&lt;li&gt;masterB.cls2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;datanode&lt;ul&gt;
&lt;li&gt;slave1.cls&lt;/li&gt;
&lt;li&gt;slave2.cls&lt;/li&gt;
&lt;li&gt;slave3.cls&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;zookeeper&lt;ul&gt;
&lt;li&gt;slave1.cls&lt;/li&gt;
&lt;li&gt;slave2.cls&lt;/li&gt;
&lt;li&gt;slave3.cls&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;journalnode&lt;ul&gt;
&lt;li&gt;slave1.cls&lt;/li&gt;
&lt;li&gt;slave2.cls&lt;/li&gt;
&lt;li&gt;slave3.cls&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Configuration&quot;&gt;&lt;a href=&quot;#Configuration&quot; class=&quot;headerlink&quot; title=&quot;Configuration&quot;&gt;&lt;/a&gt;Configuration&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;hadoop-env.sh (on all nodes)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; export JAVA_HOME=/usr/local/jdk1.8
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Cluster1 (on masterA.cls1,masterB.cls1)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;core-site.sh&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://cluster1&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hadoop.tmp.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;/usr/local/hadoop/tmp&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;ha.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;slave1.cls:2181,slave2.cls:2181,slave3.cls:2181&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;hdfs-site.xml&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;3&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.nameservices&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;cluster1,cluster2&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;!-- journal nodes --&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.shared.edits.dir&amp;lt;/name&amp;gt;
       &amp;lt;value&amp;gt;qjournal://slave1.cls:8485;slave2.cls:8485;slave3.cls:8485/cluster1&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.journalnode.edits.dir&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/usr/local/hadoop/tmp/journal&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;!-- Using ssh to switch namenode --&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.fencing.methods&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;sshfence&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.fencing.ssh.private-key-files&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;/root/.ssh/id_rsa&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;

  &amp;lt;!-- Cluster1 --&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.namenodes.cluster1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterA.cls1,masterB.cls1&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.rpc-address.cluster1.masterA.cls1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterA.cls1:9000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.http-address.cluster1.masterA.cls1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterA.cls1:50070&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.rpc-address.cluster1.masterB.cls1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterB.cls1:9000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.http-address.cluster1.masterB.cls1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterB.cls1:50070&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled.cluster1&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.client.failover.proxy.provider.cluster1&amp;lt;/name&amp;gt;
       &amp;lt;value&amp;gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;!-- Cluster2 --&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.namenodes.cluster2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterA.cls2,masterB.cls2&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.rpc-address.cluster2.masterA.cls2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterA.cls2:9000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.http-address.cluster2.masterA.cls2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterA.cls2:50070&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.rpc-address.cluster2.masterB.cls2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterB.cls2:9000&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.namenode.http-address.cluster2.masterB.cls2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;masterB.cls2:50070&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.ha.automatic-failover.enabled.cluster2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
      &amp;lt;name&amp;gt;dfs.client.failover.proxy.provider.cluster2&amp;lt;/name&amp;gt;
      &amp;lt;value&amp;gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Cluster2 (on masterA.cls2,masterB.cls2)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;core-site.sh (copy from cluster1) update:&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt; &amp;lt;property&amp;gt;
     &amp;lt;name&amp;gt;fs.defaultFS&amp;lt;/name&amp;gt;
     &amp;lt;value&amp;gt;hdfs://cluster2&amp;lt;/value&amp;gt;
 &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;hdfs-site.xml (copy from cluster1) update:&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&amp;lt;property&amp;gt;
   &amp;lt;name&amp;gt;dfs.namenode.shared.edits.dir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;qjournal://slave1.cls:8485;slave2.cls:8485;slave3.cls:8485/cluster2&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;slaves (on all nodes)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  slave1.cls
  slave2.cls
  slave3.cls
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;Run&quot;&gt;&lt;a href=&quot;#Run&quot; class=&quot;headerlink&quot; title=&quot;Run&quot;&gt;&lt;/a&gt;Run&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;start zookeeper&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  # slave1.cls,slave2.cls,slave3.cls
  zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;start namenode&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # slave1.cls,slave2.cls,slave3.cls
 sbin/hadoop-daemon.sh start journalnode

 # masterA.cls1,masterB.cls1
 bin/hdfs zkfc -formatZK

 # masterA.cls1
 bin/hdfs namenode -format
 sbin/hadoop-daemon.sh start namenode

 # masterB.cls1
 bin/hdfs namenode -bootstrapStandby
 sbin/hadoop-daemon.sh start namenode

 # masterA.cls1,masterB.cls2
 sbin/hadoop-daemon.sh start zkfc
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;start datanode&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # slave1.cls,slave2.cls,slave3.cls
 sbin/hadoop-daemons.sh start datanode
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;MapReduce&quot;&gt;&lt;a href=&quot;#MapReduce&quot; class=&quot;headerlink&quot; title=&quot;MapReduce&quot;&gt;&lt;/a&gt;MapReduce&lt;/h2&gt;&lt;h3 id=&quot;1-x缺点-1&quot;&gt;&lt;a href=&quot;#1-x缺点-1&quot; class=&quot;headerlink&quot; title=&quot;1.x缺点&quot;&gt;&lt;/a&gt;1.x缺点&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;JobTracker under greate pressure&lt;ul&gt;
&lt;li&gt;Job Coordination&lt;/li&gt;
&lt;li&gt;Scheduling&lt;/li&gt;
&lt;li&gt;Resource Management&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cluster 资源利用率不高 (不同作业需要搭建不同的集群环境)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;2-x改进-1&quot;&gt;&lt;a href=&quot;#2-x改进-1&quot; class=&quot;headerlink&quot; title=&quot;2.x改进&quot;&gt;&lt;/a&gt;2.x改进&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;2016-05-25-Hadoop2.x-Basic/hadoop.png&quot; alt=&quot;Hadoop&quot;&gt;&lt;/p&gt;
&lt;p&gt;引入Yarn&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JobTracker的功能分离成Yarn的两个单独的组件完成&lt;ul&gt;
&lt;li&gt;ResourceManager 全局管理所有应用程序计算资源的分配&lt;/li&gt;
&lt;li&gt;ApplicationMaster 负责某一应用的任务调度和协调（每个应用一个，例如MapReduce,Storm,Spark等）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Yarn具有通用性，因此整个集群也可作为其他计算框架的管理平台（例如Spark，Storm等）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Yarn&quot;&gt;&lt;a href=&quot;#Yarn&quot; class=&quot;headerlink&quot; title=&quot;Yarn&quot;&gt;&lt;/a&gt;Yarn&lt;/h3&gt;&lt;p&gt;Yarn：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一套资源统一管理和调度的平台&lt;/li&gt;
&lt;li&gt;可管理各种计算框架，包括 MapReduce 、 Spark 、 Strom 等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;2016-05-25-Hadoop2.x-Basic/yarn.png&quot; alt=&quot;Hadoop&quot;&gt;&lt;/p&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ResourceManager&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;YARN集群的Master，负责管理整个集群的资源分配和作业调度&lt;/li&gt;
&lt;li&gt;接收提交的job，根据job的Context，NodeManager反馈的status，启动分配一个NodeManager的Container作为ApplicationManager&lt;/li&gt;
&lt;li&gt;主要包含两个组件：&lt;ul&gt;
&lt;li&gt;Scheduler 负责将集群资源分配给应用程序&lt;/li&gt;
&lt;li&gt;ApplicationManager 负责接收任务，调度启动每个Job所属的ApplicationMaster，&lt;br&gt;监控重启ApplicationMaster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;NodeManager&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;YARN集群的Slave，是集群中实际拥有实际资源的工作节点&lt;/li&gt;
&lt;li&gt;负责Container状态的维护，并向RM保持心跳（类似RM在每台机器的上代理）&lt;/li&gt;
&lt;li&gt;注：&lt;ul&gt;
&lt;li&gt;RM可将某个NM上的Container分配给某个Job的AppMstr&lt;/li&gt;
&lt;li&gt;AppMstr将组成Job的多个Task调度到对应的NM上进行执行&lt;/li&gt;
&lt;li&gt;一般DN和NM在同一个节点&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ApplicationMaster&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负责申请资源，监控管理任务运行（一个Job生命周期内的所有工作）&lt;/li&gt;
&lt;li&gt;比如:&lt;ul&gt;
&lt;li&gt;运行Task的资源，由AM向RM申请；&lt;/li&gt;
&lt;li&gt;启动/停止NM上某Task的对应的Container，由AM向NM请求来完成&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;是一个可变部分，用户可对不同编程模型写自己的AM实现，让更多类型的编程模型能够跑在此集群中&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Container&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;资源的抽象，Yarn为了作资源隔离而提出的一个框架&lt;ul&gt;
&lt;li&gt;对NodeManager上的资源进行量化，组装成一个个Container，服务于已授权资源的任务&lt;/li&gt;
&lt;li&gt;完成任务后，系统回收资源，供后续任务申请使用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;资源包括：内存，CPU，硬盘，网络等&lt;/li&gt;
&lt;li&gt;对于资源的表示以内存为单位，比之前以剩余slot数目更合理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;Yarn配置示例&quot;&gt;&lt;a href=&quot;#Yarn配置示例&quot; class=&quot;headerlink&quot; title=&quot;Yarn配置示例&quot;&gt;&lt;/a&gt;Yarn配置示例&lt;/h3&gt;&lt;h4 id=&quot;Configuration-1&quot;&gt;&lt;a href=&quot;#Configuration-1&quot; class=&quot;headerlink&quot; title=&quot;Configuration&quot;&gt;&lt;/a&gt;Configuration&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;mapred-site.xml&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;mapreduce.framework.name&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;yarn&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;yarn-site.xml&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &amp;lt;property&amp;gt;
       &amp;lt;name&amp;gt;yarn.resourcemanager.hostname&amp;lt;/name&amp;gt;
       &amp;lt;value&amp;gt;masterA.cls1&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
       &amp;lt;name&amp;gt;yarn.nodemanager.aux-services&amp;lt;/name&amp;gt;
       &amp;lt;value&amp;gt;mapreduce_shuffle&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;Run-1&quot;&gt;&lt;a href=&quot;#Run-1&quot; class=&quot;headerlink&quot; title=&quot;Run&quot;&gt;&lt;/a&gt;Run&lt;/h4&gt;&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;# masterA.cls1
sbin/start-yarn.sh

sbin/stop-yarn.sh
&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      Hadoop2.x Basic Introduce (HDFS+Yarn+MapReduce)
    
    </summary>
    
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>Flume</title>
    <link href="http://sixdegree.github.io/2016/05/20/Flume.html"/>
    <id>http://sixdegree.github.io/2016/05/20/Flume.html</id>
    <published>2016-05-19T16:00:00.000Z</published>
    <updated>2016-06-04T08:35:45.000Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;Flume概述（Agent组件：Source，Channel，Sink）；&lt;/li&gt;
&lt;li&gt;Flume安装；&lt;/li&gt;
&lt;li&gt;Flume使用示例；&lt;/li&gt;
&lt;/ol&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;Flume 分布式的日志收集系统 &lt;a href=&quot;https://flume.apache.org/FlumeUserGuide.html#setting-up-an-agent&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官网手册&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;2016-05-20-flume/frame1.png&quot; alt=&quot;Frame 1&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;agent：收集日志发送到目的地（运行在日志收集端的一个Java进程），包括三个核心组件：&lt;ul&gt;
&lt;li&gt;source 收集日志（数据临时存放在channel中）&lt;ul&gt;
&lt;li&gt;可处理各种类型各种格式的日志数据&lt;/li&gt;
&lt;li&gt;例如日志类型：avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy、自定义&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;channel 缓冲数据（数据只有在sink发送成功之后才会被删除）&lt;ul&gt;
&lt;li&gt;例如存放在：memory、jdbc、file、自定义&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;sink 发送日志到目的地&lt;ul&gt;
&lt;li&gt;例如目的地：hdfs、logger、avro、thrift、ipc、file、null、hbase、solr、自定义&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;特殊：interceptor 拦截器（在日志进入到source前，包装清洗过滤event）&lt;ul&gt;
&lt;li&gt;chain形式：可对一个source指定多个拦截器，按先后顺序依次处理&lt;/li&gt;
&lt;li&gt;官方已有的拦截器：Timestamp/Host/Static/Regex Filtering/Regex Extractor/… &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;event：在整个数据传输过程中，流动的是event&lt;/li&gt;
&lt;li&gt;注意：&lt;ul&gt;
&lt;li&gt;事务保证在event级别&lt;/li&gt;
&lt;li&gt;flume支持多级agent&lt;/li&gt;
&lt;li&gt;flume支持扇入(fan-in)，扇出(fan-out)&lt;br&gt;  &lt;img src=&quot;2016-05-20-flume/frame2.png&quot; alt=&quot;Frame 2&quot;&gt;&lt;br&gt;  &lt;img src=&quot;2016-05-20-flume/frame3.png&quot; alt=&quot;Frame 3&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;使用示例&quot;&gt;&lt;a href=&quot;#使用示例&quot; class=&quot;headerlink&quot; title=&quot;使用示例&quot;&gt;&lt;/a&gt;使用示例&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;安装：直接下载解压即可&lt;/li&gt;
&lt;li&gt;&lt;p&gt;配置：在&lt;code&gt;$FLUME_HOME/conf&lt;/code&gt;下添加一个配置文件（例如：&lt;code&gt;flume-conf-test1.properties&lt;/code&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt; # agent1表示代理名称
 agent1.sources=source1
 agent1.sinks=sink1
 agent1.channels=channel1

 # 配置source1
 # 1. Spooling Directory是监控指定文件夹中新文件的变化
 # 一旦新文件出现，就解析该文件内容，然后写入到channle
 # 写入完成后，标记该文件已完成或者删除该文件
 # 2. 添加Timestamp Interceptor
 # 在event的header中添加一个key叫timestamp,value为当前的时间戳
 agent1.sources.source1.type=spooldir
 agent1.sources.source1.spoolDir=/home/hadoop/input/flume
 agent1.sources.source1.channels=channel1
 agent1.sources.source1.fileHeader = false
 agent1.sources.source1.interceptors = i1
 agent1.sources.source1.interceptors.i1.type = timestamp

 # 配置sink1
 agent1.sinks.sink1.type=hdfs
 agent1.sinks.sink1.hdfs.path=hdfs://cj.storm:9000/output/flume
 agent1.sinks.sink1.hdfs.fileType=DataStream
 agent1.sinks.sink1.hdfs.writeFormat=TEXT
 # agent1.sinks.sink1.hdfs.rollInterval=0
 # agent1.sinks.sink1.hdfs.rollSize=10485760
 agent1.sinks.sink1.channel=channel1
 agent1.sinks.sink1.hdfs.filePrefix=%Y-%m-%d

 # 配置channel1
 agent1.channels.channel1.type=file
 agent1.channels.channel1.checkpointDir=/home/hadoop/input/flume_tmp/checkpoint
 agent1.channels.channel1.dataDirs=/home/hadoop/input/flume_tmp/data
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;测试&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # 1. 创建被监控目录
 &amp;gt; mkdir -p /home/hadoop/input/flume

 # 2. 启动flume agent1
 # -n 指定agent名称
 # -c 指定配置文件目录
 # -f 指定配置文件
 &amp;gt; bin/flume-ng agent -n agent1 -c conf -f conf/flume-conf-test1.properties \
 -Dflume.root.logger=DEBUG,console

 # 3. 放入测试文件
 # 4. 查看运行结果
 &amp;gt; hadoop fs -lsr /output/flume
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      Log Collection
    
    </summary>
    
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>Sqoop</title>
    <link href="http://sixdegree.github.io/2016/05/15/Sqoop.html"/>
    <id>http://sixdegree.github.io/2016/05/15/Sqoop.html</id>
    <published>2016-05-14T16:00:00.000Z</published>
    <updated>2016-06-04T08:52:29.000Z</updated>
    
    <content type="html">&lt;p&gt;HDFS数据到关系型数据库的导入导出工具Sqoop简介和基本使用示例&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;SQOOP – 使用MapReduce实现用于对数据进行导入导出&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Import: 把MySQL、Oracle等数据库中的数据导入到HDFS、Hive、HBase中&lt;/li&gt;
&lt;li&gt;Export: 把HDFS、Hive、HBase中的数据导出到MySQL、Oracle等数据库中&lt;/li&gt;
&lt;li&gt;注意：导入导出的事务是以Mapper任务为单位&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://sqoop.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html#_incremental_imports&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;用户手册&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;2016-05-15-Sqoop/frame.png&quot; alt=&quot;Export/Import&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;下载解压&lt;/li&gt;
&lt;li&gt;配置环境变量（&lt;code&gt;/etc/profile&lt;/code&gt;）&lt;ul&gt;
&lt;li&gt;SQOOP_HOME&lt;/li&gt;
&lt;li&gt;HADOOP_HOME&lt;/li&gt;
&lt;li&gt;PATH&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;将要使用的JDBC Connector Jar包放入&lt;code&gt;$SQOOP_HOME/lib&lt;/code&gt;下&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;使用示例&quot;&gt;&lt;a href=&quot;#使用示例&quot; class=&quot;headerlink&quot; title=&quot;使用示例&quot;&gt;&lt;/a&gt;使用示例&lt;/h2&gt;&lt;h3 id=&quot;查询&quot;&gt;&lt;a href=&quot;#查询&quot; class=&quot;headerlink&quot; title=&quot;查询&quot;&gt;&lt;/a&gt;查询&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;list databases&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  sqoop list-databases \
  --connect jdbc:mysql://cj.storm:3306 --username root --password cj123
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;list tables&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  sqoop list-tables \
  --connect jdbc:mysql://cj.storm:3306/hive --username root --password cj123
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;list jobs&lt;pre&gt;&lt;code&gt;  sqoop job --list
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Import-MySQL-gt-HDFS&quot;&gt;&lt;a href=&quot;#Import-MySQL-gt-HDFS&quot; class=&quot;headerlink&quot; title=&quot;Import(MySQL=&amp;gt;HDFS)&quot;&gt;&lt;/a&gt;Import(MySQL=&amp;gt;HDFS)&lt;/h3&gt;&lt;p&gt;一些参数说明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-m &amp;lt;num&amp;gt;&lt;/code&gt;: 使用的mapper数（注意：对于无主键的表，需要增加参数&lt;code&gt;--split-by xxx&lt;/code&gt; 或 &lt;code&gt;-m 1&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--warehouse-dir &amp;lt;path&amp;gt;&lt;/code&gt;: 指定存放的数据仓库（默认：&lt;code&gt;/user/{USER_NAME}&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--target-dir &amp;lt;path&amp;gt;&lt;/code&gt;: 指定存放的数据路径 （默认：&lt;code&gt;/user/{USER_NAME}/{tablename}&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--null-string &amp;lt;str&amp;gt;&lt;/code&gt;: 指定用什么代表空字段（默认：NULL）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--hive-import&lt;/code&gt;: 表导入到hive中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--hive-table &amp;lt;tablename&amp;gt;&lt;/code&gt;: hive table name&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--hive-overwrite&lt;/code&gt;: overwite hive table&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;mysql table =&amp;gt; hdfs file&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # use --warehouse-dir
 # final file: /output/log/part-m-00000
 sqoop import \
 --connect jdbc:mysql://cj.storm:3306/sqoop --username root --password cj123 \
 --table log --fields-terminated-by &amp;#39;,&amp;#39; \
 --warehouse-dir &amp;#39;/output&amp;#39; \
 -m 1

 # use --target-dir &amp;amp; query
 # final file: /output/log_2/part-m-00000
 sqoop import \
 --connect jdbc:mysql://cj.storm:3306/sqoop  --username root --P \
 --query &amp;quot;select * from log where \$CONDITIONS&amp;quot; \
 --target-dir /output/log_2 \
 -m 1  

 # use --target-dir &amp;amp; columns &amp;amp; where
 sqoop import \
 --connect jdbc:mysql://cj.storm:3306/sqoop --username root --password cj123 \
 --table log \
 --columns &amp;quot;ip,status,method&amp;quot; \
 --where &amp;quot;status=&amp;#39;200&amp;#39; and method in (&amp;#39;GET&amp;#39;,&amp;#39;POST&amp;#39;)&amp;quot;  \
 -m 1  \
 --target-dir /output/log_3 \
 --fields-terminated-by &amp;quot;,&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;mysql table =&amp;gt; hive table&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # use hive-import
 sqoop import 
 --connect jdbc:mysql://cj.storm:3306/hive  --username root --password cj123 
 --table TBLS 
 --fields-terminated-by &amp;#39;\t&amp;#39;  
 --null-string &amp;#39;**&amp;#39;  
 -m 1 
 --hive-import

 # use hive-import &amp;amp; hive-table
 sqoop import \
 --connect jdbc:mysql://cj.storm:3306/hive  --username root --password cj123 \
 --table TBLS \
 --fields-terminated-by &amp;#39;\t&amp;#39; \
 --null-string &amp;#39;**&amp;#39; \
 -m 1 \
 --hive-import \
 --hive-table &amp;#39;tbls_2&amp;#39;

 # check hive table
 hive -e &amp;#39;describe formatted tbls&amp;#39;
 hive -e &amp;#39;describe formatted tbls_2&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;mysql table schema =&amp;gt; hive table schema&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # just copy table schema (no data)
 sqoop create-hive-table \
 --connect jdbc:mysql://cj.storm:3306/sqoop --username root --password cj123 \
 --table log \
 --hive-table log_sqoop \
 --fields-terminated-by &amp;#39;,&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;Job&quot;&gt;&lt;a href=&quot;#Job&quot; class=&quot;headerlink&quot; title=&quot;Job&quot;&gt;&lt;/a&gt;Job&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;create job:&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; sqoop job \
 --create myjob \
 -- import --connect jdbc:mysql://cj.storm:3306/hive  --username root -P \
 --table TBLS \
 --fields-terminated-by &amp;#39;\t&amp;#39;  \
 --null-string &amp;#39;**&amp;#39; \
 -m 1 \
 --hive-import \
 --hive-table &amp;#39;tbls_4&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;exec job:&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; sqoop job --exec myjob
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看 job:&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; sqoop job --list
 sqoop job --show myjob
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除 job:&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; sqoop job --delete myjob
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      Sqoop introduction
    
    </summary>
    
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>Hive</title>
    <link href="http://sixdegree.github.io/2016/05/10/Hive.html"/>
    <id>http://sixdegree.github.io/2016/05/10/Hive.html</id>
    <published>2016-05-09T16:00:00.000Z</published>
    <updated>2016-10-22T07:37:44.000Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;Hive概述，安装；&lt;/li&gt;
&lt;li&gt;HiveQL操作；&lt;/li&gt;
&lt;li&gt;Hive的Java客户端操作；&lt;/li&gt;
&lt;/ol&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;建立在Hadoop基础上的数据仓库，能够管理查询Hadoop中的数据&lt;/li&gt;
&lt;li&gt;本质上，Hive是一个SQL解析引擎，将SQL语句转译成M/R Job，在Hadoop执行&lt;/li&gt;
&lt;li&gt;Hive的表其实就是HDFS的目录，字段即为文件中的列，可以直接在M/R Job里使用这些数据&lt;/li&gt;
&lt;li&gt;在HDFS中的默认存放位置：/user/hive/warehouse（hive-conf.xml的hive.metastore.warehouse.dir属性）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;系统架构&quot;&gt;&lt;a href=&quot;#系统架构&quot; class=&quot;headerlink&quot; title=&quot;系统架构&quot;&gt;&lt;/a&gt;系统架构&lt;/h3&gt;&lt;p&gt;&lt;img src=&quot;2016-05-10-Hive/frame.png&quot; alt=&quot;Frame&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用户接口&lt;ul&gt;
&lt;li&gt;CLI：Shell命令行&lt;/li&gt;
&lt;li&gt;JDBC/ODBC：Java Connection （与使用传统数据库JDBC的方式类似）&lt;/li&gt;
&lt;li&gt;WebGUI：通过浏览器访问 Hive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MetaStore&lt;ul&gt;
&lt;li&gt;存储元数据（例如：表名，表属性，列属性，分区属性，数据所在路径等）&lt;/li&gt;
&lt;li&gt;存储在数据库中，目前支持 mysql、derby(默认，内置)&lt;ul&gt;
&lt;li&gt;默认使用内嵌的derby数据库作为存储引擎&lt;/li&gt;
&lt;li&gt;Derby引擎的一次只能打开一个会话&lt;/li&gt;
&lt;li&gt;MySQL等外置存储引擎，可支持多用户同时访问&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Driver&lt;ul&gt;
&lt;li&gt;包含解释器，编译器，优化器，执行器&lt;/li&gt;
&lt;li&gt;完成HQL=&amp;gt;Job，Trigger Exec&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hadoop&lt;ul&gt;
&lt;li&gt;用 HDFS 进行存储&lt;/li&gt;
&lt;li&gt;利用 MapReduce 进行计算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;注意：大部分的查询由 MapReduce 完成，但有些不是，例如&lt;code&gt;select * from table&lt;/code&gt;（包含&lt;code&gt;*&lt;/code&gt;的查询）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现在Hive的整体框架，计算引擎不仅仅支持Map/Reduce，并且还支持Tez、Spark等。根&lt;br&gt;据不同的计算引擎又可以使用不同的资源调度和存储系统&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;2016-05-10-Hive/frame-new.png&quot; alt=&quot;Frame New&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;数据存储&quot;&gt;&lt;a href=&quot;#数据存储&quot; class=&quot;headerlink&quot; title=&quot;数据存储&quot;&gt;&lt;/a&gt;数据存储&lt;/h3&gt;&lt;p&gt;存储结构主要包括：数据库、文件、表、视图&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 HDFS 进行存储，无专门的数据存储格式，也没有为数据建立索引&lt;/li&gt;
&lt;li&gt;用户只需在建表时，指定Hive数据的列分隔符与行分隔符，Hive即可解析数据文件为Table&lt;/li&gt;
&lt;li&gt;默认可以直接加载文本文件（TextFile），也支持SequenceFile &lt;/li&gt;
&lt;li&gt;每一个 Table 在 Hive 中都有一个相应的目录存储数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;p&gt;Hive可以安装在Hadoop集群中的任何一台机器上&lt;br&gt;metastore支持三种存储模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本地内嵌模式（默认）：元数据保持在Hive内嵌的derby中，只允许一个会话连接&lt;/li&gt;
&lt;li&gt;本地独立模式：元数据保持在本地的一个DB中，允许多会话连接&lt;/li&gt;
&lt;li&gt;&lt;p&gt;远端独立模式：元数据保持在远程的一个DB中，允许多会话连接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;安装Hive：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;下载解压&lt;/li&gt;
&lt;li&gt;设置环境变量（&lt;code&gt;/etc/profile&lt;/code&gt;文件）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;HIVE_HOME&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;HADOOP_HOME&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PATH&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;配置（&lt;code&gt;$HIVE_HOME/conf&lt;/code&gt;目录下）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hive-log4j.properties.template&lt;/code&gt; =&amp;gt; &lt;code&gt;hive-log4j.properties&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hive-default.xml.template&lt;/code&gt; =&amp;gt; &lt;code&gt;hive-site.xml&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;hive.metastore.warehouse.dir&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;/user/hive/warehouse&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;hive.exec.stagingdir&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;/tmp/hive/.hive-staging&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;hive.exec.scratchdir&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;/tmp/hive&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;hive.exec.local.scratchdir&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;/tmp/hive&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;hive.downloaded.resources.dir&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;/tmp/hive/${hive.session.id}_resources&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;hive.server2.logging.operation.log.location&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;/tmp/hive/operation_logs&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;HDFS上创建和授权目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hadoop fs -mkidr /tmp
hadoop fs -chmod g+w /tmp

hadoop fs -mkidr /user/hive/warehouse
hadoop fs -chmod g+w /user/hive/warehouse
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用外部数据库（例如MySQL）作为Hive的metastore：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装MySQL&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; rpm -qa |grep mysql             # 检查mysql
&amp;gt; rpm -e --nodeps mysql           # 强力卸载mysql

&amp;gt; rpm -i mysql-server-********    # 安装mysql服务端
&amp;gt; rpm -i mysql-client-********    # 安装mysql客户端

&amp;gt; mysqld_safe &amp;amp;                   # 启动mysql 服务端  
&amp;gt; mysql_secure_installation       # 设置root用户密码
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;mysql 连接权限修改&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; mysql -u root -p
mysql&amp;gt; use mysql;
mysql&amp;gt; select host,user from user;
mysql&amp;gt; grant all privileges on *.* to &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; identified by &amp;#39;mypassword&amp;#39; with grant option;
mysql&amp;gt; select host,user from user;
mysql&amp;gt; flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;添加mysql的jdbc驱动包（置于到&lt;code&gt;$HIVE_HOME/lib&lt;/code&gt;目录下）&lt;/li&gt;
&lt;li&gt;添加配置Hive （&lt;code&gt;$HIVE_HOME/conf/hive-site.xml&lt;/code&gt;）&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;javax.jdo.option.ConnectionURL&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;jdbc:mysql://cj.storm:3306/hive?createDatabaseIfNotExist=true&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;javax.jdo.option.ConnectionDriverName&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;com.mysql.jdbc.Driver&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;javax.jdo.option.ConnectionUserName&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;root&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&amp;lt;property&amp;gt;
 &amp;lt;name&amp;gt;javax.jdo.option.ConnectionPassword&amp;lt;/name&amp;gt;
 &amp;lt;value&amp;gt;admin&amp;lt;/value&amp;gt;
&amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;运行Hive:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保证Hadoop是启动状态&lt;/li&gt;
&lt;li&gt;设置Hive运行模式&lt;ul&gt;
&lt;li&gt;分为本地与集群两种，可通过&lt;code&gt;mapred.job.tracker&lt;/code&gt;参数设置&lt;/li&gt;
&lt;li&gt;例如：&lt;code&gt;&amp;gt; hive -e &amp;quot;SET mapred.job.tracker=local&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;启动Hive&lt;ul&gt;
&lt;li&gt;启动命令行 &lt;code&gt;&amp;gt; hive --service cli&lt;/code&gt;，同&lt;code&gt;&amp;gt; hive&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;启动Web（port：9999） &lt;code&gt;&amp;gt; hive --service hwi &amp;amp;&lt;/code&gt;，需要另外下载放入&lt;code&gt;hive-hwi&lt;/code&gt;war包&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;验证&lt;ul&gt;
&lt;li&gt;Hive命令&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; hive -help
&amp;gt; hive
hive&amp;gt; show databases;
OK
default
hive&amp;gt; exit;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;HiveQL&quot;&gt;&lt;a href=&quot;#HiveQL&quot; class=&quot;headerlink&quot; title=&quot;HiveQL&quot;&gt;&lt;/a&gt;HiveQL&lt;/h2&gt;&lt;h3 id=&quot;数据库&quot;&gt;&lt;a href=&quot;#数据库&quot; class=&quot;headerlink&quot; title=&quot;数据库&quot;&gt;&lt;/a&gt;数据库&lt;/h3&gt;&lt;p&gt;类似传统数据库的DataBase，系统默认使用数据库&lt;code&gt;default&lt;/code&gt;，也可指定&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; hive
hive&amp;gt; create database &amp;lt;数据库名&amp;gt; ;
hive&amp;gt; use &amp;lt;数据库名&amp;gt; ;
...
hive&amp;gt; drop database  &amp;lt;数据库名&amp;gt;;
hive&amp;gt; drop database  &amp;lt;数据库名&amp;gt; cascade;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;表&quot;&gt;&lt;a href=&quot;#表&quot; class=&quot;headerlink&quot; title=&quot;表&quot;&gt;&lt;/a&gt;表&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;查看表：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 查看所有的表
show tables; 
# 支持模糊查询
show tables &amp;#39;*tmp*&amp;#39;; 

# 查看表有哪些分区
show partitions tmp_tb; 

#查看表详情
describe tmp_tb; 
describe formatted tmp_tb;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;修改表结构（alter）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;alter table tmp_tb add columns (cols,string);
alter table tmp_tb add if not exists partition(day=&amp;#39;2016-04-01&amp;#39;,city=&amp;#39;wx&amp;#39;);
alter table tmp_tb drop if exists partition (daytime=&amp;#39;2016-05-01&amp;#39;,city=&amp;#39;sz&amp;#39;);
alter table tmp_tb clustered by (ip) into 3 buckets;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除表（drop）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;drop table
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;清空表 （truncate）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 无法清空外部表
truncate table table_name;  # 不指定分区，将清空表中的所有分区
truncate table table_name partition (dt=&amp;#39;20080808&amp;#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;视图（view）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;CREATE VIEW v1 AS select * from t1;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建表&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 创建表
Create [EXTERNAL] TABLE [IF NOT EXISTS] table_name 
  [(col_name data_type, ...)]
  [PARTITIONED BY (col_name data_type, ...)] 
  [
    CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] 
    INTO num_buckets BUCKETS
  ] 
  [ROW FORMAT DELIMITED row_format] 
  [STORED AS file_format] 
  [LOCATION hdfs_path]

# 复制表结构
CREATE [EXTERNAL] TABLE target_table LIKE source_table [LOCATION hdfs_path];
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;EXTERNAL ：标识创建一个外部表&lt;/li&gt;
&lt;li&gt;PARTITIONED By ：分区（每个分区列单独一个目录，分区列本身不会存储在数据文件中）&lt;/li&gt;
&lt;li&gt;CLUSTERED By ：分桶，根据指定列的Hash值切分（一个桶一个数据文件，内容包含桶列）&lt;/li&gt;
&lt;li&gt;ROW FORMAT DELIMITED ：指定数据分割符（默认只认单个字符）&lt;ul&gt;
&lt;li&gt;FIELDS TERMINATED BY&lt;/li&gt;
&lt;li&gt;LINES TERMINATED BY&lt;/li&gt;
&lt;li&gt;COLLECTION ITEMS TERMINATED BY&lt;/li&gt;
&lt;li&gt;MAP KEYS TERMINATED BY&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;STORED AS ：数据存储方式&lt;ul&gt;
&lt;li&gt;TEXTFILE 纯文本，不压缩&lt;/li&gt;
&lt;li&gt;SEQUENCEFILE 序列化，压缩&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LOCATION ：创建表时就加载数据，指定数据文件所在位置（可选）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加载数据(Load dataset)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LOAD Cmd：将HDFS文件导入已创建的Hive表（加载时不做检查，查询时检查）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;LOAD DATA [LOCAL] INPATH &amp;#39;filepath&amp;#39; [OVERWRITE] 
INTO TABLE tablename
[PARTITION (partcol1=val1, partcol2=val2 ...)]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;!hadoop fs -ls input/hive/stocks_db;
load data inpath &amp;#39;input/hive/stocks_db&amp;#39; into table stocks;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;CTAS：将Hive查询结果存放入一个新创表，原子级（select失败，table不会创建），目标表不能是分区表和外部表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;CREATE TABLE [IF NOT EXISTS] table_name 
AS SELECT …
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table stocks_ctas as select * from stocks;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;INSERT…SELECT：将Hive查询结果存入一个已创表&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;INSERT OVERWRITE|INTO TABLE tablename 
[PARTITION (partcol1=val1, partcol2=val2 ...)] 
select_statement FROM from_statement
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert into table stocks_ctas select s.* from stocks s;
insert overwrite table stocks_ctas select s.* from stocks s;

# 可以在同一个查询中使用多个insert子句
from stocks_ctas
insert into t1 select id,name
insert into t2 select id,tel
where age&amp;gt;25
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;LOCATION：指定Hive表数据文件位置（注意：不会再移动数据文件到Hive配置的数据仓库中）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;!hadoop fs -ls /user/hive/input/hive/stocks_db;
create table stocks_loc(...) 
row format delimited fields terminated by &amp;#39;,&amp;#39;
location &amp;#39;/user/hive/input/hive/stocks_db&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Hive中有两种性质的表（Table Type）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;managed_table (Hive内部表) &lt;ul&gt;
&lt;li&gt;使用Load data命令插数据时，会将数据文件&lt;code&gt;移动&lt;/code&gt;到数据仓库（由&lt;code&gt;hive-site.xml&lt;/code&gt;配置的&lt;code&gt;hive.metastore.warehouse.dir&lt;/code&gt;指定）&lt;/li&gt;
&lt;li&gt;使用Drop table命令删除表时，元数据（metastore的db中）与对应的数据文件都会被删除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;external_table (Hive外部表)&lt;ul&gt;
&lt;li&gt;使用Load data命令插数据时，不会将数据文件&lt;code&gt;移动&lt;/code&gt;到数据仓库&lt;/li&gt;
&lt;li&gt;使用Drop table命令删除表时，只有元数据会被删除，实际数据文件不会有影响&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hive中表的数据类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基本数据类型&lt;ul&gt;
&lt;li&gt;tinyint/smallint/int/bigint&lt;/li&gt;
&lt;li&gt;float/double&lt;/li&gt;
&lt;li&gt;boolean&lt;/li&gt;
&lt;li&gt;string&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;复杂数据类型&lt;ul&gt;
&lt;li&gt;Array/Map/Struct&lt;/li&gt;
&lt;li&gt;没有date/datetime&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;分区表&quot;&gt;&lt;a href=&quot;#分区表&quot; class=&quot;headerlink&quot; title=&quot;分区表&quot;&gt;&lt;/a&gt;分区表&lt;/h3&gt;&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 使用普通表，会scan整张表，效率低
select * from stocks where symbol=&amp;#39;XYZ&amp;#39; and ymd=&amp;#39;2003-02-01&amp;#39;;

# 使用分区表，会先找到对应分区列目录，效率高
select * from stocks_partition where symbol=&amp;#39;XYZ&amp;#39; and ymd=&amp;#39;2003-02-01&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分区表（partition table）&lt;br&gt;粗粒度的划分，分区列成了目录（为虚拟列），条件查询时可定位到目录提高效率&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建分区表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table if not exists stocks_partition(
  col1 string,
  col2 string,
  exch_name string,
  yr int
)
partitioned by (symbol string)
row format delimited fields terminated by &amp;#39;,&amp;#39; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加载数据&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Using &lt;code&gt;insert&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# add partition(symbol=B7J) data:
insert into table stocks_partition partition(symbol=&amp;#39;B7J&amp;#39;)
select col1,col2,exch_name,yr from stocks where symbol =&amp;#39;B7J&amp;#39;;

# add partition(symbol=BB3) data:
insert into table stocks_partition partition(symbol=&amp;#39;BB3&amp;#39;)
select col1,col2,exch_name,yr from stocks where symbol =&amp;#39;BB3&amp;#39;;

=&amp;gt; 也合并成一个insert
from stocks
insert into table stocks_partition partition(symbol=&amp;#39;B7J&amp;#39;)
select col1,col2,exch_name,yr from stocks where symbol=&amp;#39;B7J&amp;#39;
insert into table stocks_partition partition(symbol=&amp;#39;BB3&amp;#39;)
select col1,col2,exch_name,yr from stocks where symbol =&amp;#39;BB3&amp;#39;;

# 注意：如下方式是错误的
insert overwrite table stocks_partition partition(symbol=&amp;#39;APPL&amp;#39;)
select col1,col2,exch_name,yr from stocks where symbol=&amp;#39;ZUU&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using &lt;code&gt;location&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# add partition(symbol=ZUU) data:
insert overwrite directory &amp;#39;output/hive/stocks-zuu&amp;#39;
select col1,col2,exch_name,yr from stocks where symbol=&amp;#39;ZUU&amp;#39;;

alter table stocks_partition add if not exists partition (symbol=&amp;#39;ZUU&amp;#39;) 
location &amp;#39;/output/hive/stocks-zuu&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;添加删除分区&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;alter table stocks_partition add if not exists partition(symbol=&amp;#39;ZUU&amp;#39;);
alter table stocks_partition drop if exists partition(symbol=&amp;#39;ZUU&amp;#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看表分区 &lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;hive&amp;gt; show partitions stocks_partition
OK
symbol=B7K
symbol=BB3
symbol=ZUU
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;数据查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;selecet * from stocks_partitions where symbol=&amp;#39;XYZ&amp;#39; and ymd=&amp;#39;2003-02-01&amp;#39;;

# 若设置了strict方式，则select的where中一定要包含partition column条件查询
set hive.mapred.mode=strict;
select * from stocks_partitions where ymd=&amp;#39;2003-02-01&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;动态分区&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建动态分区表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table if not exists stocks_dynamic_partition(
 col1 string,
 col2 string
)
partitioned by (exch_name string,yr int,sym string)
row format delimited fields terminated by &amp;#39;,&amp;#39; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;启动动态分区&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set hive.exec.dynamic.partition=true;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加载数据（注意：默认动态分区要求至少有一个静态分区）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 如下方式，默认会报错
# SemanticException:dynamic partition strict mode requires at least one static partition column
insert overwrite table stocks_dynamic_partition partition(exch_name,yr,symbol)
select col1,col2,exch_name,year(ymd),symbol from stocks;

=&amp;gt; 解决方案1：
set hive.exec.dynamic.partition.mode=nostrict;

=&amp;gt; 解决方案2：
insert overwrite table stocks_dynamic_partition partition(exch_name=&amp;#39;ABCSE&amp;#39;,yr,symbol)
select col1,col2,exch_name,year(ymd),symbol from stocks;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;查看表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;show partitions stocks_dynamic_partition;
select * from stocks_dynamic_partition where exch_name=&amp;#39;ABCSE&amp;#39; and yr=2013 limit 10;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;注意动态分区的分区数量是有限制的，可根据需要扩大设置（不推荐partition数量过多）：&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set hive.exec.max.dynamic.partitions=1000;
set hive.exec.max.dynamic.partitions.pernode=500;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;数据表的目录结构&lt;pre&gt;&lt;code&gt;stocks_dynamic_partition/exch_name=ABCSE/yr=2013/symbol=GEL/
stocks_dynamic_partition/exch_name=ABCSE/yr=2013/symbol=ZUU/
stocks_dynamic_partition/exch_name=ABCSE/yr=2014/symbol=GEL/
...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;桶表&quot;&gt;&lt;a href=&quot;#桶表&quot; class=&quot;headerlink&quot; title=&quot;桶表&quot;&gt;&lt;/a&gt;桶表&lt;/h3&gt;&lt;p&gt;桶表(Bucket Table)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;细粒度的划分，桶列仍在数据文件中&lt;/li&gt;
&lt;li&gt;主要应用：&lt;ul&gt;
&lt;li&gt;提高数据抽样效率&lt;/li&gt;
&lt;li&gt;提升某些查询操作效率，例如mapside join&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;创建表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt; # 必须设置这个数据，hive才会按照你设置的桶的个数去生成数据
 set hive.enforce.bucketing = true;
 create table t4(id int) clustered by(id) into 4 buckets;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt; insert into table t4 select id from t3;      # 追加
 insert overrite table t4 select id from t3;  # 全部重写
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;抽样查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 查询带桶的表(在一部分桶上检索，效率高)
select * from t4 tablesample(bucket 1 out of 4 on id);

# 不带桶的表(会在整个数据集上检索，效率低)
select * from t3 tablesample(bucket 1 out of 4 on id);
select * from t3 tablesample(bucket 1 out of 4 on rand());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;数据表的目录结构&lt;pre&gt;&lt;code&gt;t4/000000_0
t4/000000_1
t4/000000_2
t4/000000_3
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;分区+分桶：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 创建表
create table if not exists stocks_bucket(
  col1 string,
  col2 string,
  symbol string
)
partitioned by (exch_name string,yr string)
clustered by (symbol) into 3 buckets
row format delimited fields terminated by &amp;#39;,&amp;#39; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 设置动态分区和使用桶
set hive.exec.dynamic.partition=true;
set hive.enforce.bucketing = true; 

# 插入数据
insert into table stocks_bucket partition (exch_name=&amp;#39;ABCE&amp;#39;,yr)
select col1,col2,year(ymd) from stocks
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 抽样查询对比
select * from stocks tablesample(bucket 3 out of 5 on symbol) s;        # 低效
select * from stocks_bucket tablesample(bucket 3 out of 5 on symbol) s; # 高效
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 数据表的目录结构
stocks_bucket/exch_name=ABCE/yr=2013
stocks_bucket/exch_name=ABCE/yr=2013/000000_0
stocks_bucket/exch_name=ABCE/yr=2013/000000_1
stocks_bucket/exch_name=ABCE/yr=2013/000000_2
stocks_bucket/exch_name=ABCE/yr=2014
stocks_bucket/exch_name=ABCE/yr=2014/000000_0
stocks_bucket/exch_name=ABCE/yr=2014/000000_1
stocks_bucket/exch_name=ABCE/yr=2014/000000_2
...
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;抽样&quot;&gt;&lt;a href=&quot;#抽样&quot; class=&quot;headerlink&quot; title=&quot;抽样&quot;&gt;&lt;/a&gt;抽样&lt;/h3&gt;&lt;p&gt;tablesample 抽样&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tablesample(n precent/rows)&lt;ul&gt;
&lt;li&gt;n precent&lt;/li&gt;
&lt;li&gt;n rows&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;tablesample(nM)&lt;ul&gt;
&lt;li&gt;n兆&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;tablesample(bucket x out of y [on columns])&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;x: 从第几个桶开始抽样（从1开始）&lt;/li&gt;
&lt;li&gt;y: 抽样的桶数（若是分桶表，则必须为总bucket数的倍数或者因子）&lt;/li&gt;
&lt;li&gt;columns: 抽样的列&lt;/li&gt;
&lt;li&gt;注意：&lt;ul&gt;
&lt;li&gt;基于已经分桶的表抽样，查询只会扫描相应桶中的数据&lt;/li&gt;
&lt;li&gt;基于未分桶表的抽样，查询时候需要扫描整表数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;示例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 1. t1 为未分桶表
# 1.1 scan全表，根据col1分为10个桶，从第3个桶中取数据；
select * from t1 tablesample(bucket 3 out of 10 on col1);

# 1.2 scan全表，根据随机数分为10个桶，从第3个桶中取数据；
select * from t1 tablesample(bucket 3 out of 10 on rand());

# 2. t2 为分桶表，有10个桶
# 2.1 直接从第3个桶中取数据
select * from t2 tablesample(bucket 3 out of 10 on col1);

# 2.2 共抽取2(10/5)个桶的数据，从第3个和第8(3+5)个桶中抽取数据
select * from t2 tablesample(bucket 3 out of 5 on col1);

# 2.3 共抽取0.5(10/20)个桶的数据，从第3个桶中抽取一半数据
select * from t2 tablesample(bucket 3 out of 20 on col1);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;例如：&lt;ul&gt;
&lt;li&gt;tablesample(50 precent)&lt;/li&gt;
&lt;li&gt;tablesample(50 rows)&lt;/li&gt;
&lt;li&gt;tablesample(50M)&lt;/li&gt;
&lt;li&gt;tablesample(bucket 3 out of 10)&lt;/li&gt;
&lt;li&gt;tablesample(bucket 3 out of 10 on rand())&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;单表查询&quot;&gt;&lt;a href=&quot;#单表查询&quot; class=&quot;headerlink&quot; title=&quot;单表查询&quot;&gt;&lt;/a&gt;单表查询&lt;/h3&gt;&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;SELECT [ALL | DISTINCT] select_expr, select_expr, ...
  FROM table_reference 
  [WHERE condition] 
  [GROUP BY col_list] [Having condition]
  [CLUSTER BY col_list | [DISTRIBUTE BY col_list] [SORT BY col_list] | [ORDER BY col_list] ]
  [LIMIT number]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;where：过滤（mapper端）&lt;/li&gt;
&lt;li&gt;group by：局部分组（reducer端），select中可使用一些聚合函数，例如sum，avg，count等&lt;/li&gt;
&lt;li&gt;cluster by：等价于distribute by + sort by ,只是无法指定排序规则（默认asc）&lt;/li&gt;
&lt;li&gt;distribute by：分区（partitioner），按指定字段划分数据到各个reduce/file&lt;/li&gt;
&lt;li&gt;sort by：局部排序（reducer端）&lt;/li&gt;
&lt;li&gt;order by：全局排序，只有一个reducer（数据量很大时慎用）&lt;/li&gt;
&lt;li&gt;limit：减少数据量，传输到reduce端（单机）的数据记录数就减少到&lt;code&gt;n*(map个数)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加查询结果写入HDFS中&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert overwrite local directory &amp;#39;/home/hive/output/hive/stocks&amp;#39;
row format delimited fields terminated by &amp;#39;,&amp;#39;
select * from stocks distributed by symbol sort by symbol asc,price_close desc;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;全局排序 order by&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 无论设置了多少个reducer，这里只会使用一个reducer（数据量很大时效率低）
set mapreduce.job.reduces=3;
select * from stocks order by price_close desc;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;局部排序 sort by&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 每个reducer中排序
set mapreduce.job.reduces=3;
select * from stocks sort by price_close desc;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;分区 distribute/cluster by&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# distribute by 控制某个特定行应该到哪个reducer
# sort by 为每个reducer产生一个排好序的文件
# distribute by + sort by = cluster by
set mapreduce.job.reduces=3;
select * from stocks distributed by symbol sort by symbol asc;
select * from stocks cluster by symbol;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;聚合操作 group by&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;select symbol,count(*) from stocks group by symbol;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Top N查询&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;SET mapred.reduce.tasks = 1
SELECT * FROM sales SORT BY amount DESC LIMIT 5
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;连接查询&quot;&gt;&lt;a href=&quot;#连接查询&quot; class=&quot;headerlink&quot; title=&quot;连接查询&quot;&gt;&lt;/a&gt;连接查询&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用Join&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;{inner} join&lt;/code&gt;,&lt;code&gt;{left|right|full} [outer] join&lt;/code&gt;,&lt;code&gt;cross join&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;SELECT a.* FROM a JOIN b ON (a.id = b.id AND a.department = b.department);
SELECT a.* FROM a LEFT JOIN b ON (a.id = b.id AND a.department = b.department);
SELECT a.val, b.val, c.val FROM a JOIN b ON (a.key = b.key1) JOIN c ON (c.key = b.key2);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;特例：&lt;code&gt;LEFT SEMI JOIN&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;SELECT a.key, a.value FROM a WHERE a.key in (SELECT b.key FROM B);
SELECT a.key, a.val FROM a LEFT SEMI JOIN b ON (a.key = b.key);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hive中的Join可分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Common Join（Reduce阶段完成join）&lt;ul&gt;
&lt;li&gt;Map阶段：读取源表的数据，以Join on条件中的列为key，以join后所关心的(select或者where中需要用到的)列为value（value中包含Tag，用于标明此value对应哪个表）&lt;/li&gt;
&lt;li&gt;Shuffle阶段：根据key的值进行hash,并将key/value按照hash值推送至不同的reduce中，这样确保两个表中相同的key位于同一个reduce中&lt;/li&gt;
&lt;li&gt;Reduce阶段：根据key的值完成join操作，通过Tag识别不同表中的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Map Join（Map阶段完成join）：通常用于一个很小的表和一个大表进行join的场景&lt;ul&gt;
&lt;li&gt;Local Task（Client端本地执行）：扫描小表，装载到DistributeCache中&lt;/li&gt;
&lt;li&gt;Map Task：读取DistributeCache数据至内存，遍历大表记录，两者进行join，输出结果&lt;/li&gt;
&lt;li&gt;无Reducer Task&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hive中的join操作&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;join操作是在where操作之前执行，即where条件不能起到减少join数据的作用，应尽量在&lt;code&gt;on&lt;/code&gt;中加入约束条件&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;SELECT a.val, b.val FROM a 
JOIN b ON (a.key=b.key)
WHERE a.ds=&amp;#39;2009-07-07&amp;#39; AND b.ds=&amp;#39;2009-07-07&amp;#39;

=&amp;gt; 优化为：
SELECT a.val, b.val FROM a 
JOIN b ON (a.key=b.key AND b.ds=&amp;#39;2009-07-07&amp;#39; AND a.ds=&amp;#39;2009-07-07&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;多表连接，会转换成多个MR Job，但关联条件相同的多表join会自动优化成一个mapreduce job&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 在两个mapred程序中执行join
SELECT a.val, b.val, c.val FROM a 
JOIN b ON (a.key = b.key1) 
JOIN c ON (c.key = b.key2)

# 在一个mapre程序中执行join
SELECT a.val, b.val, c.val FROM a 
JOIN b ON (a.key = b.key1) 
JOIN c ON (c.key = b.key1)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;多表连接，前一个join生成的数据会缓存到内存，通过stream取后一张表数据，应尽量将记录多的表放在后面join，也可使用&lt;code&gt;/*+ STREAMTABLE(table) */&lt;/code&gt;指定将哪个大表stream化&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;SELECT /*+ STREAMTABLE(a) */ a.val, b.val, c.val FROM a 
JOIN b ON (a.key = b.key1) 
JOIN c ON (c.key = b.key1)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Map Side Join&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可在查询中使用&lt;code&gt;/*+ mapjoin(table) */&lt;/code&gt; 指定将哪个小表装载到DistributeCache中&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 注意： 这里无法使用a FULL/RIGHT JOIN b
SELECT /*+ MAPJOIN(b) */ a.key, a.value FROM a join b on a.key = b.key;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Auto Map Side Join：系统自动判断使用mapjoin（由参数hive.auto.convert.join决定，默认为true）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# Local Task 中找出符合mapjoin条件的表，装载到DistributeCache中，后续使用map join；若未找到符合条件的表，则使用common join
set hive.auto.convert.join=true;
# 根据参数hive.mapjoin.smalltable.filesize的设置判断mapjoin的表
SELECT a.key, a.value FROM a join b on a.key = b.key;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;与map join相关的hive参数&lt;pre&gt;&lt;code&gt;# hive.join.emit.interval 
# hive.auto.convert.join 
# hive.mapjoin.smalltable.filesize
# hive.mapjoin.size.key  
# hive.mapjoin.cache.numrows
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sort Map Bucket Map Join：根据join key将各个关联表进行Bucket，提高join效率&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 创建分桶表
create table a_smb(...) clustered by (key) sort by (key) into 10 buckets;
create table b_smb(...) clustered by (key) sort by (key) into 5 buckets;

# 为分桶表加载数据
set hive.enforce.bucketing=true;
insert into table a_smb select * from a;
insert into table b_smb select * from b;

# 打开SMB Map Join
set hive.auto.convert.sortmerge.join=true;
set hive.optimize.bucketmapjoin = true; 
set hive.optimize.bucketmapjoin.sortedmerge = true; 

set hive.input.format=org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat; 

select * from a_smb a join b_smb on a.key=b.key;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;示例&quot;&gt;&lt;a href=&quot;#示例&quot; class=&quot;headerlink&quot; title=&quot;示例&quot;&gt;&lt;/a&gt;示例&lt;/h2&gt;&lt;h3 id=&quot;示例1：导入Apache-log&quot;&gt;&lt;a href=&quot;#示例1：导入Apache-log&quot; class=&quot;headerlink&quot; title=&quot;示例1：导入Apache log&quot;&gt;&lt;/a&gt;示例1：导入Apache log&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;log格式:&lt;pre&gt;&lt;code&gt;127.0.0.1 - frank [10/Oct/2000:13:55:36 -0700] &amp;quot;GET /apache_pb.gif HTTP/1.0&amp;quot; 200 2326
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建表:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;CREATE TABLE apachelog (
host STRING,
identity STRING,
username STRING,
time STRING,
request STRING,
status STRING,
size STRING,
referer STRING,
agent STRING)
ROW FORMAT SERDE &amp;#39;org.apache.hadoop.hive.contrib.serde2.RegexSerDe&amp;#39;
WITH SERDEPROPERTIES (
  &amp;quot;input.regex&amp;quot; = &amp;quot;([^ ]*) ([^ ]*) ([^ ]*) (-|\\[[^\\]]*\\]) ([^ \&amp;quot;]*|\&amp;quot;[^\&amp;quot;]*\&amp;quot;) (-|[0-9]*) (-|[0-9]*)(?: ([^ \&amp;quot;]*|\&amp;quot;.*\&amp;quot;) ([^ \&amp;quot;]*|\&amp;quot;.*\&amp;quot;))?&amp;quot;,
  &amp;quot;output.format.string&amp;quot; = &amp;quot;%1$s %2$s %3$s %4$s %5$s %6$s %7$s %8$s %9$s&amp;quot;
)
STORED AS TEXTFILE;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;添加jar包到hive的执行环境:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;add jar $HIVE_HOME/lib/hive-contrib-1.2.1.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;加载数据:&lt;pre&gt;&lt;code&gt;# inpath will be deleted!
load data inpath &amp;#39;/input/access_2013_05_31.log&amp;#39; into table apachelog;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;查询:&lt;pre&gt;&lt;code&gt;show tables;
describe formatted apachelog;
select * from apachelog limit 10;
select count(*) from apachelog;
select status,count(*) from apachelog group by status;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/apachelog
/user/hive/warehouse/apachelog/access_2013_05_31.log
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;示例2：创建内部表&quot;&gt;&lt;a href=&quot;#示例2：创建内部表&quot; class=&quot;headerlink&quot; title=&quot;示例2：创建内部表&quot;&gt;&lt;/a&gt;示例2：创建内部表&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;创建内部表log:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table log(
  ip string,
  datetime string,
  method string,
  url string,
  status string,
  size string
)
row format delimited fields terminated by &amp;#39;,&amp;#39; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入数据:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert into table log 
select host,time,substring(split(request,&amp;#39; &amp;#39;)[0],2) as method,split(request,&amp;#39; &amp;#39;)[1] as url,status,size from apachelog; 

# 重新过滤掉某些数据（hive中没有delete操作，只能overwrite）
insert overwrite table log 
select * from log where length(method)&amp;lt;7 and method in (&amp;#39;GET&amp;#39;,&amp;#39;POST&amp;#39;,&amp;#39;PUT&amp;#39;,&amp;#39;DELETE&amp;#39;,&amp;#39;OPTION&amp;#39;,&amp;#39;HEAD&amp;#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查询:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;describe formatted log;

set mapred.reduce.tasks=3;
select method from log where length(method)&amp;lt;7 group by method;
select status,method,count(*) from log group by status,method;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log
/user/hive/warehouse/log/000000_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;示例3：内部静态分区表&quot;&gt;&lt;a href=&quot;#示例3：内部静态分区表&quot; class=&quot;headerlink&quot; title=&quot;示例3：内部静态分区表&quot;&gt;&lt;/a&gt;示例3：内部静态分区表&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;创建内部分区表log_partition:（注意分区字段不能包含在建表字段中）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table log_partition(
  ip string,
  datetime string,
  url string,
  size string
)
partitioned by (status string,method string)
row format delimited fields terminated by &amp;#39;,&amp;#39; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入partition数据:（使用insert…select）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert into table log_partition partition(status=&amp;#39;200&amp;#39;,method=&amp;#39;GET&amp;#39;)
select ip,datetime,url,size from log where status=&amp;#39;200&amp;#39; and method=&amp;#39;GET&amp;#39;;

insert into table log_partition partition(status=&amp;#39;200&amp;#39;,method=&amp;#39;POST&amp;#39;)
select ip,datetime,url,size from log where status=&amp;#39;200&amp;#39; and method=&amp;#39;POST&amp;#39;

from log
insert overwrite table log_partition partition(status=&amp;#39;301&amp;#39;,method=&amp;#39;GET&amp;#39;)
select ip,datetime,url,size where status=&amp;#39;301&amp;#39; and method=&amp;#39;GET&amp;#39;
insert overwrite table log_partition partition(status=&amp;#39;301&amp;#39;,method=&amp;#39;POST&amp;#39;)
select ip,datetime,url,size where status=&amp;#39;301&amp;#39; and method=&amp;#39;POST&amp;#39;
insert overwrite table log_partition partition(status=&amp;#39;400&amp;#39;,method=&amp;#39;GET&amp;#39;)
select ip,datetime,url,size where status=&amp;#39;400&amp;#39;and method=&amp;#39;GET&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入partition数据:（使用alter…location）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert overwrite directory &amp;#39;/user/hive/warehouse/log_partition/status=400/method=POST&amp;#39;
row format delimited fields terminated by &amp;#39;,&amp;#39;
select ip,datetime,url,size from log where status=&amp;#39;400&amp;#39; and method=&amp;#39;POST&amp;#39;;

alter table log_partition add if not exists partition (status=&amp;#39;400&amp;#39;,method=&amp;#39;POST&amp;#39;) 
location &amp;#39;/user/hive/warehouse/log_partition/status=400/method=POST&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除partition数据:（注意会删除partition对应的目录和文件）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;alter table log_partition drop if exists partition (status=&amp;#39;301&amp;#39;,method=&amp;#39;GET&amp;#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;describe formatted log_partition;
show partitions log_partition;
select * from log_partition where status=&amp;#39;400&amp;#39; and method=&amp;#39;POST&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log_partition
/user/hive/warehouse/log_partition/status=200
/user/hive/warehouse/log_partition/status=200/method=GET
/user/hive/warehouse/log_partition/status=200/method=GET/000000_0
/user/hive/warehouse/log_partition/status=301
/user/hive/warehouse/log_partition/status=301/method=POST
/user/hive/warehouse/log_partition/status=301/method=POST/000000_0
/user/hive/warehouse/log_partition/status=400
/user/hive/warehouse/log_partition/status=400/method=GET
/user/hive/warehouse/log_partition/status=400/method=GET/000000_0
/user/hive/warehouse/log_partition/status=400/method=POST
/user/hive/warehouse/log_partition/status=400/method=POST/000000_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;示例4：内部动态分区表&quot;&gt;&lt;a href=&quot;#示例4：内部动态分区表&quot; class=&quot;headerlink&quot; title=&quot;示例4：内部动态分区表&quot;&gt;&lt;/a&gt;示例4：内部动态分区表&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;创建内部分区表log_dynamic_partition:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table log_dynamic_partition like log_partition;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;打开动态分区:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set hive.exec.dynamic.partition=true;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据:（注意：1. 字段和顺序；2. 第一个为静态partition）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert into table log_dynamic_partition partition(status=&amp;#39;200&amp;#39;,method)
select ip,datetime,url,size,method from log where status=&amp;#39;200&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据:（注意：1. 字段和顺序；2. 所有都为动态partition）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 设置为nostrict模式
set hive.exec.dynamic.partition.mode=nostrict;
# 插入
insert overwrite table log_dynamic_partition partition(status,method)
select ip,datetime,url,size,status,method from log;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;describe formatted log_dynamic_partition;
show partitions log_dynamic_partition;
select * from log_dynamic_partition where status=&amp;#39;400&amp;#39; and method=&amp;#39;POST&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log_dynamic_partition
/user/hive/warehouse/log_dynamic_partition/status=200
/user/hive/warehouse/log_dynamic_partition/status=200/method=GET
/user/hive/warehouse/log_dynamic_partition/status=200/method=GET/000000_0
/user/hive/warehouse/log_dynamic_partition/status=301
/user/hive/warehouse/log_dynamic_partition/status=301/method=GET
/user/hive/warehouse/log_dynamic_partition/status=301/method=GET/000000_0
/user/hive/warehouse/log_dynamic_partition/status=301/method=POST
/user/hive/warehouse/log_dynamic_partition/status=301/method=POST/000000_0
/user/hive/warehouse/log_dynamic_partition/status=400
/user/hive/warehouse/log_dynamic_partition/status=400/method=GET
/user/hive/warehouse/log_dynamic_partition/status=400/method=GET/000000_0
/user/hive/warehouse/log_dynamic_partition/status=400/method=POST
/user/hive/warehouse/log_dynamic_partition/status=400/method=POST/000000_0
...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;示例5：内部表分桶&quot;&gt;&lt;a href=&quot;#示例5：内部表分桶&quot; class=&quot;headerlink&quot; title=&quot;示例5：内部表分桶&quot;&gt;&lt;/a&gt;示例5：内部表分桶&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;创建分桶表log_bucket: （注意：分桶字段为建表中的字段）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table log_bucket(
  ip string,
  datetime string,
  method string,
  url string,
  status string,
  size string
)
clustered by (status,method) into 5 buckets
row format delimited fields terminated by &amp;#39;,&amp;#39; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;打开分桶:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set hive.enforce.bucketing = true;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert into table log_bucket
select * from log;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;describe formatted log_bucket;
select * from log_bucket tablesample(bucket 1 out of 5 on status);
select * from log tablesample(bucket 1 out of 5 on status);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log_bucket
/user/hive/warehouse/log_bucket/000000_0
/user/hive/warehouse/log_bucket/000001_0
/user/hive/warehouse/log_bucket/000002_0
/user/hive/warehouse/log_bucket/000003_0
/user/hive/warehouse/log_bucket/000004_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;示例6：内部分区分桶表&quot;&gt;&lt;a href=&quot;#示例6：内部分区分桶表&quot; class=&quot;headerlink&quot; title=&quot;示例6：内部分区分桶表&quot;&gt;&lt;/a&gt;示例6：内部分区分桶表&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;创建分区分桶表log_partition_bucket:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table log_partition_bucket(
  ip string,
  datetime string,
  url string,
  size string
)
partitioned by (status string,method string) 
clustered by (ip) into 5 buckets
row format delimited fields terminated by &amp;#39;,&amp;#39; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;打开动态分区和分桶:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nostrict;
set hive.enforce.bucketing = true;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert into table log_partition_bucket partition(status,method)
select ip,datetime,url,size,status,method from log;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;describe formatted log_partition_bucket;
select * from log_partition_bucket tablesample(bucket 1 out of 5 on status) limit 5;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log_partition_bucket
/user/hive/warehouse/log_partition_bucket/status=200
/user/hive/warehouse/log_partition_bucket/status=200/method=GET
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000000_0
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000001_0
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000002_0
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000003_0
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000004_0
/user/hive/warehouse/log_partition_bucket/status=301
/user/hive/warehouse/log_partition_bucket/status=301/method=GET
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000000_0
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000001_0
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000002_0
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000003_0
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000004_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000000_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000001_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000002_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000003_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000004_0
...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;示例6：外部表&quot;&gt;&lt;a href=&quot;#示例6：外部表&quot; class=&quot;headerlink&quot; title=&quot;示例6：外部表&quot;&gt;&lt;/a&gt;示例6：外部表&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;创建外部表log_external:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create external table log_external(
  ip string,
  datetime string,
  method string,
  url string,
  status string,
  size string
)
row format delimited fields terminated by &amp;#39;,&amp;#39; 
location &amp;#39;/input/external&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入数据:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# generate file: /input/external/000000_0
insert into table log_external
select * from log where status=&amp;#39;200&amp;#39;;

# generate file: /input/external/000000_0_copy_1
insert into table log_external
select * from log where status=&amp;#39;400&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入数据:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# generate file: /input/log_301/000000_0
insert overwrite directory &amp;#39;/input/log_301&amp;#39;
row format delimited fields terminated by &amp;#39;,&amp;#39;
select * from log where status=&amp;#39;301&amp;#39;; 

# generate file: /input/external/000000_0_copy_2
# delete file: /input/log_301/000000_0
load data inpath &amp;#39;/input/log_301&amp;#39; into table log_external;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;describe formatted log_external;
select * from log_external limit 5;
select * from log_external where status=&amp;#39;400&amp;#39; limit 5;
select * from log_external where status=&amp;#39;301&amp;#39; limit 5;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/input/external/000000_0
/input/external/000000_0_copy_1
/input/external/000000_0_copy_2
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;删除表:（注意：1. 无法使用truncate清空外部表；2. 数据文件不会被删除）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;drop table log_external;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;重新创建外部表:（不用重新插入数据就有数据可查出了）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create external table log_external(
  ip string,
  datetime string,
  method string,
  url string,
  status string,
  size string
)
row format delimited fields terminated by &amp;#39;,&amp;#39; 
location &amp;#39;/input/external&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看表:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;describe formatted log_external;
select * from log_external limit 5;
select * from log_external where status=&amp;#39;400&amp;#39; limit 5;
select * from log_external where status=&amp;#39;301&amp;#39; limit 5;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;示例7：外部分区分桶表&quot;&gt;&lt;a href=&quot;#示例7：外部分区分桶表&quot; class=&quot;headerlink&quot; title=&quot;示例7：外部分区分桶表&quot;&gt;&lt;/a&gt;示例7：外部分区分桶表&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;创建外部分区分桶表log_external_partition:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create external table log_external_partition(
  ip string,
  datetime string,
  url string,
  size string
)
partitioned by (status string,method string)
clustered by (ip) into 5 buckets 
row format delimited fields terminated by &amp;#39;,&amp;#39;
location &amp;#39;/input/external_partition&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入partition数据: （alter location）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert overwrite directory &amp;#39;/input/log_301_GET&amp;#39; 
row format delimited fields terminated by &amp;#39;,&amp;#39;
select ip,datetime,url,size from log where status=&amp;#39;301&amp;#39; and method=&amp;#39;GET&amp;#39;; 

# generate file: /input/log_301_GET/000000_0~000004_0
alter table log_external_partition add partition (status=&amp;#39;301&amp;#39;,method=&amp;#39;GET&amp;#39;) 
location &amp;#39;/input/log_301_GET&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入partition数据:（动态分区）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nostrict;
set hive.enforce.bucketing = true;

# generate file: 
# /input/log_301_GET/000000_0_copy_1
# /input/external_partition/status=xxx/method=yyy/000000_0~000004_0
insert into table log_external_partition partition(status,method)
select ip,datetime,url,size,status,method from log;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;HDFS目录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/input/log_301_GET
/input/log_301_GET/000000_0
/input/log_301_GET/000000_0_copy_1
/input/log_301_GET/000001_0
/input/log_301_GET/000002_0
/input/log_301_GET/000003_0
/input/log_301_GET/000004_0

/input/external_partition
/input/external_partition/status=200
/input/external_partition/status=200/method=GET
/input/external_partition/status=200/method=GET/000000_0
/input/external_partition/status=200/method=GET/000001_0
/input/external_partition/status=200/method=GET/000002_0
/input/external_partition/status=200/method=GET/000003_0
/input/external_partition/status=200/method=GET/000004_0
/input/external_partition/status=301
/input/external_partition/status=301/method=POST
/input/external_partition/status=301/method=POST/000000_0
/input/external_partition/status=301/method=POST/000001_0
/input/external_partition/status=301/method=POST/000002_0
/input/external_partition/status=301/method=POST/000003_0
/input/external_partition/status=301/method=POST/000004_0
...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;示例8：全排序&quot;&gt;&lt;a href=&quot;#示例8：全排序&quot; class=&quot;headerlink&quot; title=&quot;示例8：全排序&quot;&gt;&lt;/a&gt;示例8：全排序&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用order by （不管设置几个reducer，最终只使用一个reducer）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set mapred.reduce.tasks=5;

# 全排序
insert overwrite directory &amp;#39;/input/log_order&amp;#39; 
select ip,size from log order by ip;

# 局部排序
insert overwrite directory &amp;#39;/input/log_distribute&amp;#39; 
select ip,size from log distribute by ip sort by size;

# 全排序（数据量很大时，效率会高些）
insert overwrite directory &amp;#39;/input/log_order_opt&amp;#39;
select * from (select ip,size from log distribute by ip sort by size) s order by ip;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;使用TotalOrderSort&lt;ul&gt;
&lt;li&gt;生成抽样文件&lt;/li&gt;
&lt;li&gt;使用TotalOrderSort&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;示例9：Join&quot;&gt;&lt;a href=&quot;#示例9：Join&quot; class=&quot;headerlink&quot; title=&quot;示例9：Join&quot;&gt;&lt;/a&gt;示例9：Join&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;创建两张表并插入数据:（create table as select）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table a_log 
row format delimited fields terminated by &amp;#39;,&amp;#39; 
as select * from log where status=&amp;#39;200&amp;#39;;

create table b_log
row format delimited fields terminated by &amp;#39;,&amp;#39; 
as select * from log where status=&amp;#39;301&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查询: （会自动判断使用mapjoin）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;select * from a_log a join b_log b on a.ip=b.ip where a.method=&amp;#39;POST&amp;#39; limit 5;
select * from a_log a join b_log b on a.ip=b.ip and a.method=&amp;#39;POST&amp;#39; limit 5;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/a_log
/user/hive/warehouse/a_log/000000_0
/user/hive/warehouse/b_log
/user/hive/warehouse/b_log/000000_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建两张分区表并插入数据:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;create table a_log_smb like a_log;
create table b_log_smb like b_log;

alter table a_log_smb clustered by (ip) into 3 buckets;
alter table b_log_smb clustered by (ip) into 5 buckets;

insert into a_log_smb select * from a_log;
insert into b_log_smb select * from b_log;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查询:(SMP)&lt;pre&gt;&lt;code&gt;select * from a_log_smb a join b_log_smb b on a.ip=b.ip limit 5;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;HDFS目录：&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/a_log_smb
/user/hive/warehouse/a_log_smb/000000_0
/user/hive/warehouse/a_log_smb/000001_0
/user/hive/warehouse/a_log_smb/000002_0
/user/hive/warehouse/b_log_smb
/user/hive/warehouse/b_log_smb/000000_0
/user/hive/warehouse/b_log_smb/000001_0
/user/hive/warehouse/b_log_smb/000002_0
/user/hive/warehouse/b_log_smb/000003_0
/user/hive/warehouse/b_log_smb/000004_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;优化策略&quot;&gt;&lt;a href=&quot;#优化策略&quot; class=&quot;headerlink&quot; title=&quot;优化策略&quot;&gt;&lt;/a&gt;优化策略&lt;/h2&gt;&lt;p&gt;数据倾斜：由于数据的不均衡原因，导致数据分布不均匀，造成数据大量的集中到一点，造成数据热点&lt;/p&gt;
&lt;p&gt;Hadoop 计算框架特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不怕数据大，怕数据倾斜&lt;/li&gt;
&lt;li&gt;job过多，耗时长（job初始化时间长）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用优化手段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少Job数&lt;/li&gt;
&lt;li&gt;并行Job，例如设置：&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 对于同一个SQL产生的JOB,如果不存在依赖的情况下，将会并行启动JOB
set hive.exec.parallel=true;
set hive.exec.parallel.thread.number=16;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;合理设置Mapper和Reducer数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少mapper数：合并小文件&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 100~128M的按照100M分割，&amp;lt;100M合并
set mapred.max.split.size=100000000;
set mapred.min.split.size.per.node=100000000;
set mapred.min.split.size.per.rack=100000000;
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;增加mapper数：拆分文件（分区，分桶）&lt;/li&gt;
&lt;li&gt;&lt;p&gt;reducer数&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 每个reduce任务处理的数据量，默认为1000^3=1G
hive.exec.reducers.bytes.per.reducer

# 每个任务最大的reduce数，默认为999
hive.exec.reducers.max

# 设置reducer数量
mapred.reduce.tasks
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;合理压缩，减少网络传输和I/O压力，例如设置：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set mapred.output.compress = true;  
set mapred.output.compression.codec = org.apache.hadoop.io.compress.GzipCodec;  
set mapred.output.compression.type = BLOCK;  
set mapred.compress.map.output = true;  
set mapred.map.output.compression.codec = org.apache.hadoop.io.compress.LzoCodec;  

set hive.exec.compress.output = true;  
set hive.exec.compress.intermediate = true;  
set hive.intermediate.compression.codec = org.apache.hadoop.io.compress.LzoCodec;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;以SequenceFile保存，节约序列化和反序列化时间&lt;/li&gt;
&lt;li&gt;少用count distinct，例如：&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;select status,count(distinct ip) from log group by status;
=&amp;gt;
select status,count(ip) from (select status,ip from log group by status,ip) a
group by status;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;join优化&lt;ul&gt;
&lt;li&gt;尽量将condition放入join on中&lt;/li&gt;
&lt;li&gt;尽量大表滞后或使用STREAMTABLE(table)标识大表&lt;/li&gt;
&lt;li&gt;使用SMB Map Join (SMB: Sort Merge Bucket) &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;合理分区，分桶&lt;/li&gt;
&lt;li&gt;小数据量，尽量使用本地MapReduce，例如设置：&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set hive.exec.mode.local.auto=true;  
set hive.exec.mode.local.auto.inputbytes.max=50000000;
set hive.exec.mode.local.auto.tasks.max=10;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;自定义函数&quot;&gt;&lt;a href=&quot;#自定义函数&quot; class=&quot;headerlink&quot; title=&quot;自定义函数&quot;&gt;&lt;/a&gt;自定义函数&lt;/h2&gt;&lt;p&gt;查看函数&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;SHOW FUNCTIONS; 
DESCRIBE FUNCTION &amp;lt;function_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;自定义函数包括三种UDF、UDAF、UDTF，可直接应用于Select语句&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UDF：User-Defined-Function&lt;ul&gt;
&lt;li&gt;用户自定义函数（只能实现一进一出的操作）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;extends UDF&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UDAF：User-Defined Aggregation Funcation&lt;ul&gt;
&lt;li&gt;用户自定义聚合函数（可实现多进一出的操作）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;extends UDAF&lt;/code&gt;+ 内部Evaluator&lt;code&gt;implements UDAFEvaluator&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;init 初始化&lt;/li&gt;
&lt;li&gt;iterate 遍历&lt;/li&gt;
&lt;li&gt;terminatePartial 类似Hadoop的Combiner&lt;/li&gt;
&lt;li&gt;merge 合并&lt;/li&gt;
&lt;li&gt;terminate 返回最终的聚集函数结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UDTF：User-Defined Table-Generating Function&lt;ul&gt;
&lt;li&gt;用户自定义表函数（可实现一进多出的操作）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;extends GenericUDTF&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;UDF示例：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;自定义函数&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;import org.apache.Hadoop.hive.ql.exec.UDF   
public class Helloword extends UDF{   
public String evaluate(){   
    return &amp;quot;hello world!&amp;quot;;   
}   
public String evaluate(String str){   
    return &amp;quot;hello world: &amp;quot; + str;   
}   
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;上传jar包到目标机器&lt;/li&gt;
&lt;li&gt;添加到Hive中&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;# 进入hive客户端，添加jar包
hive&amp;gt; add jar udf_helloword.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;创建临时函数&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;hive&amp;gt; create temporary function helloword as &amp;#39;com.cj.hive.udf.Helloword&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;测试&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;select helloword(name) from users;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除临时函数&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;hive&amp;gt; drop temporaty function helloword;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注：helloworld为临时的函数，所以每次进入hive都需要add jar以及create temporary操作&lt;/p&gt;
&lt;h2 id=&quot;Java-API&quot;&gt;&lt;a href=&quot;#Java-API&quot; class=&quot;headerlink&quot; title=&quot;Java API&quot;&gt;&lt;/a&gt;Java API&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;启动Hive远程服务&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; hive --service hiveserver2 &amp;gt;/dev/null  2&amp;gt;/dev/null &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Java客户端加入依赖包&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.apache.hive&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;hive-jdbc&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${hive.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;JAVA客户端连接操作代码&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;@Test
public void testConnection() throws ClassNotFoundException, SQLException {
  Class.forName(&amp;quot;org.apache.hive.jdbc.HiveDriver&amp;quot;);
  Connection conn = DriverManager.getConnection(&amp;quot;jdbc:hive2://cj.storm:10000/default&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;);

  Statement stmt = conn.createStatement();
  String querySQL = &amp;quot;select * from log_partition where status=&amp;#39;200&amp;#39; and method=&amp;#39;GET&amp;#39; limit 10&amp;quot;;
  ResultSet res = stmt.executeQuery(querySQL);
  while (res.next()) {
    System.out.println(res.getString(1) + &amp;quot;\t&amp;quot; + res.getString(2));
  }
  res.close();
  conn.close();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      Hive introduction
    
    </summary>
    
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>HBase</title>
    <link href="http://sixdegree.github.io/2016/05/05/HBase.html"/>
    <id>http://sixdegree.github.io/2016/05/05/HBase.html</id>
    <published>2016-05-04T16:00:00.000Z</published>
    <updated>2016-05-24T01:45:30.000Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;HBase概述，模型；&lt;/li&gt;
&lt;li&gt;HBase安装，操作；&lt;/li&gt;
&lt;/ol&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;HBase：Hadoop Database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一种在Hadoop之上的NoSQL 的Key/vale数据库,适合实时查询&lt;/li&gt;
&lt;li&gt;利用Hadoop HDFS作为其文件存储系统&lt;/li&gt;
&lt;li&gt;利用Hadoop MapReduce来处理其海量数据&lt;/li&gt;
&lt;li&gt;利用Zookeeper作为协调工具&lt;/li&gt;
&lt;li&gt;是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统&lt;/li&gt;
&lt;li&gt;适合海量数据(如20PB)的秒级简单查询的数据库&lt;ul&gt;
&lt;li&gt;适合key-value查询&lt;/li&gt;
&lt;li&gt;适合按时间排序top n的场景&lt;/li&gt;
&lt;li&gt;适合大量读写&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;数据模型&quot;&gt;&lt;a href=&quot;#数据模型&quot; class=&quot;headerlink&quot; title=&quot;数据模型&quot;&gt;&lt;/a&gt;数据模型&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;数据模型&lt;br&gt;  &lt;img src=&quot;2016-05-05-HBase/datamodal.png&quot; alt=&quot;Data Modal&quot;&gt;&lt;br&gt;  &lt;img src=&quot;2016-05-05-HBase/keyvalue.png&quot; alt=&quot;Key Value&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Table:存储管理数据&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RowKey&lt;/code&gt;:行键（类似于关系型数据库中的主键）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ColumnFamily&lt;/code&gt;：列族（定义表时指定），可包含任意多个列（插入记录时动态增加）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Cell&lt;/code&gt;：单元格，由&lt;code&gt;{rowKey,columnFamily:columnName}&lt;/code&gt;确定的存储单元&lt;ul&gt;
&lt;li&gt;可存储一份数据的多个版本，由&lt;code&gt;Timestamp（时间戳）&lt;/code&gt;属性区分，即数据具有版本特性&lt;/li&gt;
&lt;li&gt;由&lt;code&gt;{rowKey, columnFamily:columnName, version}&lt;/code&gt;可确定某一版的Data&lt;/li&gt;
&lt;li&gt;若不指定时间戳或者版本，默认取最新的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;逻辑数据模型&lt;br&gt;  &lt;img src=&quot;2016-05-05-HBase/logicalmodal.png&quot; alt=&quot;Logical Modal&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;物理数据模型&lt;br&gt;  &lt;img src=&quot;2016-05-05-HBase/physicalmodal.png&quot; alt=&quot;Physical Modal&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;说明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;存储划分：&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Table&lt;/code&gt;按&lt;code&gt;RowKey&lt;/code&gt;范围&lt;code&gt;[startKey,endKey)&lt;/code&gt;划分成N个&lt;code&gt;Region&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;各个&lt;code&gt;Region&lt;/code&gt;分散存储在不同的&lt;code&gt;RegionServer&lt;/code&gt;（单独的物理机器）中&lt;/li&gt;
&lt;li&gt;这样对表的操作转化为对多台&lt;code&gt;RegionServer&lt;/code&gt;的并行操作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Region&lt;/code&gt;按&lt;code&gt;ColumnFamily&lt;/code&gt;一对一划分成&lt;code&gt;Store&lt;/code&gt;,每个store包括:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MemStore&lt;/code&gt; 内存存储 （先，达到阀值后，写入StoreFile）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;StoreFile&lt;/code&gt; 文件存储（对应一个&lt;code&gt;HFile&lt;/code&gt;，存放在Hadoop HDFS）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;存储结构：&lt;ul&gt;
&lt;li&gt;&lt;code&gt;RowKey&lt;/code&gt;,&lt;code&gt;ColumnName&lt;/code&gt;按字典顺序物理存储&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Timestamp&lt;/code&gt;是一个64位整数&lt;/li&gt;
&lt;li&gt;所有数据以&lt;code&gt;byte[]&lt;/code&gt;存储&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;2016-05-05-HBase/region.png&quot; alt=&quot;Region&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;架构体系&quot;&gt;&lt;a href=&quot;#架构体系&quot; class=&quot;headerlink&quot; title=&quot;架构体系&quot;&gt;&lt;/a&gt;架构体系&lt;/h3&gt;&lt;p&gt;主从式结构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Master（主）：可以启动多个，由Zookeeper的Master Election机制保证总有一个Master运行&lt;ul&gt;
&lt;li&gt;管理RegionServer&lt;/li&gt;
&lt;li&gt;分配Region&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RegionServer（从）：一个物理节点一个&lt;ul&gt;
&lt;li&gt;存储Region&lt;/li&gt;
&lt;li&gt;响应用户I/O请求，向HDFS文件系统中读写数据&lt;/li&gt;
&lt;li&gt;合并切分Region（StoreFile）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Zookeeper（协调）&lt;ul&gt;
&lt;li&gt;保证集群中只有一个Running Master&lt;ul&gt;
&lt;li&gt;监控RegionServer的状态，实时通知给Master&lt;/li&gt;
&lt;li&gt;存储HBase的Schema（包括有哪些Table，每个Table有哪些ColumnFamily）&lt;/li&gt;
&lt;li&gt;存储Region寻址入口（即&lt;code&gt;-ROOT-&lt;/code&gt;表的location）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;2016-05-05-HBase/frame1.png&quot; alt=&quot;Frame&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;2016-05-05-HBase/frame2.png&quot; alt=&quot;Frame&quot;&gt;&lt;/p&gt;
&lt;p&gt;HRegion 进程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HLog ：预写式日志（所有更新操作先记录进日志，再操作），用于做灾难恢复Failover&lt;/li&gt;
&lt;li&gt;Store ：每个Store存放一个列族&lt;ul&gt;
&lt;li&gt;MemStore 内存存储 （先，达到阀值后，写入StoreFile）&lt;/li&gt;
&lt;li&gt;StoreFile 文件存储（对应一个HFile，存放在Hadoop HDFS）&lt;ul&gt;
&lt;li&gt;每次写入就形成一份单独的&lt;ul&gt;
&lt;li&gt;数量增长到一定阀值：合并StoreFile（合并时会进行版本合并和删除工作）– HDFS适合存储大文件&lt;/li&gt;
&lt;li&gt;大小超过一定阀值：分割当前Region（再由HMaster分配到其他RegionServer）– 实现负载均衡&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HBase中有两张特殊的Table（&lt;code&gt;-ROOT-&lt;/code&gt;和&lt;code&gt;.META.&lt;/code&gt;）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.META.&lt;/code&gt;：记录了&lt;code&gt;用户表&lt;/code&gt;的Region信息，&lt;code&gt;.META.&lt;/code&gt;表本身可划分成N个regoin&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ROOT-&lt;/code&gt;：记录了&lt;code&gt;.META.&lt;/code&gt;表划分成的N个Region的信息，&lt;code&gt;-ROOT-&lt;/code&gt;本身只有一个，不划分&lt;br&gt;&lt;img src=&quot;2016-05-05-HBase/meta.png&quot; alt=&quot;META&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Client访问HBase上数据数据（并不需要master参与）:&lt;code&gt;zookeeper&lt;/code&gt;=&amp;gt;&lt;code&gt;-ROOT-&lt;/code&gt;表=&amp;gt;&lt;code&gt;.META.&lt;/code&gt;表=&amp;gt;Region位置=&amp;gt;访问&lt;/li&gt;
&lt;li&gt;Client包含访问HBase的接口,可通过维护着一些cache来加快对HBase的访问（比如缓存region的位置信息）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h2&gt;&lt;h3 id=&quot;伪分布式&quot;&gt;&lt;a href=&quot;#伪分布式&quot; class=&quot;headerlink&quot; title=&quot;伪分布式&quot;&gt;&lt;/a&gt;伪分布式&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;下载解压安装包&lt;/li&gt;
&lt;li&gt;设置环境变量（&lt;code&gt;/etc/profile&lt;/code&gt;文件）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;HBASE_HOME&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PATH&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;配置（&lt;code&gt;$HBASE_HOME/conf&lt;/code&gt;目录下）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hbase-env.sh&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;  export JAVA_HOME=/usr/local/jdk
  # 使用HBase内置的Zookeeper
  export HBASE_MANAGES_ZK=true
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hbase-site.xml&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.rootdir&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hdfs://hadoop0:9000/hbase&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.cluster.distributed&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;true&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hadoop0&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;dfs.replication&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;1&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;启动&lt;ul&gt;
&lt;li&gt;运行Hadoop&lt;/li&gt;
&lt;li&gt;运行HBase: &lt;code&gt;start-hbase.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;验证&lt;ul&gt;
&lt;li&gt;&lt;code&gt;jps&lt;/code&gt; 三个进程：HMaster、HRegionServer、HQuorumPeer&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http://hadoop0:60010&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;集群式&quot;&gt;&lt;a href=&quot;#集群式&quot; class=&quot;headerlink&quot; title=&quot;集群式&quot;&gt;&lt;/a&gt;集群式&lt;/h3&gt;&lt;p&gt;（在原来的hadoop0上的hbase伪分布基础上进行搭建）&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Master：hadoop0&lt;/li&gt;
&lt;li&gt;RegionServer：hadoop1,hadoop2&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;配置（&lt;code&gt;$HBASE_HOME/conf&lt;/code&gt;目录下）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hbase-env.sh&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;  export JAVA_HOME=/usr/local/jdk
  # 不使用HBase内置的Zookeeper
  export HBASE_MANAGES_ZK=false
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hbase-site.xml&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  ...
  &amp;lt;!-- 配置Zookeeper监控管理的节点（hostname）--&amp;gt;
  &amp;lt;property&amp;gt;
    &amp;lt;name&amp;gt;hbase.zookeeper.quorum&amp;lt;/name&amp;gt;
    &amp;lt;value&amp;gt;hadoop0,hadoop1,hadoop2&amp;lt;/value&amp;gt;
  &amp;lt;/property&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;regionservers&lt;/code&gt; （配置RegionServer的hostname）&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;  hadoop1
  hadoop2
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;复制配置好的hbase到其他节点&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt; scp -rp ./hbase `hadoop`@hadoop1:~
 scp -rp ./hbase `hadoop`@hadoop2:~
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;启动&lt;ul&gt;
&lt;li&gt;运行Hadoop&lt;/li&gt;
&lt;li&gt;运行zookeeper&lt;/li&gt;
&lt;li&gt;运行HBase: &lt;code&gt;start-hbase.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;操作&quot;&gt;&lt;a href=&quot;#操作&quot; class=&quot;headerlink&quot; title=&quot;操作&quot;&gt;&lt;/a&gt;操作&lt;/h2&gt;&lt;p&gt;注意：HBase不能支持where条件、Order by 查询，只支持按照Row key来查询，但是可以通过HBase提供的API进行条件过滤&lt;/p&gt;
&lt;h3 id=&quot;Shell-Cmd&quot;&gt;&lt;a href=&quot;#Shell-Cmd&quot; class=&quot;headerlink&quot; title=&quot;Shell Cmd&quot;&gt;&lt;/a&gt;Shell Cmd&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;启用HBase Shell命令行&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; hbase shell
  ...
  &amp;gt; quite
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;常用命令&lt;br&gt;  |名称|命令表达式|&lt;br&gt;  |——|————-|&lt;br&gt;  |创建表| create ‘表名称’, ‘列族名称1’,’列族名称2’,’列族名称N’|&lt;br&gt;  |添加记录| put ‘表名称’, ‘行键’, ‘列族名称:列名称’, ‘值’|&lt;br&gt;  |查看记录| get ‘表名称’, ‘行键’|&lt;br&gt;  |查看表中的记录总数| count ‘表名称’|&lt;br&gt;  |删除记录 | delete ‘表名’ ,’行键’ , ‘列名称’|&lt;br&gt;  |删除一张表| 先要屏蔽该表，才能对该表进行删除，第一步 disable ‘表名称’ 第二步 drop ‘表名称’|&lt;br&gt;  |查看所有记录| scan “表名称” |&lt;br&gt;  |查看某个表某个列中所有数据| scan “表名称” , {COLUMNS=&amp;gt;’列族名称:列名称’} |&lt;br&gt;  |更新记录| 就是重写一遍进行覆盖 |&lt;/li&gt;
&lt;li&gt;注意：&lt;ul&gt;
&lt;li&gt;HBase其实没有delete操作，只有insert，以Timestamp区分新旧记录&lt;/li&gt;
&lt;li&gt;为充分利用分布式，可使用reverse key，hash，复合行键等技巧改造行键&lt;/li&gt;
&lt;li&gt;行键打乱后，可更均匀随机的分配到各节点，而不是集中在一个节点&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;操作示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;表操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建表&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; create &amp;#39;users&amp;#39;,&amp;#39;user_id&amp;#39;,&amp;#39;address&amp;#39;,&amp;#39;info&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看表&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; list
  &amp;gt; describe &amp;#39;users&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;验证表&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; exists &amp;#39;users&amp;#39;
  &amp;gt; is_enabled &amp;#39;users&amp;#39;
  &amp;gt; is_disabled &amp;#39;users&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除表&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; disable &amp;#39;users&amp;#39;
  &amp;gt; delete &amp;#39;users&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;记录操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;插入&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;info:age&amp;#39;,&amp;#39;24&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;info:birthday&amp;#39;,&amp;#39;1987-06-17&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;info:company&amp;#39;,&amp;#39;alibaba&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;address:contry&amp;#39;,&amp;#39;china&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;address:province&amp;#39;,&amp;#39;zhejiang&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;address:city&amp;#39;,&amp;#39;hangzhou&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;zhangyifei&amp;#39;,&amp;#39;info:birthday&amp;#39;,&amp;#39;1987-4-17&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;zhangyifei&amp;#39;,&amp;#39;info:favorite&amp;#39;,&amp;#39;movie&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;zhangyifei&amp;#39;,&amp;#39;info:company&amp;#39;,&amp;#39;alibaba&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;zhangyifei&amp;#39;,&amp;#39;address:contry&amp;#39;,&amp;#39;china&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;zhangyifei&amp;#39;,&amp;#39;address:province&amp;#39;,&amp;#39;guangdong&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;zhangyifei&amp;#39;,&amp;#39;address:city&amp;#39;,&amp;#39;jieyang&amp;#39;;
  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;zhangyifei&amp;#39;,&amp;#39;address:town&amp;#39;,&amp;#39;xianqiao&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; get &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;
  &amp;gt; get &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;info&amp;#39;
  &amp;gt; get &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;info:age&amp;#39;

  # 获取单元格数据的版本数据
  &amp;gt; get &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,{COLUMN=&amp;gt;&amp;#39;info:age&amp;#39;,VERSIONS=&amp;gt;1}
  &amp;gt; get &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,{COLUMN=&amp;gt;&amp;#39;info:age&amp;#39;,VERSIONS=&amp;gt;2}
  &amp;gt; get &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,{COLUMN=&amp;gt;&amp;#39;info:age&amp;#39;,VERSIONS=&amp;gt;3}

  # 获取单元格数据的某个版本数据
  &amp;gt; get &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,{COLUMN=&amp;gt;&amp;#39;info:age&amp;#39;,TIMESTAMP=&amp;gt;1364874937056}

  # 全表扫描
  &amp;gt; scan &amp;#39;users&amp;#39;

  # 统计表的行数
  &amp;gt; count &amp;#39;users&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;更新&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; put &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;info:age&amp;#39; ,&amp;#39;29&amp;#39;
  &amp;gt; get &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;info:age&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;删除&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  # 删除某列值
  &amp;gt; delete &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;,&amp;#39;info:age&amp;#39;

  # 删除整行
  &amp;gt;deleteall &amp;#39;users&amp;#39;,&amp;#39;xiaoming&amp;#39;

  # 清空
  &amp;gt; truncate &amp;#39;users&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;Java-API&quot;&gt;&lt;a href=&quot;#Java-API&quot; class=&quot;headerlink&quot; title=&quot;Java API&quot;&gt;&lt;/a&gt;Java API&lt;/h3&gt;&lt;p&gt;依赖包：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.apache.hbase&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;hbase-client&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${hbase.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用示例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;Configuration conf = HBaseConfiguration.create();
conf.set(&amp;quot;hbase.rootdir&amp;quot;, &amp;quot;hdfs://hadoop0:9000/hbase&amp;quot;);
//使用eclipse时必须添加这个，否则无法定位
conf.set(&amp;quot;hbase.zookeeper.quorum&amp;quot;, &amp;quot;hadoop0&amp;quot;);
HBaseAdmin admin = new HBaseAdmin(conf);


String tableName=&amp;quot;users&amp;quot;;
String columnFamily=&amp;quot;info&amp;quot;;

// 1. 创建一张表
if (admin.tableExists(tableName)) {
    System.out.println(&amp;quot;table exists!&amp;quot;);
}else{
    HTableDescriptor tableDesc = new HTableDescriptor(tableName);
    tableDesc.addFamily(new HColumnDescriptor(columnFamily));
    admin.createTable(tableDesc);
    System.out.println(&amp;quot;create table success!&amp;quot;);
}

// 2. 添加一条记录
String rowKey=&amp;quot;xiaoming&amp;quot;;
String column=&amp;quot;age&amp;quot;;
String data=&amp;quot;24&amp;quot;;

HTable table = new HTable(conf, tableName);
Put p1 = new Put(Bytes.toBytes(rowKey));
p1.add(Bytes.toBytes(columnFamily), Bytes.toBytes(column),     Bytes.toBytes(data));
table.put(p1);
System.out.println(&amp;quot;put&amp;#39;&amp;quot;+rowKey+&amp;quot;&amp;#39;,&amp;quot;+columnFamily+&amp;quot;:&amp;quot;+column+&amp;quot;&amp;#39;,&amp;#39;&amp;quot;+data+&amp;quot;&amp;#39;&amp;quot;);

// 3. 读取一条记录
Get get = new Get(Bytes.toBytes(rowKey));
Result result = table.get(get);
System.out.println(&amp;quot;Get: &amp;quot;+result);

// 4. 显示所有数据
Scan scan = new Scan();
ResultScanner scanner = table.getScanner(scan);
/*scan.setStartRow(Bytes.toBytes(&amp;quot;134/&amp;quot;));
scan.setStopRow( Bytes.toBytes(&amp;quot;134:&amp;quot;));
scan.setMaxVersions(1);*/
for (Result res : scanner) {
    System.out.println(&amp;quot;Scan: &amp;quot;+res    );
}
table.close();

// 5. 删除表
if(admin.tableExists(tableName)){
    try {
      admin.disableTable(tableName);
      admin.deleteTable(tableName);
    } catch (IOException e) {
      e.printStackTrace();
      System.out.println(&amp;quot;Delete &amp;quot;+tableName+&amp;quot; 失败&amp;quot;);
    }
}
admin.close();
System.out.println(&amp;quot;Delete &amp;quot;+tableName+&amp;quot; 成功&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;结合MapReduce操作&quot;&gt;&lt;a href=&quot;#结合MapReduce操作&quot; class=&quot;headerlink&quot; title=&quot;结合MapReduce操作&quot;&gt;&lt;/a&gt;结合MapReduce操作&lt;/h3&gt;&lt;p&gt;Hbase对Mapreduce API进行了扩展，方便Mapreduce任务读写HTable数据&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;HBase MapReduce&lt;/th&gt;
&lt;th&gt;Hadoop MapReduce&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;org.apache.hadoop.hbase.mapreduce.TableMapper&lt;/td&gt;
&lt;td&gt;org.apache.hadoop.mapreduce.Mapper&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;org.apache.hadoop.hbase.mapreduce.TableReducer&lt;/td&gt;
&lt;td&gt;org.apache.hadoop.mapreduce.Reducer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;org.apache.hadoop.hbase.mapreduce.TableInputFormat&lt;/td&gt;
&lt;td&gt;org.apache.hadoop.mapreduce.InputFormat&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;org.apache.hadoop.hbase.mapreduce.TableOutputFormat&lt;/td&gt;
&lt;td&gt;org.apache.hadoop.mapreduce.OutputFormat&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;依赖包：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&amp;lt;dependency&amp;gt;
    &amp;lt;groupId&amp;gt;org.apache.hbase&amp;lt;/groupId&amp;gt;
    &amp;lt;artifactId&amp;gt;hbase-server&amp;lt;/artifactId&amp;gt;
    &amp;lt;version&amp;gt;${hbase.version}&amp;lt;/version&amp;gt;
&amp;lt;/dependency&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用示例1：统计&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;public static void main(String[] args) throws Exception {   
    Configuration config = HBaseConfiguration.create(); 
    configuration.set(&amp;quot;hbase.zookeeper.quorum&amp;quot;, &amp;quot;hadoop0&amp;quot;);

    Job job = new Job(config,&amp;quot;HBaseTotal&amp;quot;);  
    job.setJarByClass(TotalOnHBase.class); 

    Scan scan = new Scan();  
    scan.setCaching(500);
    scan.setCacheBlocks(false);
    TableMapReduceUtil.initTableMapperJob(&amp;quot;access-log&amp;quot;,scan,MyTableMapper.class,Text.class,IntWritable.class,job);  
    TableMapReduceUtil.initTableReducerJob(&amp;quot;total-access&amp;quot;,MyTableReducer.class,job);  
    job.waitForCompletion(true);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;public class MyTableMapper extends TableMapper&amp;lt;Text, IntWritable&amp;gt;  {  
    private final IntWritable ONE = new IntWritable(1);  
    private Text text = new Text();  
    public void map(ImmutableBytesWritable row, Result value, Context context) throws IOException, InterruptedException {  
        String ip = Bytes.toString(row.get()).split(&amp;quot;-&amp;quot;)[0];  
        String url = new String(value.getValue(Bytes.toBytes(&amp;quot;info&amp;quot;), Bytes.toBytes(&amp;quot;url&amp;quot;)));  
        text.set(ip+&amp;quot;&amp;amp;&amp;quot;+url);  
        context.write(text, ONE);  
    }  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;public static class MyTableReducer extends TableReducer&amp;lt;Text, IntWritable, ImmutableBytesWritable&amp;gt;  {  
    public void reduce(Text key, Iterable&amp;lt;IntWritable&amp;gt; values, Context context) throws IOException, InterruptedException {  
        int sum = 0;  
        for (IntWritable val : values) {  
            sum += val.get();  
        }  

        Put put = new Put(key.getBytes());  
        put.add(Bytes.toBytes(&amp;quot;info&amp;quot;), Bytes.toBytes(&amp;quot;count&amp;quot;), Bytes.toBytes(String.valueOf(sum)));  

        context.write(null, put);  
    }  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用示例2：批量导入（&lt;code&gt;TableOutputFormat&lt;/code&gt;,&lt;code&gt;TableReducer&lt;/code&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;public static void main(String[] args) throws Exception {
    final Configuration configuration = new Configuration();
    //设置zookeeper
    configuration.set(&amp;quot;hbase.zookeeper.quorum&amp;quot;, &amp;quot;hadoop0&amp;quot;);
    //设置hbase表名称
    configuration.set(TableOutputFormat.OUTPUT_TABLE, &amp;quot;wlan_log&amp;quot;);
    //将该值改大，防止hbase超时退出
    configuration.set(&amp;quot;dfs.socket.timeout&amp;quot;, &amp;quot;180000&amp;quot;);

    final Job job = new Job(configuration, &amp;quot;HBaseBatchImport&amp;quot;);
    FileInputFormat.setInputPaths(job, &amp;quot;hdfs://hadoop0:9000/input&amp;quot;);
    job.setInputFormatClass(TextInputFormat.class);
    job.setMapperClass(BatchImportMapper.class);
    job.setMapOutputKeyClass(LongWritable.class);
    job.setMapOutputValueClass(Text.class);
    //BatchImportReducer extends TableReducer
    job.setReducerClass(BatchImportReducer.class);
    //不再设置输出路径，而是设置输出格式类型
    job.setOutputFormatClass(TableOutputFormat.class);
    job.waitForCompletion(true);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;// BatchImportMapper 数据清理，省略...
// BatchImportReducer 将数据写入HBase
public class BatchImportReducer extends TableReducer&amp;lt;LongWritable, Text, NullWritable&amp;gt;{
    protected void reduce(LongWritable key, Iterable&amp;lt;Text&amp;gt; values,Context context) throws IOException ,InterruptedException {
        for (Text text : values) {
            final String[] splited = text.toString().split(&amp;quot;\t&amp;quot;);
            final Put put = new Put(Bytes.toBytes(splited[0]));
            put.add(Bytes.toBytes(&amp;quot;info&amp;quot;), Bytes.toBytes(&amp;quot;age&amp;quot;), Bytes.toBytes(splited[1]));
            //省略其他字段，调用put.add(....)即可
            context.write(NullWritable.get(), put);
        }
    };
}
&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      HBase introduction
    
    </summary>
    
    
      <category term="NoSql" scheme="http://sixdegree.github.io/tags/NoSql/"/>
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
</feed>
