<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SixDegree</title>
  
  <subtitle>host by chenjin</subtitle>
  <link href="//atom.xml" rel="self"/>
  
  <link href="http://sixdegree.github.io/"/>
  <updated>2019-07-08T12:47:36.000Z</updated>
  <id>http://sixdegree.github.io/</id>
  
  <author>
    <name>Chen Jin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Python Selenium</title>
    <link href="http://sixdegree.github.io/2019/03/25/Python-Selenium.html"/>
    <id>http://sixdegree.github.io/2019/03/25/Python-Selenium.html</id>
    <published>2019-03-24T16:00:00.000Z</published>
    <updated>2019-07-08T12:47:36.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li>Install: selenium,browser drive</li><li>browser</li><li>查找元素：find_elements/find_elements_by_xxx,find_element/find_element_by_xxx</li><li>交互操作：action(eg: click,key_down,…),action_chains (ActionChains,drag_and_drop)</li><li>执行javascript: execute_script(…)</li><li>切换：switch_to.xxx，back/forward()</li><li>异常处理：selenium.common.exceptions（eg: TimeoutException, NoSuchElementException）</li><li>Cookie: add/get/delete_cookie(…),get_cookies(),delete_all_cookies()</li><li>等待元素: 强制等待 time.sleep(seconds), 隐式等待 browser.implicitly_wait(seconds),显示等待 WebDriverWait,expected_conditions</li></ol><a id="more"></a><h2 id="header-1">Install</h2><ul><li><p>安装<code>selenium</code></p><pre><code class="lang-bash">  $ pip install selenium  # check:  $ python3  &gt;&gt;&gt; from selenium import webdriver  &gt;&gt;&gt; help(webdriver)</code></pre></li><li><p>安装browser驱动程序,eg: chrome的<code>chromedrive</code></p><ul><li><a href="http://chromedriver.chromium.org/" target="_blank" rel="noopener">download</a></li><li>copy to path,eg: mac <code>/usr/local/bin</code></li><li>check: <code>chromedriver -v</code></li></ul></li></ul><h2 id="header-2">browser</h2><pre><code class="lang-python">def get_browser(slience=False):    if not slience:        return webdriver.Chrome()                           # 会弹出一个 chrome 浏览器    else:        chrome_options=Options()        chrome_options.add_argument(&#39;--headless&#39;)         chrome_options.add_argument(&#39;--disable-gpu&#39;)        browser=webdriver.Chrome(options=chrome_options)    # 创建的chrome浏览器是不可见的        return browserdef test_browser(slience=False):    browser=get_browser(slience)    browser.get(&#39;http://www.baidu.com&#39;)    print(browser.page_source)    browser.close()if __name__==&#39;__main__&#39;:    test_browser()    # test_browser(slience=True)</code></pre><h2 id="header-3">查找元素</h2><ul><li><code>find_element_by_xxx(...)</code>,<code>find_element(By.xxx,xxx)</code>: 返回匹配的第一个元素（<code>WebElement</code>类型对象），找不到则抛出异常</li><li><code>find_elements_by_xxx(...)</code>,<code>find_elements(By.xxx,xxx)</code>: 返回所有匹配的元素列表，找不到则返回空列表</li><li>eg: <code>find_elements(By.CSS_SELECTOR,&#39;.service-bd li&#39;)</code> = <code>find_elements_by_css_selector(&quot;.service-bd li&quot;)</code></li><li><code>WebElement</code>类型对象：<ul><li><code>.text</code> 获取文本值（它与它的所有子孙节点的文字的组合，无则返回空字符串）</li><li><code>.id</code></li><li><code>.tag_name</code></li><li><code>.location</code></li><li><code>.size</code></li><li><code>.get_attribute(attrName)</code> 获取属性值（无则返回None）</li><li><code>find_element_by_xxx / find_elements_by_xxx(...)</code></li><li><code>find_element / find_elements(By.xxx,xxx)</code></li></ul></li><li>使用:<ul><li>XPath<ul><li><code>find_element_by_xpath / find_elements_by_xpath(xpath)</code></li><li>eg: <code>find_element_by_xpath(&quot;//div[@class=&#39;detail&#39;]/a&quot;)</code></li></ul></li><li>CSS Selector<ul><li><code>find_element_by_css_selector / find_elements_by_css_selector(css)</code></li><li>eg: <code>find_element_by_css_selector(&quot;div[class=&#39;detail&#39;] &gt; div span&quot;)</code></li></ul></li><li>Tag<ul><li><code>find_element_by_id(id)</code>: 一个或异常</li><li><code>find_element_by_tag_name / find_elements_by_tag_name(tagName)</code></li><li><code>find_element_by_class_name / find_elements_by_class_name(classValue)</code>: 使用元素的class值查找元素</li><li><code>find_element_by_name / find_elements_by_name(name)</code>: 通过<code>name</code>属性查找</li><li><code>find_element_by_link_text / find_elements_by_link_text(linkText)</code>: 文本值为linkText的超级链接元素<code>&lt;a&gt;</code></li><li><code>find_element_by_partial_link_text / find_elements_by_partial_link_text(linkText)</code>: 文本值包含linkText的超级链接元素<code>&lt;a&gt;</code></li><li>eg: <code>find_element_by_class_name(&quot;p1&quot;)</code> = <code>find_elements_by_xpath(&quot;//*[@class=&#39;p1&#39;]&quot;)</code> = <code>find_elements_by_css_selector(&quot;*[class=&#39;p1&#39;]&quot;)</code></li></ul></li></ul></li></ul><pre><code class="lang-python">def test_element():    browser=get_browser(slience=True)    browser.get(&#39;http://www.baidu.com&#39;)    print(&#39;--- input ---&#39;)    input= browser.find_element_by_id(&#39;kw&#39;)    print_element(input)    print(&#39;--- searchBtn ---&#39;)    #searchBtn = browser.find_element_by_id(&#39;su&#39;)    searchBtn=browser.find_element(By.ID,&#39;su&#39;)    print_element(searchBtn)def print_element(ele):    print(&quot;id:&quot;,ele.id)    print(&quot;tag_name:&quot;,ele.tag_name)    print(&quot;location:&quot;,ele.location)    print(&quot;size:&quot;,ele.size)    print(&quot;text:&quot;,ele.text)    print(&quot;class:&quot;,ele.get_attribute(&quot;class&quot;))    print(&quot;name:&quot;,ele.get_attribute(&quot;name&quot;))    print(&quot;type:&quot;,ele.get_attribute(&quot;type&quot;))    print(&quot;value:&quot;,ele.get_attribute(&quot;value&quot;))    print(&quot;id:&quot;,ele.get_attribute(&quot;id&quot;))</code></pre><h2 id="header-4">交互操作</h2><p><a href="https://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.common.action_chains" target="_blank" rel="noopener">Refer to Action Chains</a></p><ul><li>click,click_and_hold,double_click,context_click</li><li>drag_and_drop,drag_and_drop_by_offset</li><li>key_down,key_up</li><li>move_by_offset,move_to_element,move_to_element_with_offset</li><li>pause,perform,release,reset_actions</li><li>send_keys,send_keys_to_element</li></ul><p><strong> Sample1: action </strong></p><pre><code class="lang-python">browser=webdriver.Chrome()input= browser.find_element_by_id(&#39;kw&#39;)input.send_keys(&quot;MakBook&quot;)searchBtn = browser.find_element_by_id(&#39;su&#39;)searchBtn.click()time.sleep(2)input.clear()input.send_keys(&quot;ipad&quot;)</code></pre><p><strong> Sample2: action_chains </strong></p><pre><code class="lang-python">from selenium.webdriver import ActionChainsbrowser=webdriver.Chrome()browser.get(&quot;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&quot;)time.sleep(1)browser.switch_to.frame(&#39;iframeResult&#39;)source = browser.find_element_by_css_selector(&#39;#draggable&#39;)target = browser.find_element_by_css_selector(&#39;#droppable&#39;)actions = ActionChains(browser)actions.drag_and_drop(source, target)actions.perform()time.sleep(1)</code></pre><h2 id="header-5">执行Javascript</h2><p><code>execute_script(script)</code></p><pre><code class="lang-python">browser=webdriver.Chrome()browser.execute_script(&#39;window.scrollTo(0, document.body.scrollHeight)&#39;)browser.execute_script(&#39;alert(&quot;To Bottom&quot;)&#39;)</code></pre><h2 id="header-6">切换</h2><ul><li><code>switch_to.xxx</code><ul><li><code>window(windowName)</code></li><li><code>frame(frameName)</code></li><li><code>parent_frame()</code></li><li><code>active_element()</code></li><li><code>default_content()</code></li><li><code>alert()</code></li></ul></li><li><code>back()</code>,<code>forward()</code></li></ul><p><strong> Sample1: window tab切换 </strong></p><pre><code class="lang-python"># 1. window tab切换：# 执行js命令`window.open()`打开选项卡# 不同的选项卡是存在`browser.window_handles`列表中# eg: 通过`browser.window_handles[0]`可以操作第一个选项卡def test_window():    browser=get_browser()    browser.get(&#39;https://www.baidu.com&#39;)    browser.execute_script(&#39;window.open()&#39;)    print(browser.window_handles)    browser.switch_to.window(browser.window_handles[1])    browser.get(&#39;https://www.douban.com/&#39;)    time.sleep(1)    browser.switch_to.window(browser.window_handles[0])    browser.get(&#39;https://python.org&#39;)    time.sleep(1)    # 浏览器的前进和后退: back(),forward()    browser.back()    time.sleep(1)    browser.forward()    time.sleep(1)    browser.close()</code></pre><p><strong> Sample2: frame切换 </strong></p><pre><code class="lang-python">def test_frame():    browser=get_browser(slience=True)    browser.get(&#39;http://www.runoob.com/try/try.php?filename=jqueryui-api-droppable&#39;)    browser.switch_to.frame(&#39;iframeResult&#39;)    source = browser.find_element_by_css_selector(&#39;div#draggable&#39;)    print(source)    print(source.text)    try:        logo = browser.find_element_by_class_name(&#39;logo&#39;)    except NoSuchElementException:        print(&#39;NO LOGO&#39;)    browser.switch_to.parent_frame()    logo = browser.find_element_by_class_name(&#39;logo&#39;)    print(logo)    print(logo.text)</code></pre><h2 id="header-7">异常处理</h2><p><code>selenium.common.exceptions</code></p><pre><code class="lang-python">from selenium import webdriverfrom selenium.common.exceptions import TimeoutException, NoSuchElementExceptionbrowser=webdriver.Chrome()try:    browser.get(&#39;http://www.baidu.com&#39;)    input= browser.find_element_by_id(&#39;kw&#39;)    input.send_keys(&quot;MakBook&quot;)    searchBtn = browser.find_element_by_id(&#39;su&#39;)    searchBtn.click()    print(&quot;clicked!&quot;)    span=browser.find_element_by_xpath(&quot;//div[@id=&#39;container&#39;]//div[@class=&#39;nums&#39;]/span[@class=&#39;nums_text&#39;]&quot;)    print(&quot;result:&quot;,span.text)except (TimeoutException,NoSuchElementException) as e:    print(&quot;Occur Exception:&quot;,e)except Exception as e:    print(&quot;Unknow Exception:&quot;,type(e),e)finally:    print(&quot;close!&quot;)    browser.close()</code></pre><h2 id="header-8">Cookie</h2><ul><li><code>get_cookie(name)</code></li><li><code>add_cookie(dict)</code>: required keys “name” and “value”</li><li><code>delete_cookie(name)</code></li><li><code>get_cookies()</code></li><li><code>delete_all_cookes()</code></li></ul><pre><code class="lang-python">def test_cookie():    browser=get_browser(slience=True)    browser.get(&#39;http://www.baidu.com&#39;)    cookies=browser.get_cookies()    print(cookies)    browser.add_cookie({&#39;name&#39;:&#39;user&#39;,&#39;value&#39;:&#39;Tom&#39;})    print(browser.get_cookie(&#39;user&#39;))</code></pre><h2 id="header-9">等待元素</h2><ul><li>强制等待 <code>time.sleep(seconds)</code></li><li><p>隐式等待 <code>browser.implicitly_wait(seconds)</code></p><pre><code class="lang-python">  browser=get_browser()  browser.get(&#39;http://www.baidu.com&#39;)  input= browser.find_element_by_id(&#39;kw&#39;)  input.send_keys(&quot;MakBook&quot;)  searchBtn = browser.find_element_by_id(&#39;su&#39;)  searchBtn.click()  browser.implicitly_wait(3)  span=browser.find_element_by_xpath(&quot;//div[@id=&#39;container&#39;]//div[@class=&#39;nums&#39;]/span[@class=&#39;nums_text&#39;]&quot;)  print(span.text)  browser.close()</code></pre></li><li><p>显示等待</p><pre><code class="lang-python">  from selenium.webdriver.support.wait import WebDriverWait  from selenium.webdriver.support import expected_conditions as EC  browser=get_browser()  browser.get(&#39;http://www.baidu.com&#39;)  input= browser.find_element_by_id(&#39;kw&#39;)  input.send_keys(&quot;MakBook&quot;)  searchBtn = browser.find_element_by_id(&#39;su&#39;)  searchBtn.click()  wait=WebDriverWait(browser,10, 0.5)  optionLocator = (By.XPATH, &quot;//select/option&quot;)  option=wait.until(EC.presence_of_element_located(optionLocator))  print(option)  btnLocator=(By.CSS_SELECTOR, &#39;.btn-search&#39;)  btn=wait.until(EC.element_to_be_clickable(btnLocator))  print(btn)  browser.close()</code></pre><ul><li>EC 常用的判断条件：<ul><li><code>title_is</code> : 标题是某内容</li><li><code>title_contains</code> : 标题包含某内容</li><li><code>visibility_of</code> : 可见，传入元素对象</li><li><code>staleness_of</code> : 判断一个元素是否仍在DOM，可判断页面是否已经刷新</li><li><code>alert_is_present</code> : 是否出现Alert</li><li><code>frame_to_be_available_and_switch_to_it</code> : frame加载并切换</li><li><code>element_selection_state_to_be</code> : 传入元素对象以及状态，相等返回True，否则返回False</li><li><code>element_located_selection_state_to_be</code> : 传入定位元组以及状态，相等返回True，否则返回False</li><li><code>presence_of_element_located(locator)</code> : 指定元素出现，传入定位元组，如(By.ID, ‘p’)</li><li><code>presence_of_all_elements_located(locator)</code></li><li><code>invisibility/visibility_of_element_located(locator)</code>: 指定元素不可见／可见</li><li><code>element_to_be_clickable(locator)</code> : 指定元素可点击</li><li><code>element_located_to_be_selected(locator)</code> : 指定元素可选择</li><li><code>element_to_be_selected(element)</code></li><li><code>text_to_be_present_in_element(locator,text)</code> : 指定元素的文本包含指定文本</li><li><code>text_to_be_present_in_element_value(locator,text)</code> : 指定元素值包含某文字</li></ul></li></ul></li></ul><h2 id="header-10">Reference</h2><ul><li><a href="https://github.com/sixDegree/python-basic-demo" target="_blank" rel="noopener">My Demo</a></li><li><a href="https://selenium-python.readthedocs.io/" target="_blank" rel="noopener">Selenium Doc</a></li><li><a href="https://www.cnblogs.com/zhaof/p/6953241.html" target="_blank" rel="noopener">python爬虫从入门到放弃（八）之 Selenium库的使用</a></li><li><a href="https://www.cnblogs.com/LOVEYU/p/8392269.html" target="_blank" rel="noopener">selenium+python自动化测试系列(一)：登录</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;Install: selenium,browser drive&lt;/li&gt;
&lt;li&gt;browser&lt;/li&gt;
&lt;li&gt;查找元素：find_elements/find_elements_by_xxx,find_element/find_element_by_xxx&lt;/li&gt;
&lt;li&gt;交互操作：action(eg: click,key_down,…),action_chains (ActionChains,drag_and_drop)&lt;/li&gt;
&lt;li&gt;执行javascript: execute_script(…)&lt;/li&gt;
&lt;li&gt;切换：switch_to.xxx，back/forward()&lt;/li&gt;
&lt;li&gt;异常处理：selenium.common.exceptions（eg: TimeoutException, NoSuchElementException）&lt;/li&gt;
&lt;li&gt;Cookie: add/get/delete_cookie(…),get_cookies(),delete_all_cookies()&lt;/li&gt;
&lt;li&gt;等待元素: 强制等待 time.sleep(seconds), 隐式等待 browser.implicitly_wait(seconds),显示等待 WebDriverWait,expected_conditions&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Python" scheme="http://sixdegree.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python 爬虫框架Scrapy</title>
    <link href="http://sixdegree.github.io/2019/03/20/Python-Scrapy.html"/>
    <id>http://sixdegree.github.io/2019/03/20/Python-Scrapy.html</id>
    <published>2019-03-19T16:00:00.000Z</published>
    <updated>2019-07-08T13:19:11.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>Scrapy架构，常用命令，文档解析</li><li>Spider: Spider,CrawlSpider,XMLFeedSpider,CSVFeedSpider,SitemapSpider</li><li>Item,ItemLoader</li><li>Middleware: ItemPipeline,Spider/DownloaderMiddleware,Item Exporters</li><li>应用示例：基于Excel爬取，Login,常见问题</li><li>Scrapy-Redis 分布式架构（共享抓取队列）</li><li>Scrapyd（分布式发布）</li></ul><a id="more"></a><h2 id="header-1">Starter</h2><ul><li><p>一套基于<code>Twisted</code>事件驱动的异步爬虫框架</p></li><li><p>是为持续运行设计的专业爬虫框架,提供了操作的Scrapy命令行</p></li><li><p>VS. Requests</p><table class="table"><thead><tr><th style="text-align:left">Requests</th><th style="text-align:left">Scrapy</th></tr></thead><tbody><tr><td style="text-align:left">功能库,重点在于页面下载（页面级爬虫）</td><td style="text-align:left">框架,重点在于爬虫结构（网站级爬虫）</td></tr><tr><td style="text-align:left">阻塞IO</td><td style="text-align:left">基于<code>Twisted</code>事件驱动，异步</td></tr><tr><td style="text-align:left">并发性考虑不足</td><td style="text-align:left">并发性好</td></tr><tr><td style="text-align:left">定制灵活</td><td style="text-align:left">一般定制灵活,深度定制困难</td></tr><tr><td style="text-align:left">场景：小需求</td><td style="text-align:left">场景：大需求</td></tr></tbody></table></li><li><p>install: <code>pip install scrapy</code></p></li><li><p>check:<code>scrapy -h</code></p><pre><code class="lang-bash">  $ scrapy -h  Scrapy 1.6.0 - no active project  Usage:    scrapy &lt;command&gt; [options] [args]  Available commands:    bench         Run quick benchmark test    fetch         Fetch a URL using the Scrapy downloader    genspider     Generate new spider using pre-defined templates    runspider     Run a self-contained spider (without creating a project)    settings      Get settings values    shell         Interactive scraping console    startproject  Create new project    version       Print Scrapy version    view          Open URL in browser, as seen by Scrapy    [ more ]      More commands available when run from project directory  Use &quot;scrapy &lt;command&gt; -h&quot; to see more info about a command</code></pre></li></ul><h3 id="header-2">使用</h3><ol><li><p>创建工程: </p><ul><li><code>scrapy startproject &lt;name&gt; [dir]</code></li></ul></li><li><p>创建<code>Spider</code>: </p><ul><li>在工程中产生一个Scrapy爬虫: <code>scrapy genspider [options] &lt;spiderName&gt; &lt;domain&gt;</code></li><li>编写<code>vi &lt;spiderName&gt;.py</code><ul><li>start_urls: 初始URL地址</li><li>parse(response): 获取页面后的解析处理</li></ul></li></ul></li><li><p>编写<code>Item Pipeline</code>: </p><ul><li><code>pipelines.py</code>: 定义对爬取项<code>Scraped Item</code>的处理类 </li><li><code>setting.py</code>: 添加到<code>ITEM_PIPELINES</code>配置项</li></ul></li><li><p>配置优化</p><ul><li>配置<code>settings.py</code>文件</li><li>eg: 配置并发连接选项<ul><li><code>CONCURRENT_REQUESTS</code>: <code>Downloader</code>最大并发请求下载数量,默认32</li><li><code>CONCURRENT_ITEMS</code>: <code>Item Pipeline</code>最大并发ITEM处理数量，默认100</li><li><code>CONCURRENT_REQUESTS_PER_DOMAIN</code>: 每个目标域名最大的并发请求数量,默认8 </li><li><code>CONCURRENT_REQUESTS_PER_IP</code>: 每个目标IP最大的并发请求数量,默认0,非0有效</li></ul></li></ul></li><li><p>执行：<code>scrapy crawl &lt;spiderName&gt;</code></p></li></ol><h3 id="header-3">Demo</h3><ol><li><p>创建项目</p><pre><code class="lang-bash"> $ scrapy startproject douban_demo New Scrapy project &#39;douban_demo&#39;, using template directory &#39;/usr/local/lib/python3.7/site-packages/scrapy/templates/project&#39;, created in:     /Users/cj/space/python/douban_demo You can start your first spider with:     cd douban_demo     scrapy genspider example example.com</code></pre><ul><li><p>查看项目目录</p><pre><code class="lang-bash">  $ tree  .  ├── douban_demo  │   ├── __init__.py  │   ├── __pycache__  │   │   ├── __init__.cpython-37.pyc  │   │   └── settings.cpython-37.pyc  │   ├── items.py  │   ├── middlewares.py  │   ├── pipelines.py  │   ├── settings.py  │   └── spiders  │       ├── __init__.py  │       ├── __pycache__  │          └── __init__.cpython-37.pyc  └── scrapy.cfg  4 directories, 10 files</code></pre></li><li>查看自动创建的<code>pipelines.py</code><pre><code class="lang-python">  # -*- coding: utf-8 -*-  # Define your item pipelines here  #  # Don&#39;t forget to add your pipeline to the ITEM_PIPELINES setting  # See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html  class DoubanDemoPipeline(object):      def process_item(self, item, spider):          return item</code></pre></li><li>查看自动创建的<code>items.py</code><pre><code class="lang-python">  # -*- coding: utf-8 -*-  # Define here the models for your scraped items  #  # See documentation in:  # https://doc.scrapy.org/en/latest/topics/items.html  import scrapy  class DoubanDemoItem(scrapy.Item):      # define the fields for your item here like:      # name = scrapy.Field()      pass</code></pre></li><li><p>查看自动生成的<code>settings.py</code></p><pre><code class="lang-python">  # -*- coding: utf-8 -*-  # Scrapy settings for douban_demo project  #  # For simplicity, this file contains only settings considered important or  # commonly used. You can find more settings consulting the documentation:  #  #     https://doc.scrapy.org/en/latest/topics/settings.html  #     https://doc.scrapy.org/en/latest/topics/downloader-middleware.html  #     https://doc.scrapy.org/en/latest/topics/spider-middleware.html  BOT_NAME = &#39;douban_demo&#39;  SPIDER_MODULES = [&#39;douban_demo.spiders&#39;]  NEWSPIDER_MODULE = &#39;douban_demo.spiders&#39;  # Crawl responsibly by identifying yourself (and your website) on the user-agent  #USER_AGENT = &#39;douban_demo (+http://www.yourdomain.com)&#39;  # Obey robots.txt rules  ROBOTSTXT_OBEY = True  # Configure maximum concurrent requests performed by Scrapy (default: 16)  #CONCURRENT_REQUESTS = 32  # ...</code></pre></li></ul></li><li><p>创建Spider</p><pre><code class="lang-bash"> # 进入项目目录，创建一个Spider $ cd douban_demo/ $ scrapy genspider movie movie.douban.com Created spider &#39;movie&#39; using template &#39;basic&#39; in module:   douban_demo.spiders.movie</code></pre><ul><li><p>查看新建的spider：<code>spider/movie.py</code></p><pre><code class="lang-python">  # -*- coding: utf-8 -*-  import scrapy  class MovieSpider(scrapy.Spider):      name = &#39;movie&#39;      allowed_domains = [&#39;movie.douban.com&#39;]      start_urls = [&#39;http://movie.douban.com/&#39;]      def parse(self, response):          pass</code></pre></li><li><p>编写spider：<code>spider/movie.py</code></p><pre><code class="lang-python">  # -*- coding: utf-8 -*-  import scrapy  import re  import json  from douban_demo.items import MovieItem  class MovieSpider(scrapy.Spider):      name = &#39;movie&#39;      allowed_domains = [&#39;movie.douban.com&#39;]      start_urls = [&#39;https://movie.douban.com/j/search_subjects?type=movie&amp;tag=热门&amp;sort=recommend&amp;page_limit=20&amp;page_start=0&#39;]      def parse(self, response):          print(response.url)          result=json.loads(response.body)          subjects=result.get(&#39;subjects&#39;)          if len(subjects)&gt;0:              for subject in subjects:                  # print(subject)                  yield MovieItem(subject)</code></pre></li><li>items.py<pre><code class="lang-python">  # -*- coding: utf-8 -*-  import scrapy  class MovieItem(scrapy.Item):      # {&#39;rate&#39;: &#39;7.0&#39;, &#39;cover_x&#39;: 7142, &#39;title&#39;: &#39;飞驰人生&#39;, &#39;url&#39;: &#39;https://movie.douban.com/subject/30163509/&#39;, &#39;playable&#39;: True, &#39;cover&#39;: &#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2542973862.jpg&#39;, &#39;id&#39;: &#39;30163509&#39;, &#39;cover_y&#39;: 10000, &#39;is_new&#39;: False}      rate=scrapy.Field()      title=scrapy.Field()      url=scrapy.Field()      id=scrapy.Field()      is_new=scrapy.Field()</code></pre></li></ul></li><li><p>编写pipeline.py（optional）</p><pre><code class="lang-python"> from scrapy.conf import settings class MoviePipeline(object):     def process_item(self, item, spider):         print(item)         return item</code></pre></li><li><p>配置<code>setting.py</code></p><pre><code class="lang-python"> USER_AGENT=&#39;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:60.0) Gecko/20100101 Firefox/60.0&#39; LOG_LEVEL = &#39;INFO&#39; FEED_EXPORT_ENCODING=&#39;utf-8&#39; # Obey robots.txt rules ROBOTSTXT_OBEY = False ITEM_PIPELINES = {     &#39;douban_demo.pipelines.MoviePipeline&#39;:100 }</code></pre></li><li><p>运行Spider</p><pre><code class="lang-bash"> $ scrapy crawl movie $ scrapy crawl movie -o movies.json -s FEED_EXPORT_ENCODING=utf-8 -L INFO</code></pre></li></ol><h2 id="header-4">架构</h2><p><img src="/2019/03/20/scrapy.png" alt="Scrapy"></p><h3 id="header-5">“5+2”结构</h3><ol><li><p>引擎 <code>Engine</code>: </p><ul><li>控制所有模块之间的数据流,根据条件触发事件</li></ul></li><li><p>下载器 <code>Downloader</code>: </p><ul><li>根据请求下载网页</li></ul></li><li><p>调度器 <code>Scheduler</code>: </p><ul><li>对所有爬取请求进行调度管理</li></ul></li><li><p>爬虫 <code>Spider</code> (需要用户编写配置代码):</p><ul><li>解析<code>Downloader</code>返回的响应<code>Response</code></li><li>产生爬取项<code>Scraped item</code></li><li>产生额外的爬取请求<code>Request</code></li></ul></li><li><p>管道 <code>Item Pipelines</code> (需要用户编写配置代码):</p><ul><li>以流水线方式处理<code>Spider</code>产生的爬取项<code>Scraped item</code></li><li>由一组操作顺序组成,类似流水线,每个操作是一个<code>Item Pipeline</code>类型</li><li>可能操作包括: 清理、检验和查重爬取项中的HTML数据、将数据存储到数据库</li></ul></li><li><p>中间件 (用户可以编写配置代码)：</p><ul><li>下载中间件 <code>Downloader Middleware</code>: 修改、丢弃、新增请求<code>Request</code>或响应<code>Response</code></li><li>爬虫中间件<code>Spider Middleware</code>: 修改、丢弃、新增<code>Request</code>或爬取项<code>Scraped item</code></li></ul></li></ol><h3 id="header-6">出入口</h3><ol><li><p>框架入口: </p><ul><li><code>Spider</code>的初始爬取请求 </li></ul></li><li><p>框架出口: </p><ul><li><code>Item Pipeline</code></li></ul></li><li><p>数据流：</p><ul><li><code>Engine</code>控制各模块数据流,不间断从<code>Scheduler</code>处获得爬取<code>Request</code>,直至<code>Request</code>为空 </li></ul></li><li><p>用户编写： </p><ul><li><code>Spider</code>：处理链接爬取和页面解析</li><li><code>Item Pipelines</code>：处理信息存储</li><li><code>Middleware</code>：<ul><li><code>Spider Middleware</code>: 过滤<code>new requests</code> &amp; <code>Scraped Item</code></li><li><code>Downloader Middleware</code>: 过滤<code>request</code> &amp; <code>response</code></li></ul></li><li><code>Setting</code>：配置</li></ul></li></ol><h3 id="header-7">流程（数据流的三个路径）</h3><ul><li>UR2IM 流程<pre><code>  URL -&gt; Request -&gt; Response -&gt; Item -&gt; More URL          ^                      |-&gt; store   |          |__________________________________|</code></pre></li><li>路径1: <ul><li>Spider =&gt; <code>request</code> =&gt; Engine =&gt; <code>request</code> =&gt; Schedule<br>  (<code>Engine</code>从<code>Spider</code>处获得爬取<code>Request</code>，然后将<code>Request</code>转发给<code>Scheduler</code>,用于调度)</li></ul></li><li>路径2:<ul><li>Schedule =&gt; <code>request</code> =&gt; Engine =&gt; <code>request</code> =&gt; Downloader Middleware =&gt; Downloader<br>  （<code>Engine</code>从<code>Scheduler</code>处获得下一个要爬取的<code>Request</code>，通过<code>Downloader Middleware</code>后发给<code>Downloader</code> ）</li><li>Downloader =&gt; <code>response</code> =&gt; Downloader Middleware =&gt; Engine =&gt; Spider Middleware =&gt; Spider<br>  （爬取网页后<code>Downloader</code>形成响应<code>Response</code>, 通过<code>Downloader Middleware</code>后发回<code>Engine</code>，<code>Engine</code>将收到的响应通过<code>Spider Middleware</code>发送给<code>Spider</code>处理）</li></ul></li><li>路径3:<ul><li>Spider =&gt; <code>Scraped Item</code> &amp; <code>New Requests</code> =&gt; Engine<br>  ( <code>Spider</code>处理响应后产生爬取项<code>Scraped Item</code> 和新的爬取请求<code>Requests</code>给<code>Engine</code>)</li><li>Engine =&gt; <code>Scraped Item</code> =&gt; Item Pipeline<br>  (<code>Engine</code>将爬取项<code>Scraped Item</code>发送给框架出口<code>Item Pipeline</code>)</li><li>Engine =&gt; <code>New Requests</code> =&gt; Scheduler<br>  (<code>Engine</code>将爬取<code>Request</code>发送给<code>Scheduler</code>)</li></ul></li></ul><p><img src="/2019/03/20/scrapy-flow.png" alt="Scrapy Flow"></p><h3 id="header-8">常用命令</h3><p>Scrapy采用命令行创建和运行爬虫</p><p>命令行格式：<code>scrapy &lt;command&gt; [options] [args]</code></p><ol><li><p>Scrapy 命令：</p><pre><code class="lang-bash"> $ scrapy -h Scrapy 1.6.0 - project: douban Usage:   scrapy &lt;command&gt; [options] [args] Available commands:   bench         Run quick benchmark test   check         Check spider contracts   crawl         Run a spider   edit          Edit spider   fetch         Fetch a URL using the Scrapy downloader   genspider     Generate new spider using pre-defined templates   list          List available spiders   parse         Parse URL (using its spider) and print the results   runspider     Run a self-contained spider (without creating a project)   settings      Get settings values   shell         Interactive scraping console   startproject  Create new project   version       Print Scrapy version   view          Open URL in browser, as seen by Scrapy Use &quot;scrapy &lt;command&gt; -h&quot; to see more info about a command</code></pre><ul><li><p>常用命令说明：</p><table class="table"><thead><tr><th style="text-align:left">命令</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left"><code>scrapy startproject &lt;name&gt; [dir]</code></td><td style="text-align:left">创建一个新工程</td></tr><tr><td style="text-align:left"><code>scrapy genspider [options] &lt;name&gt; &lt;domain&gt;</code></td><td style="text-align:left">创建一个爬虫</td></tr><tr><td style="text-align:left"><code>scrapy list</code></td><td style="text-align:left">列出工程中所有爬虫</td></tr><tr><td style="text-align:left"><code>scrapy crawl &lt;spider&gt;</code></td><td style="text-align:left">运行一个爬虫</td></tr><tr><td style="text-align:left"><code>scrapy settings [options]</code></td><td style="text-align:left">获得爬虫配置信息</td></tr><tr><td style="text-align:left"><code>scrapy shell [url]</code></td><td style="text-align:left">启动URL调试命令行</td></tr></tbody></table></li><li><p>Global Options:</p><pre><code class="lang-bash">  Global Options  --------------  ---logfile=FILE          log file. if omitted stderr will be used  --loglevel=LEVEL, -L LEVEL                          log level (default: DEBUG)  --nolog                 disable logging completely  --profile=FILE          write python cProfile stats to FILE  --pidfile=FILE          write process ID to FILE  --set=NAME=VALUE, -s NAME=VALUE                          set/override setting (may be repeated)  --pdb                   enable pdb on failure</code></pre></li></ul></li><li><p>Generate a spider options:</p><pre><code class="lang-bash"> $ scrapy genspider -h Usage =====   scrapy genspider [options] &lt;name&gt; &lt;domain&gt; Generate new spider using pre-defined templates Options ======= --help, -h              show this help message and exit --list, -l              List available templates --edit, -e              Edit spider after creating it --dump=TEMPLATE, -d TEMPLATE                         Dump template to standard output --template=TEMPLATE, -t TEMPLATE                         Uses a custom template. --force                 If the spider already exists, overwrite it with the                         template</code></pre></li><li><p>Run a spider options:</p><pre><code class="lang-bash"> Usage =====   scrapy crawl [options] &lt;spider&gt; Run a spider Options ======= --help, -h              show this help message and exit -a NAME=VALUE           set spider argument (may be repeated) --output=FILE, -o FILE  dump scraped items into FILE (use - for stdout) --output-format=FORMAT, -t FORMAT                         format to use for dumping items with -o</code></pre></li><li><p>Set spider settings:</p><pre><code class="lang-bash"> Usage =====   scrapy settings [options] Get settings values Options ======= --help, -h              show this help message and exit --get=SETTING           print raw setting value --getbool=SETTING       print setting value, interpreted as a boolean --getint=SETTING        print setting value, interpreted as an integer --getfloat=SETTING      print setting value, interpreted as a float --getlist=SETTING       print setting value, interpreted as a list</code></pre></li></ol><p><strong> 示例：使用 <code>scrapy shell</code> 交互式调试 </strong></p><pre><code class="lang-bash">$ scrapy shell...[s] Available Scrapy objects:[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x105cd57f0&gt;[s]   item       {}[s]   settings   &lt;scrapy.settings.Settings object at 0x105cd58d0&gt;[s] Useful shortcuts:[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)[s]   fetch(req)                  Fetch a scrapy.Request and update local objects[s]   shelp()           Shell help (print this help)[s]   view(response)    View response in a browser&gt;&gt;&gt; &gt;&gt;&gt; exit()</code></pre><pre><code class="lang-bash">$ scrapy shell https://movie.douban.com/top250...[s] Available Scrapy objects:[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x1037be908&gt;[s]   item       {}[s]   request    &lt;GET https://movie.douban.com/top250&gt;[s]   response   &lt;200 https://movie.douban.com/top250&gt;[s]   settings   &lt;scrapy.settings.Settings object at 0x1037be9e8&gt;[s]   spider     &lt;Top250Spider &#39;top250&#39; at 0x103bb2048&gt;[s] Useful shortcuts:[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)[s]   fetch(req)                  Fetch a scrapy.Request and update local objects[s]   shelp()           Shell help (print this help)[s]   view(response)    View response in a browser&gt;&gt;&gt; records=response.xpath(&#39;//ol[@class=&quot;grid_view&quot;]//div[@class=&quot;item&quot;]/div[@class=&quot;info&quot;]&#39;)&gt;&gt;&gt; len(records)25&gt;&gt;&gt; records.xpath(&#39;./div[@class=&quot;bd&quot;]/div[@class=&quot;star&quot;]/span[@class=&quot;rating_num&quot;]/text()&#39;).extract()[&#39;9.6&#39;, &#39;9.6&#39;, &#39;9.4&#39;, &#39;9.4&#39;, &#39;9.5&#39;, &#39;9.4&#39;, &#39;9.3&#39;, &#39;9.5&#39;, &#39;9.3&#39;, &#39;9.3&#39;, &#39;9.3&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.3&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.3&#39;, &#39;9.3&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.0&#39;, &#39;9.0&#39;, &#39;9.2&#39;]&gt;&gt;&gt; records[0].xpath(&#39;./div[@class=&quot;hd&quot;]/a/span[@class=&quot;title&quot;]/text()&#39;)[&lt;Selector xpath=&#39;./div[@class=&quot;hd&quot;]/a/span[@class=&quot;title&quot;]/text()&#39; data=&#39;肖申克&#39;&gt;, &lt;Selector xpath=&#39;./div[@class=&quot;hd&quot;]/a/span[@class=&quot;title&quot;]/text()&#39; data=&#39;\xa0/\xa0The Shawshank Redemption&#39;&gt;]&gt;&gt;&gt; records[0].xpath(&#39;./div[@class=&quot;hd&quot;]/a/span[@class=&quot;title&quot;]/text()&#39;).extract()[&#39;肖申克的救赎&#39;, &#39;\xa0/\xa0The Shawshank Redemption&#39;]&gt;&gt;&gt; records[0].xpath(&#39;./div[@class=&quot;hd&quot;]/a/span[@class=&quot;title&quot;]/text()&#39;).get()&#39;肖申克的救赎&#39;&gt;&gt;&gt; records[0].xpath(&#39;./div[@class=&quot;hd&quot;]/a/span[@class=&quot;title&quot;]/text()&#39;).extract_first()&#39;肖申克的救赎&#39;&gt;&gt;&gt;records[0].xpath(&#39;./div[@class=&quot;hd&quot;]/a/span[@class=&quot;title&quot;]/text()&#39;).re(&#39;[A-Za-z ]+&#39;)[&#39;The Shawshank Redemption&#39;]&gt;&gt;&gt; records=response.css(&#39;.grid_view .item .info&#39;)&gt;&gt;&gt; len(records)25# &gt;&gt;&gt; records.css(&#39;.bd .star .rating_num&#39;).xpath(&#39;text()&#39;).extract()# &gt;&gt;&gt; records.css(&#39;.bd .star .rating_num::text&#39;).extract()# &gt;&gt;&gt; records.css(&#39;.bd .star .rating_num&#39;).re(&#39;[\d.]+&#39;)&gt;&gt;&gt; records.xpath(&#39;./div[@class=&quot;bd&quot;]/div[@class=&quot;star&quot;]/span[@class=&quot;rating_num&quot;]/text()&#39;).extract()[&#39;9.6&#39;, &#39;9.6&#39;, &#39;9.4&#39;, &#39;9.4&#39;, &#39;9.5&#39;, &#39;9.4&#39;, &#39;9.3&#39;, &#39;9.5&#39;, &#39;9.3&#39;, &#39;9.3&#39;, &#39;9.3&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.3&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.3&#39;, &#39;9.3&#39;, &#39;9.2&#39;, &#39;9.2&#39;, &#39;9.0&#39;, &#39;9.0&#39;, &#39;9.2&#39;]&gt;&gt;&gt; len(response.css(&#39;div&#39;))183&gt;&gt;&gt; len(records.css(&#39;div&#39;))100&gt;&gt;&gt; exit()</code></pre><h3 id="header-9">解析文档</h3><ul><li>可使用BeautifulSoup,lxml解析，而Scrapy内部使用的是lxml（效率更高），可使用Xpath,CssSelector进行文档定位解析</li><li><code>response.xpath()</code>和<code>response.css()</code> 返回的<code>Selector</code>对象列表<code>SelectorList</code>是可以被串联起来的</li><li>获取<code>Selector</code>对象／<code>SelectorList</code>中的<code>data</code>，可以使用<code>.extract/getall()</code>,<code>.extract_first/get()</code>,<code>.re(pattern)</code></li><li>获取<code>Selector</code>对象/<code>SelectorList</code>中标签的某个属性值，可以使用<code>.attrib[&#39;attrName&#39;]</code></li><li>xpath可使用<code>/@attrName</code>获取属性值，eg: <code>response.xpath(//div[@class=&quot;item&quot;]//img/@src)</code></li><li>css selector 可使用伪代码<code>::</code>，eg: <ul><li>select text nodes, use <code>::text</code></li><li>select attribute values, use <code>::attr(attrName)</code></li><li>eg: <code>response.css(&#39;title::text&#39;).get(default=&#39;&#39;)</code>,<code>response.css(&#39;a::attr(href)&#39;).getall()</code></li></ul></li><li><a href="http://doc.scrapy.org/en/latest/topics/selectors.html" target="_blank" rel="noopener">Selector 文档</a></li></ul><h3 id="header-10">Settings 优先级</h3><pre><code class="lang-python">SETTINGS_PRIORITIES = {    &#39;default&#39;: 0,    &#39;command&#39;: 10,    &#39;project&#39;: 20,    &#39;spider&#39;: 30,    &#39;cmdline&#39;: 40,}</code></pre><ol><li>default: <code>scrapy/settings/default_settings.py</code></li><li>project: <code>[project]/settings.py</code></li><li>spider: Spider中配置的<code>custom_settings</code>属性</li><li>cmdline: 命令行运行时传入的 <code>-s xxxx=xxx</code> 参数</li></ol><pre><code class="lang-bash">$ scrapy settings --get CONCURRENT_REQUESTS16$ scrapy settings -s CONCURRENT_REQUESTS=19 --get CONCURRENT_REQUESTS19$ scrapy crawl movie -s CONCURRENT_REQUESTS=19$ scrapy shell -s CONCURRENT_REQUESTS=19[s] Available Scrapy objects:[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x105cd57f0&gt;[s]   item       {}[s]   settings   &lt;scrapy.settings.Settings object at 0x105cd58d0&gt;[s] Useful shortcuts:[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)[s]   fetch(req)                  Fetch a scrapy.Request and update local objects[s]   shelp()           Shell help (print this help)[s]   view(response)    View response in a browser&gt;&gt;&gt; settings.get(&#39;CONCURRENT_REQUESTS&#39;)&#39;19&#39;&gt;&gt;&gt; settings.getint(&#39;CONCURRENT_REQUESTS&#39;)19&gt;&gt;&gt; exit()</code></pre><h3 id="header-11">Default Settings</h3><ul><li><p>项目</p><pre><code class="lang-python">  BOT_NAME = &#39;scrapybot&#39;   # eg: &#39;douban&#39;  SPIDER_MODULES = []      # eg: [&#39;douban.spiders&#39;]  NEWSPIDER_MODULE = &#39;&#39;    # eg: &#39;douban.spiders&#39;  TEMPLATES_DIR = abspath(join(dirname(__file__), &#39;..&#39;, &#39;templates&#39;))  DEFAULT_ITEM_CLASS = &#39;scrapy.item.Item&#39;  EDITOR = &#39;vi&#39;  if sys.platform == &#39;win32&#39;:      EDITOR = &#39;%s -m idlelib.idle&#39;  # mail  MAIL_HOST = &#39;localhost&#39;  MAIL_PORT = 25  MAIL_FROM = &#39;scrapy@localhost&#39;  MAIL_PASS = None  MAIL_USER = None</code></pre></li><li><p>分析</p><pre><code class="lang-python">  # 日志 Log ：  LOG_ENABLED = True  LOG_ENCODING = &#39;utf-8&#39;  LOG_FORMATTER = &#39;scrapy.logformatter.LogFormatter&#39;  LOG_FORMAT = &#39;%(asctime)s [%(name)s] %(levelname)s: %(message)s&#39;  LOG_DATEFORMAT = &#39;%Y-%m-%d %H:%M:%S&#39;  LOG_STDOUT = False  LOG_LEVEL = &#39;DEBUG&#39;  LOG_FILE = None  LOG_SHORT_NAMES = False  LOGSTATS_INTERVAL = 60.0  # 统计 Stats ：  STATS_CLASS = &#39;scrapy.statscollectors.MemoryStatsCollector&#39;  STATS_DUMP = True  STATSMAILER_RCPTS = []  DEPTH_STATS_VERBOSE = False  DOWNLOADER_STATS = True  # Telnet：  TELNETCONSOLE_ENABLED = 1  TELNETCONSOLE_PORT = [6023, 6073]  TELNETCONSOLE_HOST = &#39;127.0.0.1&#39;  TELNETCONSOLE_USERNAME = &#39;scrapy&#39;  TELNETCONSOLE_PASSWORD = None</code></pre></li><li><p>爬取策略</p><pre><code class="lang-python">  # Cookie  COOKIES_ENABLED = True  COOKIES_DEBUG = False  # Request  DEFAULT_REQUEST_HEADERS = {      &#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;,      &#39;Accept-Language&#39;: &#39;en&#39;,  }  # User-Agent  USER_AGENT = &#39;Scrapy/%s (+https://scrapy.org)&#39; % import_module(&#39;scrapy&#39;).__version__  # robots.txt  ROBOTSTXT_OBEY = False  # 代理  HTTPPROXY_ENABLED = True  HTTPPROXY_AUTH_ENCODING = &#39;latin-1&#39;  # referer  REFERER_ENABLED = True  REFERRER_POLICY = &#39;scrapy.spidermiddlewares.referer.DefaultReferrerPolicy&#39;  # rediret  REDIRECT_ENABLED = True  REDIRECT_MAX_TIMES = 20  # uses Firefox default setting  REDIRECT_PRIORITY_ADJUST = +2  # retry  RETRY_ENABLED = True  RETRY_TIMES = 2  # initial response + 2 retries = 3 requests  RETRY_HTTP_CODES = [500, 502, 503, 504, 522, 524, 408]  RETRY_PRIORITY_ADJUST = -1  # meta refresh  METAREFRESH_ENABLED = True  METAREFRESH_MAXDELAY = 100  # DNS  DNSCACHE_ENABLED = True  DNSCACHE_SIZE = 10000  DNS_TIMEOUT = 60  # Http缓存  HTTPCACHE_ENABLED = False  HTTPCACHE_DIR = &#39;httpcache&#39;  HTTPCACHE_IGNORE_MISSING = False  HTTPCACHE_STORAGE = &#39;scrapy.extensions.httpcache.FilesystemCacheStorage&#39;  HTTPCACHE_EXPIRATION_SECS = 0  HTTPCACHE_ALWAYS_STORE = False  HTTPCACHE_IGNORE_HTTP_CODES = []  HTTPCACHE_IGNORE_SCHEMES = [&#39;file&#39;]  HTTPCACHE_IGNORE_RESPONSE_CACHE_CONTROLS = []  HTTPCACHE_DBM_MODULE = &#39;anydbm&#39; if six.PY2 else &#39;dbm&#39;  HTTPCACHE_POLICY = &#39;scrapy.extensions.httpcache.DummyPolicy&#39;  HTTPCACHE_GZIP = False  # 并发  CONCURRENT_ITEMS = 100  CONCURRENT_REQUESTS = 16  CONCURRENT_REQUESTS_PER_DOMAIN = 8  CONCURRENT_REQUESTS_PER_IP = 0  REACTOR_THREADPOOL_MAXSIZE = 10  # Depth  DEPTH_LIMIT = 0  DEPTH_STATS_VERBOSE = False  DEPTH_PRIORITY = 0   # 结束爬取  CLOSESPIDER_TIMEOUT = 0  CLOSESPIDER_PAGECOUNT = 0  CLOSESPIDER_ITEMCOUNT = 0  CLOSESPIDER_ERRORCOUNT = 0  # 自动限速  AUTOTHROTTLE_ENABLED = False  AUTOTHROTTLE_DEBUG = False  AUTOTHROTTLE_MAX_DELAY = 60.0  AUTOTHROTTLE_START_DELAY = 5.0  AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0   # Memory    MEMDEBUG_ENABLED = False        # enable memory debugging  MEMDEBUG_NOTIFY = []            # send memory debugging report by mail at engine shutdown  MEMUSAGE_CHECK_INTERVAL_SECONDS = 60.0  MEMUSAGE_ENABLED = True  MEMUSAGE_LIMIT_MB = 0  MEMUSAGE_NOTIFY_MAIL = []  MEMUSAGE_WARNING_MB = 0  # other   AJAXCRAWL_ENABLED = False  COMPRESSION_ENABLED = True</code></pre></li><li><p>组件</p><pre><code class="lang-python">  # 1. Scheduler  SCHEDULER = &#39;scrapy.core.scheduler.Scheduler&#39;  SCHEDULER_DISK_QUEUE = &#39;scrapy.squeues.PickleLifoDiskQueue&#39;  SCHEDULER_MEMORY_QUEUE = &#39;scrapy.squeues.LifoMemoryQueue&#39;  SCHEDULER_PRIORITY_QUEUE = &#39;queuelib.PriorityQueue&#39;  SCHEDULER_DEBUG = False  # 2. Downloader  DOWNLOADER = &#39;scrapy.core.downloader.Downloader&#39;  DOWNLOADER_HTTPCLIENTFACTORY = &#39;scrapy.core.downloader.webclient.ScrapyHTTPClientFactory&#39;  DOWNLOADER_CLIENTCONTEXTFACTORY = &#39;scrapy.core.downloader.contextfactory.ScrapyClientContextFactory&#39;  DOWNLOADER_CLIENT_TLS_METHOD = &#39;TLS&#39; # Use highest TLS/SSL protocol version supported by the platform,                                       # also allowing negotiation  DOWNLOADER_STATS = True  RANDOMIZE_DOWNLOAD_DELAY = True  DOWNLOAD_DELAY = 0  DOWNLOAD_HANDLERS = {}  DOWNLOAD_HANDLERS_BASE = {      &#39;data&#39;: &#39;scrapy.core.downloader.handlers.datauri.DataURIDownloadHandler&#39;,      &#39;file&#39;: &#39;scrapy.core.downloader.handlers.file.FileDownloadHandler&#39;,      &#39;http&#39;: &#39;scrapy.core.downloader.handlers.http.HTTPDownloadHandler&#39;,      &#39;https&#39;: &#39;scrapy.core.downloader.handlers.http.HTTPDownloadHandler&#39;,      &#39;s3&#39;: &#39;scrapy.core.downloader.handlers.s3.S3DownloadHandler&#39;,      &#39;ftp&#39;: &#39;scrapy.core.downloader.handlers.ftp.FTPDownloadHandler&#39;,  }  DOWNLOAD_TIMEOUT = 180      # 3mins  DOWNLOAD_MAXSIZE = 1024*1024*1024   # 1024m  DOWNLOAD_WARNSIZE = 32*1024*1024    # 32m  DOWNLOAD_FAIL_ON_DATALOSS = True  # 3. Item Pipeline  ITEM_PROCESSOR = &#39;scrapy.pipelines.ItemPipelineManager&#39;  ITEM_PIPELINES = {}  ITEM_PIPELINES_BASE = {}  # 4. Spider Middleware  SPIDER_MIDDLEWARES = {}  SPIDER_MIDDLEWARES_BASE = {      # Engine side      &#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;: 50,      &#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;: 500,      &#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;: 700,      &#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;: 800,      &#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;: 900,      # Spider side  }  # 5. Downloader Middleware  DOWNLOADER_MIDDLEWARES = {}  DOWNLOADER_MIDDLEWARES_BASE = {      # Engine side      &#39;scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware&#39;: 100,      &#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;: 300,      &#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;: 350,      &#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;: 400,      &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;: 500,      &#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;: 550,      &#39;scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware&#39;: 560,      &#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;: 580,      &#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;: 590,      &#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;: 600,      &#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;: 700,      &#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;: 750,      &#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;: 850,      &#39;scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware&#39;: 900,      # Downloader side  }  # 6. Extension Middleware  EXTENSIONS = {}  EXTENSIONS_BASE = {      &#39;scrapy.extensions.corestats.CoreStats&#39;: 0,      &#39;scrapy.extensions.telnet.TelnetConsole&#39;: 0,      &#39;scrapy.extensions.memusage.MemoryUsage&#39;: 0,      &#39;scrapy.extensions.memdebug.MemoryDebugger&#39;: 0,      &#39;scrapy.extensions.closespider.CloseSpider&#39;: 0,      &#39;scrapy.extensions.feedexport.FeedExporter&#39;: 0,      &#39;scrapy.extensions.logstats.LogStats&#39;: 0,      &#39;scrapy.extensions.spiderstate.SpiderState&#39;: 0,      &#39;scrapy.extensions.throttle.AutoThrottle&#39;: 0,  }</code></pre></li><li><p>Output</p><pre><code class="lang-python">  # Feeds &amp; Exporter:  FEED_TEMPDIR = None  FEED_URI = None  FEED_URI_PARAMS = None  # a function to extend uri arguments  FEED_FORMAT = &#39;jsonlines&#39;  FEED_STORE_EMPTY = False  FEED_EXPORT_ENCODING = None  FEED_EXPORT_FIELDS = None  FEED_STORAGES = {}  FEED_STORAGES_BASE = {      &#39;&#39;: &#39;scrapy.extensions.feedexport.FileFeedStorage&#39;,      &#39;file&#39;: &#39;scrapy.extensions.feedexport.FileFeedStorage&#39;,      &#39;stdout&#39;: &#39;scrapy.extensions.feedexport.StdoutFeedStorage&#39;,      &#39;s3&#39;: &#39;scrapy.extensions.feedexport.S3FeedStorage&#39;,      &#39;ftp&#39;: &#39;scrapy.extensions.feedexport.FTPFeedStorage&#39;,  }  FEED_EXPORTERS = {}  FEED_EXPORTERS_BASE = {      &#39;json&#39;: &#39;scrapy.exporters.JsonItemExporter&#39;,      &#39;jsonlines&#39;: &#39;scrapy.exporters.JsonLinesItemExporter&#39;,      &#39;jl&#39;: &#39;scrapy.exporters.JsonLinesItemExporter&#39;,      &#39;csv&#39;: &#39;scrapy.exporters.CsvItemExporter&#39;,      &#39;xml&#39;: &#39;scrapy.exporters.XmlItemExporter&#39;,      &#39;marshal&#39;: &#39;scrapy.exporters.MarshalItemExporter&#39;,      &#39;pickle&#39;: &#39;scrapy.exporters.PickleItemExporter&#39;,  }  FEED_EXPORT_INDENT = 0  # file s3/gcs store  FILES_STORE_S3_ACL = &#39;private&#39;  FILES_STORE_GCS_ACL = &#39;&#39;  # image s3/gsc store  IMAGES_STORE_S3_ACL = &#39;private&#39;  IMAGES_STORE_GCS_ACL = &#39;&#39;  # ftp  FTP_USER = &#39;anonymous&#39;  FTP_PASSWORD = &#39;guest&#39;  FTP_PASSIVE_MODE = True</code></pre></li></ul><h3 id="header-12">数据类型</h3><ul><li><p><code>Request</code></p><ul><li><code>class scrapy.http.Request()</code></li><li>表示一个HTTP请求,由<code>Spider</code>生成,<code>Downloader</code>执行</li><li>属性：<ul><li><code>.url</code> : Request对应的请求URL地址</li><li><code>.method</code> : 对应的请求方法,’GET’ ‘POST’等</li><li><code>.headers</code>: 字典类型风格的请求头</li><li><code>.body</code> : 请求内容主体,字符串类型</li><li><code>.meta</code> : 用户添加的扩展信息,在Scrapy内部模块间传递信息使用</li><li><code>.encoding</code></li><li><code>.dont_filter</code>: 默认为False（表示要过滤掉重复Request）</li></ul></li><li>方法：<ul><li><code>.copy()</code></li><li><code>.replace()</code></li></ul></li><li>子类：<ul><li><code>FormRequest</code><ul><li><code>from_response()</code></li></ul></li><li><code>XmlRpcRequest</code></li></ul></li></ul></li><li><p><code>Response</code></p><ul><li><code>class scrapy.http.Response()</code></li><li>表示一个HTTP响应,由<code>Downloader</code>生成,<code>Spider</code>处理</li><li>属性：<ul><li><code>.url</code> : Response对应的URL地址</li><li><code>.status</code> : HTTP状态码,默认是200</li><li><code>.headers</code> : Response对应的头部信息</li><li><code>.body</code> : Response对应的内容信息,字符串类型 </li><li><code>.flags</code> : 一组标记</li><li><code>.request</code> : 产生Response类型对应的Request对象</li><li><code>.meta</code></li><li><code>.text</code></li></ul></li><li>方法：<ul><li><code>.copy()</code></li><li><code>.replace()</code></li><li><code>.urljoin()</code></li><li><code>.xpath()</code></li><li><code>.css()</code></li><li><code>.follow()</code></li></ul></li><li>子类：<ul><li><code>TextResponse</code><ul><li><code>.encoding</code></li><li>子类：<code>XmlResponse</code>，<code>HtmlResponse</code></li></ul></li></ul></li></ul></li><li><p><code>Item</code></p><ul><li><code>class scrapy.item.Item()</code></li><li>表示一个从HTML页面中提取的信息内容,由<code>Spider</code>生成,<code>Item Pipeline</code>处理</li><li>似字典类型,可按照字典类型操作</li></ul></li></ul><h2 id="header-13">Spider</h2><p>Refer <a href="http://doc.scrapy.org/en/latest/topics/spiders.html#scrapy-spider" target="_blank" rel="noopener">Scrapy Spider</a></p><h3 id="header-14">创建运行Spider</h3><ol><li><p>创建Spider： <code>scrapy genspider &lt;-t [template:default is basic]&gt; [spiderName] [domain]</code></p><ul><li>查看有效Spider template：<code>scrapy genspider --list</code><pre><code class="lang-bash">  $ scrapy genspider --list  Available templates:    basic    crawl    csvfeed    xmlfeed</code></pre></li><li>eg: 创建基础Spider<pre><code class="lang-bash">  $ scrapy genspider movie movie.douban.com  Created spider &#39;movie&#39; using template &#39;basic&#39; in module:    douban_demo.spiders.movie</code></pre></li><li>eg: 创建CrawlSpider:<pre><code class="lang-bash">  $ scrapy genspider -t crawl top250 movie.douban.com   Created spider &#39;top250&#39; using template &#39;crawl&#39; in module:    douban_demo.spiders.top250</code></pre></li></ul></li><li><p>运行Spider：<code>scrapy crawl [spiderName] &lt; -a [argName]=[argValue] &gt; &lt; -o [File]&gt; &lt;-t [Format] &gt;</code></p><ul><li><code>-a [argName=argValue]</code>: passed arguments to spider,Spiders can access arguments in their <code>__init__</code> methods</li><li><code>-o [File]</code>: dump scraped items into FILE,recognize file extension as format,also could use <code>-t [Format]</code> set output format</li><li><p>eg:</p><pre><code class="lang-bash">  $ scrapy crawl movie  # 传参给spider，spider中初始化函数中添加参数：  # def __init__(self, category=None, *args, **kwargs)  $ scrapy crawl movie -a category=top  # 输出到文件，根据文件后缀名，以对应格式输出  $ scrapy crawl movie -o movies.json     # [{},{},...]  $ scrapy crawl movie -o movies.jl       # {},{},... =&gt; recommend !  $ scrapy crawl movie -o movies.csv      # xxx,xxx,xxx,...  # -s,-L same as set in setting.py: FEED_EXPORT_ENCODING=&#39;utf-8&#39;, LOG_LEVEL = &#39;INFO&#39;  $ scrapy crawl movie -o movies.json -s FEED_EXPORT_ENCODING=utf-8 -L INFO  # -s CLOSESPIDER_ITEMCOUNT 控制最多爬取10个Item  $ scrapy crawl movie -o movies.json -s CLOSESPIDER_ITEMCOUNT=10  # use - for stdout  $ scrapy crawl movie -t json -o -&gt; movies.json</code></pre></li></ul></li></ol><h3 id="header-15">基类：Spider</h3><p><strong> Sample1: 自动生成的basic spider (<code>scrapy genspider movie movie.douban.com</code>) </strong></p><pre><code class="lang-python"># -*- coding: utf-8 -*-import scrapyclass MovieSpider(scrapy.Spider):    name = &#39;movie&#39;    allowed_domains = [&#39;movie.douban.com&#39;]    start_urls = [&#39;http://movie.douban.com/&#39;]    def parse(self, response):        pass</code></pre><p><strong> Sample2: 使用<code>start_urls/start_requests()</code> &amp; <code>parse(response)</code> =&gt; <code>self.logger/log</code>, <code>yield Item,Request</code> </strong></p><pre><code class="lang-python">class MySpider(scrapy.Spider):    name = &#39;example.com&#39;    allowed_domains = [&#39;example.com&#39;]    start_urls = [        &#39;http://www.example.com/1.html&#39;,        &#39;http://www.example.com/2.html&#39;,        &#39;http://www.example.com/3.html&#39;,    ]    #def start_requests(self):    #    yield scrapy.Request(&#39;http://www.example.com/1.html&#39;, self.parse)    #    yield scrapy.Request(&#39;http://www.example.com/2.html&#39;, self.parse)    #    yield scrapy.Request(&#39;http://www.example.com/3.html&#39;, self.parse)    def parse(self, response):        self.logger.info(&#39;A response from %s just arrived!&#39;, response.url)        # or self.log(&#39;....&#39;)        for h3 in response.xpath(&#39;//h3&#39;).getall():            yield {&quot;title&quot;: h3}        for href in response.xpath(&#39;//a/@href&#39;).getall():            yield scrapy.Request(response.urljoin(href), self.parse)</code></pre><p><strong> Note：</strong></p><ol><li>属性：<ul><li>name</li><li>allowed_domains</li><li>start_urls</li><li>custom_settings</li><li>crawler</li><li>settings</li><li>logger</li></ul></li><li>方法：<ul><li><strong>init</strong>(self, name=None, **kwargs)</li><li>from_crawler(cls, crawler, <em>args, *</em>kwargs)</li><li>start_requests(self)</li><li>parse(self,response)</li><li>log(self, message, level=logging.DEBUG, **kw])</li><li>closed(self,reason)</li></ul></li><li>Key:<ul><li><code>name</code></li><li><code>allowed_domains</code></li><li><code>custom_settings</code></li><li><code>start_urls=[]</code> / <code>start_requests(self)</code> =&gt; yield Request (Note: 这里产生的Request的dont_filter=True)</li><li><code>parse(self,response)</code> =&gt; yield Item,yield Request</li><li><code>closed(self,reason)</code> =&gt; Called when the spider closes(for the <code>spider_closed</code> signal)</li></ul></li></ol><h3 id="header-16">子类：CrawlSpider</h3><p><strong> Sample1：自动生成的crawl spider (<code>scrapy genspider -t crawl top250 movie.douban.com</code>) </strong></p><pre><code class="lang-python"># -*- coding: utf-8 -*-import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Ruleclass Top250Spider(CrawlSpider):    name = &#39;top250&#39;    allowed_domains = [&#39;movie.douban.com&#39;]    start_urls = [&#39;http://movie.douban.com/&#39;]    rules = (        Rule(LinkExtractor(allow=r&#39;Items/&#39;), callback=&#39;parse_item&#39;, follow=True),    )    def parse_item(self, response):        item = {}        #item[&#39;domain_id&#39;] = response.xpath(&#39;//input[@id=&quot;sid&quot;]/@value&#39;).get()        #item[&#39;name&#39;] = response.xpath(&#39;//div[@id=&quot;name&quot;]&#39;).get()        #item[&#39;description&#39;] = response.xpath(&#39;//div[@id=&quot;description&quot;]&#39;).get()        return item</code></pre><p><strong> Sample2：<code>rules=(...)</code> &amp; self def callback <code>parse_item(self,response)</code> </strong> </p><pre><code class="lang-python"># -*- coding: utf-8 -*-import scrapyfrom scrapy.linkextractors import LinkExtractorfrom scrapy.spiders import CrawlSpider, Rulefrom douban_demo.items import Top250Itemclass Top250Spider(CrawlSpider):    name = &#39;top250&#39;    allowed_domains = [&#39;movie.douban.com&#39;]    start_urls = [&#39;https://movie.douban.com/top250&#39;]    rules = (        Rule(            LinkExtractor(allow=r&#39;\?start=\d+.*&#39;,restrict_xpaths=&#39;//div[@class=&quot;paginator&quot;]&#39;)            , callback=&#39;parse_item&#39;, follow=True),    )    def parse_item(self, response):        print(response.url)        records=response.xpath(&#39;//ol[@class=&quot;grid_view&quot;]//div[@class=&quot;item&quot;]/div[@class=&quot;info&quot;]&#39;)        for r in records:            item=Top250Item()            link=r.xpath(&#39;./div[@class=&quot;hd&quot;]/a/@href&#39;).get()            item[&#39;id&#39;]=link.split(&#39;/&#39;)[-2]            item[&#39;title&#39;]=r.xpath(&#39;./div[@class=&quot;hd&quot;]/a/span[@class=&quot;title&quot;]/text()&#39;).extract_first()            item[&#39;rate&#39;]=r.xpath(&#39;./div[@class=&quot;bd&quot;]/div[@class=&quot;star&quot;]/span[@class=&quot;rating_num&quot;]/text()&#39;).extract_first()            item[&#39;quote&#39;]=r.xpath(&#39;./div[@class=&quot;bd&quot;]/p[@class=&quot;quote&quot;]/span/text()&#39;).extract_first()            yield item</code></pre><p><strong> Note: </strong></p><ol><li>属性：<ul><li>rules=()<ul><li><code>Rule(...)</code>: defines a certain behaviour for crawling the site (内部通过<code>request.meta</code>的<code>rule</code>传递)<ul><li><code>link_extractor</code>: <code>scrapy.linkextractors.LinkExtractor</code> defines how links will be extracted from each crawled page</li><li><code>callback=None</code>: callable,handle response =&gt; yield Item,yield Request</li><li><code>cb_kwargs=None</code>: dict, passed args to the callback function</li><li><code>follow=None</code>: True/False, if still extract the response with this rule (callback:None =&gt; default follow:True; els default follow:False)</li><li><code>process_links=None</code>: callable,used for filtering extract links.</li><li><code>process_request=None</code>: callable,used for filtering extract requests.</li></ul></li><li><code>LinkExtractor(...)</code>: used for extracting links from response<ul><li>allow=()</li><li>deny=()</li><li>allow_domains=()</li><li>deny_domains=()</li><li>deny_extensions=None</li><li>restrict_xpaths=()</li><li>restrict_css=()</li><li>tags=(‘a’, ‘area’)</li><li>attrs=(‘href’, )</li><li>canonicalize=False</li><li>unique=True</li><li>process_value=None</li><li>strip=True</li></ul></li></ul></li></ul></li><li>方法：<ul><li><code>parse_start_url(self, response)</code>： call for start_urls responses =&gt; yield <code>Item</code>/<code>Request</code></li><li><code>process_results(self, response, results)</code>：call for parse_start_url results =&gt; yield <code>Item</code>/<code>Request</code></li></ul></li><li>Key：<ul><li><code>start_urls=[]</code> / <code>start_requests(self)</code> =&gt; yield Request</li><li>for start requests responses: <code>parse_start_url(self,response)</code>,<code>process_results(self,respons,results)</code> =&gt; yield <code>Item</code>/<code>Request</code></li><li>after start requests follow the rules: <code>rules=(Rule(LinkExtractor(...),callback=&#39;parse_item&#39;,follow=True),...)</code> =&gt; yield <code>Request</code></li><li>def callback func(note:avoid using <code>parse</code> as callback): <code>parse_item(self,response)</code> =&gt; yield <code>Item</code>/<code>Request</code></li></ul></li></ol><p><strong> Sample: LinkExtractor </strong></p><pre><code class="lang-python">$ scrapy shell https://movie.douban.com/top250/...&gt;&gt;&gt; from scrapy.linkextractors import LinkExtractor&gt;&gt;&gt; le=LinkExtractor(allow=r&#39;\?start=\d+.*&#39;,restrict_xpaths=&#39;//div[@class=&quot;paginator&quot;]&#39;)&gt;&gt;&gt; le.extract_links(response)[Link(url=&#39;https://movie.douban.com/top250?start=25&amp;filter=&#39;, text=&#39;2&#39;, fragment=&#39;&#39;, nofollow=False), Link(url=&#39;https://movie.douban.com/top250?start=50&amp;filter=&#39;, text=&#39;3&#39;, fragment=&#39;&#39;, nofollow=False), Link(url=&#39;https://movie.douban.com/top250?start=75&amp;filter=&#39;, text=&#39;4&#39;, fragment=&#39;&#39;, nofollow=False), Link(url=&#39;https://movie.douban.com/top250?start=100&amp;filter=&#39;, text=&#39;5&#39;, fragment=&#39;&#39;, nofollow=False), Link(url=&#39;https://movie.douban.com/top250?start=125&amp;filter=&#39;, text=&#39;6&#39;, fragment=&#39;&#39;, nofollow=False), Link(url=&#39;https://movie.douban.com/top250?start=150&amp;filter=&#39;, text=&#39;7&#39;, fragment=&#39;&#39;, nofollow=False), Link(url=&#39;https://movie.douban.com/top250?start=175&amp;filter=&#39;, text=&#39;8&#39;, fragment=&#39;&#39;, nofollow=False), Link(url=&#39;https://movie.douban.com/top250?start=200&amp;filter=&#39;, text=&#39;9&#39;, fragment=&#39;&#39;, nofollow=False), Link(url=&#39;https://movie.douban.com/top250?start=225&amp;filter=&#39;, text=&#39;10&#39;, fragment=&#39;&#39;, nofollow=False)]&gt;&gt;&gt; le.allow_res[re.compile(&#39;\\?start=\\d+.*&#39;)]&gt;&gt;&gt; le.restrict_xpaths(&#39;//div[@class=&quot;paginator&quot;]&#39;,)</code></pre><h3 id="header-17">子类：XMLFeedSpider</h3><p><strong> Sample1：</strong></p><pre><code class="lang-python">from scrapy.spiders import XMLFeedSpiderfrom myproject.items import TestItemclass MySpider(XMLFeedSpider):    name = &#39;example.com&#39;    allowed_domains = [&#39;example.com&#39;]    start_urls = [&#39;http://www.example.com/feed.xml&#39;]    iterator = &#39;iternodes&#39;  # This is actually unnecessary, since it&#39;s the default value    itertag = &#39;item&#39;        # change it accordingly    def parse_node(self, response, node):        self.logger.info(&#39;Hi, this is a &lt;%s&gt; node!: %s&#39;, self.itertag, &#39;&#39;.join(node.getall()))        item = TestItem()        item[&#39;id&#39;] = node.xpath(&#39;@id&#39;).get()        item[&#39;name&#39;] = node.xpath(&#39;name&#39;).get()        item[&#39;description&#39;] = node.xpath(&#39;description&#39;).get()        return item</code></pre><p><strong> Sample2: 用xmlfeed爬取新浪博客的订阅信息(<code>scrapy genspider -crawl xmlfeed sinaRss sina.com.cn</code>) </strong></p><pre><code class="lang-xml">&lt;rss xmlns:sns=&quot;http://blog.sina.com.cn/sns&quot; version=&quot;2.0&quot;&gt;    &lt;channel&gt;        &lt;title&gt;科幻星系&lt;/title&gt;        &lt;description/&gt;        &lt;link&gt;http://blog.sina.com.cn/sfw&lt;/link&gt;        &lt;item&gt;            &lt;title&gt;手机进化凶猛背后的“凄凉”电池何时才能飞奔起来？&lt;/title&gt;            &lt;link&gt;http://blog.sina.com.cn/s/blog_4a46c3960102zgcw.html&lt;/link&gt;            &lt;description&gt;...&lt;/description&gt;        &lt;/item&gt;        &lt;item&gt;            &lt;title&gt;中国5G，如何避免重复投资？&lt;/title&gt;            &lt;link&gt;http://blog.sina.com.cn/s/blog_4a46c3960102zgcb.html&lt;/link&gt;            &lt;description&gt;...&lt;/description&gt;        &lt;/item&gt;        &lt;item&gt;            &lt;title&gt;与英特尔分道扬镳，苹果的5G业务掉队了吗？？&lt;/title&gt;            &lt;link&gt;http://blog.sina.com.cn/s/blog_4a46c3960102zgbj.html&lt;/link&gt;            &lt;description&gt;...&lt;/description&gt;        &lt;/item&gt;    &lt;/channel&gt;&lt;/rss&gt;</code></pre><pre><code class="lang-python"># -*- coding: utf-8 -*-from scrapy.spiders import XMLFeedSpiderclass SinaRssSpider(XMLFeedSpider):    name = &#39;sinaRss&#39;    allowed_domains = [&#39;sina.com.cn&#39;]    start_urls = [&#39;http://blog.sina.com.cn/rss/1246151574.xml&#39;]    iterator = &#39;iternodes&#39; # This is actually unnecessary, since it&#39;s the default value    itertag = &#39;item&#39;       # change it accordingly    def parse_node(self, response, selector):        item = {}        item[&#39;title&#39;] = selector.xpath(&#39;title/text()&#39;).get()        item[&#39;link&#39;] = selector.xpath(&#39;link/text()&#39;).get()        return item</code></pre><p>使用 <code>scrapy parse</code> 查看：</p><pre><code class="lang-bash">$ scrapy parse --spider=sinaRss http://blog.sina.com.cn/rss/1246151574.xml...&gt;&gt;&gt; STATUS DEPTH LEVEL 1 &lt;&lt;&lt;# Scraped Items  ------------------------------------------------------------[{&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zgcw.html&#39;,  &#39;title&#39;: &#39;手机进化凶猛背后的“凄凉”电池何时才能飞奔起来？&#39;}, {&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zgcb.html&#39;,  &#39;title&#39;: &#39;中国5G，如何避免重复投资？&#39;}, {&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zgbj.html&#39;,  &#39;title&#39;: &#39;与英特尔分道扬镳，苹果的5G业务掉队了吗？&#39;}, {&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zga4.html&#39;,  &#39;title&#39;: &#39;为什么越来越多的知名品牌热衷打造快闪店？&#39;}, {&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zg9a.html&#39;,  &#39;title&#39;: &#39;电商专供还是电商专坑,背后的这些猫腻你知道多少?&#39;}, {&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zg8n.html&#39;,  &#39;title&#39;: &#39;八年坎坷崎岖路：安卓平板为何终究是扶不起的“阿斗”&#39;}, {&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zg87.html&#39;,  &#39;title&#39;: &#39;火爆的直播能让电视购物焕发第二春吗？&#39;}, {&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zg7f.html&#39;,  &#39;title&#39;: &#39;各大厂商发力5G新机，未来全球手机市场或将呈现新格局&#39;}, {&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zg6r.html&#39;,  &#39;title&#39;: &#39;研发2nm芯片，台积电如何做到天下第一？&#39;}, {&#39;link&#39;: &#39;http://blog.sina.com.cn/s/blog_4a46c3960102zg6j.html&#39;,  &#39;title&#39;: &#39;芬兰采购中国无人机，值得骄傲吗？&#39;}]# Requests  -----------------------------------------------------------------[]</code></pre><p><strong> Note: </strong></p><ol><li>属性：<ul><li><code>iterator = &#39;iternodes&#39;</code><ul><li>‘iternodes’(default): a fast iterator based on regular expressions </li><li>‘html’: an iterator which uses Selector (load all DOM in memory)</li><li>‘xml’: an iterator which uses Selector (load all DOM in memory)</li></ul></li><li><code>itertag = &#39;item&#39;</code>: the name of the node (or element) to iterate in</li><li><code>namespaces = ()</code>: A list of <code>(prefix, uri)</code> tuples</li></ul></li><li>方法：<ul><li><code>parse(self, response)</code><ul><li>call <code>adapt_response(self, response)</code>: return <code>response</code></li><li>call <code>parse_nodes(self, response, nodes)</code> =&gt; yield <code>Item</code>/<code>Request</code><ul><li>call <code>parse_node(self, response, selector)</code>: return <code>Item</code>/<code>Request</code></li><li>call <code>process_results(self, response, results)</code>: filter <code>Item</code>/<code>Request</code></li></ul></li></ul></li></ul></li><li>Key:<ul><li>pre: <code>adapt_response(self, response)</code></li><li>process item: <code>parse_node(self, response, selector)</code></li><li>post: <code>process_results(self, response, results)</code></li></ul></li></ol><h3 id="header-18">子类：CSVFeedSpider</h3><p><strong> Sample：</strong></p><pre><code class="lang-python">from scrapy.spiders import CSVFeedSpiderfrom myproject.items import TestItemclass MySpider(CSVFeedSpider):    name = &#39;example.com&#39;    allowed_domains = [&#39;example.com&#39;]    start_urls = [&#39;http://www.example.com/feed.csv&#39;]    delimiter = &#39;;&#39;    quotechar = &quot;&#39;&quot;    headers = [&#39;id&#39;, &#39;name&#39;, &#39;description&#39;]    def parse_row(self, response, row):        self.logger.info(&#39;Hi, this is a row!: %r&#39;, row)        item = TestItem()        item[&#39;id&#39;] = row[&#39;id&#39;]        item[&#39;name&#39;] = row[&#39;name&#39;]        item[&#39;description&#39;] = row[&#39;description&#39;]        return item</code></pre><p><strong> Note: </strong></p><ol><li>属性：<ul><li><code>delimiter</code>: separator character for each field, default is <code>,</code></li><li><code>quotechar</code>: enclosure character for each field,default is <code>&quot;</code></li><li><code>headers</code>: A list of the column names in the CSV file</li></ul></li><li>方法：<ul><li><code>parse(self, response)</code><ul><li>call <code>adapt_response(self, response)</code>: return <code>response</code></li><li>call <code>parse_rows(self, response)</code> =&gt; yield <code>Item</code>/<code>Request</code><ul><li>call <code>parse_row(self, response, row)</code>: return <code>Item</code>/<code>Request</code></li><li>call <code>process_results(self, response, results)</code>: filter <code>Item</code>/<code>Request</code>   </li></ul></li></ul></li></ul></li><li>Key：<ul><li>pre: <code>adapt_response(self, response)</code></li><li>process item: <code>parse_node(self, response, row)</code></li><li>post: <code>process_results(self, response, results)</code></li></ul></li></ol><h3 id="header-19">子类：SitemapSpider</h3><p><strong> Sample1：</strong></p><pre><code class="lang-python">from scrapy.spiders import SitemapSpiderclass MySpider(SitemapSpider):    sitemap_urls = [&#39;http://www.example.com/robots.txt&#39;]    sitemap_rules = [        (&#39;/shop/&#39;, &#39;parse_shop&#39;),    ]    sitemap_follow = [&#39;/sitemap_shops&#39;]    def sitemap_filter(self, entries):        for entry in entries:            date_time = datetime.strptime(entry[&#39;lastmod&#39;], &#39;%Y-%m-%d&#39;)            if date_time.year &gt;= 2005:                yield entry    def parse_shop(self, response):        pass # ... scrape shop here ...</code></pre><p><strong> Sample2: 马蜂窝 sitemapindex </strong></p><ol><li><p>View <code>http://www.mafengwo.cn/sitemapIndex.xml</code>:</p><pre><code class="lang-xml"> &lt;sitemapindex xmlns=&quot;http://www.sitemaps.org/schemas/sitemap/0.9&quot;&gt;     &lt;sitemap&gt;         &lt;loc&gt;http://www.mafengwo.cn/article-0.xml&lt;/loc&gt;         &lt;lastmod&gt;2019-03-15&lt;/lastmod&gt;     &lt;/sitemap&gt;     &lt;sitemap&gt;         &lt;loc&gt;http://www.mafengwo.cn/article-1.xml&lt;/loc&gt;         &lt;lastmod&gt;2019-03-15&lt;/lastmod&gt;     &lt;/sitemap&gt;     &lt;sitemap&gt;         &lt;loc&gt;http://www.mafengwo.cn/article-2.xml&lt;/loc&gt;         &lt;lastmod&gt;2019-03-15&lt;/lastmod&gt;     &lt;/sitemap&gt;     &lt;sitemap&gt;         &lt;loc&gt;http://www.mafengwo.cn/articleList-0.xml&lt;/loc&gt;         &lt;lastmod&gt;2019-03-15&lt;/lastmod&gt;     &lt;/sitemap&gt;     &lt;sitemap&gt;         &lt;loc&gt;http://www.mafengwo.cn/shop-0.xml&lt;/loc&gt;         &lt;lastmod&gt;2019-03-15&lt;/lastmod&gt;     &lt;/sitemap&gt; &lt;/sitemapindex&gt;</code></pre></li><li><p>View <code>http://www.mafengwo.cn/shop-0.xml</code>:</p><pre><code class="lang-xml"> &lt;urlset xmlns=&quot;http://www.sitemaps.org/schemas/sitemap/0.9&quot;&gt;     &lt;url&gt;         &lt;loc&gt;http://www.mafengwo.cn/v100029&lt;/loc&gt;         &lt;lastmod&gt;2019-07-03 02:51:02&lt;/lastmod&gt;         &lt;changefreq&gt;weekly&lt;/changefreq&gt;         &lt;priority&gt;0.7&lt;/priority&gt;     &lt;/url&gt;     &lt;url&gt;         &lt;loc&gt;http://www.mafengwo.cn/v100027&lt;/loc&gt;         &lt;lastmod&gt;2019-07-03 02:51:02&lt;/lastmod&gt;         &lt;changefreq&gt;weekly&lt;/changefreq&gt;         &lt;priority&gt;0.7&lt;/priority&gt;     &lt;/url&gt;     &lt;url&gt;         &lt;loc&gt;http://www.mafengwo.cn/shop/mdd.php?mddid=10186&lt;/loc&gt;         &lt;lastmod&gt;2019-07-03 02:51:02&lt;/lastmod&gt;         &lt;changefreq&gt;weekly&lt;/changefreq&gt;         &lt;priority&gt;0.7&lt;/priority&gt;     &lt;/url&gt;     &lt;url&gt;         &lt;loc&gt;http://www.mafengwo.cn/shop/mdd.php?mddid=10030&lt;/loc&gt;         &lt;lastmod&gt;2019-07-03 02:51:02&lt;/lastmod&gt;         &lt;changefreq&gt;weekly&lt;/changefreq&gt;         &lt;priority&gt;0.7&lt;/priority&gt;     &lt;/url&gt; &lt;/urlset&gt;</code></pre></li><li><p>Create Spider: <code>scrapy genspider siteUpdate mafengwo.cn</code></p><pre><code class="lang-python"> # -*- coding: utf-8 -*- from scrapy.spiders import SitemapSpider class SiteUpdateSpider(SitemapSpider):     name = &#39;siteUpdate&#39;     allowed_domains = [&#39;mafengwo.cn&#39;]     sitemap_urls=[&#39;http://www.mafengwo.cn/sitemapIndex.xml&#39;]     sitemap_rules=[         (r&#39;/v\d+&#39;,&#39;parse_shop&#39;)         # for parse web page(eg:html)     ]     sitemap_follow=[r&#39;/shop-\d+.xml&#39;]   # for scrapy deep sitemap loc     def sitemap_filter(self, entries):          for entry in entries:              # 1. entry: sitemap object(              # &lt;sitemap&gt;              #  &lt;loc&gt;http://www.mafengwo.cn/shop-0.xml&lt;/loc&gt;              #  &lt;lastmod&gt;2019-07-03&lt;/lastmod&gt;              # &lt;/sitemap&gt;              # )              # 2. entry: url object(              # &lt;url&gt;              #  &lt;loc&gt;http://www.mafengwo.cn/v100292&lt;/loc&gt;              #  &lt;lastmod&gt;2019-07-03 02:51:02&lt;/lastmod&gt;              #  &lt;changefreq&gt;weekly&lt;/changefreq&gt;              #  &lt;priority&gt;0.7&lt;/priority&gt;              # &lt;/url&gt;              # )              if entry[&#39;loc&#39;].find(&#39;.xml&#39;)!=-1 or entry[&#39;loc&#39;].find(&#39;mddid&#39;)==-1:                  # print(&quot;entry&quot;, entry)                  yield entry     def parse_shop(self,response):         # get response from detail web url page(not sitemap loc)         # eg: http://www.mafengwo.cn/v100292  (html)         if response.status==200:             item={}             item[&#39;title&#39;]=response.css(&#39;.t1&#39;).xpath(&#39;string(.)&#39;).get()             # 使用split()去除`\xa0`，即`&amp;nbsp`（编码原因变成了`\xa0`字符，`strip()`和`replace()`均无法有效去除该字符）             intro=&quot;&quot;.join(response.css(&#39;.address p&#39;).xpath(&#39;string(.)&#39;).getall()).split()             item[&#39;introduce&#39;]=&quot; &quot;.join(intro)             return item</code></pre></li><li><p>execute <code>scrapy crawl siteUpdate -o mafengwo.jl -s FEED_EXPORT_ENCODING=utf-8</code></p></li></ol><p><strong> Note: </strong></p><ol><li>属性：<ul><li><code>sitemap_urls = ()</code>: 可以指向robots.txt（会从中提取Sitemap网址）／sitemap网址</li><li><code>sitemap_rules = [(&#39;&#39;, &#39;parse&#39;)]</code>： A list of tuples <code>(regex, callback)</code>，regex用来匹配Sitemap中列出的网址</li><li><code>sitemap_follow = [&#39;&#39;]</code>：适用于SitemapIndex文件，符合这里设置的regex的sitemap会深入抓取（默认<code>&#39;&#39;</code>，即都会）</li><li><code>sitemap_alternate_links = False</code>：是否url使用列出的备用链接</li></ul></li><li>方法：<ul><li><code>start_requests(self)</code>: or use <code>sitemap_urls</code><ul><li><code>sitemap_filter(self,entries)</code>: entries get from the response body</li><li>if <code>sitemapindex</code> &amp; match <code>site_follow</code>: yield <code>Request</code> for <code>sitemap</code></li><li>if <code>urlset</code> &amp; match <code>site_rules</code>: yield <code>Request</code> for web page =&gt; callback func: <code>parse</code> =&gt; yield <code>Item</code>/<code>Request</code></li></ul></li></ul></li></ol><h2 id="header-20">Item</h2><ul><li>属性：<ul><li>fields={}</li></ul></li><li>方法：<ul><li>copy(item)</li><li>keys()</li><li>values()</li><li>items()</li><li>pop(key)</li><li>clear()</li><li>get(key,default)</li><li>setdefault(key,default)</li><li>update(…)</li><li>popitem(…)</li></ul></li></ul><p><strong> Sample: </strong></p><ol><li><p>自定义一个Item类：</p><pre><code class="lang-python"> import scrapy class Product(scrapy.Item):     # `class Field(dict)`,即dict的一个封装容器     name = scrapy.Field()     price = scrapy.Field()     stock = scrapy.Field()     last_updated = scrapy.Field(serializer=str)</code></pre></li><li><p>常用方法：</p><pre><code class="lang-python"> # 1. Create item &gt;&gt;&gt; product = Product({&#39;name&#39;: &#39;Laptop PC&#39;, &#39;price&#39;: 1500}) # Product(name=&#39;Laptop PC&#39;, price=1500) &gt;&gt;&gt; product = Product({&#39;name&#39;: &#39;Laptop PC&#39;, &#39;lala&#39;: 1500}) # KeyError: &#39;Product does not support field: lala&#39; &gt;&gt;&gt; product = Product(name=&#39;Desktop PC&#39;, price=1000) # Product(name=&#39;Desktop PC&#39;, price=1000) # Create Item from Item &gt;&gt;&gt; product2 = Product(product)     # Product(name=&#39;Desktop PC&#39;, price=1000) &gt;&gt;&gt; product3 = product2.copy()      # Product(name=&#39;Desktop PC&#39;, price=1000) # Creating dicts from items &gt;&gt;&gt; dict(product)                   # create a dict from all populated values {&#39;price&#39;: 1000, &#39;name&#39;: &#39;Desktop PC&#39;} # 2. Get field values &gt;&gt;&gt; product[&#39;name&#39;] Desktop PC &gt;&gt;&gt; product.get(&#39;name&#39;) Desktop PC &gt;&gt;&gt; product[&#39;last_updated&#39;] Traceback (most recent call last):     ... KeyError: &#39;last_updated&#39; &gt;&gt;&gt; product.get(&#39;last_updated&#39;, &#39;not set&#39;) not set # 3. Set field value &gt;&gt;&gt; product[&#39;name&#39;] = &#39;IPad&#39; &gt;&gt;&gt; product[&#39;name&#39;] IPad &gt;&gt;&gt; product[&#39;lala&#39;] = &#39;test&#39; # setting unknown field Traceback (most recent call last):     ... KeyError: &#39;Product does not support field: lala&#39; # 4. Access all populated values &gt;&gt;&gt; product.keys() [&#39;price&#39;, &#39;name&#39;] &gt;&gt;&gt; product.values() [&quot;1000&quot;,&quot;IPad&quot;] &gt;&gt;&gt; product.items() [(&#39;price&#39;, 1000), (&#39;name&#39;, &#39;IPad&#39;)] # 5. Check if has value &gt;&gt;&gt; &#39;name&#39; in product  # is name field populated? True &gt;&gt;&gt; &#39;last_updated&#39; in product  # is last_updated populated? False # 6. Check if has field &gt;&gt;&gt; &#39;last_updated&#39; in product.fields  # is last_updated a declared field? True &gt;&gt;&gt; &#39;lala&#39; in product.fields  # is lala a declared field? False</code></pre></li></ol><h3 id="header-21">ItemLoader</h3><p>Refer <a href="http://doc.scrapy.org/en/latest/topics/loaders.html" target="_blank" rel="noopener">Item Loaders</a></p><p>方便对数据进行格式化，填充Item（字段赋值）<br>（Item提供保存抓取到数据的容器，Itemloader提供的是填充容器的机制）</p><p><strong> Sample1: </strong></p><ol><li><p>Item：</p><pre><code class="lang-python"> class MovieItem(scrapy.Item):     id = scrapy.Field()     title = scrapy.Field()     rate = scrapy.Field()     url = scrapy.Field()     cover = scrapy.Field()     playable = scrapy.Field()     crawl_date = scrapy.Field()</code></pre></li><li><p>Spider parse：</p><pre><code class="lang-python"> # -*- coding: utf-8 -*- import scrapy from douban.items import MovieItem from scrapy.loader import ItemLoader from scrapy.loader.processors import TakeFirst, MapCompose, Join import datetime class HotMovieSpider(scrapy.Spider):     name = &#39;hotMovie&#39;     allowed_domains = [&#39;movie.douban.com&#39;]     start_urls = [&#39;http://movie.douban.com/&#39;]     def parse(self, response):         # loader=ItemLoader(item=MovieItem(),response=response)         movieSelectors = response.xpath(&quot;//*[@id=&#39;screening&#39;]//li[@data-title]&quot;)         for s in movieSelectors:             loader = ItemLoader(item=MovieItem(), selector=s)             loader.add_css(&#39;title&#39;, &#39;::attr(data-title)&#39;, TakeFirst(), MapCompose(str.strip))             loader.add_xpath(&#39;rate&#39;, &#39;./@data-rate&#39;, TakeFirst())             loader.add_xpath(&#39;url&#39;, &quot;.//li[@class=&#39;poster&#39;]/a/@href&quot;, TakeFirst())             loader.add_xpath(&#39;cover&#39;, &quot;.//li[@class=&#39;poster&#39;]//img/@src&quot;, TakeFirst())             loader.add_css(&#39;id&#39;, &quot;::attr(data-trailer)&quot;, TakeFirst(), re=r&#39;\d+&#39;)             loader.add_value(&#39;crawl_date&#39;, datetime.datetime.now())             yield loader.load_item()</code></pre></li><li><p>excute <code>scrapy crawl hotMovie -o movie.jl</code>, yield item sample:</p><pre><code class="lang-bash"> # 注：提取数据时不管使用何种processors，都是列表形式填充到Item {     &quot;title&quot;: [&quot;蜘蛛侠：英雄远征 Spider-Man: Far From Home&quot;],      &quot;rate&quot;: [&quot;8.0&quot;],      &quot;url&quot;: [&quot;https://movie.douban.com/subject/26931786/?from=showing&quot;],      &quot;cover&quot;: [&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2558293106.jpg&quot;],      &quot;id&quot;: [&quot;26931786&quot;],     &quot;crawl_date&quot;: [&quot;2019-06-30 11:43:19&quot;] }</code></pre></li><li><p>字段值去除列表形式，eg:</p><pre><code class="lang-bash"> # 注：提取数据时不管使用何种processors，都是列表形式填充到Item {     &quot;title&quot;: &quot;蜘蛛侠：英雄远征 Spider-Man: Far From Home&quot;,      &quot;rate&quot;: &quot;8.0&quot;],      &quot;url&quot;: &quot;https://movie.douban.com/subject/26931786/?from=showing&quot;,      &quot;cover&quot;: &quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2558293106.jpg&quot;,      &quot;id&quot;: &quot;26931786&quot;,     &quot;crawl_date&quot;: &quot;2019-06-30 11:43:19&quot; }</code></pre><ul><li><p>方式一：修改<code>ItemLoader</code>的<code>default_output_processor</code>为<code>Join()</code>(或其他处理List的processor)</p><pre><code class="lang-python">  def parse(self,response):      # ...      # loader.add_value(&#39;crawl_date&#39;, datetime.datetime.now())      loader.add_value(&#39;crawl_date&#39;, str(datetime.datetime.now()))  # Join() only used for str List      loader.default_output_processor = Join()  # add for convert field value List to String      yield loader.load_item()</code></pre></li><li>方式二：配置<code>Item</code>的<code>Field(output_processor=xxxx)</code> (优先级高于ItemLoader中的default)<pre><code class="lang-python">  from scrapy.loader.processors import Join  class MovieItem(scrapy.Item):      # ...      title = scrapy.Field(output_processor=Join())</code></pre></li></ul></li></ol><p><strong> Note: </strong></p><ul><li>属性：<ul><li><code>item</code></li><li><code>selector</code></li><li><code>context</code></li><li><code>parent</code></li><li><code>default_item_class = Item</code></li><li><code>default_input_processor = Identity()</code></li><li><code>default_output_processor = Identity()</code></li><li><code>default_selector_class = Selector</code></li></ul></li><li>方法：<ul><li><code>__init__(self, item=None, selector=None, response=None, parent=None, **context)</code></li><li><code>add_value/replace_value(field_name,value,*processors,**kw)</code>, <code>get_value(value, *processors, **kw)</code></li><li><code>add_xpath/replace_xpath(field_name, xpath, *processors, **kw)</code>, <code>get_xpath(xpath, *processors, **kw)</code></li><li><code>add_css/replace_css(field_name, css, *processors, **kw)</code>, <code>get_css(css, *processors, **kw)</code></li><li><code>nested_xpath(xpath,**context)</code>, <code>nested_css(css,**context)</code> </li><li><code>get_input_processor/get_output_processor(field_name)</code></li><li><code>get_output_value/get_collected_values(field_name)</code></li><li><code>load_item()</code></li></ul></li><li><p>processors:</p><ul><li>内置的processor<ul><li><code>Identity</code>: 不进行任何处理，直接返回原来的数据</li><li><code>TakeFirst</code>: 返回第一个非空值</li><li><code>Join</code>: 返回用分隔符连接后的值（默认是使用空格连接）</li><li><code>Compose</code>： 返回多个函数组合处理后的数据（默认遇到None值时停止处理，可传入<code>stop_on_none = False</code>修改）</li><li><code>MapCompose</code>：与<code>Compose</code>类似，只是输入值是被迭代的处理传入各个函数</li><li><code>SelectJmes</code>：使用jsonpath,返回json对象某个field值（Requires <code>jmespath</code>） </li></ul></li><li>可直接使用内置的processors，也可使用自定义</li><li><p>在<code>Compose／MapCompose</code>中的函数也可使用lambda表达式，更简便</p><pre><code class="lang-python">  &gt;&gt;&gt; from scrapy.loader.processors import MapCompose  &gt;&gt;&gt; def filter_world(x):  ...     return None if x == &#39;world&#39; else x  &gt;&gt;&gt; proc = MapCompose(filter_world, str.upper)  &gt;&gt;&gt; proc([&#39;hello&#39;, &#39;world&#39;, &#39;this&#39;, &#39;is&#39;, &#39;scrapy&#39;])  &gt;&gt;&gt; [&#39;HELLO&#39;, &#39;THIS&#39;, &#39;IS&#39;, &#39;SCRAPY&#39;]  &gt;&gt;&gt; proc2 = MapCompose(lambda i : i.replace(&#39;=&#39;,&#39;:&#39;),str.strip)  &gt;&gt;&gt; proc2([&#39;a=1&#39;,&#39; b = Tom &#39;,&#39;c:OK&#39;])  [&#39;a:1&#39;, &#39;b : Tom&#39;, &#39;c:OK&#39;]</code></pre></li><li>使用：<ul><li>ItemLoader <code>add/replace/get_value/xpath/css(...)</code>提取数据时传入</li><li>ItemLoader <code>default_input/output_processor</code>配置</li><li>Item Field <code>input/output_processor</code>配置      </li></ul></li></ul></li><li>步骤：    <ul><li><code>add_value/add_xpath/add_css(...)</code>提取数据<ul><li>可传入processors处理提取的数据</li><li>可传入参数<code>re=&#39;regex&#39;</code>正则表达式来过滤匹配值</li><li>默认提取的数据，填充进去的对象都是List类型(即每个字段存储的都是List类型)</li></ul></li><li>=&gt; <code>input_processor</code> &amp; <code>output_processor</code>数据预处理（填充到Item的Field前的处理）<ul><li>优先使用Item对象的Field字段配置的<code>input/output_processor</code>，未配置则使用ItemLoader中的<code>default_input／output_processor</code></li><li>Item Loader中的<code>default_input／output_processor</code>默认都是<code>Identity</code>，即维持原样，不处理</li></ul></li><li>=&gt; <code>load_item()</code>填充到Item对象</li></ul></li></ul><h2 id="header-22">Middleware</h2><ol><li><p><code>MiddlewareManager</code>:</p><ul><li>方法：<ul><li>from_settings(cls, settings, crawler=None)</li><li>from_crawler(cls, crawler)</li><li>open_spider(self, spider)</li><li>close_spider(self, spider)</li></ul></li><li>子类：<ul><li><code>ItemPipelineManager</code>: item pipeline<ul><li>process_item(self, item, spider)</li></ul></li><li><code>SpiderMiddlewareManager</code>: spider middleware<ul><li>scrape_response(self, scrape_func, response, request, spider)<ul><li>process_spider_input(response)</li><li>process_spider_exception(_failure)</li><li>process_spider_output(result)</li></ul></li><li>process_start_requests(self, start_requests, spider)</li></ul></li><li><code>DownloaderMiddlewareManager</code>: downloader middleware<ul><li>download(self, download_func, request, spider)<ul><li>process_request(request)</li><li>process_response(response)</li><li>process_exception(_failure)</li><li>Note: @defer.inlineCallbacks</li></ul></li></ul></li><li><code>ExtensionManager</code>: extension</li></ul></li></ul></li><li><p>Project Middleware:</p><ul><li>ItemPipeline: <code>pipelines.py</code><ul><li><code>open_spider(self, spider)</code></li><li><code>process_item(self, item, spider)</code></li><li><code>close_spider(self, spider)</code></li></ul></li><li>SpiderMiddleware: <code>middleware.py</code><ul><li><code>spider_opened(self, spider)</code></li><li><code>process_start_requests(self, start_requests, spider)</code><ul><li>yied Request (no items)</li></ul></li><li><code>process_spider_input(self, response, spider)</code><ul><li>return None</li><li>or raise Exception</li></ul></li><li><code>process_spider_output(self, response, result, spider)</code><ul><li>yield Request/Item</li></ul></li><li><code>process_spider_exception(self, response, exception, spider)</code></li></ul></li><li>DownloaderMiddleware: <code>middleware.py</code>    <ul><li>spider_opened(self, spider)</li><li>process_request(self, request, spider): <ul><li>return None(continue processing)/Response/Request</li><li>or raise IgnoreRequest =&gt; call downloader middleware <code>process_exception()</code></li></ul></li><li>process_response(self, request, response, spider)<ul><li>return Response/Request</li><li>or raise IgnoreRequest</li></ul></li><li>process_exception(self, request, exception, spider)<ul><li>return None/Response/Request</li><li>Note: return None will continue processing this exception, return Response/Request stops process_exception() chain</li></ul></li></ul></li></ul></li><li><p><code>scrapy/settings/default_settings.py</code>:</p><pre><code class="lang-python"> ITEM_PIPELINES_BASE = {} SPIDER_MIDDLEWARES_BASE = {     # Engine side     &#39;scrapy.spidermiddlewares.httperror.HttpErrorMiddleware&#39;: 50,     &#39;scrapy.spidermiddlewares.offsite.OffsiteMiddleware&#39;: 500,     &#39;scrapy.spidermiddlewares.referer.RefererMiddleware&#39;: 700,     &#39;scrapy.spidermiddlewares.urllength.UrlLengthMiddleware&#39;: 800,     &#39;scrapy.spidermiddlewares.depth.DepthMiddleware&#39;: 900,     # Spider side } DOWNLOADER_MIDDLEWARES_BASE = {     # Engine side     &#39;scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware&#39;: 100,     &#39;scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware&#39;: 300,     &#39;scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware&#39;: 350,     &#39;scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware&#39;: 400,     &#39;scrapy.downloadermiddlewares.useragent.UserAgentMiddleware&#39;: 500,     &#39;scrapy.downloadermiddlewares.retry.RetryMiddleware&#39;: 550,     &#39;scrapy.downloadermiddlewares.ajaxcrawl.AjaxCrawlMiddleware&#39;: 560,     &#39;scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware&#39;: 580,     &#39;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&#39;: 590,     &#39;scrapy.downloadermiddlewares.redirect.RedirectMiddleware&#39;: 600,     &#39;scrapy.downloadermiddlewares.cookies.CookiesMiddleware&#39;: 700,     &#39;scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware&#39;: 750,     &#39;scrapy.downloadermiddlewares.stats.DownloaderStats&#39;: 850,     &#39;scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware&#39;: 900,     # Downloader side } EXTENSIONS_BASE = {     &#39;scrapy.extensions.corestats.CoreStats&#39;: 0,     &#39;scrapy.extensions.telnet.TelnetConsole&#39;: 0,     &#39;scrapy.extensions.memusage.MemoryUsage&#39;: 0,     &#39;scrapy.extensions.memdebug.MemoryDebugger&#39;: 0,     &#39;scrapy.extensions.closespider.CloseSpider&#39;: 0,     &#39;scrapy.extensions.feedexport.FeedExporter&#39;: 0,     &#39;scrapy.extensions.logstats.LogStats&#39;: 0,     &#39;scrapy.extensions.spiderstate.SpiderState&#39;: 0,     &#39;scrapy.extensions.throttle.AutoThrottle&#39;: 0, }</code></pre></li><li><p>project <code>settings.py</code>：</p><pre><code class="lang-python"> ITEM_PIPELINES = {     #&#39;douban.pipelines.DoubanPipeline&#39;: 300, } SPIDER_MIDDLEWARES = {     #&#39;douban.middlewares.DoubanSpiderMiddleware&#39;: 543, } DOWNLOADER_MIDDLEWARES = {     #&#39;douban.middlewares.DoubanDownloaderMiddleware&#39;: 543, } EXTENSIONS = {     #&#39;scrapy.extensions.telnet.TelnetConsole&#39;: None, }</code></pre></li></ol><h3 id="header-23">Item Pipeline</h3><ul><li>project下pipeline.py文件</li><li>不需要继承特定的基类，只需要实现特定的方法：<ul><li><code>open_spider</code>:爬虫运行前执行的操作</li><li><code>process_item</code>：爬虫获取到的每项item数据的处理方法</li><li><code>close_spider</code>:爬虫运行结束时执行的操作</li><li><code>from_crawler</code>：pipeline类方法，是创建item pipeline的回调方法，通常该方法用于读取setting中的配置参数</li><li>注：其中<code>process_item</code>必须实现</li></ul></li></ul><p><strong> Sample: </strong></p><ol><li><p>Duplicates filter</p><pre><code class="lang-python"> from scrapy.exceptions import DropItem class DuplicatesPipeline(object):     def __init__(self):         self.ids_seen = set()     def process_item(self, item, spider):         if item[&#39;id&#39;] in self.ids_seen:             raise DropItem(&quot;Duplicate item found: %s&quot; % item)         else:             self.ids_seen.add(item[&#39;id&#39;])             return item</code></pre></li><li><p>Take screenshot of item</p><pre><code class="lang-python"> # 从方法返回Deferred process_item() # Pipeline请求本地运行的Splash实例，获取项目网址的屏幕截图 # 在Deferred回调函数中保存截图，yield Item import scrapy import hashlib from urllib.parse import quote class ScreenshotPipeline(object):     &quot;&quot;&quot;Pipeline that uses Splash to render screenshot of     every Scrapy item.&quot;&quot;&quot;     SPLASH_URL = &quot;http://localhost:8050/render.png?url={}&quot;     def process_item(self, item, spider):         encoded_item_url = quote(item[&quot;url&quot;])         screenshot_url = self.SPLASH_URL.format(encoded_item_url)         request = scrapy.Request(screenshot_url)         dfd = spider.crawler.engine.download(request, spider)         dfd.addBoth(self.return_item, item)         return dfd     def return_item(self, response, item):         if response.status != 200:             # Error happened, return item.             return item         # Save screenshot to file, filename will be hash of url.         url = item[&quot;url&quot;]         url_hash = hashlib.md5(url.encode(&quot;utf8&quot;)).hexdigest()         filename = &quot;{}.png&quot;.format(url_hash)         with open(filename, &quot;wb&quot;) as f:             f.write(response.body)         # Store filename in item.         item[&quot;screenshot_filename&quot;] = filename         return item</code></pre></li><li><p>Write items to file</p><pre><code class="lang-python"> class ItemFilePipeline(object):     def __init__(self):         self.filepath=settings[&#39;ITEM_STORE&#39;]     def open_spider(self,spider):         filename=os.path.join(self.filepath,spider.name+&#39;.json&#39;)         self.file=open(filename,&#39;w&#39;,encoding=&#39;utf-8&#39;)         self.file.write(&#39;[\n&#39;)     def process_item(self,item,spider):         #print(item)         record=json.dumps(dict(item),ensure_ascii=False)         #print(record)         self.file.write(record+&quot;,\n&quot;)         return item     def close_spider(self,spider):         self.file.write(&#39;]\n&#39;)         self.file.close()</code></pre></li><li><p>Write items to MongoDB</p><pre><code class="lang-python"> class MongoPipeline(object):     def __init__(self):         self.mongo_uri=settings[&#39;MONGO_CONN_STR&#39;]         self.mongo_db=settings.get(&#39;MONGO_DB&#39;,&#39;scrapy&#39;)     def process_item(self, item, spider):         record=dict(item)         record[&#39;_id&#39;]=record[&#39;id&#39;]         record.pop(&#39;id&#39;)         result=self.db[spider.name].update_one({&#39;_id&#39;:record[&#39;_id&#39;]},{&#39;$set&#39;:record},upsert=True)         # print(result.raw_result)         return item     def open_spider(self,spider):         self.client = pymongo.MongoClient(self.mongo_uri)         self.db = self.client[self.mongo_db]         #print(self.client.list_database_names())         #print(self.db.list_collection_names())     def close_spider(self,spider):         self.client.close()</code></pre></li></ol><h3 id="header-24">Media Pipeline</h3><ol><li><p>FilesPipeline（继承自MediaPipeline）</p><ul><li><code>DEFAULT_FILES_URLS_FIELD = &#39;file_urls&#39;</code><ul><li>默认从Item的<code>file_urls=[]</code>（在Spider中抓取填充该字段）获取文件的URLs，下载文件</li><li>可在settings配置<code>FILES_URLS_FIELD</code>另外指定</li><li>也可在<code>get_media_requests(...)</code>中动态修改</li></ul></li><li><code>DEFAULT_FILES_RESULT_FIELD＝&#39;files&#39;</code><ul><li>默认将下载的文件信息存储到Item的<code>files={}</code>字段,包括<code>url</code>,<code>path</code>,<code>checksum</code></li><li>可在settings配置<code>FILES_RESULT_FIELD</code>另外指定</li><li>也可在<code>item_completed(...)</code>中动态修改</li></ul></li><li><code>EXPIRES=90</code><ul><li>文件多少天后过期（避免重复下载最近的文件）, 默认设置为90天后文件过期</li><li>可在settings配置<code>FILES_EXPIRES</code>另外指定</li></ul></li><li>settings中配置：<code>FILES_STORE</code> 指定文件存储位置文件系统(或者亚马逊S3）<ul><li>文件存储：<code>&lt;FILES_STORE&gt;/file_path(...)</code></li></ul></li><li>Overridable methods:<ul><li><code>get_media_requests(self, item, info)</code><ul><li>return Request (get from file_urls field)</li></ul></li><li><code>file_downloaded(self, response, request, info)</code><ul><li>persist_file</li><li>return checksum</li></ul></li><li><code>item_completed(self, results, item, info)</code><ul><li>store the files information which downloaded successfully into Item field</li><li>return item</li><li>eg:<pre><code class="lang-python">  # results＝(True, {dict}：  [(True,    {&#39;checksum&#39;: &#39;2b00042f7481c7b056c4b410d28f33cf&#39;,     &#39;path&#39;: &#39;full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg&#39;,     &#39;url&#39;: &#39;http://www.example.com/files/product1.pdf&#39;}),   (False,    Failure(...))]  # store the successful files information to Item files field  # item[&#39;files&#39;]:  [{&#39;checksum&#39;: &#39;2b00042f7481c7b056c4b410d28f33cf&#39;,     &#39;path&#39;: &#39;full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg&#39;,     &#39;url&#39;: &#39;http://www.example.com/files/product1.pdf&#39;}]</code></pre></li></ul></li><li><code>file_path(self, request, response=None, info=None)</code><ul><li>return path </li><li><code>&#39;full/%s%s&#39; % (media_guid, media_ext)</code></li><li>eg: <code>full/0a79c461a4062ac383dc4fade7bc09f1384a3910.jpg</code></li></ul></li></ul></li></ul></li><li><p>ImagesPipeline（继承自FilesPipeline）</p><ul><li><code>DEFAULT_IMAGES_URLS_FIELD=&#39;image_urls&#39;</code><ul><li>默认从Item的<code>image_urls=[]</code>（在Spider中抓取填充该字段）获取Image的URLs，下载Image</li><li>可在settings配置<code>IMAGES_URLS_FIELD</code>另外指定</li></ul></li><li><code>DEFAULT_IMAGES_RESULT_FIELD = &#39;images&#39;</code><ul><li>默认将下载的文件信息存储到Item的<code>images={}</code>字段,包括<code>url</code>,<code>path</code>,<code>checksum</code></li><li>可在settings配置<code>IMAGES_RESULT_FIELD</code>另外指定</li></ul></li><li><code>EXPIRES = 90</code><ul><li>文件多少天后过期（避免重复下载最近的文件）, 默认设置为90天后文件过期</li><li>可在settings配置<code>IMAGES_EXPIRES</code>另外指定</li></ul></li><li><code>MIN_WIDTH = 0</code>,<code>MIN_HEIGHT = 0</code><ul><li>Filtering out small images 只下载大于某长宽的图片</li><li>settings: <code>IMAGES_MIN_WIDTH</code>,<code>IMAGES_MIN_HEIGHT</code></li></ul></li><li><code>THUMBS = {}</code><ul><li>配置缩略图，默认无</li><li>可在settings中配置<code>IMAGES_THUMBS={size_name:(x,y),...}</code>另外指定，eg: <pre><code class="lang-python">  IMAGES_THUMBS = {      &#39;small&#39;: (50, 50),      &#39;big&#39;: (270, 270),  }  # 则下载的Images存储路径为（checksum相同）：  # &lt;IMAGES_STORE&gt;/full/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg  # &lt;IMAGES_STORE&gt;/thumbs/small/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg  # &lt;IMAGES_STORE&gt;/thumbs/big/63bbfea82b8880ed33cdb762aa11fab722a90a24.jpg</code></pre></li></ul></li><li>settings中配置： <code>IMAGES_STORE</code><ul><li>Image 原图存储：<code>&lt;IMAGES_STORE&gt;/file_path(...)</code></li><li>Image 缩略图存储：<code>&lt;IMAGES_STORE&gt;/thumb_path(...)</code></li></ul></li><li>methods:<ul><li>convert_image(self, image, size=None)<ul><li>将图片转换成常见格式（JPG）和模式（RGB）</li><li>修正Image大小(生成缩略图)</li></ul></li><li>get_images(self, response, request, info)<ul><li>调用convert_image转换image</li><li>yield path, image, buf （若配置了thumbs，也会yield对应转换后的images）</li></ul></li><li>get_media_requests(self, item, info)<ul><li>同FilesPipeline</li></ul></li><li>file_downloaded/image_downloaded(self, response, request, info)<ul><li>同FilesPipeline</li></ul></li><li>item_completed(self, results, item, info)<ul><li>同FilesPipeline</li></ul></li><li>file_path(self, request, response=None, info=None)<ul><li>return path</li><li><code>&#39;full/%s.jpg&#39; % (image_guid)</code></li></ul></li><li>thumb_path(self, request, thumb_id, response=None, info=None)<ul><li>return <code>&#39;thumbs/%s/%s.jpg&#39; % (thumb_id, thumb_guid)</code></li></ul></li></ul></li></ul></li><li><p>Note: 生效需要settings中配置<code>ITEM_PIPELINES = { ... }</code>      </p></li></ol><p><strong> Sample : Douban Top 250 Item and Cover(image) download </strong></p><ul><li>Store items to file</li><li>Download item’s cover (image)</li></ul><ol><li><p>item.py</p><pre><code class="lang-python"> class CoverItem(scrapy.Item):     name=scrapy.Field()     url=scrapy.Field()     path=scrapy.Field()     #images=scrapy.Field()     checksum=scrapy.Field()</code></pre></li><li><p>spider/cover.py</p><pre><code class="lang-python"> # -*- coding: utf-8 -*- import scrapy from scrapy.linkextractors import LinkExtractor from scrapy.spiders import CrawlSpider, Rule from douban_demo.items import CoverItem from scrapy.exceptions import DropItem class CoverSpider(CrawlSpider):     name = &#39;cover&#39;     allowed_domains = [&#39;movie.douban.com&#39;]     start_urls = [&#39;https://movie.douban.com/top250/&#39;]     rules = (         Rule(LinkExtractor(allow=r&#39;\?start=\d+.*&#39;,restrict_xpaths=&#39;//div[@class=&quot;paginator&quot;]&#39;), callback=&#39;parse_item&#39;, follow=True),     )     def parse_item(self, response):         print(response.url)         records=response.xpath(&#39;//ol[@class=&quot;grid_view&quot;]//div[@class=&quot;item&quot;]/div[@class=&quot;pic&quot;]//img&#39;)         for r in records:             item=CoverItem()             item[&#39;name&#39;]=r.xpath(&#39;./@alt&#39;).get()             item[&#39;url&#39;]=r.xpath(&#39;./@src&#39;).get()             print(item[&#39;url&#39;])             yield item</code></pre></li><li><p>pipeline.py</p><pre><code class="lang-python"> import scrapy from scrapy.pipelines.images import ImagesPipeline class CoverImagePipeline(ImagesPipeline):     def get_media_requests(self,item,info):         ext=item[&#39;url&#39;].split(&#39;.&#39;)[-1]         yield scrapy.Request(item[&#39;url&#39;],meta={&#39;image_name&#39;:item[&#39;name&#39;]+&quot;.&quot;+ext})     def item_completed(self,results, item, info):         #item[&#39;images&#39;]=results         r = [(x[&#39;path&#39;],x[&#39;checksum&#39;]) for ok, x in results if ok]         if not r:             raise DropItem(&quot;Item contains no images&quot;)         item[&#39;path&#39;] = r[0][0]         item[&#39;checksum&#39;]=r[0][1]         return item     def file_path(self,request,response=None,info=None):         return &#39;full/%s&#39; % request.meta[&#39;image_name&#39;] class CoverItemPipeline(object):     def __init__(self):         self.filepath=settings[&#39;COVER_FILE&#39;]     def open_spider(self,spider):         self.file=open(self.filepath,&#39;w&#39;,encoding=&#39;utf-8&#39;)     def process_item(self,item,spider):         #print(item)         record=json.dumps(dict(item),ensure_ascii=False)         #print(record)         self.file.write(record+&quot;\n&quot;)         return item     def close_spider(self,spider):         self.file.close()</code></pre></li><li><p>setting.py</p><pre><code class="lang-python"> COVER_FILE=&#39;D:\Space\python\images\cover.txt&#39; ITEM_PIPELINES = {     #&#39;douban_demo.pipelines.DoubanDemoPipeline&#39;: 300,     &#39;douban_demo.pipelines.CoverImagePipeline&#39;:310,     &#39;douban_demo.pipelines.CoverItemPipeline&#39;:320 } IMAGES_STORE=&#39;D:\Space\python\images&#39; IMAGES_EXPIRES = 30 IMAGES_THUMBS = {     &#39;small&#39;: (50, 50),     &#39;big&#39;: (250, 250), }</code></pre></li><li><p>run.py</p><pre><code class="lang-python"> from scrapy import cmdline cmdline.execute(&quot;scrapy crawl cover -s LOG_ENABLED=False&quot;.split()) #from scrapy.cmdline import execute #execute([&#39;scrapy&#39;, &#39;crawl&#39;, &#39;cover&#39;])</code></pre></li><li><p>execute</p><pre><code class="lang-bash"> scrapy crawl cover # or execute the run.py: # python run</code></pre></li><li><p>sample item：</p><pre><code class="lang-python">{  &quot;_id&quot; : &quot;1900841&quot;,  &quot;quote&quot; : &quot;别样人生。&quot;,  &quot;rate&quot; : &quot;9.1&quot;,  &quot;title&quot; : &quot;窃听风暴&quot;,  &quot;cover&quot; : {      &quot;name&quot; : &quot;窃听风暴&quot;,      &quot;url&quot; : &quot;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p1808872109.jpg&quot;,      &quot;path&quot; : &quot;full/窃听风暴.jpg&quot;,      &quot;checksum&quot; : &quot;c7ac16a9361d57718543ccea182543a9&quot;  } }</code></pre></li></ol><h3 id="header-25">Item Exporters</h3><p>数据导出器(Exporter)：</p><ul><li><p>scrapy内置了6中数据导出格式：<code>json</code>,<code>json lines</code>,<code>CSV</code>,<code>xml</code>,<code>pickle</code>,<code>marshal</code></p><pre><code class="lang-python">  FEED_EXPORTERS = {}  FEED_EXPORTERS_BASE = {      &#39;json&#39;: &#39;scrapy.exporters.JsonItemExporter&#39;,      &#39;jsonlines&#39;: &#39;scrapy.exporters.JsonLinesItemExporter&#39;,      &#39;jl&#39;: &#39;scrapy.exporters.JsonLinesItemExporter&#39;,      &#39;csv&#39;: &#39;scrapy.exporters.CsvItemExporter&#39;,      &#39;xml&#39;: &#39;scrapy.exporters.XmlItemExporter&#39;,      &#39;pickle&#39;: &#39;scrapy.exporters.PickleItemExporter&#39;,      &#39;marshal&#39;: &#39;scrapy.exporters.MarshalItemExporter&#39;,  }</code></pre></li><li><p>其他相关配置</p><pre><code class="lang-python">  FEED_TEMPDIR = None  FEED_URI = None             # 导出文件路径,eg: &#39;export_data\%(name)s.data&#39;（name自动替换成spider的name）  FEED_URI_PARAMS = None      # a function to extend uri arguments  FEED_FORMAT = &#39;jsonlines&#39;   # 导出文件的格式,即默认导出器类型，eg: &#39;csv&#39;  FEED_STORE_EMPTY = False  FEED_EXPORT_ENCODING = None # 导出文件的编码格式  FEED_EXPORT_FIELDS = None   # 默认导出全部字段,对字段进行排序,eg [&#39;name&#39;,&#39;author&#39;,&#39;price&#39;]  FEED_STORAGES = {}  FEED_STORAGES_BASE = {      &#39;&#39;: &#39;scrapy.extensions.feedexport.FileFeedStorage&#39;,      &#39;file&#39;: &#39;scrapy.extensions.feedexport.FileFeedStorage&#39;,      &#39;stdout&#39;: &#39;scrapy.extensions.feedexport.StdoutFeedStorage&#39;,      &#39;s3&#39;: &#39;scrapy.extensions.feedexport.S3FeedStorage&#39;,      &#39;ftp&#39;: &#39;scrapy.extensions.feedexport.FTPFeedStorage&#39;,  }  FEED_EXPORT_INDENT = 0</code></pre></li><li><p>基类：<code>BaseItemExporter</code></p><ul><li><code>serialize_field(self, field, name, value)</code></li><li><code>start_exporting(self)</code>：导出开始时被调用，用于初始化（类似pipelines的open_spider）</li><li><code>export_item(self, item)</code>：用于处理每项数据（类似pipelines的process_item），必须实现(默认raise NotImplementedError)</li><li><code>finish_exporting(self)</code>：导出完成后调用，用于收尾工作（类似pipelines的close_spider）</li></ul></li><li><p>子类：    </p><ul><li>JsonLinesItemExporter</li><li>JsonItemExporter</li><li>XmlItemExporter</li><li>CsvItemExporter</li><li>PickleItemExporter</li><li>MarshalItemExporter</li><li>PprintItemExporter</li><li>PythonItemExporter</li><li>JsonItemExporter Vs. JsonLinesItemExporter<ul><li>JsonItemExporter: 每次把数据添加到内存中，最后统一写入到磁盘文件中(耗内存),整个文件(<code>.json</code>)：<code>[{},{},...]</code></li><li>JsonLinesItemExporter：每次调用export_item的时候就把item存储到磁盘中（即一个字典一行，不耗内存），整个文件(<code>.jl</code>)：<code>{},{}...</code> (不是一个满足json格式的文件)</li></ul></li></ul></li><li>过程：<ul><li>运行爬虫（<code>scrapy crawl</code>）时指定<code>-o filepath</code> 导出到文件，则会使用Exporter</li><li>导出器类型：根据保存文件后缀确定，若指定<code>-t format</code>，则使用指定的</li><li>确定导出器类型后，再从settings中查找对应导出器进行导出</li><li>eg:<pre><code class="lang-bash">  $ scrapy crawl movie -o text.json  $ scrapy crawl movie -t json -o test.json</code></pre></li></ul></li></ul><h2 id="header-26">应用</h2><h3 id="header-27">基于Excel爬取</h3><pre><code class="lang-python"># -*- coding: utf-8 -*-import scrapyimport csvfrom scrapy.item import Item, Fieldfrom scrapy.loader import ItemLoaderfrom scrapy.loader.processors import Identity, Join, MapComposeimport datetimeclass MoviecsvSpider(scrapy.Spider):    name = &#39;movieCsv&#39;    allowed_domains = [&#39;movie.douban.com&#39;]    # start_urls = [&#39;http://movie.douban.com/&#39;]    def start_requests(self):        with open(&quot;movie.csv&quot;, &#39;rU&#39;) as f:            reader = csv.DictReader(f)            for line in reader:                print(line)                # OrderedDict([(&#39;src_url&#39;, &#39;http://movie.douban.com/&#39;),                # (&#39;src_selector&#39;, &#39;#screening li[data-title]&#39;),                # (&#39;title&#39;, &#39;::attr(data-title)&#39;),                # (&#39;rate&#39;, &#39;::attr(data-rate)&#39;),                # (&#39;url&#39;, &#39;li.poster&gt;a::attr(href)&#39;),                # (&#39;cover&#39;, &#39;li.poster img::attr(src)&#39;),                # (&#39;id&#39;, &#39;::attr(data-trailer)&#39;)]                yield scrapy.Request(url=line.pop(&#39;src_url&#39;), callback=self.parse, meta={&#39;rule&#39;: line})    def parse(self, response):        line = response.meta[&#39;rule&#39;]        src_selector = response.css(line.pop(&#39;src_selector&#39;))        for s in src_selector:            item = Item()            loader = ItemLoader(item=item, selector=s)            for name, exp in line.items():                if exp:                    item.fields[name] = Field()                    loader.add_css(name, exp)            item.fields[&#39;crawl_date&#39;] = Field() # Field(output_processor=Identity())            loader.add_value(&#39;crawl_date&#39;, datetime.datetime.now(), str)            loader.default_output_processor = Join()            yield loader.load_item()</code></pre><pre><code class="lang-bash">$ cat movie.csvsrc_url,src_selector,title,rate,url,cover,idhttp://movie.douban.com/,#screening li[data-title],::attr(data-title),::attr(data-rate),li.poster&gt;a::attr(href),li.poster img::attr(src),::attr(data-trailer)</code></pre><p>execute <code>scrapy crawl movieCsv -o movie.jl</code>, result sample:</p><pre><code class="lang-bash">{    &quot;title&quot;: &quot;监护风云 Jusqu’à la Garde&quot;,     &quot;rate&quot;: &quot;7.3&quot;,     &quot;url&quot;: &quot;https://movie.douban.com/subject/26995532/?from=showing&quot;,     &quot;cover&quot;: &quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2560052923.jpg&quot;,     &quot;id&quot;: &quot;https://movie.douban.com/subject/26995532/trailer&quot;,     &quot;crawl_date&quot;: &quot;2019-06-30 16:21:15.310231&quot;}</code></pre><h3 id="header-28">Login</h3><ul><li>Method1: spider start_requests: post form request to login first</li><li>Method2: login in web page, then copy the cookie to settings <code>DEFAULT_REQUEST_HEADERS={&#39;Cookie&#39;:&#39;xx=xxx...&#39;}</code></li></ul><p><strong> Sample: post form request to login in spider </strong></p><pre><code class="lang-python">class LessonSpider(scrapy.Spider):    name = &#39;lesson&#39;    allowed_domains = [&#39;class.121talk.cn&#39;]    start_urls=[&#39;https://class.121talk.cn/business/Index&#39;]    login_url=&#39;https://class.121talk.cn/business/Index/login&#39;    course_url=&#39;https://class.121talk.cn/business/Teachers/detail/id/3313&#39;    def __init__(self,username=None,password=None,*args, **kwargs):        super(LessonSpider, self).__init__(*args, **kwargs)        if username is None or password is None:            raise Exception(&#39;No username or password to login&#39;)        self.username=username        self.password=password    # login - method1:    def start_requests(self):        print(&#39;start_request&#39;)        yield scrapy.FormRequest(self.login_url            ,formdata={&#39;username&#39;:self.username,&#39;password&#39;:self.password}            ,callback=self.after_login)    # login - method2:    # def parse(self, response):    #     yield scrapy.FormRequest.from_response(response    #         ,url=self.login_url    #         ,formdata={&#39;username&#39;:self.username,&#39;password&#39;:self.password}    #         #,meta={&#39;cookiejar&#39;:1}    #         ,callback=self.after_login)    def after_login(self,response):        print(&#39;after_login&#39;)        print(&#39;login:&#39;,response)        print(&#39;login headers:&#39;,response.headers)        print(&#39;login cookie:&#39;,response.request.headers.getlist(&#39;Cookie&#39;))        print(&#39;login Set-Cookie:&#39;,response.headers.getlist(&#39;Set-Cookie&#39;))        result=json.loads(response.body)        print(&quot;login result:&quot;,result)        if result.get(&#39;status&#39;):            yield scrapy.Request(self.course_url            #,meta={&#39;cookiejar&#39;:response.meta[&#39;cookiejar&#39;]}            ,callback=self.parse_course)</code></pre><p>run:</p><pre><code class="lang-bash">$ scrapy crawl lesson -a username=xxxx -a password=xxx</code></pre><h3 id="header-29">常见问题</h3><ol><li><p>ImportError: No module named win32api.</p><pre><code class="lang-bash"> pip install pypiwin32</code></pre></li><li><p>AttributeError: ‘TelnetConsole’ object has no attribute ‘port’</p><pre><code> set TELNETCONSOLE_PORT setting to None (instead of default [6023, 6073]).  If that doesn&#39;t work and if you don&#39;t need the telnet console, simply disable the extension altogether with setting `TELNETCONSOLE_ENABLED=False`</code></pre></li><li><p>AttributeError: ‘module’ object has no attribute ‘F_GETFD’ </p><pre><code> 找到python3/Lib 中将fcntl.py改名成fcntl_ex.py再运行</code></pre></li><li><p>403 forbidden :  <a href="https://www.jianshu.com/p/31c7426c0da8" target="_blank" rel="noopener">https://www.jianshu.com/p/31c7426c0da8</a></p><pre><code class="lang-python"> # setting.py: set &#39;User-Agent&#39; #  method1: Override the default request headers: DEFAULT_REQUEST_HEADERS = {     &#39;User-Agent&#39;:&#39;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:60.0) Gecko/20100101 Firefox/60.0&#39;    #&#39;Accept&#39;: &#39;text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8&#39;,    #&#39;Accept-Language&#39;: &#39;en&#39;, } #  method2: USER_AGENT=&#39;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:60.0) Gecko/20100101 Firefox/60.0&#39;</code></pre></li><li><p>proxy:  <a href="https://blog.csdn.net/wuchenlhy/article/details/80683829" target="_blank" rel="noopener">https://blog.csdn.net/wuchenlhy/article/details/80683829</a></p><ul><li><p>method1: middlewares.py:</p><pre><code class="lang-python">  # downloader middleware:  class ProxyMiddleware(object):      def process_request(self, request, spider):          spider.logger.info(&#39;Set proxy.....&#39;)          request.meta[&#39;proxy&#39;] = &quot;http://xxxxxxx&quot;  # setting.py:  DOWNLOADER_MIDDLEWARES = {       &#39;douban_demo.middlewares.ProxyMiddleware&#39;:100  #    &#39;douban_demo.middlewares.DoubanDemoDownloaderMiddleware&#39;: 543,  }</code></pre></li><li>method2: spider/xxxx.py:<pre><code class="lang-python">  def start_requests(self):      start_url=&quot;http://xxx&quot;      return [scrapy.Request(start_url,callback=self.parse,meta={&#39;proxy&#39;:&#39;http://xxx&#39;})]</code></pre></li></ul></li><li><p>scrapy 爬虫使用FilesPipeline 下载 出现302</p><pre><code> [scrapy] WARNING: File (code: 302): Error downloading file from 在settings文件中没有设置MEDIA_ALLOW_REDIRECTS参数的话，默认会将值赋值成False  如果在下载的过程中如果有重定向过程，将不再重定向settings文件中  设置 MEDIA_ALLOW_REDIRECTS =True</code></pre></li></ol><h2 id="header-30">Scrapy-Redis</h2><ul><li>单机架构：本机Scheduler调度本机的一个Requests队列</li><li>分布式架构：各机Scheduler调度一个共享Requests队列</li><li><code>Scrapy-Redis</code>: <ul><li>在Scrapy基础上，重新实现了Scrapy的Scheduler，Queue等组建，使用Redis维护共享队列</li><li>如果Requests队列为空，则会从第一个启动的爬虫的start_urls开始；不为空，则继续从队列中调度出Request进行爬取解析</li><li>Refer <a href="https://github.com/rolando/scrapy-redis" target="_blank" rel="noopener">Github Scrapy-Redis</a></li><li>安装：<code>pip install scrapy-redis</code></li></ul></li></ul><h3 id="header-31">Sample1: use scrapy Spider</h3><ol><li><p>添加Scrapy-redis相关配置（settings.py）</p><pre><code class="lang-python"> # Start Scrapy-Redis Settings: SCHEDULER = &quot;scrapy_redis.scheduler.Scheduler&quot; DUPEFILTER_CLASS = &quot;scrapy_redis.dupefilter.RFPDupeFilter&quot; SCHEDULER_PERSIST = True #SCHEDULER_FLUSH_ON_START=False ITEM_PIPELINES = {     &#39;scrapy_redis.pipelines.RedisPipeline&#39;: 300 } #REDIS_ITEMS_KEY = &#39;%(spider)s:items&#39; #REDIS_ITEMS_SERIALIZER = &#39;json.dumps&#39; #REDIS_HOST = &#39;localhost&#39; #REDIS_PORT = 6379 #REDIS_PARAMS  = {} REDIS_URL = &#39;redis://root:123456@localhost:6379&#39; REDIS_ENCODING = &#39;utf-8&#39; #REDIS_START_URLS_KEY = &#39;%(name)s:start_urls&#39; #REDIS_START_URLS_AS_SET = False # End Srapy-Redis Settings!</code></pre></li><li><p>Spider：</p><pre><code class="lang-python"> # -*- coding: utf-8 -*- import scrapy from scrapy.linkextractors import LinkExtractor from scrapy.spiders import CrawlSpider, Rule from douban.items import Top250Item class Top250Spider(CrawlSpider):     name = &#39;top250&#39;     allowed_domains = [&#39;movie.douban.com&#39;]     start_urls = [&#39;https://movie.douban.com/top250&#39;]     rules = (         Rule(             LinkExtractor(allow=r&#39;\?start=\d+.*&#39;, restrict_xpaths=&#39;//div[@class=&quot;paginator&quot;]&#39;)             , callback=&#39;parse_item&#39;, follow=True),     )     def parse_item(self, response):         print(response.url)         records = response.xpath(&#39;//ol[@class=&quot;grid_view&quot;]//div[@class=&quot;item&quot;]&#39;)         for r in records:             infoPath = r.xpath(&#39;./div[@class=&quot;info&quot;]&#39;)             picPath = r.xpath(&#39;./div[@class=&quot;pic&quot;]//img&#39;)             item = Top250Item()             link = infoPath.xpath(&#39;./div[@class=&quot;hd&quot;]/a/@href&#39;).get()             item[&#39;id&#39;] = link.split(&#39;/&#39;)[-2]             item[&#39;title&#39;] = infoPath.xpath(&#39;./div[@class=&quot;hd&quot;]/a/span[@class=&quot;title&quot;]/text()&#39;).extract_first()             item[&#39;rate&#39;] = infoPath.xpath(                 &#39;./div[@class=&quot;bd&quot;]/div[@class=&quot;star&quot;]/span[@class=&quot;rating_num&quot;]/text()&#39;).extract_first()             item[&#39;quote&#39;] = infoPath.xpath(&#39;./div[@class=&quot;bd&quot;]/p[@class=&quot;quote&quot;]/span/text()&#39;).extract_first()             item[&#39;cover&#39;] = {                 &#39;name&#39;: picPath.xpath(&#39;./@alt&#39;).get()                 , &#39;url&#39;: picPath.xpath(&#39;./@src&#39;).get()             }             yield item</code></pre></li><li><p>执行 <code>scrapy crawl top250</code></p></li><li><p>查看Redis:</p><pre><code class="lang-bash"> # 1. Processing redis:6379&gt; keys * 1) &quot;top250:requests&quot; 2) &quot;top250:items&quot; 3) &quot;top250:dupefilter&quot; redis:6379&gt; type top250:requests zset redis:6379&gt; zrange top250:requests 0 -1 withscores 1) &quot;\x80\x04\x95a\x01\x00\x00\x00\x00\x00\x00}\x94(\x8c\x03url\x94\x8c1https://movie.douban.com/top250?start=225&amp;filter=\x94\x8c\bcallback\x94\x8c\x14_response_downloaded\x94\x8c\aerrback\x94N\x8c\x06method\x94\x8c\x03GET\x94\x8c\aheaders\x94}\x94C\aReferer\x94]\x94C\x1fhttps://movie.douban.com/top250\x94as\x8c\x04body\x94C\x00\x94\x8c\acookies\x94}\x94\x8c\x04meta\x94}\x94(\x8c\x04rule\x94K\x00\x8c\tlink_text\x94\x8c\nlxml.etree\x94\x8c\x15_ElementUnicodeResult\x94\x93\x94\x8c\x0210\x94\x85\x94\x81\x94\x8c\x05depth\x94K\x01u\x8c\t_encoding\x94\x8c\x05utf-8\x94\x8c\bpriority\x94K\x00\x8c\x0bdont_filter\x94\x89\x8c\x05flags\x94]\x94u.&quot; 2) &quot;0&quot; 3) &quot;\x80\x04\x95u\x01\x00\x00\x00\x00\x00\x00}\x94(\x8c\x03url\x94\x8c/https://movie.douban.com/top250?start=0&amp;filter=\x94\x8c\bcallback\x94\x8c\x14_response_downloaded\x94\x8c\aerrback\x94N\x8c\x06method\x94\x8c\x03GET\x94\x8c\aheaders\x94}\x94C\aReferer\x94]\x94C0https://movie.douban.com/top250?start=25&amp;filter=\x94as\x8c\x04body\x94C\x00\x94\x8c\acookies\x94}\x94\x8c\x04meta\x94}\x94(\x8c\x04rule\x94K\x00\x8c\tlink_text\x94\x8c\nlxml.etree\x94\x8c\x15_ElementUnicodeResult\x94\x93\x94\x8c\a&lt;\xe5\x89\x8d\xe9\xa1\xb5\x94\x85\x94\x81\x94\x8c\x05depth\x94K\x02u\x8c\t_encoding\x94\x8c\x05utf-8\x94\x8c\bpriority\x94K\x00\x8c\x0bdont_filter\x94\x89\x8c\x05flags\x94]\x94u.&quot; 4) &quot;0&quot; # 2. Done redis:6379&gt; keys * 1) &quot;top250:items&quot; 2) &quot;top250:dupefilter&quot; # 3. check requests footprinter (if set SCHEDULER_PERSIST=True): redis:6379&gt; type top250:dupefilter set redis:6379&gt; smembers top250:dupefilter  1) &quot;a6d5976e3143b3d8445e1f70a9250e05a2147ba0&quot;  2) &quot;1eaddf9a0730560642a4d1b2eb7e90ec26ea9c0e&quot;  3) &quot;7efe48768f3d586dcef1245e877eda8c9377385b&quot;  4) &quot;368a5242083cc9dab290d77cbe6a81107c882290&quot;  5) &quot;a7db0795dad78984b0e6622ab7699b53358be585&quot;  6) &quot;c4f38f7d4635b51955cc4129dbbba9c33b202242&quot;  7) &quot;5153c8f0e792e26f62c13e110e7a8a522392f817&quot;  8) &quot;41432c2cf211502120954135e7a9eacc24d15a30&quot;  9) &quot;0a8d961c5cf075725ce493439e64ecef9797cea6&quot; 10) &quot;e8f772a1cff43b734c16f4298dff62dc2ba2cfc7&quot; # 4. check items (if set scrapy_redis.pipelines.RedisPipeline): redis:6379&gt; type top250:items list redis:6379&gt; llen top250:items (integer) 250 lindex top250:items 0 &quot;{\&quot;id\&quot;: \&quot;1851857\&quot;, \&quot;title\&quot;: \&quot;\\u8759\\u8760\\u4fa0\\uff1a\\u9ed1\\u6697\\u9a91\\u58eb\&quot;, \&quot;rate\&quot;: \&quot;9.1\&quot;, \&quot;quote\&quot;: \&quot;\\u65e0\\u5c3d\\u7684\\u9ed1\\u6697\\u3002\&quot;, \&quot;cover\&quot;: {\&quot;name\&quot;: \&quot;\\u8759\\u8760\\u4fa0\\uff1a\\u9ed1\\u6697\\u9a91\\u58eb\&quot;, \&quot;url\&quot;: \&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p462657443.jpg\&quot;}}&quot;</code></pre></li></ol><h3 id="header-32">Sample2: 动态start_urls</h3><ol><li><p>Spider: 使用RedisSpider或者RedisCrawlSpider</p><pre><code class="lang-python"> from scrapy_redis.spiders import RedisCrawlSpider class Top250Spider(CrawlSpider):     name = &#39;top250&#39;     allowed_domains = [&#39;movie.douban.com&#39;]     # start_urls -- no need     # could get from Redis - set `redis_key=&#39;...&#39;`     # (default setting:`START_URLS_KEY=&#39;%(name)s:start_urls&#39;`)     # start_urls = [&#39;https://movie.douban.com/top250&#39;]     rules = (         Rule(             LinkExtractor(allow=r&#39;\?start=\d+.*&#39;, restrict_xpaths=&#39;//div[@class=&quot;paginator&quot;]&#39;)             , callback=&#39;parse_item&#39;, follow=True),     )     def parse_item(self, response):         #....</code></pre></li><li><p>execute <code>scrapy crawl top250</code> (it will keep running and waiting for the start_urls)</p></li><li>redis cli: <code>lpush key value</code> 插入start_urls<pre><code class="lang-bash"> redis:6379&gt; lpush top:start_urls https://movie.douban.com/top250 (integer) 1 redis:6379&gt; keys * 1) &quot;top:items&quot; 2) &quot;top:dupefilter&quot; 3) &quot;top:requests&quot; redis:6379&gt; keys * 1) &quot;top:items&quot; 2) &quot;top:dupefilter&quot;</code></pre></li></ol><h2 id="header-33">Scrapyd (for Deploy)</h2><ul><li><a href="https://scrapyd.readthedocs.io/en/latest/" target="_blank" rel="noopener">Scrapyd Doc</a></li><li>安装：<code>pip install scrapyd</code>,check: <code>scrapyd -h</code></li><li>启动：<code>scrapyd</code>,then could visit: <code>http://127.0.0.1:6800/</code></li></ul><h3 id="header-34">deploy project</h3><p>deploy tools: <a href="https://github.com/scrapy/scrapyd-client" target="_blank" rel="noopener">scrapyd-client</a></p><ul><li>安装：<code>pip install scrapyd-client</code></li><li>编辑项目的<code>scrapy.cfg</code>文件的<code>[deploy]</code>部分：<pre><code>  [deploy]  url = http://localhost:6800/  project = douban</code></pre></li><li>执行打包上传：<code>scrapyd-deploy</code>，then visit <code>http://localhost:6800/</code> to check<pre><code class="lang-python">  $ scrapyd-deploy  Packing version 1562566994  Deploying to project &quot;douban&quot; in http://localhost:6800/addversion.json  Server response (200):  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;project&quot;: &quot;douban&quot;, &quot;version&quot;: &quot;1562566994&quot;, &quot;spiders&quot;: 6}</code></pre></li></ul><h3 id="header-35">调用Scrapyd API（直接使用curl）</h3><ul><li>status<pre><code class="lang-bash">  $ curl http://localhost:6800/daemonstatus.json  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;pending&quot;: 0, &quot;running&quot;: 0, &quot;finished&quot;: 0}</code></pre></li><li><p>list &amp; delete</p><pre><code class="lang-bash">  # 1.1 list projects  $ curl http://localhost:6800/listprojects.json  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;projects&quot;: [&quot;douban&quot;, &quot;default&quot;]}  # 1.2 list project versions  $ curl http://localhost:6800/listversions.json?project=douban  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;versions&quot;: [&quot;1562566994&quot;, &quot;1562567575&quot;]}  # 1.3 list spiders  $ curl http://localhost:6800/listspiders.json?project=douban  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;spiders&quot;: [&quot;hotMovie&quot;, &quot;movieCsv&quot;, &quot;sinaRss&quot;, &quot;siteUpdate&quot;, &quot;top&quot;, &quot;top250&quot;]}  # 1.4 list jobs  $ curl http://localhost:6800/listjobs.json?project=douban  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;pending&quot;: [], &quot;running&quot;: [], &quot;finished&quot;: []}  $ curl http://localhost:6800/listjobs.json?project=douban | python -m json.tool    % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current Dload  Upload   Total   Spent    Left  Speed    0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--   100   106  100   106    0     0  14239      0 --:--:-- --:--:-- --:--:-- 15142  {      &quot;finished&quot;: [],      &quot;node_name&quot;: &quot;cj-Pro.local&quot;,      &quot;pending&quot;: [],      &quot;running&quot;: [],      &quot;status&quot;: &quot;ok&quot;  }  # 2.1 delete version  $ curl http://localhost:6800/delversion.json -d project=douban -d version=1562567575  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;}  $ curl http://localhost:6800/listversions.json?project=douban  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;versions&quot;: [&quot;1562566994&quot;]}  # 2.2 delte project  $ curl http://localhost:6800/delproject.json -d project=douban  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;}  $ curl http://localhost:6800/listprojects.json  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;projects&quot;: [&quot;default&quot;]}</code></pre></li><li><p>schedule &amp; cancel job (run &amp; stop spider)</p><pre><code class="lang-bash">  # 1. schedule  $ curl http://localhost:6800/schedule.json -d project=douban -d spider=top  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;jobid&quot;: &quot;73b3a61ca14d11e98c68f45c898fde83&quot;}  # 2. cancel  $ curl http://localhost:6800/cancel.json -d project=douban -d job=73b3a61ca14d11e98c68f45c898fde83  {&quot;node_name&quot;: &quot;cj-Pro.local&quot;, &quot;status&quot;: &quot;ok&quot;, &quot;prevstate&quot;: &quot;running&quot;}  # 3. list  $ curl http://localhost:6800/listjobs.json?project=douban | python -m json.tool    % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current     Dload  Upload   Total   Spent    Left  Speed    0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--   100   398  100   398    0     0  51883      0 --:--:-- --:--:-- --:--:-- 56857  {      &quot;finished&quot;: [          {              &quot;end_time&quot;: &quot;2019-04-08 14:56:05.819583&quot;,              &quot;id&quot;: &quot;73b3a61ca14d11e98c68f45c898fde83&quot;,              &quot;spider&quot;: &quot;top&quot;,              &quot;start_time&quot;: &quot;2019-04-08 14:56:04.831726&quot;          }      ],      &quot;node_name&quot;: &quot;cj-Pro.local&quot;,      &quot;pending&quot;: [],      &quot;running&quot;: [],      &quot;status&quot;: &quot;ok&quot;  }  # 4. log  $ curl http://127.0.0.1:6800/logs/douban/top/73b3a61ca14d11e98c68f45c898fde83.log  ....</code></pre></li></ul><h3 id="header-36">调用Scrapyd API（使用python-scrapyd-api包）</h3><ul><li>Refer <a href="https://github.com/djm/python-scrapyd-api" target="_blank" rel="noopener">Github</a></li><li>安装：<code>pip install python-scrapyd-api</code></li><li><p>使用：</p><pre><code class="lang-python">  &gt;&gt;&gt; from scrapyd_api import ScrapydAPI  &gt;&gt;&gt; scrapyd = ScrapydAPI(&#39;http://localhost:6800&#39;)  &gt;&gt;&gt; scrapyd.endpoints  {&#39;add_version&#39;: &#39;/addversion.json&#39;, &#39;cancel&#39;: &#39;/cancel.json&#39;, &#39;delete_project&#39;: &#39;/delproject.json&#39;, &#39;delete_version&#39;: &#39;/delversion.json&#39;, &#39;list_jobs&#39;:&#39;/listjobs.json&#39;, &#39;list_projects&#39;: &#39;/listprojects.json&#39;, &#39;list_spiders&#39;: &#39;/listspiders.json&#39;, &#39;list_versions&#39;: &#39;/listversions.json&#39;, &#39;schedule&#39;: &#39;/schedule.json&#39;}  # 1. list &amp; delete  &gt;&gt;&gt; scrapyd.list_projects()         # scrapyd.delete_project(&#39;project_name&#39;) -- return True/False  [&#39;douban&#39;, &#39;default&#39;]  &gt;&gt;&gt; scrapyd.list_versions(&#39;douban&#39;) # scrapyd.delete_version(&#39;project_name&#39;) -- return True/False  [&#39;1562569685&#39;]  &gt;&gt;&gt; scrapyd.list_spiders(&#39;douban&#39;)  [&#39;hotMovie&#39;, &#39;movieCsv&#39;, &#39;sinaRss&#39;, &#39;siteUpdate&#39;, &#39;top&#39;, &#39;top250&#39;]  &gt;&gt;&gt; scrapyd.list_jobs(&#39;douban&#39;)  {      &#39;node_name&#39;: &#39;cj-Pro.local&#39;,       &#39;pending&#39;: [],       &#39;running&#39;: [],       &#39;finished&#39;: [          {&#39;id&#39;: &#39;db52e176a14c11e98c68f45c898fde83&#39;, &#39;spider&#39;: &#39;top&#39;, &#39;start_time&#39;: &#39;2019-04-08 14:51:49.828399&#39;, &#39;end_time&#39;: &#39;2019-04-08 14:51:50.803166&#39;},           {&#39;id&#39;: &#39;73b3a61ca14d11e98c68f45c898fde83&#39;, &#39;spider&#39;: &#39;top&#39;, &#39;start_time&#39;: &#39;2019-04-08 14:56:04.831726&#39;, &#39;end_time&#39;: &#39;2019-04-08 14:56:05.819583&#39;},           {&#39;id&#39;: &#39;33402590a14f11e98c68f45c898fde83&#39;, &#39;spider&#39;: &#39;top&#39;, &#39;start_time&#39;: &#39;2019-04-08 15:08:34.827750&#39;, &#39;end_time&#39;: &#39;2019-04-08 15:13:33.890973&#39;}      ]  }  # schedule &amp; cancel  &gt;&gt;&gt; settings = {&#39;DOWNLOAD_DELAY&#39;: 2}  &gt;&gt;&gt; scrapyd.schedule(&#39;douban&#39;, &#39;top&#39;, settings=settings)  &#39;3df6469ca15211e98c68f45c898fde83&#39;  &gt;&gt;&gt; scrapyd.job_status(&#39;douban&#39;,&#39;3df6469ca15211e98c68f45c898fde83&#39;)  &#39;running&#39;  &gt;&gt;&gt; scrapyd.cancel(&#39;douban&#39;,&#39;3df6469ca15211e98c68f45c898fde83&#39;)  &#39;running&#39;  &gt;&gt;&gt; scrapyd.job_status(&#39;douban&#39;,&#39;3df6469ca15211e98c68f45c898fde83&#39;)  &#39;finished&#39;</code></pre></li></ul><h2 id="header-37">Reference</h2><ul><li><a href="https://github.com/sixDegree/python-scrapy-demo" target="_blank" rel="noopener">My Demo</a></li><li><a href="https://github.com/jackfrued/Python-100-Days/tree/master/Day66-75" target="_blank" rel="noopener">Python - 100天从新手到大师:爬虫开发</a></li><li><a href="https://blog.csdn.net/zwq912318834/article/details/79530828" target="_blank" rel="noopener">如何使用scrapy中的ItemLoader提取数据？</a></li><li><a href="https://cuiqingcai.com/4421.html" target="_blank" rel="noopener">小白进阶之Scrapy第四篇（图片下载管道篇）</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;Scrapy架构，常用命令，文档解析&lt;/li&gt;
&lt;li&gt;Spider: Spider,CrawlSpider,XMLFeedSpider,CSVFeedSpider,SitemapSpider&lt;/li&gt;
&lt;li&gt;Item,ItemLoader&lt;/li&gt;
&lt;li&gt;Middleware: ItemPipeline,Spider/DownloaderMiddleware,Item Exporters&lt;/li&gt;
&lt;li&gt;应用示例：基于Excel爬取，Login,常见问题&lt;/li&gt;
&lt;li&gt;Scrapy-Redis 分布式架构（共享抓取队列）&lt;/li&gt;
&lt;li&gt;Scrapyd（分布式发布）&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Python" scheme="http://sixdegree.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python 爬虫之Requests &amp; AioHttp</title>
    <link href="http://sixdegree.github.io/2019/03/18/Python-Requests-AioHttp.html"/>
    <id>http://sixdegree.github.io/2019/03/18/Python-Requests-AioHttp.html</id>
    <published>2019-03-17T16:00:00.000Z</published>
    <updated>2019-07-08T15:46:37.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>requests</li><li>aiohttp</li><li>demo: download files</li></ul><a id="more"></a><h2 id="header-1">Requests Introduction</h2><ul><li>第三方的HTTP客户端库，<a href="http://www.python-requests.org/en/master/" target="_blank" rel="noopener">官网</a>| <a href="http://docs.python-requests.org/zh_CN/latest/index.html" target="_blank" rel="noopener">Doc</a></li><li><p>支持<code>HTTP</code>连接保持和连接池,支持使用<code>cookie</code>保持会话，文件上传，自动确定响应内容的编码，国际化的URL，POST数据自动编码等</p></li><li><p>vs. <code>urllib</code>:</p><ul><li><code>urllib</code>,<code>urllib2</code>,<code>urllib3</code>是python原生类库</li><li><code>urllib</code> 与 <code>urllib2</code> 是两个相互独立的模块(在python3中<code>urllib2</code>被改为<code>urllib.request</code>)</li><li><code>requests</code>库使用了<code>urllib3</code>，支持连接保持（eg:多次请求重复使用一个<code>socket</code>)，更方便<br>  <img src="/2019/03/18/requests-urllib.png" alt=" urllib vs. requests "></li></ul></li><li><p>安装</p><pre><code class="lang-bash">pip install requests</code></pre></li><li><p>使用</p><pre><code class="lang-python">import requestsresponse=requests.get(&#39;http://www.baidu.com&#39;)print(type(response))print(response.status_code,response.reason)print(response.encoding,response.apparent_encoding)print(response.request.headers)print(response.headers)print(response.content)</code></pre></li><li><p>注：</p><ul><li><code>Requests</code>默认的传输适配器使用<code>阻塞IO</code>，<code>Response.content</code>属性会阻塞，直到整个响应下载完成(数据流功能允许每次接受少量的一部分响应，但依然是阻塞式的)</li><li>非阻塞可以考虑其他异步框架，例如<code>grequests</code>，<code>requests-futures</code></li></ul></li></ul><h2 id="header-2">Requests 基础对象和方法</h2><h3 id="header-3">Request 对象</h3><ul><li><code>requests.request(method,url,**kwargs)</code> 构造一个请求,支撑以下各方法的基础方法(method:对应get/put/post等7种)</li><li><code>requests.get(url,params=None,**kwargs)</code></li><li><code>requests.head(url,**kwargs)</code></li><li><code>requests.post(url,data=None,json=None,**kwargs)</code></li><li><code>requests.put/patch(url,data=None,**kwargs)</code></li><li><code>requests.delete(url,**kwargs)</code></li><li>方法参数：<ul><li><code>url</code></li><li><code>params</code>: 作为参数增加到url中 (字典或字节流格式)</li><li><code>data</code>: 作为Request的内容 (字典、字节序列或文件)</li><li><code>json</code>: 作为Request的内容 (JSON格式的数据)</li><li><code>headers</code>: HTTP定制头 (字典)</li><li><code>cookies</code> : Request中的cookie (字典或CookieJar)</li><li><code>auth</code> : 支持HTTP认证功能 (元组)</li><li><code>files</code> : 传输文件 (字典类型)</li><li><code>timeout</code> : 设定超时时间(秒为单位),默认为None，即一直等待</li><li><code>proxies</code> : 设定访问代理服务器,可以增加登录认证(字典类型)</li><li><code>allow_redirects</code> : 重定向开关 (True/False,默认为True)</li><li><code>stream</code> : 获取内容立即下载开关 (True/False)<ul><li>False(默认): 表示立即开始下载文件并存放到内存当中(若文件过大就会导致内存不足的情况)</li><li>True: 推迟下载响应体直到访问 Response.content 属性（请求连接不会被关闭直到读取所有数据或者调用<code>Response.close</code>，使用<code>with</code> 语句发送请求，这样可以保证请求一定会被关闭）</li></ul></li><li><code>verify</code> : 认证SSL证书开关 (True/False,默认为True)</li><li><code>cert</code> : 本地SSL证书路径</li></ul></li></ul><h3 id="header-4">Response 对象</h3><ul><li>类： <code>&lt;class &#39;requests.models.Response&#39;&gt;</code></li><li>状态<ul><li><code>response.status_code</code></li><li><code>response.reason</code></li></ul></li><li>body<ul><li><code>response.raw</code> (原始响应内容 <code>urllib3.response.HTTPResponse</code>, raw.read(),need set <code>stream=True</code> when request)</li><li><code>response.content</code> (二进制形式)</li><li><code>response.text</code> (字符串形式,根据encoding显示网页内容)</li><li><code>response.json()</code> (JSON格式，字典类型)</li></ul></li><li>header<ul><li><code>response.headers</code></li><li><code>request.headers</code></li></ul></li><li>编码<ul><li><code>response.encoding</code> (从HTTP header中猜测的响应内容编码方式)</li><li><code>resposne.apparent_encoding</code> (encoding的备选,从网页内容中分析出的响应内容编码方式) </li></ul></li><li><code>response.raise_for_status()</code><ul><li>在方法内部判断是否等于<code>200</code>,不是则抛出<code>requests.HTTPError</code>异常</li><li>注：不需要增加额外的<code>if</code>语句,该语句便于利用<code>try except</code>进行异常处理</li></ul></li></ul><h3 id="header-5">Exception 对象</h3><ul><li><code>requests.HTTPError</code> : HTTP错误异常</li><li><code>requests.URLRequired</code> : URL缺失异常</li><li><code>requests.Timeout</code> : 请求URL超时,产生超时异常</li><li><code>requests.ConnectTimeout</code> : 连接远程服务器超时异常</li><li><code>requests.ConnectionError</code> : 网络连接错误异常,如DNS查询失败、拒绝连接等</li><li><code>requests.TooManyRedirects</code> 超过最大重定向次数,产生重定向异常</li></ul><h2 id="header-6">Requests 基础示例</h2><p><strong> Visit <code>http://httpbin.org/</code> </strong></p><h3 id="header-7"><code>requests.get</code></h3><pre><code class="lang-python">&gt;&gt;&gt; r=requests.get(&#39;http://httpbin.org/get&#39;)&gt;&gt;&gt; type(r)&lt;class &#39;requests.models.Response&#39;&gt;&gt;&gt;&gt; r.status_code,r.reason(200,&#39;OK&#39;)&gt;&gt;&gt; r.encoding,r.apparent_encoding(None, &#39;ascii&#39;)&gt;&gt;&gt; r.headers{&#39;Access-Control-Allow-Credentials&#39;: &#39;true&#39;, &#39;Access-Control-Allow-Origin&#39;: &#39;*&#39;, &#39;Content-Encoding&#39;: &#39;gzip&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;, &#39;Date&#39;: &#39;Thu, 21 Mar 2019 16:40:42 GMT&#39;, &#39;Server&#39;: &#39;nginx&#39;, &#39;Content-Length&#39;: &#39;184&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}&gt;&gt;&gt; r.request.headers{&#39;User-Agent&#39;: &#39;python-requests/2.21.0&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}&gt;&gt;&gt; r.json(){  &quot;args&quot;: {},  &quot;headers&quot;: {    &quot;Accept&quot;: &quot;*/*&quot;,    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;,    &quot;Host&quot;: &quot;httpbin.org&quot;,    &quot;User-Agent&quot;: &quot;python-requests/2.21.0&quot;  },  ...}</code></pre><h3 id="header-8"><code>requests.head</code></h3><pre><code class="lang-python">&gt;&gt;&gt; r=requests.head(&#39;http://httpbin.org/get&#39;)&gt;&gt;&gt; r.text&#39;&#39;&gt;&gt;&gt; r.headers{&#39;Access-Control-Allow-Credentials&#39;: &#39;true&#39;, &#39;Access-Control-Allow-Origin&#39;: &#39;*&#39;, &#39;Content-Encoding&#39;: &#39;gzip&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;, &#39;Date&#39;: &#39;Tue, 19 Mar 2019 13:16:24 GMT&#39;, &#39;Server&#39;: &#39;nginx&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}</code></pre><h3 id="header-9"><code>requests.post</code>+<code>data</code>/<code>json</code></h3><pre><code class="lang-python"># `data={...}` # 字典,自动编码为form(表单)# content-type: application/x-www-form-urlencoded# request body： key1=value1&amp;key2=value2&gt;&gt;&gt; record={&#39;key1&#39;:&#39;value1&#39;,&#39;key2&#39;:&#39;value2&#39;}&gt;&gt;&gt; r=requests.post(&#39;http://httpbin.org/post&#39;,data=record)&gt;&gt;&gt; r.request.headers[&#39;content-type&#39;]application/x-www-form-urlencoded&gt;&gt;&gt; r.json(){&#39;args&#39;: {}, &#39;data&#39;: &#39;&#39;, &#39;files&#39;: {}, &#39;form&#39;: {&#39;key1&#39;: &#39;value1&#39;, &#39;key2&#39;: &#39;value2&#39;}, &#39;headers&#39;: {&#39;Accept&#39;: &#39;*/*&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Content-Length&#39;: &#39;23&#39;, &#39;Content-Type&#39;: &#39;application/x-www-form-urlencoded&#39;, &#39;Host&#39;: &#39;httpbin.org&#39;, &#39;User-Agent&#39;: &#39;python-requests/2.21.0&#39;}, &#39;json&#39;: None, ...}# `data=&#39;...&#39;`# 字符串,自动编码为data# request body: &#39;ABC123&#39;&gt;&gt;&gt; record=&quot;ABC123&quot;&gt;&gt;&gt; r=requests.post(&#39;http://httpbin.org/post&#39;,data=record)&gt;&gt;&gt; r.request.headers.get(&#39;content-type&#39;,None)None&gt;&gt;&gt; r.json(){&#39;args&#39;: {}, &#39;data&#39;: &#39;ABC123&#39;, &#39;files&#39;: {}, &#39;form&#39;: {}, &#39;headers&#39;: {&#39;Accept&#39;: &#39;*/*&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Content-Length&#39;: &#39;6&#39;, &#39;Host&#39;: &#39;httpbin.org&#39;, &#39;User-Agent&#39;: &#39;python-requests/2.21.0&#39;}, &#39;json&#39;: None, ...}# `json={...}`# 字典# content-type: application/json# request body: {&#39;key1&#39;: &#39;value1&#39;, &#39;key2&#39;: &#39;value2&#39;}&gt;&gt;&gt; record={&#39;key1&#39;:&#39;value1&#39;,&#39;key2&#39;:&#39;value2&#39;}&gt;&gt;&gt; r = requests.request(&#39;POST&#39;, &#39;http://httpbin.org/post&#39;, json=record)&gt;&gt;&gt; r.request.headers[&#39;Content-Type&#39;]application/json&gt;&gt;&gt; r.json(){&#39;args&#39;: {}, &#39;data&#39;: &#39;{&quot;key1&quot;: &quot;value1&quot;, &quot;key2&quot;: &quot;value2&quot;}&#39;, &#39;files&#39;: {}, &#39;form&#39;: {}, &#39;headers&#39;: {&#39;Accept&#39;: &#39;*/*&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Content-Length&#39;: &#39;36&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;, &#39;Host&#39;: &#39;httpbin.org&#39;, &#39;User-Agent&#39;: &#39;python-requests/2.21.0&#39;}, &#39;json&#39;: {&#39;key1&#39;: &#39;value1&#39;, &#39;key2&#39;: &#39;value2&#39;}, ...}</code></pre><h3 id="header-10">kwargs: <code>params</code></h3><pre><code class="lang-python">&gt;&gt;&gt; kv = {&#39;key1&#39;: &#39;value1&#39;, &#39;key2&#39;: &#39;value2&#39;}&gt;&gt;&gt; r = requests.request(&#39;GET&#39;, &#39;http://httpbin.org/get&#39;, params=kv) &gt;&gt;&gt; r.urlhttp://httpbin.org/get?key1=value1&amp;key2=value2&gt;&gt;&gt; r.json(){&#39;args&#39;: {&#39;key1&#39;: &#39;value1&#39;, &#39;key2&#39;: &#39;value2&#39;}, &#39;headers&#39;: {&#39;Accept&#39;: &#39;*/*&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Host&#39;: &#39;httpbin.org&#39;, &#39;User-Agent&#39;: &#39;python-requests/2.21.0&#39;}, &#39;origin&#39;: &#39;117.83.222.100, 117.83.222.100&#39;, &#39;url&#39;: &#39;https://httpbin.org/get?key1=value1&amp;key2=value2&#39;}</code></pre><h3 id="header-11">kwargs: <code>auth</code></h3><pre><code class="lang-python">import requestsEndpoint=&quot;http://httpbin.org&quot;# 1. basic authr=requests.request(&#39;GET&#39;,Endpoint+&#39;/basic-auth/Tom/Tom111&#39;)print(r.status_code,r.reason)# 401 UNAUTHORIZEDr=requests.request(&#39;GET&#39;,Endpoint+&#39;/basic-auth/Tom/Tom111&#39;,auth=(&#39;Tom&#39;,&#39;Tom123&#39;))print(r.status_code,r.reason)# 401 UNAUTHORIZEDr=requests.request(&#39;GET&#39;,Endpoint+&#39;/basic-auth/Tom/Tom123&#39;,auth=(&#39;Tom&#39;,&#39;Tom123&#39;))print(r.status_code,r.reason)print(r.request.headers)print(r.text)# 200 OK# {&#39;User-Agent&#39;: &#39;python-requests/2.21.0&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;, &#39;Authorization&#39;: &#39;Basic VG9tOlRvbTEyMw==&#39;}# {#   &quot;authenticated&quot;: true,#   &quot;user&quot;: &quot;Tom&quot;# }print(base64.b64decode(&#39;VG9tOlRvbTEyMw==&#39;))print(&#39;--------------------------&#39;)# 2. oauthr=requests.request(&#39;GET&#39;,Endpoint+&#39;/bearer&#39;)print(r.status_code,r.reason)           # 401 UNAUTHORIZEDprint(r.headers)                        # Note: &#39;WWW-Authenticate&#39;: &#39;Bearer&#39;r=requests.request(&#39;GET&#39;,Endpoint+&#39;/bearer&#39;,headers={&#39;Authorization&#39;:&#39;Bearer 1234567&#39;})print(r.status_code,r.reason)           # 200 OKprint(r.headers)print(&#39;--------------------------&#39;)# 3. advance: 自定义身份验证（继承requests.auth.AuthBase）from requests.auth import AuthBaseclass MyAuth(AuthBase):    def __init__(self,authType,token):        self.authType=authType        self.token=token    def __call__(self,req):        req.headers[&#39;Authorization&#39;]=&#39; &#39;.join([self.authType,self.token])        return reqr=requests.request(&#39;GET&#39;,Endpoint+&#39;/bearer&#39;,auth=MyAuth(&#39;Bearer&#39;,&#39;123456&#39;))print(r.status_code,r.reason)                   # 200 OKprint(&quot;Request Headers:&quot;,r.request.headers)print(&quot;Response Headers:&quot;,r.headers)print(&quot;Response Text:&quot;,r.text)</code></pre><h3 id="header-12">kwargs: <code>cookies</code></h3><pre><code class="lang-python">&gt;&gt;&gt; r=requests.request(&#39;GET&#39;,&#39;http://httpbin.org/cookies/set?freedom=test123&#39;)&gt;&gt;&gt; r.cookies&gt;&gt;&gt; r.request.headers{&#39;User-Agent&#39;: &#39;python-requests/2.21.0&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;, &#39;Cookie&#39;: &#39;freedom=test123&#39;}&gt;&gt;&gt; cookies = dict(cookies_are=&#39;working&#39;)       # {&#39;cookies_are&#39;:&#39;working&#39;}&gt;&gt;&gt; r = requests.get(&#39;http://httpbin.org/cookies&#39;, cookies=cookies)&gt;&gt;&gt; r.text&#39;{&quot;cookies&quot;: {&quot;cookies_are&quot;: &quot;working&quot;}}&#39;&gt;&gt;&gt; jar = requests.cookies.RequestsCookieJar()&gt;&gt;&gt; jar.set(&#39;tasty_cookie&#39;, &#39;yum&#39;, domain=&#39;httpbin.org&#39;, path=&#39;/cookies&#39;)&gt;&gt;&gt; jar.set(&#39;gross_cookie&#39;, &#39;blech&#39;, domain=&#39;httpbin.org&#39;, path=&#39;/get&#39;)&gt;&gt;&gt; r = requests.get(&#39;http://httpbin.org/cookies&#39;, cookies=jar)&gt;&gt;&gt; r.text&#39;{&quot;cookies&quot;: {&quot;tasty_cookie&quot;: &quot;yum&quot;}}&#39;</code></pre><h3 id="header-13">kwargs: <code>timeout</code></h3><pre><code class="lang-python">def timeout_request(url,timeout):    try:        resp=requests.get(url,timeout=timeout)        resp.raise_for_status()    except requests.Timeout or requests.HTTPError as e:        print(e)    except Exception as e:        print(&quot;unknow exception:&quot;,e)    else:        print(resp.text)        print(resp.status_code)timeout_request(&#39;http://httpbin.org/get&#39;,0.1)# HTTPConnectionPool(host=&#39;httpbin.org&#39;, port=80): Max retries exceeded with url: /get (Caused by ConnectTimeoutError(&lt;urllib3.connection.HTTPConnection object at 0x1025d9400&gt;, &#39;Connection to httpbin.org timed out. (connect timeout=0.1)&#39;))</code></pre><h3 id="header-14">kwargs: <code>proxies</code></h3><pre><code class="lang-python">&gt;&gt;&gt; pxs = { &#39;http&#39;: &#39;http://user:pass@10.10.10.1:1234&#39; &#39;https&#39;: &#39;https://10.10.10.1:4321&#39; }&gt;&gt;&gt; r = requests.request(&#39;GET&#39;, &#39;http://www.baidu.com&#39;, proxies=pxs)</code></pre><h3 id="header-15">kwargs: <code>files</code></h3><pre><code class="lang-python">f={&#39;image&#39;: open(&#39;黑洞1.jpg&#39;, &#39;rb&#39;)}r = requests.post(Endpoint+&#39;/post&#39;, files=f)print(r.status_code,r.reason)print(r.headers)print(r.text[100:200])print(&#39;--------------------------&#39;)# POST Multiple Multipart-Encoded Filesmultiple_files = [    (&#39;images&#39;, (&#39;黑洞1.jpg&#39;, open(&#39;黑洞1.jpg&#39;, &#39;rb&#39;), &#39;image/jpg&#39;)),    (&#39;images&#39;, (&#39;极光1.jpg&#39;, open(&#39;极光1.jpg&#39;, &#39;rb&#39;), &#39;image/jpg&#39;))]r = requests.post(Endpoint+&#39;/post&#39;, files=multiple_files)print(r.status_code,r.reason)print(r.headers)print(r.text[100:200])print(&#39;--------------------------&#39;)</code></pre><h3 id="header-16">kwargs: <code>stream</code></h3><pre><code class="lang-python">with requests.get(Endpoint+&quot;/stream/3&quot;,stream=True) as r:    print(r.status_code,r.reason)    contentLength=int(r.headers.get(&#39;content-length&#39;,0))    print(&quot;content-length:&quot;,contentLength)    # 此时仅有响应头被下载下来了，连接保持打开状态，因此允许我们根据条件获取内容    if contentLength&lt;100:        print(r.content)    else:        print(&#39;read line by line&#39;)        lines=r.iter_lines() # iter_content 一块一块的下载遍历内容        for line in lines:              if line:                print(line)                 print(&#39;Done&#39;)print(&#39;--------------------------&#39;)</code></pre><h3 id="header-17">Exception</h3><pre><code class="lang-python">import requestsdef do_request(url):  try:    r=requests.get(url,timeout=0.1)    r.raise_for_status()    r.encoding=r.apparent_encoding  except requests.Timeout or requests.HTTPError as e:    print(e)  except Exception as e:    print(&quot;Request Error:&quot;,e)  else:    print(r.text)    print(r.status_code)    return rif __name__==&#39;__main__&#39;:  do_request(&quot;http://www.baidu.com&quot;)</code></pre><h2 id="header-18">Requests 进阶使用</h2><h3 id="header-19">Event hooks</h3><pre><code class="lang-python">def get_key_info(response,*args,**kwargs):    print(&quot;callback:content-type&quot;,response.headers[&#39;Content-Type&#39;])r=requests.get(Endpoint+&#39;/get&#39;,hooks=dict(response=get_key_info))print(r.status_code,r.reason)# callback:content-type application/json# 200 OK</code></pre><h3 id="header-20">Session</h3><ul><li><p>跨请求保持某些参数</p><pre><code class="lang-python">  # 在同一个 Session 实例发出的所有请求之间保持 cookie， 期间使用 urllib3 的 connection pooling 功能  s = requests.Session()  r=s.get(Endpoint+&#39;/cookies/set/mycookie/123456&#39;)  print(&quot;set cookies&quot;,r.status_code,r.reason)     # set cookies 200 OK  r = s.get(Endpoint+&quot;/cookies&quot;)  print(&quot;get cookies&quot;,r.status_code,r.reason)     # get cookies 200 OK  print(r.text)  # {  #   &quot;cookies&quot;: {  #     &quot;mycookie&quot;: &quot;123456&quot;  #   }  # }</code></pre></li><li><p>为请求方法提供缺省数据</p><pre><code class="lang-python">  # 通过为会话对象的属性提供数据来实现（注：方法层的参数覆盖会会话的参数）  s = requests.Session()  s.auth = (&#39;user&#39;, &#39;pass&#39;)  s.headers.update({&#39;x-test&#39;: &#39;true&#39;})  # both &#39;x-test&#39; and &#39;x-test2&#39; are sent  r=s.get(Endpoint+&#39;/headers&#39;, headers={&#39;x-test2&#39;: &#39;true&#39;})  print(r.request.headers)  # {&#39;User-Agent&#39;: &#39;python-requests/2.21.0&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Accept&#39;: &#39;*/*&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;, &#39;x-test&#39;: &#39;true&#39;, &#39;x-test2&#39;: &#39;true&#39;, &#39;Authorization&#39;: &#39;Basic dXNlcjpwYXNz&#39;}</code></pre></li><li><p>用作前后文管理器</p><pre><code class="lang-python">  with requests.Session() as s:       # 这样能确保 with 区块退出后会话能被关闭，即使发生了异常也一样      s.get(&#39;http://httpbin.org/cookies/set/mycookie/Test123&#39;)      r = s.get(Endpoint+&quot;/cookies&quot;)      print(&quot;set cookies&quot;,r.status_code,r.reason)      print(r.text)      # {      #   &quot;cookies&quot;: {      #     &quot;mycookie&quot;: &quot;Test123&quot;      #   }      # }  print(&quot;out with:&quot;)  r = s.get(Endpoint+&quot;/cookies&quot;)  print(&quot;get cookies&quot;,r.status_code,r.reason)  print(r.text)  # {  #   &quot;cookies&quot;: {  #     &quot;mycookie&quot;: &quot;Test123&quot;  #   }  # }</code></pre></li></ul><h3 id="header-21">Prepared Request</h3><pre><code class="lang-python"># 可在发送请求前，对body／header等做一些额外处理s=Session()req=Request(&#39;GET&#39;,Endpoint+&#39;/get&#39;,headers={&#39;User-Agent&#39;:&#39;fake1.0.0&#39;})prepared=req.prepare()  # 要获取一个带有状态的 PreparedRequest需使用`s.prepare_request(req)`# could do something with prepared.body/prepared.headers here# ...resp=s.send(prepared,timeout=3)print(resp.status_code,resp.reason)print(&quot;request headers:&quot;,resp.request.headers)# {&#39;User-Agent&#39;: &#39;fake1.0.0&#39;}print(&quot;response headers:&quot;,resp.headers)# {&#39;Access-Control-Allow-Credentials&#39;: &#39;true&#39;, &#39;Access-Control-Allow-Origin&#39;: &#39;*&#39;, &#39;Content-Type&#39;: &#39;application/json&#39;, &#39;Date&#39;: &#39;Thu, 21 Mar 2019 15:47:30 GMT&#39;, &#39;Server&#39;: &#39;nginx&#39;, &#39;Content-Length&#39;: &#39;216&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;}print(resp.text)# {#   &quot;args&quot;: {},#   &quot;headers&quot;: {#     &quot;Accept-Encoding&quot;: &quot;identity&quot;,#     &quot;Host&quot;: &quot;httpbin.org&quot;,#     &quot;User-Agent&quot;: &quot;fake1.0.0&quot;#   },#   &quot;origin&quot;: &quot;117.83.222.100, 117.83.222.100&quot;,#   &quot;url&quot;: &quot;https://httpbin.org/get&quot;# }</code></pre><h3 id="header-22">Chunk-Encoded Requests</h3><pre><code class="lang-python"># 分块传输,使用生成器或任意没有具体长度的迭代器def gen():    yield b&#39;hi &#39;    yield b&#39;there! &#39;    yield b&#39;How are you?&#39;    yield b&#39;This is for test 123567890.....!&#39;    yield b&#39;Test ABCDEFG HIGKLMN OPQ RST UVWXYZ.....!&#39;r=requests.post(Endpoint+&#39;/post&#39;, data=gen())    # stream=Trueprint(r.status_code,r.reason,r.headers[&#39;content-length&#39;])for chunk in r.iter_content(chunk_size=100):        # chunk_size=None    if chunk:        print(chunk)print(&#39;done&#39;)</code></pre><h2 id="header-23">Reqeusts 应用示例</h2><p><strong> Download pic from <code>http://www.nationalgeographic.com.cn</code> </strong></p><h3 id="header-24">一次性下载（小文件，<code>stream=False</code>)</h3><pre><code class="lang-python">import requestsimport osdef download_small_file(url):    try:        r=requests.get(url)        r.raise_for_status()        print(r.status_code,r.reason)        contentType=r.headers[&quot;Content-Type&quot;]        contentLength=int(r.headers.get(&quot;Content-Length&quot;,0))        print(contentType,contentLength)    except Exception as e:        print(e)    else:        filename=r.url.split(&#39;/&#39;)[-1]        print(&#39;filename:&#39;,filename)        target=os.path.join(&#39;.&#39;,filename)        if os.path.exists(target) and os.path.getsize(target):            print(&#39;Exist -- Skip download!&#39;)        else:            with open(target,&#39;wb&#39;) as fd:                fd.write(r.content)    print(&#39;done!&#39;)if __name__ == &#39;__main__&#39;:    import time    print(&#39;start&#39;)    start = time.time()    url=&quot;http://image.nationalgeographic.com.cn/2017/0211/20170211061910157.jpg&quot;    download_small_file(url)    end=time.time()    print(&#39;Runs %0.2f seconds.&#39; % (end - start))    print(&#39;end&#39;)</code></pre><h3 id="header-25">流式分块下载（大文件，<code>stream=True</code>）</h3><pre><code class="lang-python">import requestsimport osdef download_large_file(url):    try:        r=requests.get(url,stream=True)        r.raise_for_status()        print(r.status_code,r.reason)        contentType=r.headers[&quot;Content-Type&quot;]        contentLength=int(r.headers.get(&quot;Content-Length&quot;,0))        print(contentType,contentLength)            except Exception as e:        print(e)    else:        filename=r.url.split(&#39;/&#39;)[-1]        print(&#39;filename:&#39;,filename)        target=os.path.join(&#39;.&#39;,filename)        if os.path.exists(target) and os.path.getsize(target):            print(&#39;Exist -- Skip download!&#39;)        else:            with open(target,&#39;wb&#39;) as fd:                for chunk in r.iter_content(chunk_size=10240):                    if chunk:                        fd.write(chunk)                        print(&#39;download:&#39;,len(chunk))    finally:        r.close()        print(&#39;close&#39;)if __name__ == &#39;__main__&#39;:    import time    print(&#39;start&#39;)    start = time.time()    url=&quot;http://image.nationalgeographic.com.cn/2017/0211/20170211061910157.jpg&quot;    download_large_file(url)    end=time.time()    print(&#39;Runs %0.2f seconds.&#39; % (end - start))    print(&#39;end&#39;)</code></pre><h3 id="header-26">显示进度条</h3><pre><code class="lang-python">import requestsimport osdef download_with_progress(url):    try:        with requests.get(url,stream=True) as r:            r.raise_for_status()            print(r.status_code,r.reason)            contentType=r.headers[&quot;Content-Type&quot;]            contentLength=int(r.headers.get(&quot;Content-Length&quot;,0))            print(contentType,contentLength)            filename=r.url.split(&#39;/&#39;)[-1]            print(&#39;filename:&#39;,filename)            target=os.path.join(&#39;.&#39;,filename)            if os.path.exists(target) and os.path.getsize(target):                print(&#39;Exist -- Skip download!&#39;)            else:                chunk_size=1024                progress =ProgressBar(filename, total=content_length,chunk_size=1024,unit=&quot;KB&quot;)                with open(target,&#39;wb&#39;) as fd:                    for chunk in r.iter_content(chunk_size=chunk_size):                        if chunk:                            fd.write(chunk)                            #print(&#39;download:&#39;,len(chunk))                            progress.refresh(count=len(chunk))    except Exception as e:        print(e)    print(&#39;done&#39;)# ProgressBarclass ProgressBar(object):def __init__(self,title,total,chunk_size=1024,unit=&#39;KB&#39;):    self.title=title    self.total=total    self.chunk_size=chunk_size    self.unit=unit    self.progress=0.0def __info(self):    return &quot;【%s】%s %.2f%s / %.2f%s&quot; % (self.title,self.status,self.progress/self.chunk_size,self.unit,self.total/self.chunk_size,self.unit)def refresh(self,progress):    self.progress += progress    self.status=&quot;......&quot;    end_str=&#39;\r&#39;    if self.total&gt;0 and self.progress&gt;=self.total:        end_str=&#39;\n&#39;        self.status=&#39;completed&#39;    print(self.__info(),end=end_str)if __name__ == &#39;__main__&#39;:    import time    print(&#39;start&#39;)    start = time.time()    url=&quot;http://image.nationalgeographic.com.cn/2017/0211/20170211061910157.jpg&quot;    download_with_progress(url)    end=time.time()    print(&#39;Runs %0.2f seconds.&#39; % (end - start))    print(&#39;end&#39;)</code></pre><h3 id="header-27">多任务下载</h3><ul><li><p>多进程下载：并行（同时）</p><pre><code class="lang-python">  import multiprocessing  from multiprocessing import Pool  # do multiple downloads - multiprocessing  def do_multiple_download_multiprocessing(url_list,targetDir):      cpu_cnt=multiprocessing.cpu_count()      print(&quot;系统进程数: %s, Parent Pid: %s&quot; % (cpu_cnt,os.getpid()))      p = Pool(cpu_cnt)      results=[]      for i,url in enumerate(url_list):          result=p.apply_async(do_download,args=(i,url,targetDir,False,),callback=print_return)          results.append(result)      print(&#39;Waiting for all subprocesses done...&#39;)      p.close()      p.join()      for result in results:          print(os.getpid(),result.get())      print(&#39;All subprocesses done.&#39;)  # callback  def print_return(result):      print(os.getpid(),result)</code></pre></li><li><p>多线程下载：并发（交替）</p><pre><code class="lang-python">  import threading  def do_multiple_downloads_threads(url_list,targetDir):      thread_list=[]      for i,url in enumerate(url_list):          thread=threading.Thread(target=do_download,args=(i,url,targetDir,True,))          thread.start()          thread_list.append(thread)      print(&#39;Waiting for all threads done...&#39;)      for thread in thread_list:          thread.join()      print(&#39;All threads done.&#39;)</code></pre></li><li><p>verify</p><pre><code class="lang-python">  import requests  from bs4 import BeautifulSoup  import os,time  import re  # do download using `requests`  def do_download(i,url,targetDir,isPrint=False):      headers={          &#39;User-Agent&#39;:&#39;Mozilla/5.0 (Windows NT 6.1; WOW64; rv:60.0) Gecko/20100101 Firefox/60.0&#39;      }      try:          response=requests.get(url,headers=headers,stream=True,verify=False)          response.raise_for_status()      except Exception as e:          print(&quot;Occur Exception:&quot;,e)      else:          content_length = int(response.headers.get(&#39;Content-Length&#39;,0))          filename=str(i)+&quot;.&quot;+url.split(&#39;/&#39;)[-1]          print(response.status_code,response.reason,content_length,filename)          progressBar=ProgressBar(filename, total=content_length,chunk_size=1024,unit=&quot;KB&quot;)          with open(os.path.join(targetDir,filename),&#39;wb&#39;) as fd:              for chunk in response.iter_content(chunk_size=1024):                  if chunk:                      fd.write(chunk)                      progressBar.refresh(len(chunk))          if isPrint:              print(os.getpid(),threading.current_thread().name,filename,&quot;Done!&quot;)          return &#39;%s %s %s Done&#39; % (os.getpid(),threading.current_thread().name,filename)  # prepare download urls  def url_list_crawler():      url=&quot;http://m.ngchina.com.cn/travel/photo_galleries/5793.html&quot;      response=requests.get(url)      print(response.status_code,response.reason,response.encoding,response.apparent_encoding)      response.encoding=response.apparent_encoding      soup=BeautifulSoup(response.text,&#39;html.parser&#39;)      #results=soup.select(&#39;div#slideBox ul a img&#39;)      #results=soup.find_all(&#39;img&#39;)      results=soup.select(&quot;div.sub_center img[src^=&#39;http&#39;]&quot;)      url_list=[ r[&quot;src&quot;] for r in results]      print(&quot;url_list:&quot;,len(url_list))      print(url_list)      return url_list  # main  if __name__==&#39;__main__&#39;:      print(&#39;start&#39;)      targetDir=&quot;/Users/cj/space/python/download&quot;      url=&quot;http://image.ngchina.com.cn/2019/0325/20190325110244384.jpg&quot;      url_list=url_list_crawler()      start=time.time()      # 0 download one file using `requests`      do_download(&quot;A&quot;,url,targetDir)      end = time.time()      print(&#39;Total cost %0.2f seconds.&#39; %  (end-start))      start=end      # 1 using multiple processings      do_multiple_download_multiprocessing(url_list,targetDir)      end = time.time()      print(&#39;Total cost %0.2f seconds.&#39; %  (end-start))      start=end      # 2 using multiple threads      do_multiple_downloads_threads(url_list,targetDir)      end = time.time()      print(&#39;Total cost %0.2f seconds.&#39; %  (end-start))      start=end      print(&#39;end&#39;)</code></pre></li></ul><h2 id="header-28">aiohttp</h2><p><a href="https://aiohttp.readthedocs.io/en/stable/" target="_blank" rel="noopener">官网</a></p><blockquote><p>Asynchronous HTTP Client/Server for asyncio and Python.</p></blockquote><ul><li>支持客户端和HTTP服务器</li><li>提供异步web服务的库 ( <code>requests</code>是同步阻塞的)</li><li>无需使用Callback Hell即可支持Server/Client WebSockets</li><li>install: <code>pip install aiohttp</code></li></ul><h3 id="header-29">Client Sample</h3><p>Refer to <a href="https://aiohttp.readthedocs.io/en/stable/client_quickstart.html#" target="_blank" rel="noopener">Client Quickstart</a></p><pre><code class="lang-python">import aiohttpimport asyncioasync def fetch(session, url):    async with session.get(url) as response:        return await response.text()async def main():    async with aiohttp.ClientSession() as session:        html = await fetch(session, &#39;http://httpbin.org/headers&#39;)        print(html)loop = asyncio.get_event_loop()loop.run_until_complete(main())</code></pre><h3 id="header-30">Server Sample</h3><p>Refer to <a href="https://aiohttp.readthedocs.io/en/stable/web_quickstart.html" target="_blank" rel="noopener">Web Server Quickstart</a></p><pre><code class="lang-python">from aiohttp import webasync def handle(request):    name = request.match_info.get(&#39;name&#39;, &quot;Anonymous&quot;)    text = &quot;Hello, &quot; + name    return web.Response(text=text)app = web.Application()app.add_routes([web.get(&#39;/&#39;, handle),                web.get(&#39;/{name}&#39;, handle)])web.run_app(app)</code></pre><h3 id="header-31">应用：协程并发下载文件</h3><p>单线程 &amp; 异步 &amp; 非阻塞</p><ul><li><p>do download using <code>aiohttp</code></p><pre><code class="lang-python">  async def do_aiohttp_download(session,i,url,targetDir):      async with session.get(url) as response:          content_length = int(response.headers.get(&#39;Content-Length&#39;,0))          filename=str(i)+&quot;.&quot;+url.split(&#39;/&#39;)[-1]          print(response.status,response.reason,content_length,filename)          progressBar=ProgressBar(filename, total=content_length,chunk_size=1024,unit=&quot;KB&quot;)          with open(os.path.join(targetDir,filename),&#39;wb&#39;) as fd:              while True:                  chunk=await response.content.read(1024)                  if not chunk:                      break;                  fd.write(chunk)                  progressBar.refresh(len(chunk))          await response.release()      # print(filename,&quot;Done!&quot;)      return filename  # callback  def print_async_return(task):      print(task.result(),&quot;Done&quot;)  def print_async_return2(i,task):      print(i,&quot;:&quot;,task.result(),&quot;Done&quot;)</code></pre></li><li><p>case1: do one download</p><pre><code class="lang-python">  async def do_async_download(i,url,targetDir):      async with aiohttp.ClientSession() as session:          return await do_aiohttp_download(session,i,url,targetDir)</code></pre></li><li><p>case2: do multiple download</p><pre><code class="lang-python">  # do multiple downloads - asyncio  async def do_multiple_downloads_async(url_list,targetDir):       async with aiohttp.ClientSession() as session:          # tasks=[do_aiohttp_download(session,url,targetDir) for url in url_list]          # await asyncio.gather(*tasks)                    tasks=[]          for i,url in enumerate(url_list):              task=asyncio.create_task(do_aiohttp_download(session,i,url,targetDir))              # task.add_done_callback(print_async_return)              task.add_done_callback(functools.partial(print_async_return2,i))              tasks.append(task)              await asyncio.gather(*tasks)</code></pre></li><li><p>verify</p><pre><code class="lang-python">  import os,time  import asyncio  import aiohttp  import functools  import re  # prepare download urls  def url_list_crawler():      url=&quot;http://m.ngchina.com.cn/travel/photo_galleries/5793.html&quot;      response=requests.get(url)      print(response.status_code,response.reason,response.encoding,response.apparent_encoding)      response.encoding=response.apparent_encoding      soup=BeautifulSoup(response.text,&#39;html.parser&#39;)      #results=soup.select(&#39;div#slideBox ul a img&#39;)      #results=soup.find_all(&#39;img&#39;)      results=soup.select(&quot;div.sub_center img[src^=&#39;http&#39;]&quot;)      url_list=[ r[&quot;src&quot;] for r in results]      print(&quot;url_list:&quot;,len(url_list))      print(url_list)      return url_list  # main            if __name__==&#39;__main__&#39;:      print(&#39;start&#39;)      targetDir=&quot;/Users/cj/space/python/download&quot;      url=&quot;http://image.ngchina.com.cn/2019/0325/20190325110244384.jpg&quot;      url_list=url_list_crawler()      start=time.time()      # 1. download one file using `aiohttp`      loop=asyncio.get_event_loop()      loop.run_until_complete(do_async_download(&quot;A&quot;,url,targetDir))      loop.close()      end = time.time()      print(&#39;Total cost %0.2f seconds.&#39; %  (end-start))      start=end      # 2. download many files using `aiohttp`      loop=asyncio.get_event_loop()      loop.run_until_complete(do_multiple_downloads_async(url_list,targetDir))      loop.close()      end = time.time()      print(&#39;Total cost %0.2f seconds.&#39; %  (end-start))      start=end      print(&#39;end&#39;)</code></pre></li></ul><h2 id="header-32">Reference</h2><ul><li><a href="https://github.com/sixDegree/python-basic-demo" target="_blank" rel="noopener">My Demo</a></li><li><a href="https://zhuanlan.zhihu.com/p/37824910" target="_blank" rel="noopener">python下载文件—-requests</a></li><li><a href="https://www.cnblogs.com/ssyfj/p/9222342.html" target="_blank" rel="noopener">python—aiohttp的使用</a></li><li><a href="https://blog.fudenglong.site/2017/06/04/Python%E5%B9%B6%E5%8F%91%E4%B8%8B%E8%BD%BD%E7%9A%84%E4%BE%8B%E5%AD%90%E5%92%8C%E6%AF%94%E8%BE%83/" target="_blank" rel="noopener">Python并发下载的例子和比较</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;requests&lt;/li&gt;
&lt;li&gt;aiohttp&lt;/li&gt;
&lt;li&gt;demo: download files&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Python" scheme="http://sixdegree.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python 爬虫基础</title>
    <link href="http://sixdegree.github.io/2019/03/15/Python-Crawler-Basic.html"/>
    <id>http://sixdegree.github.io/2019/03/15/Python-Crawler-Basic.html</id>
    <published>2019-03-14T16:00:00.000Z</published>
    <updated>2019-07-10T03:32:03.000Z</updated>
    
    <content type="html"><![CDATA[<ul><li>爬虫基础</li><li>Re</li><li>BeautifulSoup(include CSS Selector)</li><li>XPath</li><li>JSONPath</li></ul><a id="more"></a><h2 id="header-1">基础概念</h2><h3 id="header-2">HTTP协议</h3><blockquote><p>wikipedia:<br>The Hypertext transfer Protocal(HTTP) is a stateless(无状态) application-level protocol for distributed(分布式),collaborative(协作式),hypertext information systems.</p></blockquote><p>HyperText Transfer Protocol 超文本传输协议</p><ul><li><p>是一个基于“请求与响应”模式的、无状态的应用层协议</p></li><li><p>采用URL作为定位网络资源的标识,格式如下: <code>http://host[:port][path]</code></p><ul><li><code>host</code>: 合法的Internet主机域名或IP地址 </li><li><code>port</code>: 端口号,缺省端口为80</li><li><code>path</code>: 请求资源的路径</li></ul></li><li><p>对资源的操作：</p><ul><li><code>GET</code> 请求获取URL位置的资源</li><li><code>HEAD</code> 请求获取URL位置资源的响应消息报告,即获得该资源的头部信息 </li><li><code>POST</code> 请求向URL位置的资源后附加新的数据</li><li><code>PUT</code> 请求向URL位置存储一个资源,覆盖原URL位置的资源</li><li><code>PATCH</code> 请求局部更新URL位置的资源,即改变该处资源的部分内容</li><li><code>DELETE</code> 请求删除URL位置存储的资源</li><li><code>PATCH</code> vs. <code>PUT</code>: <ul><li>假设URL位置有一组数据UserInfo,包括UserID、UserName等20个字段, 需求:用户修改了UserName,其他不变</li><li><code>PATCH</code>: 仅向URL提交UserName的局部更新请求</li><li><code>PUT</code> 须将所有20个字段一并提交到URL,未提交字段被删除 </li><li><code>PATCH</code>的最主要好处:节省网络带宽</li></ul></li></ul></li><li><p>响应状态码</p><ul><li><code>2xx</code> 成功</li><li><code>3xx</code> 跳转<ul><li>300 Multiple Choices 存在多个可用资源，可处理可丢弃</li><li>301 Moved Permanetly 重定向</li><li>302 Found 重定向</li><li>304 Not Modified 请求资源未更新，丢弃</li><li>注：一些python库（urllib2,requests,…）已经对重定向做了处理，会自动跳转</li></ul></li><li><code>4xx</code> 客户端错误<ul><li>400 Bad Request 客户端请求有语法错误，不能被服务器所理解（请求参数或者路径错误）</li><li>401 Unauthorized 请求未经授权，这个状态吗需和www-Authenticate报头域一起使用（无权限访问）</li><li>403 Forbidden 服务器收到请求，但拒绝提供服务（未登录/IP被封/…）</li><li>404 Not Found 请求资源部存在</li></ul></li><li><code>5xx</code> 服务端错误<ul><li>500 Internal Server Error 服务器发生了不可预期的错误</li><li>503 Server Unavailable 服务器当前不能处理客户端请求，一段时间后可能恢复正常</li></ul></li></ul></li><li><p>Http Header</p><ul><li>Request Http Header<pre><code>  Accept: text/plain  Accept-Charset: utf-8  Accept-Encoding: gzip,deflate  Accept-Language: en-US  Connection: keep-alive  Content-Length: 348  Content-Type: application/x-www-form-urlencoded  User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:60.0) Gecko/20100101 Firefox/60.0  Cookie: $version=1; Skin=new;  Date: ...  Host: ...  ....</code></pre></li><li>Response Http Header<pre><code>  Status: 200 OK  Accept: text/plain;charset=utf-8  Content-Eoncoding: gzip  Content_Language: en-US  Content-Length: 348  Set-Cookie: UserID=xxx,Max-Age=3600;Version=1;...  Location: ...  Last-Modified: ...  ...</code></pre></li></ul></li></ul><h3 id="header-3">深度抓取与广度抓取</h3><pre><code>        A     /     \    B       C    /       \ D,E,F,G     X,Y,Z|H,I,J,K</code></pre><ul><li>深度抓取(垂直)<ul><li>堆栈（递归，先进后出）</li><li>A -&gt; B -&gt; D -&gt; H -&gt; I,J,K -&gt; E,F,G -&gt; C -&gt; X,Y,Z</li></ul></li><li>广度抓取(水平)<ul><li>队列（先进先出）</li><li>A -&gt; B,C -&gt; D,E,F,G ; X,Y,Z -&gt; H,I,J,K</li></ul></li><li>策略：<ul><li>重要的网页距离种子站点比较近</li><li>一个网页可能有很多路径可以到达（图）</li><li>广度优先有利于多爬虫并行抓取</li><li>深度与广度结合</li></ul></li></ul><h3 id="header-4">不重复抓取策略</h3><ul><li>记录抓取历史（URL）<ul><li>保存到数据库（效率低）</li><li>使用HashSet(内存限制)</li></ul></li><li>尽量压缩URL<ul><li>MD5／SHA-1编码成一段统一长度的数字／字符串，太长，一般会编码后再取模</li><li>BitMap方法：建立BitSet,将URL（可在MD5基础上）经过Hash函数映射到一个或多个Bit位来记录</li><li>BloomFilter: 在BitMap基础上，使用多个Hash函数</li><li>注：存在一定碰撞</li></ul></li><li>操作：<ul><li>评估网站的网页数量</li><li>选择合适的Hash算法和空间阈值，降低碰撞几率</li><li>选择合适的存储结构和算法</li></ul></li><li>注：<ul><li>网页数量少的情况下，不需要进行压缩（多数情况）</li><li>网页数量大的情况下，可使用BloomFilter压缩URL，重点是计算碰撞概率，以此确定存储空间的阈值</li><li>分布式系统，可将散列映射到多台主机</li></ul></li></ul><h3 id="header-5">网络爬虫的限制</h3><ul><li>来源审查: 检查来访HTTP协议头的<code>User‐Agent</code>域,只响应浏览器或友好爬虫的访问</li><li>发布公告: <code>Robots</code>协议,网站告知网络爬虫哪些页面可以抓取,哪些不行<ul><li>在网站根目录下的<code>robots.txt</code>文件 (Robots Exclusion Standard 网络爬虫排除标准)</li><li><code>Robots</code>协议是建议但非约束性,网络爬虫可以不遵守,但存在法律风险</li><li>基本语法<pre><code>  # `*`代表所有, `/`代表根目录   User‐agent: *  Disallow: /</code></pre></li><li>eg: <code>https://www.jd.com/robots.txt</code><pre><code>  User‐agent: *  Disallow: /?*  Disallow: /pop/*.html  Disallow: /pinpai/*.html?*  User‐agent: EtaoSpider  Disallow: /  User‐agent: HuihuiSpider  Disallow: /  User‐agent: GwdangSpider  Disallow: /  User‐agent: WochachaSpider  Disallow: /</code></pre></li></ul></li></ul><h3 id="header-6">网站结构分析</h3><ul><li>利用sitemap里的信息</li><li>对网站目录结构进行分析</li><li>网页解析器：<ul><li>模糊匹配：<ul><li>正则表达式</li></ul></li><li>结构化解析：<ul><li>htmp.parser</li><li>BeautifulSoup</li><li>lxml</li><li>。。。</li></ul></li></ul></li></ul><h2 id="header-7">文档解析之Re</h2><h3 id="header-8">正则表达式</h3><p>Regular Expression(regex)</p><ul><li>一种通用的字符串表达框架,简洁表达一组字符串</li><li>特点: 简洁,一行胜千言（一行就是特征，即模式)</li><li>用途(主要应用在字符串匹配中)：<ul><li>表达文本类型的特征(病毒、入侵等)</li><li>匹配字符串的全部或部分</li><li>查找或替换一组字符串</li><li>…</li></ul></li><li><p>语法由字符和操作符构成, 常用操作符:</p><ul><li><p>匹配单个字符</p><table class="table"><thead><tr><th style="text-align:left">操作符</th><th style="text-align:left">说明</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left"><code>.</code></td><td style="text-align:left">表示任何单个字符</td><td style="text-align:left">/</td></tr><tr><td style="text-align:left"><code>[]</code></td><td style="text-align:left">匹配<code>[]</code>中列举的字符</td><td style="text-align:left"><code>[abc]</code>表示a、b、c,<code>[a‐z]</code>表示a到z单个字符</td></tr><tr><td style="text-align:left"><code>[^ ]</code></td><td style="text-align:left">非字符集,对单个字符给出排除范围</td><td style="text-align:left"><code>[^abc]</code>表示非a或b或c的单个字符</td></tr><tr><td style="text-align:left"><code>\d</code></td><td style="text-align:left">数字,等价于<code>[0‐9]</code></td><td style="text-align:left">/</td></tr><tr><td style="text-align:left"><code>\D</code></td><td style="text-align:left">匹配非数字</td><td style="text-align:left">/</td></tr><tr><td style="text-align:left"><code>\w</code></td><td style="text-align:left">单词字符,等价于<code>[A‐Za‐z0‐9]</code></td><td style="text-align:left">/</td></tr><tr><td style="text-align:left"><code>\W</code></td><td style="text-align:left">匹配非单词字符</td><td style="text-align:left">/</td></tr><tr><td style="text-align:left"><code>\s</code></td><td style="text-align:left">匹配空白，即 空格，tab键</td><td style="text-align:left">/</td></tr><tr><td style="text-align:left"><code>\S</code></td><td style="text-align:left">匹配非空白</td><td style="text-align:left">/</td></tr></tbody></table></li><li><p>匹配数量</p><table class="table"><thead><tr><th style="text-align:left">操作符</th><th style="text-align:left">说明</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left"><code>*</code></td><td style="text-align:left">前一个字符0次或无限次扩展,即可有可无</td><td style="text-align:left"><code>abc*</code> 表示 ab、abc、abcc、abccc等</td></tr><tr><td style="text-align:left"><code>+</code></td><td style="text-align:left">前一个字符1次或无限次扩展,即至少有1次</td><td style="text-align:left"><code>abc+</code> 表示 abc、abcc、abccc等</td></tr><tr><td style="text-align:left"><code>?</code></td><td style="text-align:left">前一个字符0次或1次扩展,即要么有1次，要么没有</td><td style="text-align:left"><code>abc?</code> 表示 ab、abc</td></tr><tr><td style="text-align:left"><code>{m}</code></td><td style="text-align:left">扩展前一个字符m次</td><td style="text-align:left"><code>ab{2}c</code>表示abbc</td></tr><tr><td style="text-align:left"><code>{m,}</code></td><td style="text-align:left">扩展前一个字符至少m次</td><td style="text-align:left"><code>ab{2}c</code>表示abbc,abbbc,abbbbc等</td></tr><tr><td style="text-align:left"><code>{m,n}</code></td><td style="text-align:left">扩展前一个字符m至n次(含n)</td><td style="text-align:left"><code>ab{1,2}c</code>表示abc、abbc</td></tr></tbody></table></li><li><p>匹配边界</p><table class="table"><thead><tr><th style="text-align:left">操作符</th><th style="text-align:left">说明</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left"><code>^</code></td><td style="text-align:left">匹配字符串开头</td><td style="text-align:left"><code>^abc</code>表示abc且在一个字符串的开头</td></tr><tr><td style="text-align:left"><code>$</code></td><td style="text-align:left">匹配字符串结尾</td><td style="text-align:left"><code>abc$</code>表示abc且在一个字符串的结尾</td></tr><tr><td style="text-align:left"><code>\b</code></td><td style="text-align:left">匹配一个单词的边界，注意：并不是匹配分隔符，而是单词和符号之间的边界 <br>（单词可是中英文字符,数字；符号可是中英文符号,空格,制表符,换行）</td><td style="text-align:left">“a nice day”,”a niceday”: <code>\bnice\b</code>可匹配出”a nice day”的”nice”</td></tr><tr><td style="text-align:left"><code>\B</code></td><td style="text-align:left">匹配一个非单词的边界</td><td style="text-align:left">“a nice day”,”a niceday”: <code>\bnice\B</code>可匹配出”a niceday”的”nice”</td></tr></tbody></table></li><li><p>匹配分组</p><table class="table"><thead><tr><th style="text-align:left">操作符</th><th style="text-align:left">说明</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left"><code>|</code></td><td style="text-align:left">左右表达式任意一个</td><td style="text-align:left"><code>abc|def</code> 表示 abc、def</td></tr><tr><td style="text-align:left"><code>( )</code></td><td style="text-align:left">分组标记,内部只能使用</td><td style="text-align:left"><code>(abc)</code>表示abc,<code>(abc|def)</code>表示abc、def</td></tr><tr><td style="text-align:left"><code>\num</code></td><td style="text-align:left">引用分组num匹配到的字符串</td><td style="text-align:left"><code>&lt;(\w*)&gt;&lt;(\w*)&gt;.*&lt;/\2&gt;&lt;/\1&gt;</code> =&gt; <code>&lt;html&gt;&lt;h1&gt;hh&lt;h1&gt;&lt;/html&gt;</code>正确，<code>&lt;html&gt;&lt;h1&gt;hh&lt;/h1&gt;&lt;/abc&gt;</code> 错误</td></tr><tr><td style="text-align:left"><code>(?P&lt;name&gt;)</code></td><td style="text-align:left">分组起别名</td><td style="text-align:left"><code>&lt;(?P&lt;name1&gt;\w*)&gt;&lt;(?P&lt;name2&gt;\w*)&gt;.*&lt;/(?P=name2)&gt;&lt;/(?P=name1)&gt;</code> =&gt; <code>&lt;html&gt;&lt;h1&gt;hh&lt;h1&gt;&lt;/html&gt;</code>正确,<code>&lt;html&gt;&lt;h1&gt;hh&lt;/h1&gt;&lt;/abc&gt;</code> 错误</td></tr><tr><td style="text-align:left"><code>(?P=name)</code></td><td style="text-align:left">引用别名为name分组匹配到的字符串</td><td style="text-align:left">/</td></tr></tbody></table></li></ul></li><li><p>eg1:</p><ul><li>一组字符串(无穷个): ‘PY’, ‘PYY’, ‘PYYY’, ‘PYYYY’, ……, ‘PYYYY……’</li><li>正则表达式(无穷字符串组的简洁表达): <code>PY+</code></li></ul></li><li>eg2: <ul><li>一组字符串:  ‘PN’, ‘PYN’, ‘PYTN’, ‘PYTHN’, ‘PYTHON’</li><li>正则表达式(简洁表达):<code>P(Y|YT|YTH|YTHO)?N</code></li></ul></li><li>eg3:<ul><li>表示一组’PY’开头，后续存在不多于10个字符，且不能是’P’或’Y’的字符串(如：’PYABC’ 正确;’PYKXYZ’ 不正确)</li><li>正则表达式（特征字符串组的简洁表达）：<code>PY[^PY]{0,10}</code></li></ul></li><li><p>eg4:</p><ul><li>‘PN’、’PYN’、’PYYN’、’PYYYN’…</li><li><code>PY{:3}N</code></li></ul></li><li><p>经典正则表达式实例：</p><ul><li><code>^[A‐Za‐z]+$</code> 由26个字母组成的字符串</li><li><code>^[A‐Za‐z0‐9]+$</code> 由26个字母和数字组成的字符串</li><li><code>[1‐9]\d{5}</code> 中国境内6位邮政编码</li><li><code>[\u4e00‐\u9fa5]</code> 匹配中文字符</li><li><code>\d{3}‐\d{8}|\d{4}‐\d{7}</code> 国内电话号码(eg: 010‐68913536)</li><li><code>(([1‐9]?\d|1\d{2}|2[0‐4]\d|25[0‐5]).){3}([1‐9]?\d|1\d{2}|2[0‐4]\d|25[0‐5])</code> IP地址(4段)<ul><li>0‐99: <code>[1‐9]?\d</code></li><li>100‐199: <code>1\d{2}</code></li><li>200‐249: <code>2[0‐4]\d</code> </li><li>250‐255: <code>25[0‐5]</code></li><li>简化表达：<code>\d+.\d+.\d+.\d+</code> 或 <code>\d{1,3}.\d{1,3}.\d{1,3}.\d{1,3}</code></li></ul></li></ul></li></ul><h3 id="header-9">Re库</h3><ul><li>Python的标准库(用于字符串匹配)</li><li>导入<code>import re</code></li><li>正则表达式的表示类型：<ul><li>raw string(原生字符串类型)：<code>r&#39;text&#39;</code>, eg: <code>r&#39;[1‐9]\d{5}&#39;</code>, <code>r&#39;\d{3}‐\d{8}|\d{4}‐\d{7}&#39;</code></li><li>string(更繁琐), eg: <code>&#39;[1‐9]\\d{5}&#39;</code>,<code>&#39;\\d{3}‐\\d{8}|\\d{4}‐\\d{7}&#39;</code></li><li>注：raw string不包含对转义符再次转义的字符串,所以建议当正则表达式包含转义符时,使用raw string</li></ul></li><li><p>函数式用法: 一次性操作</p><ul><li><code>re.search(pattern, string, flags=0)</code>: 搜索第一个匹配的,返回<code>match</code>对象<ul><li><code>pattern</code> : 正则表达式(string/raw string)</li><li><code>string</code> : 待匹配字符串</li><li><code>flags</code>: 控制标记<ul><li><code>re.I</code>,<code>re.IGNORECASE</code> : 忽略大小写</li><li><code>re.M</code>,<code>re.MULTILINE</code> : <code>^</code>操作符能将给定字符串的每行当作匹配开始</li><li><code>re.S</code>,<code>re.DOTALL</code> : <code>.</code>操作符能匹配所有字符(默认是匹配除换行外的所有字符）</li></ul></li><li>eg: <pre><code class="lang-python">  import re  match=re.search(r&#39;[1-9]\d{5}&#39;,&#39;BIT100081 TSU100084&#39;)  if match:      print(match.group(0))   # 100081</code></pre></li></ul></li><li><p><code>re.match(pattern, string, flags=0)</code>: 从头开始匹配，返回<code>match</code>对象</p><ul><li>参数同上</li><li><p>eg:</p><pre><code class="lang-python">  match=re.match(r&#39;[1-9]\d{5}&#39;,&#39;BIT100081 TSU100084&#39;)  if match:      print(match.group(0))   # AttributeError: &#39;NoneType&#39; object has no attribute &#39;group&#39;  match=re.match(r&#39;[1-9]\d{5}&#39;,&#39;100081BIT TSU100084&#39;)  if match:      print(match.group(0))   # 100081</code></pre></li></ul></li><li><code>re.findall(pattern, string, flags=0)</code>: 搜索,返回匹配字串列表<ul><li>参数同上</li><li>eg:<pre><code class="lang-python">  ls=re.findall(r&#39;[1-9]\d{5}&#39;,&#39;BIT100081 TSU100084&#39;) # [&#39;100081&#39;,&#39;100084&#39;]</code></pre></li></ul></li><li><code>re.finditer(pattern, string, flags=0)</code>: 搜索,返回匹配结果的迭代类型,每个迭代元素是<code>match</code>对象<ul><li>参数同上</li><li>eg:<pre><code class="lang-python">  for match in re.finditer(r&#39;[1-9]\d{5}&#39;,&#39;BIT100081 TSU100084&#39;):      if match:          print(match.group(0))  # 100081  # 100084</code></pre></li></ul></li><li><code>re.split(pattern, string, maxsplit=0, flags=0)</code>: 分割, 返回列表<ul><li><code>maxsplit</code>: 最大分割数,剩余部分作为最后一个元素输出</li><li>eg:<pre><code class="lang-python">  re.split(r&#39;[1-9]\d{5}&#39;,&#39;BIT100081 TSU100084&#39;)   # [&#39;BIT&#39;,&#39; TSU&#39;,&#39;&#39;]   re.split(r&#39;[1-9]\d{3}&#39;,&#39;BIT100081 TSU100084&#39;)   # [&#39;BIT&#39;, &#39;81 TSU&#39;, &#39;84&#39;]  re.split(r&#39;[1-9]\d{5}&#39;,&#39;BIT100081 TSU100084&#39;,maxsplit=1) # [&#39;BIT&#39;,&#39; TSU100084&#39;]</code></pre></li></ul></li><li><code>re.sub(pattern, repl, string, count=0, flags=0)</code>: 替换所有匹配的子串,返回替换后的字符串<ul><li><code>repl</code> 替换字符串</li><li><code>string</code> : 待匹配字符串</li><li><code>count</code> 最大替换次数</li><li>eg: <pre><code class="lang-python">  re.sub(r&#39;[1-9]\d{5}&#39;,&#39;:zipcode&#39;,&#39;BIT100081 TSU100084&#39;) # &#39;BIT:zipcode TSU:zipcode&#39;</code></pre></li></ul></li></ul></li><li><p>面向对象用法:编译后的多次操作</p><ul><li>Step1: <code>regex = re.compile(pattern, flags=0)</code> 将正则表达式的字符串形式<code>编译</code>成正则表达式对象</li><li>Step2:<ul><li><code>regex.search(string, flags=0)</code></li><li><code>regex.match(string, flags=0)</code></li><li><code>regex.findall(string, flags=0)</code></li><li><code>regex.finditer(string, flags=0)</code></li><li><code>regex.split(string, maxsplit=0, flags=0)</code></li><li><code>regex.sub(repl, string, count=0, flags=0)</code></li></ul></li></ul></li><li><p>Match对象：</p><ul><li>一次匹配的结果,包含匹配的很多信息</li><li>属性：<ul><li><code>.string</code>: 待匹配的文本</li><li><code>.re</code>: 匹配时使用的pattern对象(正则表达式)</li><li><code>.pos</code>: 搜索文本的开始位置</li><li><code>.endpos</code>: 搜索文本的结束位置</li></ul></li><li>方法：<ul><li><code>.group(0)</code>: 获得匹配后的字符串 </li><li><code>.start()</code>: 匹配字符串在原始字符串的开始位置 </li><li><code>.end()</code>: 匹配字符串在原始字符串的结束位置 </li><li><code>.span()</code>: 返回<code>(.start(), .end())</code></li></ul></li><li>eg:<pre><code class="lang-python">  match=re.search(r&#39;[1-9]\d{5}&#39;,&#39;BIT100081 TSU100084&#39;)  # 属性：  match.string    # &#39;BIT100081 TSU100084&#39;  match.re        # re.compile(&#39;[1-9]\\d{5}&#39;)  match.pos       # 0  match.endpos    # 19  # 方法：  match.group(0)  # 100081  match.start()   # 3  match.end()     # 9  match.span()    # (3,9)</code></pre></li></ul></li><li><p>贪婪匹配（默认）：输出匹配最长的子串</p><pre><code class="lang-python">  match = re.search(r&#39;PY.*N&#39;, &#39;PYANBNCNDN&#39;)  match.group(0)  # &#39;PYANBNCNDN&#39;</code></pre></li><li><p>最小匹配: 输出最短匹配子串，操作符后增加<code>?</code>操作符</p><pre><code class="lang-python">  &#39;&#39;&#39;  只要长度输出可能不同的,都可以通过在操作符后增加?变成最小匹配  `*?`: 前一个字符0次或无限次扩展,最小匹配  `+?`: 前一个字符1次或无限次扩展,最小匹配  `??`: 前一个字符0次或1次扩展,最小匹配  `{m,n}?`: 扩展前一个字符m至n次(含n),最小匹配  &#39;&#39;&#39;  match = re.search(r&#39;PY.*?N&#39;, &#39;PYANBNCNDN&#39;)  match.group(0)  # &#39;PYAN&#39;</code></pre></li></ul><h2 id="header-10">文档解析之BeautifulSoup</h2><blockquote><p>一个网页解析库，处理高效，目前可支持<code>html</code>, <code>xml</code>,<code>html5</code>文档解析，可配置使用不同解析器</p></blockquote><p>常见解析器：</p><table class="table"><thead><tr><th style="text-align:left">解析器</th><th style="text-align:left">使用</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">html.parser</td><td style="text-align:left">BeautifulSoup(content,’html.parser’)</td><td style="text-align:left">Python内置标准库,速度适中，容错能力适中，不依赖扩展</td></tr><tr><td style="text-align:left">lxml</td><td style="text-align:left">BeautifulSoup(content,’lxml’),BeautifulSoup(content,’xml’)</td><td style="text-align:left">第三方库（<code>pip install lxml</code>），速度快(局部遍历），支持XML解析，容错能力强，依赖C扩展</td></tr><tr><td style="text-align:left">html5hib</td><td style="text-align:left">BeautifulSoup(content,’html5hib’)</td><td style="text-align:left">第三方库（<code>pip install html5hib</code>）,速度慢，以浏览器的方式解析生成HTML5格式的文档，容错能力最好，不依赖外部扩展</td></tr></tbody></table><ol><li><p>安装 （BeautifulSoup 包含在一个名为 bs4 的文件包中，需要另外安装）</p><pre><code class="lang-bash"> pip install bs4</code></pre></li><li><p>创建BeautifulSoup对象，结构化解析Dom树（<code>HTML/XML</code> &lt;=&gt; <code>文档树</code> &lt;=&gt; <code>BeautifulSoup对象</code>）</p><pre><code class="lang-python"> from bs4 import BeautifulSoup # soup = BeautifulSoup(&quot;&lt;html&gt;&lt;body&gt;&lt;p&gt;data&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;&quot;,&#39;html.parser&#39;) soup = BeautifulSoup(&quot;&lt;html&gt;&lt;body&gt;&lt;p&gt;data&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;&quot;) print(soup.p) # 格式化输出（为HTML文本及其内容增加添加`\n`），也可用于标签:`&lt;tag&gt;.prettify()` print(soup.prettify())</code></pre></li><li><p>访问节点</p><table class="table"><thead><tr><th style="text-align:left">BeautifulSoup基本元素</th><th style="text-align:left">说明</th><th style="text-align:left">使用</th><th style="text-align:left">示例</th></tr></thead><tbody><tr><td style="text-align:left">Tag</td><td style="text-align:left">标签</td><td style="text-align:left"><code>&lt;tag&gt;</code></td><td style="text-align:left"><code>soup.p</code></td></tr><tr><td style="text-align:left">Name</td><td style="text-align:left">标签名字，字符串类型</td><td style="text-align:left"><code>&lt;tag&gt;.name</code></td><td style="text-align:left"><code>soup.p.name</code></td></tr><tr><td style="text-align:left">Attributes</td><td style="text-align:left">标签的属性，字典形式组织</td><td style="text-align:left"><code>&lt;tag&gt;.attrs</code></td><td style="text-align:left"><code>soup.p.attrs</code>,<code>soup.p[&#39;attrname&#39;]</code></td></tr><tr><td style="text-align:left">NavigableString</td><td style="text-align:left">标签内非属性字符串(<code>&lt;&gt;⋯&lt;/&gt;</code>中字符串)</td><td style="text-align:left"><code>&lt;tag&gt;.string</code></td><td style="text-align:left"><code>soup.p.string</code></td></tr><tr><td style="text-align:left">Comment</td><td style="text-align:left">标签内字符串的注释部分, 特殊类型的 NavigableString 对象</td><td style="text-align:left">/</td><td style="text-align:left">/</td></tr></tbody></table><ul><li>是否有设置属性<ul><li><code>has_attr(&quot;attrname&quot;)</code></li></ul></li><li>获取属性<ul><li><code>.attrs[&quot;attrname&quot;]</code></li><li><code>[&quot;attrname&quot;]</code></li></ul></li><li>获取内容<ul><li><code>.text</code></li><li><code>.get_text()</code></li></ul></li><li><p><code>.string</code> vs <code>.text</code></p><ul><li><code>.string</code> on a Tag type object returns a <code>NavigableString</code> type object.</li><li><code>.text</code> gets all the child strings and return concatenated using the given separator. </li><li><p>sample:</p><table class="table"><thead><tr><th style="text-align:left">Html</th><th style="text-align:left">string</th><th style="text-align:left">text</th></tr></thead><tbody><tr><td style="text-align:left"><code>&lt;td&gt;some text&lt;/td&gt;</code></td><td style="text-align:left"><code>some text</code></td><td style="text-align:left"><code>some text</code></td></tr><tr><td style="text-align:left"><code>&lt;td&gt;&lt;/td&gt;</code></td><td style="text-align:left"><code>None</code></td><td style="text-align:left">/</td></tr><tr><td style="text-align:left"><code>&lt;td&gt;&lt;p&gt;more text&lt;/p&gt;&lt;/td&gt;</code></td><td style="text-align:left"><code>more text</code></td><td style="text-align:left"><code>more text</code></td></tr><tr><td style="text-align:left"><code>&lt;td&gt;even &lt;p&gt;more text&lt;/p&gt;&lt;/td&gt;</code></td><td style="text-align:left"><code>None</code> (因为文本数<code>&gt;=2</code>，<code>.string</code>不知道获取哪一个)</td><td style="text-align:left"><code>even more text</code> (<code>.text</code>返回的是，两段文本的拼接)</td></tr><tr><td style="text-align:left"><code>&lt;td&gt;&lt;!--This is comment--&gt;&lt;/td&gt;</code></td><td style="text-align:left"><code>This is comment</code></td><td style="text-align:left">/</td></tr><tr><td style="text-align:left"><code>&lt;td&gt;even &lt;!--This is comment--&gt;&lt;/td&gt;</code></td><td style="text-align:left"><code>None</code></td><td style="text-align:left"><code>even</code></td></tr></tbody></table></li></ul></li></ul></li><li><p>Navigating the Tree</p><ul><li>Going Down: 下行遍历(子节点和子孙节点)<ul><li><code>.contents</code> 返回儿子节点列表<code>list</code></li><li><code>.children</code> 返回儿子节点迭代类型<code>list_iterator</code></li><li><code>.descendants</code> 返回子孙节点迭代类型<code>generator</code> (包含所有子孙节点)</li></ul></li><li>Going up: 上行遍历(父节点和祖先节点)<ul><li><code>.parent</code> 返回节点的父亲节点</li><li><code>.parents</code> 返回所有先辈节点的迭代类型<code>generator</code> (包括soup本身)</li></ul></li><li>Going sideways: 平行遍历(兄弟节点)<ul><li><code>.next_sibling</code> / <code>.previous_sibling</code> 返回HTML文本顺序的下/上一个平行节点</li><li><code>.next_siblings</code> / <code>.previous_siblings</code> 返回HTML文本顺序的后/前续所有平行节点的迭代类型<code>generator</code></li></ul></li><li>Going back and forth: 前后遍历（不分层次） <ul><li><code>.next_element</code> / <code>.next_elements</code></li><li><code>.previous_element</code> / <code>.previous_elements</code></li></ul></li></ul></li><li><p>Searching the Tree</p><ul><li>Searching Down: 下行搜索（子孙）<ul><li><code>find</code>/<code>find_all</code></li></ul></li><li>Searching up: 上行搜索（父祖）<ul><li><code>find_parent</code> / <code>find_parents</code> </li></ul></li><li>Searching sideway: 平行搜索（兄弟）：<ul><li><code>find_next_sibling</code> / <code>find_previous_sibling</code></li><li><code>find_next_siblings</code> / <code>find_previous_siblings</code></li></ul></li><li>Searching back and forth: 前后搜索（不分层次的前/后节点）：<ul><li><code>find_next</code> / <code>find_all_next</code></li><li><code>find_previous</code> / <code>find_all_previous</code></li></ul></li><li>注： <ul><li>方法参数<code>(name=None,attrs={},recursive=True,text=None,limit=None,**kwargs)</code>，可以使用正则表达式<ul><li><code>name</code>: 标签名称</li><li><code>attrs</code>: 标签属性</li><li><code>recursive</code>: 是否对子孙全部检索,默认True</li><li><code>text</code>: 内容字符串</li><li><code>limit</code>: 限制条数</li></ul></li><li><code>&lt;tag&gt;(..)</code> 等价于 <code>&lt;tag&gt;.find_all(..)</code> </li><li><code>soup(..)</code> 等价于 <code>soup.find_all(..)</code></li><li>每个元素是一个 <code>bs4.element.Tag</code> 对象</li></ul></li></ul></li><li><p>可使用CSS Selectors选择节点: <code>.select(&#39;...&#39;)</code> </p><ul><li>基础选择：<ul><li><code>#id</code></li><li><code>tagName</code></li><li><code>.styleClass</code></li></ul></li><li>属性过滤:<ul><li><code>[attribute]</code></li><li><code>[attribute=value]</code></li><li><code>[attribute!=value]</code></li><li><code>[attribute^=value]</code></li><li><code>[attribute$=value]</code></li><li><code>[attribute*=value]</code></li></ul></li><li>层级选择:<ul><li><code>ancestor descendent</code></li><li><code>parent &gt; child</code></li><li><code>prev + next</code> (next sibling tag)</li><li><code>prev ~ siblings</code> (next all sibling tags)</li></ul></li><li>元素过滤:<ul><li><code>:not(selector)</code></li><li><code>:nth-of-type(index)</code></li><li><code>:nth-child(index)</code></li><li><code>:first-child</code></li><li><code>:last-child</code></li><li><code>:only-child</code></li></ul></li><li>内容过滤:<ul><li><code>:contains(text)</code></li><li><code>:empty</code></li><li><code>:has(selector)</code></li></ul></li><li>表单属性过滤:<ul><li><code>:enabled</code></li><li><code>:checked</code></li><li><code>:disabled</code></li></ul></li><li>混合:<ul><li><code>selector1, selector2, selectorN</code>：获取多个选择符的合集</li><li><code>[selector1][selector2][selectorN]</code>：匹配同时符合多个属性选择符的对象</li></ul></li></ul></li><li><p>注： </p><ul><li>BeautifulSoup用编码自动检测子库来识别当前文档编码并转换成<code>Unicode</code>编码，输出使用<code>utf-8</code>编码</li><li>获取属性值<code>.attrs</code>,<code>.attrs[&#39;xxx&#39;]</code></li><li>获取内容<code>.text</code>,<code>.get_text()</code>,<code>.string</code>,<code>.strings</code></li></ul></li></ol><h3 id="header-11">Demo: 访问节点</h3><pre><code class="lang-python">from bs4 import BeautifulSoupcontent=&#39;&#39;&#39;&lt;b&gt;Chat with sb&lt;/b&gt;&lt;a&gt; This is title  &lt;!-- Guess --&gt; &lt;/a&gt;&lt;i&gt;&lt;!--This is comment--&gt;&lt;/i&gt;&lt;div id=&quot;div1&quot;&gt;    &lt;div id=&quot;div2&quot;&gt;        &lt;p id=&quot;test&quot; class=&quot;highlight&quot;&gt;            Hello &lt;a&gt;Tom&lt;/a&gt;            Nice to meet you &lt;!-- This is a comment --&gt;        &lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&#39;&#39;&#39;soup=BeautifulSoup(content,&#39;html.parser&#39;)</code></pre><ol><li><p>Tag <code>name</code>,<code>attrs</code></p><pre><code class="lang-python"> print(&quot;soup.p:&quot;,soup.p) # &lt;p class=&quot;highlight&quot; id=&quot;test1&quot;&gt; #                 Hello &lt;a&gt;Tom&lt;/a&gt; #                 Nice to meet you &lt;!-- This is a comment --&gt; # &lt;/p&gt; print(&quot;soup.p.name:&quot;,soup.p.name) # p print(&quot;soup.p.attrs:&quot;,soup.p.attrs) # {&#39;id&#39;: &#39;test1&#39;, &#39;class&#39;: [&#39;highlight&#39;]} print(&quot;soup.p.attr[&#39;class&#39;]:&quot;,soup.p.attrs[&quot;class&quot;]) # [&#39;highlight&#39;] print(&quot;soup.p.attrs[&#39;id&#39;]:&quot;,soup.p.attrs[&quot;id&quot;]) #  test1 print(&quot;soup.p[&#39;class&#39;]:&quot;,soup.p[&quot;class&quot;]) #[&#39;highlight&#39;]</code></pre></li><li><p>Tag <code>text</code>/<code>string</code></p><pre><code class="lang-python"> print(&quot;soup.p.text:&quot;,soup.p.text) # #                Hello Tom #                Nice to meet you # print(&quot;soup.p.get_text():&quot;,soup.p.get_text()) # #                Hello Tom #                Nice to meet you # print(&quot;type(soup.p.get_text()):&quot;,type(soup.p.get_text()))   # &lt;class &#39;str&#39;&gt; print(&quot;-----------------------------------&quot;) print(&#39;--- Demo: Tag &lt;p&gt; string ---&#39;) print(&quot;soup.p.string:&quot;,soup.p.string)               # None print(&quot;type(soup.p.string)&quot;,type(soup.p.string))    # &lt;class &#39;NoneType&#39;&gt; print(&quot;soup.p.strings:&quot;,soup.p.strings)             # &lt;generator object Tag._all_strings at 0x00000000028FDD68&gt; for i,s in enumerate(soup.p.strings):     print(i,&quot;:&quot;,s) print(&quot;-----------------------------------&quot;)     # 0 : #                 Hello # 1 : Tom # 2 : #                 Nice to meet you # 3 : print(&#39;--- Demo: Tag &lt;a&gt; text/string ---&#39;) print(&quot;soup.a.text:&quot;,soup.a.text)                       # Chat with sb print(&quot;soup.a.string:&quot;,soup.a.string)                   # Chat with sb print(&quot;type(soup.a.string):&quot;,type(soup.a.string))       # &lt;class &#39;bs4.element.NavigableString&#39;&gt; print(&quot;-----------------------------------&quot;) print(&#39;--- Demo: Tag &lt;b&gt; text/string ---&#39;) print(&quot;soup.b.text:&quot;,soup.b.text)                       # This is title print(&quot;soup.b.string:&quot;,soup.b.string)                   # None print(&quot;type(soup.b.string):&quot;,type(soup.b.string))       # &lt;class &#39;NoneType&#39;&gt; print(&quot;-----------------------------------&quot;) print(&#39;--- Demo: Tag &lt;i&gt; text/string ---&#39;) print(&quot;soup.i.text:&quot;,soup.i.text)                       # print(&quot;soup.i.string:&quot;,soup.i.string)                   # This is comment print(&quot;type(soup.i.string):&quot;,type(soup.i.string))       # &lt;class &#39;bs4.element.Comment&#39;&gt;</code></pre></li></ol><h3 id="header-12">Demo: Navigating the Tree</h3><pre><code class="lang-python">from bs4 import BeautifulSoupcontent=&#39;&#39;&#39;&lt;b&gt;Chat with sb&lt;/b&gt;&lt;a&gt; This is title  &lt;!-- Guess --&gt; &lt;/a&gt;&lt;i&gt;&lt;!--This is comment--&gt;&lt;/i&gt;&lt;div id=&quot;div1&quot;&gt;    &lt;div id=&quot;div2&quot;&gt;        &lt;p id=&quot;test&quot; class=&quot;highlight&quot;&gt;            Hello &lt;a&gt;Tom&lt;/a&gt;            Nice to meet you &lt;!-- This is a comment --&gt;        &lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&#39;&#39;&#39;soup=BeautifulSoup(content,&#39;html.parser&#39;)def print_result(result):    if type(result)==element.Tag or (type(result)== list and len(result)==0):        print(result)        return    for i,r in enumerate(result):        print(i,&quot;:&quot;,r)    print(&#39;-------------------------&#39;)def print_result_name(result):    if type(result)==element.Tag or type(result)==element.NavigableString or (type(result)== list and len(result)==0):        print(result)        return    for i,r in enumerate(result):        print(i,&quot;:&quot;,r.name)    print(&#39;-------------------------&#39;)</code></pre><ol><li><p>Going down:</p><ul><li><p><code>.contents</code></p><pre><code class="lang-python">  print(soup.p.contents)  # &lt;class &#39;list&#39;&gt;  print_result(soup.p.contents)  # 0 :  #                 Hello  # 1 : &lt;a&gt;Tom&lt;/a&gt;  # 2 :  #                 Nice to meet you  # 3 :  This is a comment  # 4 :</code></pre></li><li><p><code>.children</code>   </p><pre><code class="lang-python">  print(soup.p.children)            # &lt;list_iterator object at 0x0000000001E742E8&gt;  print_result(soup.p.children)  # 0 :  #                 Hello  # 1 : &lt;a&gt;Tom&lt;/a&gt;  # 2 :  #                 Nice to meet you  # 3 :  This is a comment  # 4 :</code></pre></li><li><p><code>.descendants</code></p><pre><code class="lang-python">  print(&#39;--- Demo: Tag &lt;p&gt; descendants ---&#39;)  print(soup.p.descendants)  # &lt;generator object Tag.descendants at 0x00000000028ADD68&gt;  print_result(soup.p.descendants)  # 0 :  #                 Hello  # 1 : &lt;a&gt;Tom&lt;/a&gt;  # 2 : Tom  # 3 :  #                 Nice to meet you  # 4 :  This is a comment  # 5 :</code></pre></li></ul></li><li><p>Going up:</p><ul><li><p><code>.parent</code></p><pre><code class="lang-python">  print(type(soup.p.parent))        # &lt;class &#39;bs4.element.Tag&#39;&gt;  print_result(soup.p.parent)  # &lt;div id=&quot;div2&quot;&gt;  # &lt;p class=&quot;highlight&quot; id=&quot;test1&quot;&gt;  #                 Hello &lt;a&gt;Tom&lt;/a&gt;  #                 Nice to meet you &lt;!-- This is a comment --&gt;  # &lt;/p&gt;  # &lt;p class=&quot;story&quot; id=&quot;test2&quot;&gt;Story1&lt;/p&gt;  # &lt;p class=&quot;story&quot; id=&quot;test3&quot;&gt;Story2&lt;/p&gt;  # &lt;/div&gt;</code></pre></li><li><p><code>.parents</code></p><pre><code class="lang-python">  print(soup.p.parents)             # &lt;generator object PageElement.parents at 0x00000000028FDD68&gt;  print_result_name(soup.p.parents)  # 0 : div  # 1 : div  # 2 : [document]</code></pre></li></ul></li><li><p>Going sideway:</p><ul><li><code>next_sibling</code><pre><code class="lang-python">  print_result(soup.p.next_sibling)  # 0 :</code></pre></li><li><p><code>next_siblings</code></p><pre><code class="lang-python">  print(soup.p.next_siblings)       # &lt;generator object PageElement.next_siblings at 0x00000000028FDD68&gt;  print_result(soup.p.next_siblings)  # 0 :  #   # 1 : &lt;p class=&quot;story&quot; id=&quot;test2&quot;&gt;Story1&lt;/p&gt;  # 2 :  #   # 3 : &lt;p class=&quot;story&quot; id=&quot;test3&quot;&gt;Story2&lt;/p&gt;  # 4 :</code></pre></li><li>vs. <code>find_next_silbings</code><pre><code class="lang-python">  print(&#39;--- Demo: `find_next_siblings()` ---&#39;)  result=soup.p.find_next_siblings()  print_result(result)  # 0 : &lt;p class=&quot;story&quot; id=&quot;test2&quot;&gt;Story1&lt;/p&gt;  # 1 : &lt;p class=&quot;story&quot; id=&quot;test3&quot;&gt;Story2&lt;/p&gt;</code></pre></li></ul></li><li><p>Going forth and back:</p><ul><li><code>next_element</code><pre><code class="lang-python">  print(soup.p.next_element)  #  # Hello  print(type(soup.p.next_element))  # &lt;class &#39;bs4.element.NavigableString&#39;&gt;</code></pre></li><li><p><code>next_elements</code></p><pre><code class="lang-python">  print(soup.p.next_elements)       # &lt;generator object PageElement.next_elements at 0x00000000028FDD68&gt;  print_result(soup.p.next_elements)  # 0 :  #                 Hello  # 1 : &lt;a&gt;Tom&lt;/a&gt;  # 2 : Tom  # 3 :  #                 Nice to meet you  # 4 :  This is a comment  # 5 :  #   # 6 :  #   # 7 : &lt;p class=&quot;story&quot; id=&quot;test2&quot;&gt;Story1&lt;/p&gt;  # 8 : Story1  # 9 :  #   # 10 : &lt;p class=&quot;story&quot; id=&quot;test3&quot;&gt;Story2&lt;/p&gt;  # 11 : Story2  # 12 :  #   # 13 :  #   # 14 :</code></pre></li><li>vs. <code>find_all_next()</code><pre><code class="lang-python">  result=soup.p.find_all_next()  print_result(result)  # 0 : &lt;a&gt;Tom&lt;/a&gt;  # 1 : &lt;p class=&quot;story&quot; id=&quot;test2&quot;&gt;Story1&lt;/p&gt;  # 2 : &lt;p class=&quot;story&quot; id=&quot;test3&quot;&gt;Story2&lt;/p&gt;</code></pre></li></ul></li></ol><h3 id="header-13">Demo: Searching the Tree</h3><pre><code class="lang-python">from bs4 import BeautifulSoupfrom bs4 import elementimport recontent=&#39;&#39;&#39;&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt; &lt;body&gt;&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;&#39;&#39;&#39;soup=BeautifulSoup(content,&#39;html.parser&#39;)print(soup.prettify())def print_result(result):    if type(result)==element.Tag or (type(result)== list and len(result)==0):        print(result)        return    for i,r in enumerate(result):        print(i,&quot;:&quot;,r)    print(&#39;-------------------------&#39;)def print_result_name(result):    if type(result)==element.Tag or (type(result)== list and len(result)==0):        print(result)        return    for i,r in enumerate(result):        print(i,&quot;:&quot;,r.name)    print(&#39;-------------------------&#39;)</code></pre><ol><li><p>Searching down</p><ul><li><p>by <code>name</code></p><pre><code class="lang-python">  print(&#39;--- Demo: `find_all(&quot;a&quot;)` ---&#39;)  result=soup.find_all(&#39;a&#39;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;  print(&#39;--- Demo: `find_all([&quot;a&quot;,&quot;title&quot;])` ---&#39;)  result=soup.find_all([&#39;a&#39;,&#39;title&#39;])  print_result(result)  # 0 : &lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 3 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;  print(&#39;--- Demo: `find_all(True)` ---&#39;)  result=soup.find_all(True)  print_result(result)  # 0 : &lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt; &lt;body&gt;  # &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;  # &lt;p class=&quot;story&quot;&gt;  # Once upon a time there were three little sisters; and their names were  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well.  # &lt;/p&gt;  # &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;  # &lt;/body&gt;  # &lt;/html&gt;  # 1 : &lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt;  # 2 : &lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;  # 3 : &lt;body&gt;  # &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;  # &lt;p class=&quot;story&quot;&gt;  # Once upon a time there were three little sisters; and their names were  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well.  # &lt;/p&gt;  # &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;  # &lt;/body&gt;  # 4 : &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;  # 5 : &lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;  # 6 : &lt;p class=&quot;story&quot;&gt;  # Once upon a time there were three little sisters; and their names were  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well.  # &lt;/p&gt;  # 7 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 8 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 9 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;  # 10 : &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;  print(&#39;--- Demo: `find_all(re.compile(&quot;b&quot;)` ---&#39;)  result=soup.find_all(re.compile(&#39;b&#39;))  print_result(result)  # 0 : &lt;body&gt;  # &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;  # &lt;p class=&quot;story&quot;&gt;  # Once upon a time there were three little sisters; and their names were  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well.  # &lt;/p&gt;  # &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;  # &lt;/body&gt;  # 1 : &lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;</code></pre></li><li><p>by <code>attrs</code></p><pre><code class="lang-python">  print(&#39;--- Demo: find_all(&quot;p&quot;,&quot;story&quot;) ---&#39;)  result=soup.find_all(&#39;p&#39;,&#39;story&#39;)  print_result(result)  # 0 : &lt;p class=&quot;story&quot;&gt;  # Once upon a time there were three little sisters; and their names were  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well.  # &lt;/p&gt;  # 1 : &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;  print(&#39;--- Demo: find_all(id=&quot;link1&quot;) ---&#39;)  result=soup.find_all(id=&#39;link1&#39;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  print(&#39;--- Demo: find_all(class_=&quot;sister&quot;) ---&#39;)  result=soup.find_all(class_=&#39;sister&#39;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;  print(&#39;--- Demo: find_all(re.compile(&quot;link&quot;)) ---&#39;)  result=soup.find_all(id=re.compile(&#39;link&#39;))  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;  print(&#39;--- Demo: find_all(attrs={&quot;class&quot;:&quot;story&quot;}) ---&#39;)  result=soup.find_all(attrs={&#39;class&#39;:&#39;story&#39;})  print_result(result)  # 0 : &lt;p class=&quot;story&quot;&gt;  # Once upon a time there were three little sisters; and their names were  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well.  # &lt;/p&gt;  # 1 : &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</code></pre></li><li><p>by <code>recursive</code></p><pre><code class="lang-python">  print(&#39;--- Demo: find_all(&quot;a&quot;) ---&#39;)  result=soup.find_all(&#39;a&#39;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;  print(&#39;--- Demo: find_all(&quot;a&quot;,recursive=False) ---&#39;)  result=soup.find_all(&#39;a&#39;,recursive=False)  print_result(result)  # []</code></pre></li><li><p>by <code>string/text</code></p><pre><code class="lang-python">  print(&#39;--- Demo: find_all(string=&quot;three&quot;) ---&#39;)  result=soup.find_all(string=&#39;three&#39;)  print_result(result)  # []  print(&#39;--- Demo: find_all(string=re.compile(&quot;e&quot;)) ---&#39;)  result=soup.find_all(string=re.compile(&#39;e&#39;))  print_result(result)  # 0 : The Dormouse&#39;s story  # 1 : The Dormouse&#39;s story  # 2 :  # Once upon a time there were three little sisters; and their names were  #  # 3 : Elsie  # 4 : Lacie  # 5 : Tillie  # 6 : ; and they lived at the bottom of a well.</code></pre></li><li>by <code>limit</code> : <code>find()</code>也就是当<code>limit=1</code>时的<code>find_all()</code><pre><code class="lang-python">  print(&#39;--- Demo: find_all(&quot;a&quot;,limit-2) ---&#39;)  result=soup.find_all(&#39;a&#39;,limit=2)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;</code></pre></li><li><p>by <code>self def function</code></p><pre><code class="lang-python">  print(&#39;--- Demo: using `self def function` ---&#39;)  def my_filter(tag):      return tag.has_attr(&#39;id&#39;) and re.match(&#39;link&#39;,tag.get(&quot;id&quot;))  result=soup.find_all(my_filter)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</code></pre></li></ul></li><li><p>Searching up: <code>find_parents</code></p><pre><code class="lang-python"> print(&#39;--- Demo: link2.`find_parents()` ---&#39;) result=soup.find(id=&quot;link2&quot;).find_parents() print_result_name(result) # 0 : p # 1 : body # 2 : html # 3 : [document] print(&#39;--- Demo: link2.`find_parents(&quot;p&quot;)` ---&#39;) result=soup.find(id=&quot;link2&quot;).find_parents(&#39;p&#39;) print_result(result) # 0 : &lt;p class=&quot;story&quot;&gt; # Once upon a time there were three little sisters; and their names were # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;, # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well. # &lt;/p&gt;</code></pre></li><li><p>Searching sideway: <code>find_next_siblings</code></p><pre><code class="lang-python"> print(&#39;--- Demo: `find_next_siblings()` ---&#39;) result=soup.find(id=&quot;link1&quot;).find_next_siblings() print_result(result) # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</code></pre></li><li><p>Searching forth and back: <code>find_all_next</code></p><pre><code class="lang-python"> print(&#39;--- Demo: `find_all_next()` ---&#39;) result=soup.find(id=&quot;link1&quot;).find_all_next() print_result(result) # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt; # 2 : &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</code></pre></li></ol><h3 id="header-14">Demo: CSS Selectors</h3><pre><code class="lang-html">&lt;html&gt;&lt;head&gt;&lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;&lt;/head&gt; &lt;body&gt;&lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;Once upon a time there were three little sisters; and their names were&lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,&lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; and &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well.&lt;/p&gt;&lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;&lt;input type=&quot;text&quot; disabled value=&quot;input something&quot;&gt;&lt;/input&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><ol><li><p>基础选择</p><ul><li><p><code>#id</code></p><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;#link1&quot;)` ---&#39;)  result=soup.select(&quot;#link1&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  print(&#39;--- Demo: `select(&quot;a#link1&quot;)` ---&#39;)  result=soup.select(&quot;a#link2&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;</code></pre></li><li><code>tagName</code><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;title&quot;)` ---&#39;)  result=soup.select(&quot;title&quot;)  print_result(result)  # 0 : &lt;title&gt;The Dormouse&#39;s story&lt;/title&gt;</code></pre></li><li><code>.styleClass</code><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;.sister&quot;)` ---&#39;)  result=soup.select(&quot;.sister&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</code></pre></li></ul></li><li><p>属性过滤</p><ul><li><p><code>[attribute]</code></p><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;a[href]&quot;)` ---&#39;)  result=soup.select(&#39;a[href]&#39;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</code></pre></li><li><p><code>[attribute=value]</code></p><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;[class=sister]&quot;)` ---&#39;)  result=soup.select(&quot;[class=sister]&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</code></pre></li><li><code>[attribute^=value]</code><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;a[href^=&quot;http://example.com/&quot;]&quot;)` ---&#39;)  result=soup.select(&#39;a[href^=&quot;http://example.com/&quot;]&#39;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</code></pre></li><li><code>[attribute$=value]</code><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;a[href$=&quot;tillie&quot;])` ---&#39;)  result=soup.select(&#39;a[href$=&quot;tillie&quot;]&#39;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</code></pre>-<code>[attribute*=value]</code><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;a[href*=&quot;.com/el&quot;]&quot;)` ---&#39;)  result=soup.select(&#39;a[href*=&quot;.com/el&quot;]&#39;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</code></pre></li><li><code>[selector1][selector2][selectorN]</code><pre><code class="lang-python">  print(&quot;--- Demo: `[class=&#39;sister&#39;][id=link2]` --- &quot;)  print_result(soup.select(&quot;[class=sister][id=link2]&quot;))  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;</code></pre></li></ul></li><li><p>层级选择</p><ul><li><code>ancestor descendent</code><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;body a&quot;)` ---&#39;)  result=soup.select(&quot;body a&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</code></pre></li><li><p><code>parent &gt; child</code></p><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;body &gt; a&quot;) ---&#39;)  result=soup.select(&quot;body &gt; a&quot;)  print_result(result)  # []  print(&#39;--- Demo: `select(&quot;p &gt; a&quot;) ---&#39;)  result=soup.select(&quot;p &gt; a&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;  print(&#39;--- Demo: `select(&quot;p &gt; a:nth-of-type(2)&quot;)` ---&#39;)  result=soup.select(&quot;p &gt; a:nth-of-type(2)&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  print(&#39;--- Demo: `select(&quot;p &gt; #link1&quot;)` ---&#39;)  result=soup.select(&quot;p &gt; #link1&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</code></pre></li><li><code>prev + next</code> ：next sibling tag<pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;#link1 ~ .sister&quot;)` ---&#39;)  result=soup.select(&quot;#link1 ~ .sister&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;</code></pre></li><li><code>prev ~ siblings</code> ：next all sibling tags<pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;#link1 + .sister&quot;)` ---&#39;)  result=soup.select(&quot;#link1 + .sister&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;</code></pre></li></ul></li><li><p>元素过滤</p><ul><li><code>:not(selector)</code><pre><code class="lang-python">  print(&quot;--- Demo: `:not(.story)` --- &quot;)  print_result(soup.select(&quot;p:not(.story)&quot;))  # 0 : &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;</code></pre></li><li><code>:nth-of-type(index)</code><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;p:nth-of-type(3)&quot;)` ---&#39;)  result=soup.select(&quot;p:nth-of-type(3)&quot;)  print_result(result)  # 0 : &lt;p class=&quot;story&quot;&gt;...&lt;/p&gt;</code></pre></li><li><code>:nth-child(index)</code><pre><code class="lang-python">  print(&quot;--- Demo: `p &gt; :nth-child(1)` --- &quot;)  print_result(soup.select(&quot;p &gt; :nth-child(1)&quot;))  # 0 : &lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</code></pre></li><li><code>:first-child</code><pre><code class="lang-python">  print(&quot;--- Demo: `p &gt; :first-child` --- &quot;)  print_result(soup.select(&quot;p &gt; :first-child&quot;))  # 0 : &lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</code></pre></li><li><code>:last-child</code><pre><code class="lang-python">  print(&quot;--- Demo: `p &gt; :last-child` --- &quot;)  print_result(soup.select(&quot;p &gt; :last-child&quot;))  # 0 : &lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</code></pre></li><li><code>:only-child</code><pre><code class="lang-python">  print(&quot;--- Demo: `p &gt; :only-child` --- &quot;)  print_result(soup.select(&quot;p &gt; :only-child&quot;))  # 0 : &lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;</code></pre></li></ul></li><li><p>内容过滤</p><ul><li><code>:contains(text)</code><pre><code class="lang-python">  print(&quot;--- Demo: `p:contains(story)` --- &quot;)  print_result(soup.select(&quot;p:contains(story)&quot;))  # 0 : &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;</code></pre></li><li><code>:empty</code><pre><code class="lang-python">  print(&quot;--- Demo: `p:empty` --- &quot;)  print_result(soup.select(&quot;p:empty&quot;))  # []</code></pre></li><li><code>:has(selector)</code><pre><code class="lang-python">  print(&quot;--- Demo: `p:has(b)` --- &quot;)  print_result(soup.select(&quot;p:has(b)&quot;))  # 0 : &lt;p class=&quot;title&quot;&gt;&lt;b&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;</code></pre></li></ul></li><li><p>表单属性过滤</p><ul><li><code>:enabled</code>,<code>:disabled</code>,<code>:checked</code><pre><code class="lang-python">  print(&quot;--- Demo: `:disabled`` --- &quot;)  print_result(soup.select(&quot;:disabled&quot;))  # 0 : &lt;input disabled=&quot;&quot; type=&quot;text&quot; value=&quot;input something&quot;/&gt;</code></pre></li></ul></li><li><p>其他：</p><ul><li><code>selector1, selector2, selectorN</code><pre><code class="lang-python">  print(&#39;--- Demo: `select(&quot;#link1,#link2&quot;)` ---&#39;)  result=soup.select(&quot;#link1,#link2&quot;)  print_result(result)  # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;  # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;</code></pre></li><li><code>select_one()</code><pre><code class="lang-python">  print(&#39;--- Demo: `select_one(&quot;.sister&quot;)` ---&#39;)  result=soup.select_one(&quot;.sister&quot;)  print_result(result)  # &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;</code></pre></li></ul></li><li><p>get attribute value:</p><pre><code class="lang-python"> print(&#39;--- Demo: `get attribute value` ---&#39;) result=soup.select(&quot;.sister&quot;) print_result(result) # 0 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/elsie&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt; # 1 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/lacie&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt; # 2 : &lt;a class=&quot;sister&quot; href=&quot;http://example.com/tillie&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt; print(result[0].get_text()) #Elsie print(result[0].attrs) #{&#39;href&#39;: &#39;http://example.com/elsie&#39;, &#39;class&#39;: [&#39;sister&#39;], &#39;id&#39;: &#39;link1&#39;} print(result[0].attrs[&#39;id&#39;]) #link1</code></pre></li></ol><h2 id="header-15">文档解析之XPath</h2><ul><li>使用路径表达式来选取<code>XML/HTML</code>文档中的节点或节点集</li><li>安装: <code>pip install lxml</code></li><li>导入：<code>from lxml import etree</code></li><li>注意：<code>lxml</code>和正则一样用<code>C</code>实现，是一款高性能的Python<code>HTML/XML</code>解析器，可以利用<code>XPath</code>语法来快速的定位特定元素以及节点信息</li><li>Tools: Chrome的插件<code>XPath Helper</code>，快速得到页面元素的匹配规则</li></ul><h3 id="header-16">路径表达式</h3><ul><li><p><code>//</code> : 选取所有的当前节点，不考虑他们的位置</p><ul><li><code>//p</code> (<code>.//p</code>)</li><li><code>/p//a</code></li><li><code>//p/a</code></li></ul></li><li><p><code>/</code> : 从根节点选取</p><ul><li><code>/p</code> (<code>./p</code>)</li><li><code>/p/a</code></li></ul></li><li><p><code>.</code> 当前节点,<code>..</code> : 当前节点的父节点</p><ul><li><code>./p</code> </li><li><code>../p</code></li><li><code>//p/b/../a</code></li><li><code>root.xpath(&#39;//p/b&#39;).xpath(&#39;./a&#39;)</code></li><li><code>root.xpath(&#39;//p/b&#39;).xpath(&#39;../text()&#39;)</code></li><li><code>root.xpath(&#39;//p/b/..//a&#39;)[0].text</code></li></ul></li><li><p><code>@</code> : 选取属性</p><ul><li><code>//@class</code></li><li><code>//p/@class</code></li><li><code>//p//@class</code></li><li><code>//p[@class]</code></li><li><code>//p[@class=&#39;s1&#39;]</code></li><li><code>//p[@class=&#39;s1&#39;]/@class</code></li></ul></li><li><p><code>/text()</code>,<code>string(.)</code> 选择内容</p><ul><li><code>&quot;//b/text()&quot;</code></li><li><code>//b//text()</code></li><li><code>string(.)</code></li><li><code>string(./description)</code></li></ul></li><li><p><code>[]</code>: Predicates</p><ul><li><code>//p[1]</code>,<code>//p[last()]</code>,<code>//p[last()-1]</code></li><li><code>//p[position()&lt;=2]</code></li><li><code>//p[@class]</code>,<code>//p[@class=&#39;s1&#39;]</code></li><li><code>//p[b]</code>,<code>//p[b/@class]</code>,<code>//p[b[@class=&#39;s1&#39;]]</code></li></ul></li><li><p><code>*</code> : 通配符，匹配任何 </p><ul><li><code>//p/*</code></li><li><code>//p//*</code></li><li><code>//p/*/a</code></li><li><code>//p[@*]</code></li><li><code>//*[@class=&#39;s1&#39;]</code></li></ul></li><li><p><code>|</code> : 选取多个路径</p><ul><li><code>/p | //b</code></li><li><code>//p/a | //p/b[@class]</code></li></ul></li><li><p><code>and</code>,<code>or</code>,<code>not</code>:</p><ul><li><code>//a[@class=&#39;sister&#39; and @id=&#39;link2&#39;]</code>,<code>//a[@class=&#39;sister&#39;][@id=&#39;link2&#39;]</code></li><li><code>//a[@id=&#39;link1&#39; or @class=&#39;outAstyle&#39;]</code></li><li><code>//a[not(@class=&#39;sister&#39;)]</code></li><li><code>//a[not(@class=&#39;sister&#39;) and @class or @id=&#39;link1&#39;]</code></li></ul></li><li><p><code>xxx()</code>: </p><ul><li><code>starts-with()</code>: <code>//a[starts-with(@href,&#39;http://example.com/&#39;)]</code></li><li><code>contains()</code>: <code>//a[contains(text(),&#39;ie&#39;) and contains(@id,&#39;link&#39;)]</code></li><li><code>text()</code>: <code>//b/text()</code>,<code>//b//text()</code></li><li><code>string(.)</code>: <code>data.xpath(&#39;//div[@class=&quot;name&quot;]&#39;)[0].xpath(&#39;string(.)&#39;)</code></li></ul></li><li><p><code>::</code></p><ul><li>go self: <code>self::</code>,eg: <code>//self::b</code></li><li>go up: <code>ancestor::</code> , <code>ancestor-or-self::</code>,<code>parent::</code>,eg: <code>//a/ancestor::p</code></li><li>go down: <code>descendant::</code>,<code>child::</code>,eg: <code>//p/descendant::a[not(@class)]</code></li><li>go forward: <code>following::</code>,<code>following-sibling::</code>, eg: <code>p[last()-1]/following::*</code></li><li>go back: <code>preceding::</code>,<code>preceding-sibling::</code> , eg: <code>p[2]/preceding::*</code></li><li>get attributes: <code>attribute::</code>,eg: <code>//a/attribute::*</code>,<code>//a/attribute::class</code></li></ul></li><li><p><code>lxml.etree._Element</code>:</p><ul><li><code>tag</code></li><li><code>attrib</code></li><li><code>text</code></li><li><code>.xpath(&#39;string(.)&#39;)</code></li><li><code>.get(&#39;attribute&#39;)</code></li></ul></li></ul><h3 id="header-17">Demo: 解析HTML</h3><pre><code class="lang-python">#!/usr/bin/env python# -*- coding:utf-8 -*-from lxml import etreecontent=&#39;&#39;&#39;&lt;div&gt;    &lt;p class=&quot;title&quot;&gt;&lt;b class=&#39;bstyle&#39;&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;    &lt;p class=&quot;story&quot;&gt;        Once upon a time there were three little sisters; and their names were        &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,        &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;         and &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;        ; and they lived at the bottom of a well.        &lt;p&gt; hello ...&lt;b&gt;&lt;a&gt; World &lt;/a&gt;&lt;/b&gt; &lt;/p&gt;    &lt;/p&gt;    &lt;p class=&quot;story&quot;&gt;...&lt;a class=&quot;outAstyle&quot;&gt;Miss&lt;/a&gt; &lt;/p&gt;&lt;/div&gt;&#39;&#39;&#39;# html = etree.parse(&#39;./test.html&#39;,etree.HTMLParser())html = etree.HTML(content)print(html)# &lt;Element html at 0x1019312c8&gt;# result = etree.tostring(html)     # 会补全缺胳膊少腿的标签# print(result.decode(&quot;utf-8&quot;))print(etree.tounicode(html))        # 会补全缺胳膊少腿的标签# &lt;html&gt;&lt;body&gt;&lt;div&gt;#   &lt;p class=&quot;title&quot;&gt;&lt;b class=&quot;bstyle&quot;&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;#   &lt;p class=&quot;story&quot;&gt;#       Once upon a time there were three little sisters; and their names were#       &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,#       &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;#       and &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;#       ; and they lived at the bottom of a well.#       &lt;/p&gt;&lt;p&gt; hello ...&lt;b&gt;&lt;a&gt; World &lt;/a&gt;&lt;/b&gt; &lt;/p&gt;#   &lt;p class=&quot;story&quot;&gt;...&lt;a class=&quot;outAstyle&quot;&gt;Miss&lt;/a&gt; &lt;/p&gt;# &lt;/div&gt;# &lt;/body&gt;&lt;/html&gt;result=html.xpath(&quot;//p/b&quot;)for i,r in enumerate(result):    print(i,type(r),&quot;:&quot;,r.tag,r.attrib,r.get(&#39;class&#39;),r.text,r.xpath(&#39;string(.)&#39;))# 0 &lt;class &#39;lxml.etree._Element&#39;&gt; : b {&#39;class&#39;: &#39;bstyle&#39;} bstyle The Dormouse&#39;s story The Dormouse&#39;s story# 1 &lt;class &#39;lxml.etree._Element&#39;&gt; : b {} None None  World############################ More test:test_path_any(html)test_path_attr(html)test_path_predicates(html)def test_path_any(root):    print(&quot;--- `//` ----&quot;)    do_xpath(root,&#39;p&#39;)    # []    do_xpath(root,&#39;//p&#39;)    # [&lt;Element p at 0x109f34148&gt;, &lt;Element p at 0x109f34188&gt;, &lt;Element p at 0x109f34248&gt;, &lt;Element p at 0x109f34288&gt;]    do_xpath(root,&#39;//p/a/text()&#39;)    # [&#39;Elsie&#39;, &#39;Lacie&#39;, &#39;Tillie&#39;, &#39;Miss&#39;]    do_xpath(root,&#39;//p//a/text()&#39;)    # [&#39;Elsie&#39;, &#39;Lacie&#39;, &#39;Tillie&#39;, &#39; World &#39;, &#39;Miss&#39;]    do_xpath(root,&#39;.//a/text()&#39;)    # [&#39;Elsie&#39;, &#39;Lacie&#39;, &#39;Tillie&#39;, &#39; World &#39;, &#39;Miss&#39;]    print(&#39;--- `xpath` ---&#39;)    print(root.xpath(&quot;//p/b//a&quot;))    # [&lt;Element a at 0x10b555f08&gt;]    print(root.xpath(&quot;//p/b&quot;)[1].xpath(&quot;//a&quot;))    # [&lt;Element a at 0x10b555f08&gt;, &lt;Element a at 0x10b5770c8&gt;, &lt;Element a at 0x10b577108&gt;, &lt;Element a at 0x10b577048&gt;, &lt;Element a at 0x10b577088&gt;]    print(root.xpath(&quot;//p/b&quot;)[1].xpath(&quot;./a&quot;))    # [&lt;Element a at 0x10c719f48&gt;]    print(root.xpath(&quot;//p/b&quot;)[1].xpath(&quot;../text()&quot;))    # [&#39; hello ...&#39;, &#39; &#39;]    print(root.xpath(&#39;//p/b/..//a&#39;)[0].text)    # World    print(&#39;------------------------&#39;)def test_path_attr(root):    print(&quot;--- `@` ----&quot;)    do_xpath(root,&#39;/@class&#39;)    # []    do_xpath(root,&#39;//@class&#39;)    # [&#39;title&#39;, &#39;bstyle&#39;, &#39;story&#39;, &#39;sister&#39;, &#39;sister&#39;, &#39;sister&#39;, &#39;story&#39;, &#39;outAstyle&#39;]    do_xpath(root,&#39;//p[@class]&#39;)    # [&lt;Element p at 0x10e4c3888&gt;, &lt;Element p at 0x10e4c36c8&gt;, &lt;Element p at 0x10e4c3708&gt;]    do_xpath(root,&quot;//p[@class=&#39;story&#39;]&quot;)    # [&lt;Element p at 0x110ba8708&gt;, &lt;Element p at 0x110ba8548&gt;]    do_xpath(root,&quot;//p/@class&quot;)    # [&#39;title&#39;, &#39;story&#39;, &#39;story&#39;]    do_xpath(root,&quot;//p[@class=&#39;story&#39;]/@class&quot;)    # [&#39;story&#39;, &#39;story&#39;]    do_xpath(root,&quot;//p[@class=&#39;story&#39;]//@class&quot;)    # [&#39;story&#39;, &#39;sister&#39;, &#39;sister&#39;, &#39;sister&#39;, &#39;story&#39;, &#39;outAstyle&#39;]    print(&#39;------------------------&#39;)def test_path_predicates(root):    print(&quot;--- `[]` ----&quot;)    do_xpath_detail(root,&#39;//p[1]&#39;)    # 0 : &lt;p class=&quot;title&quot;&gt;&lt;b class=&quot;bstyle&quot;&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;    do_xpath_detail(root,&#39;//p[last()]&#39;)    # 0 : &lt;p class=&quot;story&quot;&gt;...&lt;a class=&quot;outAstyle&quot;&gt;Miss&lt;/a&gt; &lt;/p&gt;    do_xpath_detail(root,&#39;//p[last()-1]&#39;)    # 0 : &lt;p&gt; hello ...&lt;b&gt;&lt;a&gt; World &lt;/a&gt;&lt;/b&gt; &lt;/p&gt;    do_xpath_detail(root,&#39;//a[1]&#39;)    # 0 : &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,    # 1 : &lt;a&gt; World &lt;/a&gt;    # 2 : &lt;a class=&quot;outAstyle&quot;&gt;Miss&lt;/a&gt;    do_xpath_detail(root,&#39;//p/a[1]&#39;)    # 0 : &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,    # 1 : &lt;a class=&quot;outAstyle&quot;&gt;Miss&lt;/a&gt;    do_xpath_detail(root,&#39;//a[position()&lt;=2]&#39;)    # 0 : &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,    # 1 : &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;and    # 2 : &lt;a&gt; World &lt;/a&gt;    # 3 : &lt;a class=&quot;outAstyle&quot;&gt;Miss&lt;/a&gt;    do_xpath_detail(root,&#39;//a[@class]&#39;)    # 0 : &lt;a href=&quot;http://example.com/elsie&quot; class=&quot;sister&quot; id=&quot;link1&quot;&gt;Elsie&lt;/a&gt;,    # 1 : &lt;a href=&quot;http://example.com/lacie&quot; class=&quot;sister&quot; id=&quot;link2&quot;&gt;Lacie&lt;/a&gt;and    # 2 : &lt;a href=&quot;http://example.com/tillie&quot; class=&quot;sister&quot; id=&quot;link3&quot;&gt;Tillie&lt;/a&gt;; and they lived at the bottom of a well.    # 3 : &lt;a class=&quot;outAstyle&quot;&gt;Miss&lt;/a&gt;    do_xpath_detail(root,&#39;//a[@class=&quot;outAstyle&quot;]&#39;)    # 0 : &lt;a class=&quot;outAstyle&quot;&gt;Miss&lt;/a&gt;    do_xpath_detail(root,&#39;//p[b]&#39;)    # 0 : &lt;p class=&quot;title&quot;&gt;&lt;b class=&quot;bstyle&quot;&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;    # 1 : &lt;p&gt; hello ...&lt;b&gt;&lt;a&gt; World &lt;/a&gt;&lt;/b&gt; &lt;/p&gt;    do_xpath_detail(root,&quot;//p[b/@class]&quot;)    # 0 : &lt;p class=&quot;title&quot;&gt;&lt;b class=&quot;bstyle&quot;&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;    do_xpath_detail(root,&quot;//p[b[@class=&#39;bstyle&#39;]]&quot;)    # 0 : &lt;p class=&quot;title&quot;&gt;&lt;b class=&quot;bstyle&quot;&gt;The Dormouse&#39;s story&lt;/b&gt;&lt;/p&gt;    print(&#39;------------------------&#39;)def do_xpath(root,path):    result=root.xpath(path)    print(&quot;%s : \n%s&quot; % (path,result))    return resultdef do_xpath_detail(root,path):    result=root.xpath(path)    print(path,&quot;:&quot;)    if type(result)==list and len(result)&gt;0:        for i,r in enumerate(result):            if type(r)==etree._Element:                print(i,&quot;:&quot;,etree.tounicode(r))            else:                print(i,&quot;:&quot;,r)    else:        print(result)    return result</code></pre><h3 id="header-18">Demo: 解析XML</h3><pre><code class="lang-python">from lxml import etreecontent=&#39;&#39;&#39;&lt;collection shelf=&quot;New Arrivals&quot;&gt;    &lt;movie title=&quot;Enemy Behind&quot;&gt;       &lt;type&gt;War, Thriller&lt;/type&gt;       &lt;format&gt;DVD&lt;/format&gt;       &lt;year&gt;2003&lt;/year&gt;       &lt;rating&gt;PG&lt;/rating&gt;       &lt;stars&gt;10&lt;/stars&gt;       &lt;description&gt;Talk about a US-Japan war&lt;/description&gt;    &lt;/movie&gt;    &lt;movie title=&quot;Transformers&quot;&gt;       &lt;type&gt;Anime, Science Fiction&lt;/type&gt;       &lt;format&gt;DVD&lt;/format&gt;       &lt;year&gt;1989&lt;/year&gt;       &lt;rating&gt;R&lt;/rating&gt;       &lt;stars&gt;8&lt;/stars&gt;       &lt;description&gt;A schientific fiction&lt;/description&gt;    &lt;/movie&gt;&lt;/collection&gt;&#39;&#39;&#39;root=etree.XML(content)print(root)print(etree.tounicode(root))result=root.xpath(&#39;//movie&#39;)for i,r in enumerate(result):    print(i,r,&quot;:&quot;,r.tag,r.attrib,r.get(&#39;title&#39;))    print(&quot;text:&quot;,r.text)    print(&quot;string:&quot;,r.xpath(&#39;string(./description)&#39;))    print(&#39;rating:&#39;,r.xpath(&#39;./rating/text()&#39;))</code></pre><h2 id="header-19">文档解析之JSonPath</h2><ul><li>是一种信息抽取类库, 是从<code>JSON</code>文档中抽取指定信息的工具，提供多种语言实现版本，包括：Javascript,Python,PHP，Java</li><li>JsonPath对于<code>JSON</code>来说，相当于<code>XPATH</code> 对于<code>XML</code>, Refer <a href="https://goessner.net/articles/JsonPath/" target="_blank" rel="noopener">JSONPath - XPath for JSON</a></li><li>python中有2个类库可使用<ul><li><code>pip install jsonpath</code>,<code>import jsonpath</code></li><li><code>pip install jsonpath-rw</code>, <code>from jsonpath import jsonpath,parse</code> , Refer <a href="https://pypi.org/project/jsonpath-rw/" target="_blank" rel="noopener">Github</a></li></ul></li></ul><h3 id="header-20">Jsonpath 操作符</h3><ul><li><code>$</code>: 根节点</li><li><code>@</code>: 当前节点</li><li><code>*</code>: 通配符，匹配所有</li><li><code>..</code>: 递归搜索</li><li><code>.</code> : 子节点</li><li><code>[]</code>: 取子节点,迭代器标示(可在里面做简单的迭代操作，如数组下标，根据内容选值等) <ul><li><code>[start:end]</code>,<code>[start:end:step]</code></li><li><code>[,]</code> 支持迭代器中做多选</li></ul></li><li><code>()</code>: 支持表达式计算<ul><li><code>?()</code>: 过滤操作，表达式结果必须是boolean类型</li></ul></li></ul><h3 id="header-21">Json转换</h3><ul><li><code>import json</code></li><li>function:<ul><li><code>loads</code>,<code>load</code>: jsonString -&gt; pythonObj</li><li><code>dumps</code>,<code>dump</code>: pythonObj -&gt; jsonString</li></ul></li><li>转换：<table class="table"><thead><tr><th style="text-align:left">Json</th><th style="text-align:left">Python</th></tr></thead><tbody><tr><td style="text-align:left">object</td><td style="text-align:left">dict</td></tr><tr><td style="text-align:left">array</td><td style="text-align:left">list</td></tr><tr><td style="text-align:left">string</td><td style="text-align:left">unicode</td></tr><tr><td style="text-align:left">number(int)</td><td style="text-align:left">int,long</td></tr><tr><td style="text-align:left">number(real)</td><td style="text-align:left">float</td></tr><tr><td style="text-align:left">true</td><td style="text-align:left">True</td></tr><tr><td style="text-align:left">false</td><td style="text-align:left">False</td></tr><tr><td style="text-align:left">null</td><td style="text-align:left">None</td></tr></tbody></table></li></ul><p><strong> 示例：</strong></p><pre><code class="lang-python">import jsoncontent=&#39;&#39;&#39;{&quot;subjects&quot;:[    {&quot;rate&quot;:&quot;6.5&quot;,&quot;cover_x&quot;:1000,&quot;title&quot;:&quot;硬核&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/27109879/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2532653002.webp&quot;,&quot;id&quot;:&quot;27109879&quot;,&quot;cover_y&quot;:1414,&quot;is_new&quot;:false}    ,{&quot;rate&quot;:&quot;7.1&quot;,&quot;cover_x&quot;:2000,&quot;title&quot;:&quot;奎迪：英雄再起&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/26707088/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2544510053.webp&quot;,&quot;id&quot;:&quot;26707088&quot;,&quot;cover_y&quot;:2800,&quot;is_new&quot;:false}    ,{&quot;rate&quot;:&quot;6.1&quot;,&quot;cover_x&quot;:800,&quot;title&quot;:&quot;芳龄十六&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/30334122/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2549923514.webp&quot;,&quot;id&quot;:&quot;30334122&quot;,&quot;cover_y&quot;:1185,&quot;is_new&quot;:false}    ,{&quot;rate&quot;:&quot;7.7&quot;,&quot;cover_x&quot;:1500,&quot;title&quot;:&quot;污垢&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/1945750/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2548709468.webp&quot;,&quot;id&quot;:&quot;1945750&quot;,&quot;cover_y&quot;:2222,&quot;is_new&quot;:false}    ,{&quot;rate&quot;:&quot;6.8&quot;,&quot;cover_x&quot;:1179,&quot;title&quot;:&quot;欢乐满人间2&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/26611891/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2515404175.webp&quot;,&quot;id&quot;:&quot;26611891&quot;,&quot;cover_y&quot;:1746,&quot;is_new&quot;:false}]}&#39;&#39;&#39;# 1. loads: string -&gt; python objprint(&#39;---- loads: --------------&#39;)result=json.loads(content)print(type(result))                             # &lt;class &#39;dict&#39;&gt;print(result)# 2. dumps: python obj -&gt; stringprint(&#39;---- dumps: --------------&#39;)subjects=result.get(&#39;subjects&#39;)result=json.dumps(subjects,ensure_ascii=False)  # 禁用ascii编码，按utf-8编码    print(type(result))                             # &lt;class &#39;str&#39;&gt;print(result)# 3. dump: python obj -&gt; string -&gt; fileprint(&#39;---- dump: --------------&#39;)json.dump(subjects,open(&#39;test.json&#39;,&#39;w&#39;),ensure_ascii=False)with open(&#39;test.json&#39;,&#39;r&#39;) as f:    print(f.read())# 4. load: file -&gt; string -&gt; python objprint(&#39;---- load: --------------&#39;)result=json.load(open(&#39;test.json&#39;,&#39;r&#39;))print(type(result))                             # &lt;class &#39;list&#39;&gt;print(result)print(&#39;-------------------------&#39;)</code></pre><h3 id="header-22">Demo：使用Jsonpath解析JSON</h3><pre><code class="lang-python">import jsonimport jsonpathcontent=&#39;&#39;&#39;{&quot;subjects&quot;:[    {&quot;rate&quot;:&quot;6.5&quot;,&quot;cover_x&quot;:1000,&quot;title&quot;:&quot;硬核&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/27109879/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2532653002.webp&quot;,&quot;id&quot;:&quot;27109879&quot;,&quot;cover_y&quot;:1414,&quot;is_new&quot;:false}    ,{&quot;rate&quot;:&quot;7.1&quot;,&quot;cover_x&quot;:2000,&quot;title&quot;:&quot;奎迪：英雄再起&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/26707088/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2544510053.webp&quot;,&quot;id&quot;:&quot;26707088&quot;,&quot;cover_y&quot;:2800,&quot;is_new&quot;:false}    ,{&quot;rate&quot;:&quot;6.1&quot;,&quot;cover_x&quot;:800,&quot;title&quot;:&quot;芳龄十六&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/30334122/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2549923514.webp&quot;,&quot;id&quot;:&quot;30334122&quot;,&quot;cover_y&quot;:1185,&quot;is_new&quot;:false}    ,{&quot;rate&quot;:&quot;7.7&quot;,&quot;cover_x&quot;:1500,&quot;title&quot;:&quot;污垢&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/1945750/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2548709468.webp&quot;,&quot;id&quot;:&quot;1945750&quot;,&quot;cover_y&quot;:2222,&quot;is_new&quot;:false}    ,{&quot;rate&quot;:&quot;6.8&quot;,&quot;cover_x&quot;:1179,&quot;title&quot;:&quot;欢乐满人间2&quot;,&quot;url&quot;:&quot;https://movie.douban.com/subject/26611891/&quot;,&quot;playable&quot;:false,&quot;cover&quot;:&quot;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2515404175.webp&quot;,&quot;id&quot;:&quot;26611891&quot;,&quot;cover_y&quot;:1746,&quot;is_new&quot;:false}]}&#39;&#39;&#39;# 0. 加载obj=json.loads(content)# 1. `[?()]`results=jsonpath.jsonpath(obj,&#39;$.subjects[?(float(@.rate)&gt;=7)]&#39;)print(type(results))# &lt;class &#39;list&#39;&gt;    print(results)#[{&#39;rate&#39;: &#39;7.1&#39;, &#39;cover_x&#39;: 2000, &#39;title&#39;: &#39;奎迪：英雄再起&#39;, &#39;url&#39;: &#39;https://movie.douban.com/subject/26707088/&#39;, &#39;playable&#39;: False, &#39;cover&#39;: &#39;https://img3.doubanio.com/view/photo/s_ratio_poster/public/p2544510053.webp&#39;, &#39;id&#39;: &#39;26707088&#39;, &#39;cover_y&#39;: 2800, &#39;is_new&#39;: False}# , {&#39;rate&#39;: &#39;7.7&#39;, &#39;cover_x&#39;: 1500, &#39;title&#39;: &#39;污垢&#39;, &#39;url&#39;: &#39;https://movie.douban.com/subject/1945750/&#39;, &#39;playable&#39;: False, &#39;cover&#39;: &#39;https://img1.doubanio.com/view/photo/s_ratio_poster/public/p2548709468.webp&#39;, &#39;id&#39;: &#39;1945750&#39;, &#39;cover_y&#39;: 2222, &#39;is_new&#39;: False}# ]# 2. `.xxx`results=jsonpath.jsonpath(obj,&#39;$.subjects[?(float(@.rate)&gt;=7)].title&#39;)print(results)# [&#39;奎迪：英雄再起&#39;, &#39;污垢&#39;]# 3. `[index1,index2]`results=jsonpath.jsonpath(obj,&#39;$.subjects[0,2,3].cover_x&#39;)print(results)# [1000, 800, 1500]# 4. `[start:end]`results=jsonpath.jsonpath(obj,&#39;$.subjects[0:3].cover_x&#39;)print(results)# [1000, 2000, 800]# 5. `[start:end:step]`results=jsonpath.jsonpath(obj,&#39;$.subjects[0:3:2].cover_x&#39;)print(results)# [1000, 800]# 6. `?( &amp;&amp; )`,`?(,)`# cover_x   cover_y# 1000      1414# 2000      2800# 800       1185# 1500      2222# 1179      1746results=jsonpath.jsonpath(obj,&#39;$.subjects[?(@.cover_x&gt;=1000 &amp;&amp; @.cover_y&lt;1500)]&#39;)print(len(results))# 1results=jsonpath.jsonpath(obj,&#39;$.subjects[?(@.cover_x&gt;=1000,@.cover_y&lt;1500)]&#39;)print(len(results))# 5print(&#39;-------------------------&#39;)</code></pre><h2 id="header-23">Reference</h2><ul><li><a href="https://github.com/sixDegree/python-basic-demo" target="_blank" rel="noopener">My Demo</a></li><li><a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.html" target="_blank" rel="noopener">Beautiful Soup Documentation</a></li><li><a href="http://www.cnblogs.com/descusr/archive/2012/06/20/2557075.html" target="_blank" rel="noopener">用lxml解析HTML</a></li><li><a href="https://www.cnblogs.com/MUMO/p/5732836.html" target="_blank" rel="noopener">Python爬虫：Xpath语法笔记</a></li><li><a href="https://www.cnblogs.com/lei0213/p/7506130.html" target="_blank" rel="noopener">python爬虫之xpath的基本使用</a></li><li><a href="https://cloud.tencent.com/developer/news/374969" target="_blank" rel="noopener">Python使用JsonPath</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ul&gt;
&lt;li&gt;爬虫基础&lt;/li&gt;
&lt;li&gt;Re&lt;/li&gt;
&lt;li&gt;BeautifulSoup(include CSS Selector)&lt;/li&gt;
&lt;li&gt;XPath&lt;/li&gt;
&lt;li&gt;JSONPath&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="Python" scheme="http://sixdegree.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>Python 基础</title>
    <link href="http://sixdegree.github.io/2019/03/11/python-basic.html"/>
    <id>http://sixdegree.github.io/2019/03/11/python-basic.html</id>
    <published>2019-03-10T16:00:00.000Z</published>
    <updated>2019-07-21T11:40:24.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li>Env &amp; Tools: python(+pip),ipython,Anaconda(+conda),PyCharm</li><li>基础：keywords,comment,input,print,operation,if-else,for,while,try…except,sys.argv,unittest</li><li>基础数据类型: 不可变对象(int,float,str,tuple,) &amp; 可变对象(list,set,dict),垃圾回收机制,类型转换,位运算</li><li>函数: 局部／全局变量，默认／不定长参数，闭包，列表生成式，生成器，迭代器，装饰器，匿名函数，常用内建函数</li><li>类: 类属性／方法／静态方法，实例属性／方法，继承与多态，元类，枚举类，单例模式，内置类属性，定制类</li><li>库：模块与包，导入，自定义库，发布／安装，常用标准库，常用扩展库</li><li>文件IO：读写文件，操作文件／目录</li><li>多任务：进程，线程，协程</li><li>访问数据库：SQLite,MySQL,Redis,MongoDB</li></ol><a id="more"></a><h2 id="header-1">Starter</h2><ul><li><a href="https://www.python.org/" target="_blank" rel="noopener">官网</a></li><li><a href="https://docs.python.org/3/library/" target="_blank" rel="noopener">Python Standard Library</a></li><li><a href="https://pypi.org/" target="_blank" rel="noopener">Python Package Index</a>  </li><li>安装 <code>python</code> ：<ul><li>mac: <code>brew install python3</code></li><li>windows: download and install from python website</li></ul></li><li>包管理工具 <code>pip</code>:<ul><li><code>pip/pip3 [cmd] [opts]</code></li><li>eg: <code>pip instal xxx</code>,<code>pip install --upgrade xxx</code>,<code>pip install xxx==version</code>,<code>pip uninstall xxx</code>,<code>pip list</code></li></ul></li></ul><h3 id="header-2">开发环境 (IDE)</h3><ol><li><p>python自带的开发环境</p><pre><code class="lang-bash"> # 交互式 $ python Python 3.7.2 (tags/v3.7.2:9a3ffc0492, Dec 23 2018, 23:09:28) [MSC v.1916 64 bit (AMD64)] on win32 Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. &gt;&gt;&gt; 100+200 300 &gt;&gt;&gt; exit()</code></pre><pre><code class="lang-bash"> # 直接运行 $ python hello.py 100+200=300</code></pre><pre><code class="lang-bash"> # 调试： # pdb调试器, 以参数`-m pdb`启动，输入命令`n`单步执行代码，`p 变量名`查看变量，`q`  结束调试退出程序 D:\Space\python&gt; python -m pdb hello.py &gt; d:\space\python\hello.py(2)&lt;module&gt;() -&gt; print(&#39;--- Print --- &#39;) (Pdb) n --- Print --- &gt; d:\space\python\hello.py(3)&lt;module&gt;() -&gt; print(&#39;100+200=&#39;+str(100+200)) (Pdb) n 100+200=300 &gt; d:\space\python\hello.py(4)&lt;module&gt;() -&gt; print(&#39;100+200=&#39;,100+200) (Pdb) n 100+200= 300 &gt; d:\space\python\hello.py(7)&lt;module&gt;() -&gt; print(&#39;--- Inport --- &#39;) (Pdb) n --- Inport --- &gt; d:\space\python\hello.py(8)&lt;module&gt;() -&gt; name=input(&#39;input name:&#39;) (Pdb) n input name:Tom &gt; d:\space\python\hello.py(9)&lt;module&gt;() -&gt; print(&#39;Hello &#39;+name) (Pdb) p name &#39;Tom&#39; (Pdb) n Hello Tom &gt; d:\space\python\hello.py(12)&lt;module&gt;() -&gt; print(&#39;--- Function --- &#39;) (Pdb) q D:\Space\python&gt;</code></pre></li><li><p>Anaconda </p><ul><li>开源免费 <a href="https://www.anaconda.com/distribution" target="_blank" rel="noopener">Download</a></li><li>一个集成各类Python工具的集成平台</li><li>包括 conda包管理工具, 某版本Python, 一批第三方库，编程工具Spyder，交互式编程工具IPython,网页交互式编程工具Jupyter Notebook等</li><li><p><code>ipython</code></p><ul><li><code>?</code>: 变量前或后增加<code>?</code>将显示一些通用信息,包括函数对应的源代码</li><li><code>%</code><ul><li><code>%run</code>: 用于运行<code>.py</code>程序 (注意在一个空的命名空间执行<code>%</code>)</li><li><code>%magic</code>: 显示所有魔术命令</li><li><code>%hist</code>: IPython命令的输入历史</li><li><code>%pdb</code>: 异常发生后是否自动进入调试器</li><li><code>%reset</code>: 重置，即删除当前命名空间中的全部变量或名称</li><li><code>%who</code>: 显示Ipython当前命名空间中已经定义的变量</li><li><code>%time</code>: 给出代码的执行时间 </li><li><code>%timeit</code>: 多次执行代码,计算综合平均执行时间</li></ul></li></ul></li><li><p><code>conda</code> 包管理和环境管理工具</p><ul><li>包管理与pip类似,管理Python第三方库 </li><li>环境管理能够允许用户使用不同版本Python,并能灵活切换</li><li><p>常用命令：</p><ul><li>获取conda版本 <code>conda ‐‐version</code></li><li>升级conda <code>conda update conda</code></li><li>下载／卸载包 <code>conda install/uninstall xxx</code></li><li>列出安装的包 <code>conda list</code></li><li>搜索包 <code>conda search xxx</code> eg: <code>conda search numpy&gt;=1.12</code></li><li><p>创建／启用／退出env <code>conda create/activate/deactivate xxx</code></p><pre><code class="lang-python">  # conda activate/deactivate envName  $ conda activate base  (base) $ ipython3  Python 3.7.3 (default, Mar 27 2019, 16:54:48)  Type &#39;copyright&#39;, &#39;credits&#39; or &#39;license&#39; for more information  IPython 7.4.0 -- An enhanced Interactive Python. Type &#39;?&#39; for help.  In [1]: 100+200  Out[1]: 300  In [2]: exit()  (base) $</code></pre></li></ul></li></ul></li></ul></li><li><p>PyCharm </p><ul><li>Community版本免费 <a href="http://www.jetbrains.com/pycharm" target="_blank" rel="noopener">Download</a></li><li>类似 Eclipse，有调试、语法高亮、Project管理、代码跳转、智能提示、自动完成、单元测试、版本控制等功能</li><li><code>Preference -&gt; Project Interpreter -&gt; 配置 environment</code> (若安装)</li></ul></li></ol><h2 id="header-3">基础</h2><h3 id="header-4">关键字</h3><pre><code class="lang-python">&gt;&gt;&gt; import keyword&gt;&gt;&gt; help(keyword)&gt;&gt;&gt; keyword.kwlist[&#39;False&#39;, &#39;None&#39;, &#39;True&#39;, &#39;and&#39;, &#39;as&#39;, &#39;assert&#39;, &#39;async&#39;, &#39;await&#39;, &#39;break&#39;, &#39;class&#39;, &#39;continue&#39;, &#39;def&#39;, &#39;del&#39;, &#39;elif&#39;, &#39;else&#39;, &#39;except&#39;, &#39;finally&#39;, &#39;for&#39;, &#39;from&#39;, &#39;global&#39;, &#39;if&#39;, &#39;import&#39;, &#39;in&#39;, &#39;is&#39;, &#39;lambda&#39;, &#39;nonlocal&#39;, &#39;not&#39;, &#39;or&#39;, &#39;pass&#39;, &#39;raise&#39;, &#39;return&#39;, &#39;try&#39;, &#39;while&#39;, &#39;with&#39;, &#39;yield&#39;]</code></pre><h3 id="header-5">注释</h3><ul><li>单行注释<pre><code class="lang-python">  # Test  print(&quot;Hello World&quot;)</code></pre></li><li>多行注释<pre><code class="lang-python">  &#39;&#39;&#39;  This is test program  Author: CJ  Date: 2019/03/10  &#39;&#39;&#39;</code></pre></li><li>中文支持(for <code>Syntax Error:Non-ASCII Character ...</code>)<pre><code class="lang-python">  # -*- coding:utf-8 -*-  print(&#39;你好&#39;)</code></pre><ul><li>注：<code># -*- coding:utf-8 -*-</code> 一般放文件首行</li></ul></li></ul><h3 id="header-6">输出</h3><pre><code class="lang-python"># 1. &quot;&quot;,&#39;&#39;,&#39;&#39;&#39;print(&#39;123&#39;)print(12)print(&quot;It&#39;s a.&quot;)print(&#39;It\&#39;s a.&#39;)print(&quot;Hello &#39;Tom&#39;.&quot;)    # Hello &#39;Tom&#39;.print(&#39;Hello &quot;Tom&quot;.&#39;)    # Hello &quot;Tom&quot;.# 2. &#39;&#39;&#39;,\nprint(&#39;sdf\nsdfd&#39;)print(&#39;&#39;&#39;sdfsdfd&#39;&#39;&#39;)print(&#39;&#39;&#39;Hello Tom.Miss youHow are you?&#39;&#39;&#39;)#Hello Tom.#Miss you#How are you?print(&quot;Hello Tom.\nMiss you\nHow are you?&quot;)#Hello Tom.#Miss you#How are you?# 3. a bprint(&quot;Hello&quot;,&quot;Tom&quot;) # Hello Tom# 4. %print(&quot;Hello %s&quot; % &quot;Tom&quot;)    # Hello Tomprint(&quot;a=%d&quot; % 123.5)        # a=123print(&quot;Hello %s,a=%d&quot; % (&quot;Tom&quot;,123.5)) # Hello Tom,a=123x=[1,2,3]print(&quot;Hello %s&quot; % x)        # Hello [1, 2, 3]x=&quot;Hello %s,a=%d&quot;print(x % (&quot;Tom&quot;,123.5))    # Hello Tom,a=123x=&quot;Hello %s,a=%d&quot; % (&quot;Tom&quot;,123.5)type(x)                        # strprint(x)                    # Hello Tom,a=123# 5. str,intx=123y=&#39;123&#39;print(x)print(y)print(str(x)+y)</code></pre><p><strong>格式化输出，常用的格式符号：</strong></p><ul><li>字符<ul><li><code>%c</code>: 字符</li><li><code>%s</code>: 字符串,通过<code>str()</code>字符串转换格式化,eg:<ul><li><code>%10s</code>: 右对齐，占位符10位</li><li><code>%-10s</code>: 左对齐，占位符10位</li><li><code>%.2s</code>: 截取2位字符串</li><li><code>%10.2s</code>: 10位占位符，截取两位字符串</li></ul></li></ul></li><li>整数<ul><li><code>%d</code>: dec 十进制整数</li><li><code>%o</code>: oct 八进制整数</li><li><code>%x</code>: hex 十六进制整数<pre><code class="lang-python">&gt;&gt;&gt; a=123&gt;&gt;&gt; print(&quot;a=%x&quot; % a)a=7b&gt;&gt;&gt; print(&quot;a=%X&quot; % a)a=7B</code></pre></li></ul></li><li><p>小数</p><ul><li><code>%f</code>: 浮点实数(默认保留小数点后面六位有效数字)<ul><li><code>%.3f</code>: 保留3位小数位</li></ul></li><li><code>%e</code>: 指数形式输出(默认保留小数点后面六位有效数字)<br>　　* <code>%.3e</code>: 保留3位小数位，使用科学计数法</li><li><p><code>%g</code>: <code>%f+%e</code>（默认保证六位有效数字）<br>　　* <code>%.3g</code>: 保留3位有效数字，使用小数或科学计数法</p><pre><code class="lang-python">&gt;&gt;&gt; a=123.5# f%&gt;&gt;&gt; print(&quot;a1=%f,a2=%.3f&quot; % (a,a))a1=123.500000,a2=123.500# e%&gt;&gt;&gt; print(&quot;a=%e,a=%.3e&quot; % (a,a))a1=1.235000e+02,a2=1.235e+02# g%&gt;&gt;&gt; print(&quot;a=%g&quot; % a)a=123.5&gt;&gt;&gt; print(&quot;a=%.2g&quot; % a)a=1.2e+02&gt;&gt;&gt; print(&quot;a=%.3g&quot; % a)a=124&gt;&gt;&gt; print(&quot;a=%.5g&quot; % a)a=123.5&gt;&gt;&gt; print(&quot;a=%g&quot; % 123.56789)a=123.568</code></pre></li></ul></li></ul><h3 id="header-7">输入</h3><p><code>input(prompt=None)</code> </p><p>注意：input获取的数据，都以字符串的方式进行保存</p><pre><code class="lang-python">&gt;&gt;&gt; a=input()Tom&gt;&gt;&gt; print(a)Tom&gt;&gt;&gt; a=input(&quot;Enter your name:&quot;)Enter your name:Tom&gt;&gt;&gt; print(a)Tom&gt;&gt;&gt; a=input(&quot;Enter your num:&quot;)Enter you num: 123&gt;&gt;&gt; print(a)123&gt;&gt;&gt; type(a)&lt;class &#39;str&#39;&gt;</code></pre><pre><code class="lang-python">name=input(&#39;name:&#39;)        # 输入值会被强制性地转换为字符串类型print(&#39;Hi &#39;+name);age=int(input(&#39;age:&#39;))print(&#39;get age:&#39;+str(age))</code></pre><h3 id="header-8">运算符</h3><ol><li><p>算术运算符</p><table class="table"><thead><tr><th style="text-align:left">运算符</th><th style="text-align:left">描述</th><th style="text-align:left">实例</th></tr></thead><tbody><tr><td style="text-align:left"><code>+</code></td><td style="text-align:left">加</td><td style="text-align:left">print(10+20) =&gt; 30</td></tr><tr><td style="text-align:left"><code>-</code></td><td style="text-align:left">减</td><td style="text-align:left">print(10-20) =&gt; -10</td></tr><tr><td style="text-align:left"><code>*</code></td><td style="text-align:left">乘</td><td style="text-align:left">print(a<em>b) =&gt; 200 ; print(‘##’</em>3) =&gt; ######</td></tr><tr><td style="text-align:left"><code>/</code></td><td style="text-align:left">除</td><td style="text-align:left">print(10/20) =&gt; 0.5</td></tr><tr><td style="text-align:left"><code>//</code></td><td style="text-align:left">取整除</td><td style="text-align:left">print(10//20) =&gt; 0 ; print(20/10) =&gt; 2</td></tr><tr><td style="text-align:left"><code>%</code></td><td style="text-align:left">取余</td><td style="text-align:left">print(20%10) =&gt; 0 ; print(20/3) =&gt; 2</td></tr><tr><td style="text-align:left"><code>**</code></td><td style="text-align:left">幂</td><td style="text-align:left">print(2**3) =&gt; 8</td></tr></tbody></table></li><li><p>比较运算符: <code>==</code>,<code>!=</code>,<code>&lt;&gt;</code>,<code>&gt;</code>,<code>&lt;</code>,<code>&gt;=</code>,<code>&lt;=</code></p></li><li><p>逻辑运算符：<code>and</code>,<code>or</code>,<code>not</code></p></li></ol><h3 id="header-9">判断语句</h3><p>keyword: <code>if</code>,<code>elif</code>,<code>else</code></p><pre><code class="lang-python"># if-elsea=100if a&gt;100:    print(&#39;a&gt;100&#39;)else    print(&#39;a&lt;=100&#39;)# if-elif(else)if a&gt;100:    print(&#39;a&gt;50&#39;)elif a==100:    print(&#39;a==100&#39;)elif a&lt;100 and a&gt;50:    print(&#39;a (50,100)&#39;)else:    print(&#39;a&lt;=50&#39;)</code></pre><h3 id="header-10">循环语句</h3><p>keyword: <code>for</code>,<code>while</code>,<code>break</code>,<code>continue</code></p><pre><code class="lang-python"># whilei=0while i&lt;100:    if i%2==0        print(i,&quot;偶数&quot;)    else        print(i,&quot;奇数&quot;)    i+=1</code></pre><pre><code class="lang-python"># for in# sample1:for i in &#39;abcdefg123456&#39;:    if i==&#39;d&#39;:        print(&#39;find d before 5&#39;)        continue    if i==&#39;5&#39;:        break    print(i)# sample2:for i in range(10):    if i == 11:        print(&#39;找到结果&#39;)        breakelse:    print(&#39;未找到结果&#39;)</code></pre><h3 id="header-11">异常处理</h3><ul><li>Python的错误也是class，所有的错误类型都继承自<code>BaseException</code>，可使用继承自定义异常类</li><li>如果错误没有被捕获，它就会一直往上抛，最后被Python解释器捕获，打印一个错误信息，然后程序退出</li><li>捕获异常：<ul><li><code>try...except...</code></li><li><code>try...finally...</code></li><li><code>try...except...else...</code></li><li><code>try...except...finally...</code></li><li><code>try...except...else...finally...</code></li><li>说明：<ul><li>捕获到<code>except</code>中匹配的异常，则执行<code>except</code>下的语句，反之则执行<code>else</code>中的语句</li><li>无论是否捕获到异常，都会执行<code>finally</code>中的语句</li></ul></li></ul></li><li>手动抛出异常：<code>raise 异常实例</code> （注：在<code>except</code>中可直接用<code>raise</code>重新抛出捕获的异常）</li><li>借助Python内置的<code>logging</code>模块，可以容易地记录错误信息（输出或记录到文件），方便事后排查</li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python"># 1. 捕获某个异常def testCatchOneException():                    try:        print(&#39;Begin&#39;)        open(&#39;test.json&#39;,&#39;r&#39;)        # 若test.json不存在，则会产生 IOError 异常        print(&#39;End&#39;)    except IOError:                 # 用变量记录可使用 `except IOError as ex:`        print(&#39;Catch IOError&#39;)    else:        print(&#39;Not catch&#39;)    finally:        print(&#39;Done&#39;)# 2. 捕获多个异常def testCatchMultiException():                     try:        print(&#39;Begin&#39;)        open(&#39;test.json&#39;,&#39;r&#39;)         # 若test.json不存在，则会产生 IOError 异常        print(&#39;then&#39;)        print(num)                     # 若num未定义，则会会产生 NameError 异常        print(&#39;End&#39;)    except IOError or NameError:     # catch IOError or NameError        print(&#39;Catch Error&#39;)    except:                            # catch other all exception (under BaseException)        print(&#39;Catch Error&#39;)        else:        print(&#39;Not catch&#39;)    finally:        print(&#39;Done&#39;)# 3. 用变量保存捕获到的异常def testRecordException():    try:        print(&#39;Begin&#39;)        open(&#39;test.json&#39;,&#39;r&#39;)        print(&#39;Then&#39;)        print(num)        print(&#39;End&#39;)    except (IOError,NameError) as ex:     # 等同：`except IOError or NameError as ex:`        print(&#39;Catch error:&#39;,type(ex),ex)# 4. 用raise抛出异常def testRaiseException1():    try:        print(&#39;Begin&#39;)        raise ValueError(&#39;Hello&#39;,1,2)    # 抛出异常(异常实例，构造可传入任意参数，无限制)        print(&#39;End&#39;)    except:                             # 捕获异常        print(&#39;Catch Error&#39;)             # 记录一下        raise                             # 再抛出    finally:        print(&#39;Done&#39;)def testRaiseException2():    try:        print(&#39;Begin&#39;)        open(&#39;test.json&#39;,&#39;r&#39;)        print(&#39;then&#39;)        print(num)        print(&#39;End&#39;)    except (IOError,NameError) as ex:        print(&#39;Catch error:&#39;,type(ex),ex)        raise         # 抛出发生的IOError或NameError异常实例，                    # 也可抛出另一个异常实例，如：`raise ValueError(msg)`    finally:        print(&#39;Done&#39;)# 5. 使用logging模块，记录错误信息import loggingdef testLogException():    try:        print(&#39;Begin&#39;)        raise ValueError(&#39;Hello&#39;)        print(&#39;End&#39;)    except Exception as ex:        print(&quot;Catch error:&quot;,type(ex),ex)        logging.exception(ex)    finally:        print(&quot;Done&quot;)&gt;&gt;&gt; testLogException()BeginCatch error: &lt;class &#39;ValueError&#39;&gt; HelloERROR:root:HelloTraceback (most recent call last):  File &quot;&lt;ipython-input-34-817d16b0d2f0&gt;&quot;, line 4, in testLogException    raise ValueError(&#39;Hello&#39;)ValueError: HelloDone</code></pre><p><strong>Python Build-in Exceptions</strong></p><p>Refer <a href="https://docs.python.org/3/library/exceptions.html#exception-hierarchy" target="_blank" rel="noopener">Doc</a></p><pre><code>BaseException +-- SystemExit +-- KeyboardInterrupt +-- GeneratorExit +-- Exception      +-- StopIteration      +-- StopAsyncIteration      +-- ArithmeticError      |    +-- FloatingPointError      |    +-- OverflowError      |    +-- ZeroDivisionError      +-- AssertionError      +-- AttributeError      +-- BufferError      +-- EOFError      +-- ImportError      |    +-- ModuleNotFoundError      +-- LookupError      |    +-- IndexError      |    +-- KeyError      +-- MemoryError      +-- NameError      |    +-- UnboundLocalError      +-- OSError      |    +-- BlockingIOError      |    +-- ChildProcessError      |    +-- ConnectionError      |    |    +-- BrokenPipeError      |    |    +-- ConnectionAbortedError      |    |    +-- ConnectionRefusedError      |    |    +-- ConnectionResetError      |    +-- FileExistsError      |    +-- FileNotFoundError      |    +-- InterruptedError      |    +-- IsADirectoryError      |    +-- NotADirectoryError      |    +-- PermissionError      |    +-- ProcessLookupError      |    +-- TimeoutError      +-- ReferenceError      +-- RuntimeError      |    +-- NotImplementedError      |    +-- RecursionError      +-- SyntaxError      |    +-- IndentationError      |         +-- TabError      +-- SystemError      +-- TypeError      +-- ValueError      |    +-- UnicodeError      |         +-- UnicodeDecodeError      |         +-- UnicodeEncodeError      |         +-- UnicodeTranslateError      +-- Warning           +-- DeprecationWarning           +-- PendingDeprecationWarning           +-- RuntimeWarning           +-- SyntaxWarning           +-- UserWarning           +-- FutureWarning           +-- ImportWarning           +-- UnicodeWarning           +-- BytesWarning           +-- ResourceWarning</code></pre><h3 id="header-12">给程序传参</h3><pre><code class="lang-python">$ vi argv-demo.pyimport sysprint(&quot;Hello argv:&quot;,sys.argv)$ python3 argv-demo.py abc 123 456Hello argv: [&#39;argv-demo.py&#39;, &#39;abc&#39;, &#39;123&#39;, &#39;456&#39;]</code></pre><h3 id="header-13">测试</h3><ol><li><p>单元测试 <code>unittest</code></p><ul><li>导入包：<code>import unittest</code></li><li>编写测试类（继承自<code>unittest.TestCase</code>）：<code>class Xxx(unittest.TestCase)</code> </li><li>编写测试函数（以test开头）: <code>def testXxx()</code></li><li>添加测试切面函数（自动在每一个测试方法前后执行）：<code>setUp()</code>,<code>tearDown()</code></li><li>运行：<ul><li>method1: 添加：<code>if __name__ == &#39;__main__&#39;:unittest.main()</code>，执行：<code>python unittest-demo.py</code></li><li>method2: 直接执行<code>python -m unittest unittest-demo.py</code></li></ul></li></ul></li><li><p>文档测试 <code>doctest</code></p><ul><li>导入包：<code>import doctest</code></li><li>doctest 模块可以直接提取py开始的注释和函数开始的注释<code>&#39;&#39;&#39;...&#39;&#39;&#39;</code></li><li>运行：<code>if __name__==&#39;__main__&#39;: doctest.testmod()</code></li></ul></li></ol><p><strong>Sample1: 单元测试 unittest</strong></p><pre><code class="lang-python">import unittestclass MyTest(unittest.TestCase):    def setUp(self):        print(&#39;setUp...&#39;)    def tearDown(self):        print(&#39;tearDown...&#39;)    def test_dict(self):        print(&#39;test 1&#39;)        d={&#39;a&#39;:1,&#39;b&#39;:2}        self.assertEqual(d[&#39;a&#39;],1)        self.assertEqual(d[&#39;b&#39;],2)        self.assertTrue(isinstance(d, dict))    def testdict2(self):        print(&#39;test 2&#39;)        d={&#39;a&#39;:1,&#39;b&#39;:2}        with self.assertRaises(KeyError):   # 期待抛出指定类型的Error            value = d[&#39;c&#39;]if __name__ == &#39;__main__&#39;:    unittest.main()</code></pre><pre><code class="lang-bash">$ python unittest-demo.pysetUp...test 1tearDown....setUp...test 2tearDown....----------------------------------------------------------------------Ran 2 tests in 0.000sOK</code></pre><p><strong>Sample2:文档测试 doctest</strong></p><pre><code class="lang-python">&#39;&#39;&#39;&gt;&gt;&gt; hello([4,5,6])hello: [4,5,6]&#39;&#39;&#39;def hello(x):    &#39;&#39;&#39;    doc test demo -- helo    &gt;&gt;&gt; hello(&#39;Tom&#39;)    hello: Tom    &gt;&gt;&gt; hello(1/0)    Traceback (most recent call last):    ...    ZeroDivisionError: division by zero    &gt;&gt;&gt; hello([1,2,3])    hello: [1,2,3]    &#39;&#39;&#39;    print(&#39;hello:&#39;,x)if __name__==&#39;__main__&#39;:    import doctest    doctest.testmod()</code></pre><pre><code class="lang-python">$ python doctest-demo.py**********************************************************************File &quot;doctest-demo.py&quot;, line 2, in __main__Failed example:    hello([4,5,6])Expected:    hello: [4,5,6]Got:    hello: [4, 5, 6]**********************************************************************File &quot;doctest-demo.py&quot;, line 15, in __main__.helloFailed example:    hello([1,2,3])Expected:    hello: [1,2,3]Got:    hello: [1, 2, 3]**********************************************************************2 items had failures:   1 of   1 in __main__   1 of   3 in __main__.hello***Test Failed*** 2 failures.</code></pre><h2 id="header-14">基础数据类型</h2><h3 id="header-15">不可变对象 &amp; 可变对象</h3><ol><li><p>不可变对象：即无法修改这个对象的值，每次对变量的修改，实际上是创建一个新的对象 (=&gt; 可做key)</p><ul><li>整数 <code>int</code> eg: <code>a=123</code></li><li>浮点数 <code>float</code> eg: <code>a=123.0</code></li><li>布尔 <code>bool</code> eg: <code>a=True</code>,<code>a=False</code>,<code>a=bool(1)</code>,<code>bool(&#39;&#39;)</code></li><li>字符串 <code>str</code> eg: <code>a=&quot;123abc&quot;</code></li><li>元祖 <code>tuple</code> eg: <code>a=(1,23.4,&#39;ef&#39;)</code></li><li>空 <code>NoneType</code> eg: <code>a=None</code></li></ul></li><li><p>可变对象(=&gt; 不可做key)</p><ul><li>列表 <code>list</code> eg: <code>a=[1,23.4,&#39;ef&#39;]</code></li><li>字典 <code>dict</code> eg: <code>a={&#39;a&#39;:1,1:&#39;d&#39;,(1,2):&#39;123&#39;}</code></li><li>集合 <code>set</code> eg: <code>a={1,2,&#39;ef&#39;,12.4}</code>    </li></ul></li><li><p>对象比较</p><ul><li><code>id(obj)</code> 查看对象的唯一标识 </li><li><code>==</code> 比较两个对象内容是否相等</li><li><code>is</code> 比较两个对象是否相等（是否是同一块地址空间）</li></ul></li></ol><p><strong>Sample:</strong></p><pre><code class="lang-python"># 1. 不可变对象：int&gt;&gt;&gt; a=555&gt;&gt;&gt; b=a&gt;&gt;&gt; id(a),id(b)                # a和b相等，指向同一个地址空间(4566055600,4566055600)&gt;&gt;&gt; b=789                     # b指向新开辟的另一个地址空间,a与b不同了&gt;&gt;&gt; id(a),id(b)(4324742368,4566055696)# 2. 可变对象：list&gt;&gt;&gt; a=[1,2,3]&gt;&gt;&gt; b=a&gt;&gt;&gt; id(a),id(b)             # a和b相等，指向同一个地址空间(4333307784,4333307784)&gt;&gt;&gt; b.append(4)             # b和a依旧相等，指向同一块地址空间&gt;&gt;&gt; id(a),id(b)(4333307784,4333307784)&gt;&gt;&gt; import copy&gt;&gt;&gt; c=copy.deepcopy(a)         # 拷贝内容（开辟了一块新空间存储被拷贝对象的所有内容）,相当于执行了c=[1,2,3]&gt;&gt;&gt; id(a),id(c)(4333307784,4397232200)&gt;&gt;&gt; a==c,a is c             # a与c内容相同，但指向不同地址空间(True,False)</code></pre><h3 id="header-16">垃圾回收机制</h3><ol><li><p>intern机制：Python为了优化速度，对一些对象使用了对象池，避免为频繁申请和销毁内存空间</p><pre><code class="lang-python"> # 小整数：共用对象 &gt;&gt;&gt; a=123 &gt;&gt;&gt; b=123 &gt;&gt;&gt; id(a),id(b),id(123)             # 相同 (4557612256, 4557612256, 4557612256) # 大整数：不共用对象 &gt;&gt;&gt; a=789 &gt;&gt;&gt; b=789 &gt;&gt;&gt; id(a),id(b),id(789)             # 不相同 (4566055600, 4566055760, 4561935984) # 一个字符：共用对象 &gt;&gt;&gt; a=&#39;A&#39; &gt;&gt;&gt; b=&#39;A&#39; &gt;&gt;&gt; id(a),id(b),id(&#39;A&#39;)              # 相同 (4562778576, 4562778576,4562778576) # 一个单词：共用对象 &gt;&gt;&gt; a=&quot;Hello&quot; &gt;&gt;&gt; b=&quot;Hello&quot; &gt;&gt;&gt; id(a),id(b),id(&quot;Hello&quot;)         # 相同 (4566204968, 4566204968,4566204968) # 非单词字符串：不共用对象 &gt;&gt;&gt; a=&quot;Hello World&quot; &gt;&gt;&gt; b=&quot;Hello World&quot; &gt;&gt;&gt; id(a),id(b),id(&quot;Hello World&quot;)   # 不相同 (4564866736, 4565787824, 4565787888)</code></pre><ul><li><code>小整数[-5,257)</code>: 共用对象，常驻内存</li><li><code>单个字符</code>: 共用对象，常驻内存</li><li><code>单个单词</code>: 共用对象，不常驻内存，引用计数为0时销毁</li><li>注：<ul><li>非单个但单词的字符串（如含有空格等），不会使用intern机制（即不共用对象），引用计数为0则销毁</li><li>数值类型和字符串类型在Python中都是不可变类型，即无法修改这个对象的值，每次对变量的修改，实际上是创建一个新的对象</li></ul></li></ul></li><li><p>引用计数</p><pre><code class="lang-python"> # 查看一个对象的引用计数 &gt;&gt;&gt; import sys &gt;&gt;&gt; a=&quot;Hello World&quot; &gt;&gt;&gt; sys.getrefcount(a)  # 比正常计数大1，因为调用函数的时候传入a，这会让a的引用计数+1 2 &gt;&gt;&gt; b=a &gt;&gt;&gt; sys.getrefcount(a) 3  &gt;&gt;&gt; del b &gt;&gt;&gt; sys.getrefcount(a) 2</code></pre><ul><li>一旦引用计数为0则销毁以释放内存，具有实时性，处理回收内存的时间分摊到了平时（不用像其他机制等到特定时机）</li><li>循环引用所占用的内存永远无法被回收</li><li>维护消耗资源：占空间且处理相对较慢</li></ul></li><li><p>标记-清除（判别出垃圾清除）</p><ul><li>标记出有指针引用的对象，剩下未被标记的对象则为垃圾，可进行清除</li></ul></li><li><p>分代收集 Generational GC（可处理循环引用释放问题）</p><ul><li>使用链表来持续追踪活跃对象</li><li>内部使用多代（个）链表：Generation Zero &amp; Generation One &amp; Generation Two（新创建的对象放入Generation Zero链表）</li><li>周期性地检查链表，根据规则减掉上面互相引用的对象的引用计数，清除引用计数为0的对象，剩下的活跃对象则移动到下一代链表</li><li>GC阈值：一旦被分配对象与被释放对象的计数值之差达到阈值，就启动检查，释放“浮动的垃圾”，活跃对象移动到下一代链表</li></ul></li><li><p><code>gc</code>模块: 提供设置垃圾回收的API</p><ul><li><code>gc.isenabled()</code></li><li><code>gc.disable()</code></li><li><code>gc.set_debug(flags)</code> 设置gc的debug日志，一般设置为<code>gc.DEBUG_LEAK</code></li><li><code>gc.collect(generation=2)</code>: <ul><li>0: 只检查0代的对象；</li><li>1:检查0，1代对象；</li><li>2:检查0，1，2代对象；</li><li>返回收集的垃圾数</li></ul></li><li><code>gc.get_count()</code>:<ul><li>返回一个长度为3的元组，代表各代自动执行垃圾回收的计数器</li><li>eg: (488,0,0) 488是指距离上一次0代垃圾检查，Python分配内存的数目减去释放内存的数目</li></ul></li><li><code>gc.get_threshold()</code>:<ul><li>返回一个长度为3的元组，代表各代自动执行垃圾回收的阈值</li><li>每一次计数器增加，gc模块会检查增加后的计数是否达到阀值的数目，如果是，就会执行对应的代数的垃圾检查，然后重置计数器</li><li>eg:(700,10,10)</li></ul></li><li><code>gc.set_threshold(threshold0[, threshold1[, threshold2])</code> <ul><li>设置各代阈值</li></ul></li><li>eg: 阈值:(700,10,10), 计数器:<ul><li>(699,3,0)增到(700,3,0)时 =&gt; gc模块执行<code>gc.collect(0)</code>检查0代对象的垃圾，重置计数器为<code>(0,4,0)</code></li><li>(699,9,0)增到(700,9,0)时 =&gt; gc模块执行<code>gc.collect(1)</code>检查1,2代对象的垃圾，重置计数器为<code>(0,0,1)</code></li><li>(699,9,9)增到(700,9,9)时 =&gt; gc模块执行<code>gc.collect(2)</code>检查0,1,2,3代对象的垃圾，重置计数器为<code>(0,0,0)</code></li></ul></li></ul></li><li><p>垃圾回收触发点：</p><ul><li>调用<code>gc.collect()</code></li><li><code>gc</code>模块的计数器达到阀值时</li><li>程序退出时</li></ul></li><li><p>总结：</p><ul><li>Python中使用<code>intern机制</code>共用一些对象以优化速度</li><li>垃圾回收采用<code>引用计数</code>为主，<code>标记-清除</code>+<code>分代收集</code>为辅的策略</li><li><code>gc</code>模块提供垃圾回收的API</li></ul></li></ol><h3 id="header-17">类型转换</h3><ol><li><p>整数：<code>int(x [,base ])</code> </p><ul><li><code>int(20.4)</code> =&gt; 20</li><li><code>int(&#39;20.4&#39;)</code> =&gt; Error</li><li><code>int(&#39;89&#39;)</code> =&gt; 89</li><li><code>int(&quot;0xc&quot;,base=16)</code> =&gt; 12</li></ul></li><li><p>浮点数： <code>float(x)</code></p><ul><li><code>float(&quot;123&quot;)</code>,<code>flaot(123)</code> =&gt; 123.0</li><li><code>float(&quot;123.5&quot;)</code>,<code>float(123.5)</code> =&gt; 123.5</li><li><code>float(&quot;12e+2&quot;)</code>,<code>float(12e+2)</code> =&gt; 1200.0</li></ul></li><li><p>字符串: <code>str(obj)</code> 参数可为任意对象</p><ul><li><code>str(123.5)</code>,<code>str(&quot;123.5&quot;)</code> =&gt; “123.5”</li><li><code>str([12,123.5,&quot;se&quot;])</code> =&gt; “[12, 123.5, ‘se’]”</li><li><code>str({&#39;a&#39;:1,&#39;b&#39;:2})</code> =&gt; “{‘a’: 1, ‘b’: 2}”</li></ul></li><li><p>元组：    <code>tuple(s)</code> 参数可以是元组,列表,字典(只取keys),集合,字符串</p><ul><li><code>tuple((1,2,3))</code> =&gt; (1,2,3)</li><li><code>tuple([1,2,3])</code> =&gt; (1,2,3)</li><li><code>tuple({&#39;a&#39;:1,&#39;b&#39;:2})</code> =&gt; (‘a’, ‘b’)</li><li><code>tuple({1, 23.0, &#39;ef&#39;})</code> =&gt; (1, 23.0, ‘ef’)</li><li><code>tuple(&#39;123&#39;)</code> =&gt; (‘1’, ‘2’, ‘3’)</li></ul></li><li><p>列表：<code>list(s)</code> 参数可为元组,字典,列表,字典(只取keys),集合,字符串</p><ul><li><code>list([1,2,3])</code> =&gt; [1,2,3]</li><li><code>list((1,2,3))</code> =&gt; [1,2,3]</li><li><code>list({&#39;a&#39;:1,&#39;b&#39;:2})</code> =&gt; [‘a’, ‘b’]</li><li><code>list(&#39;123&#39;)</code> =&gt; [‘1’,’2’,’3’]</li><li><code>list(set([1,2,3]))</code> =&gt; [1,2,3]</li></ul></li><li><p>集合：<code>set(s)</code> 参数可以是元组,列表,字典(只取keys),集合,字符串</p><ul><li><code>set((1,2,3))</code> =&gt; {1,2,3}</li><li><code>set({1,2,3})</code> =&gt; {1,2,3}</li><li><code>set([1,2,2,3,1,2])</code> =&gt; {1,2,3}</li><li><code>set({&#39;a&#39;:1,&#39;b&#39;:2})</code> =&gt; {‘a’, ‘b’}</li><li><code>set(&#39;123&#39;)</code> =&gt; {‘2’, ‘3’, ‘1’}</li></ul></li><li><p>其他：</p><ul><li>整数转换某进制(字符串表示)<ul><li><code>hex(x)</code> : 把一个整数转换为十六进制字符串 eg: <code>hex(12)</code> =&gt; ‘0xc’</li><li><code>oct(x)</code> : 把一个整数转换为八进制字符串 eg: <code>oct(12)</code> =&gt; ‘0o14’</li></ul></li><li>执行一个字符串表达式，返回计算的结果: <code>eval(str)</code><ul><li><code>eval(&quot;12+23&quot;)</code> =&gt; 35</li></ul></li><li>利用<code>enumerate</code>将list中的item转换为tuple<pre><code class="lang-python">  &gt;&gt;&gt; seasons = [&#39;Spring&#39;, &#39;Summer&#39;, &#39;Fall&#39;, &#39;Winter&#39;]  &gt;&gt;&gt; list(enumerate(seasons))  [(0, &#39;Spring&#39;), (1, &#39;Summer&#39;), (2, &#39;Fall&#39;), (3, &#39;Winter&#39;)]</code></pre></li></ul></li></ol><h3 id="header-18">字符编码</h3><ol><li><p><code>ASCII</code> &amp; <code>Unicode</code> &amp; <code>UTF-8</code>编码</p><ul><li><code>ASCII</code> : 1个字节</li><li><code>Unicode</code> : 2个字节(偏僻的字符要4个字节)</li><li><code>UTF-8</code> : 可变长编码,能节省空间(把一个Unicode字符根据不同的数字大小编码成1-6个字节,英文字母1个字节,汉字通常是3个字节,偏僻的字符要4~6个字节)</li><li><p>eg:</p><table class="table"><thead><tr><th style="text-align:left">字符</th><th style="text-align:left">ASCII</th><th style="text-align:left">Unicode</th><th style="text-align:left">UTF-8</th></tr></thead><tbody><tr><td style="text-align:left">A</td><td style="text-align:left">01000001</td><td style="text-align:left">00000000 01000001</td><td style="text-align:left">01000001</td></tr><tr><td style="text-align:left">中</td><td style="text-align:left">/</td><td style="text-align:left">01001110 00101101</td><td style="text-align:left">11100100 10111000 10101101</td></tr></tbody></table></li></ul></li><li><p>工作方式: </p><ul><li>在计算机内存中，统一使用<code>Unicode</code>编码，当需要保存到硬盘或者需要传输的时候，就转换为<code>UTF-8</code>编码</li><li>python中<code>str</code>在内存中以<code>Unicode</code>表示，一个字符对应若干个字节，传输或者保存到磁盘，则变为以字节为单位的<code>bytes</code></li></ul></li><li><p>获取字符编码的整数表示<code>ord(x)</code></p><ul><li><code>ord(&#39;a&#39;)</code> =&gt; 97</li><li><code>ord(&#39;A&#39;)</code> =&gt; 65</li><li><code>ord(&#39;你&#39;)</code> =&gt; 20320</li><li><code>ord(&#39;中&#39;)</code> =&gt; 20013</li></ul></li><li><p>把编码转换为对应的字符<code>chr(x)</code></p><ul><li><code>chr(65)</code> =&gt; ‘A’</li><li><code>chr(20013)</code> =&gt; ‘中’</li></ul></li><li><p>encode/decode</p><ul><li>encode: str -&gt; bytes</li><li>decode: str &lt;- bytes</li></ul></li></ol><p><strong>Sample:</strong></p><pre><code class="lang-python"># 1. encode/decodea=&#39;abc&#39;b=a.encode()        print(b)            # b&#39;abc&#39;print(b.decode())    # abca=&#39;你好&#39;b=a.encode()print(b)            # b&#39;\xe4\xbd\xa0\xe5\xa5\xbd&#39;print(b.decode())    # 你好# 2. len#     - len(str)         返回字符数#     - len(bytes)     返回字节数a=&#39;abc&#39;print(len(a))    # 3a=b&#39;abc&#39;print(len(a))    # 3a=&#39;你好&#39;print(len(a))                    # 2print(a.encode(&#39;utf-8&#39;))         # b&#39;\xe4\xbd\xa0\xe5\xa5\xbd&#39;print(len(a.encode(&#39;utf-8&#39;)))    # 6</code></pre><h3 id="header-19">整数：进制转换／位运算</h3><ol><li><p>进制</p><ul><li>十进制(逢十进一): 0,1,2,3,4,5,6,7,8,9,10,11,12,…</li><li>二进制(逢二进一): 0,1,10,11,100,…</li><li>八进制(逢八进一): 0,1,2,3,4,5,6,7,10,11,12,…</li><li>十六进制(逢十六进一): 0,1,2,…8,9,10,a,b,c,d,e,f,10,11,12,…</li></ul></li><li><p>计算机存储:</p><ul><li>以二进制的补码形式存储，人们看到的数字是原码转化来的，而原码是通过补码得到的</li><li>即：<code>补码(机器存储) -&gt; 原码 -&gt; 转换对应进制 -&gt; 最后人们看到的数</code></li><li>符号位：第一位为符号位，表正数或负数</li><li>原码：用来转换对应进制</li><li>反码：符号位不变，其他位数取反</li><li>补码: 用来做数据的存储运算(运算包括符号位). 补码提出的根源是让计算机底层用加法实现减法操作，即减去一个数＝加上一个负数</li><li>进制转换时,需要先把内存中存储的补码拿出来变成原码,再进行转换输出</li><li><p>原码,补码转换规则：</p><pre><code class="lang-bash">  正数: 5  补码存储        -&gt; 原码（＝补码）       -&gt; 人们看到的数（一般为十进制)  0,000,0101      0,000,0101          5  负数：-5  补码存储        -&gt; 原码（＝补码取反+1） -&gt; 人们看到的数（一般为十进制)  1,111,1011       1,000,0101         -5</code></pre><ul><li>正数：原码 &lt;=&gt; 补码 （原码＝反码＝补码，即：无需转换）</li><li>负数：原码 &lt;=&gt; 取反+1 &lt;=&gt; 补码</li></ul></li><li><p>运算：用补码运算</p><pre><code class="lang-bash">  负数：-5  补码存储        -&gt; 原码（＝补码取反+1） -&gt; 人们看到的数（一般为十进制)  1,111,1011       1,000,0101         -5  运算：  -5 &lt;&lt; 1:  1,111,0110       1,000,1010         -10  -5 &gt;&gt; 1  1,111,1011       1,000,00101        -3  -5 + 1  1,111,1100       1,000,0100         -4</code></pre><ul><li><code>+,-</code>: 用加法加上正负数, eg: <code>1-1 = 1+(-1) = (1的补码) + (-1的补码) = 0</code></li><li><code>*,/</code>: 按位左右移<code>&lt;&lt;,&gt;&gt;</code>, eg: <code>5*2 = 0101&lt;&lt;1 = 1010 = 10</code> , <code>5*3=5*2+5=(0101&lt;&lt;1)+(0101)=1111=15</code></li></ul></li><li>注意：<ul><li>运算时用补码，包括符号位</li><li>原补码转换（取反）时，不包括符号位</li><li>进制间转换时用原码，不包括符号位</li></ul></li></ul></li><li><p>进制转换</p><pre><code class="lang-python"> # 1. 十进制 (type:int) =&gt; `bin(num)`/`oct(num)`/`hex(num)` =&gt; 二进制(0b),八进制(0o),十六进制(0x) (type:str) &gt;&gt;&gt; bin(18) &#39;0b10010&#39; &gt;&gt;&gt; oct(18) &#39;0o22&#39; &gt;&gt;&gt; hex(18) &#39;0x12&#39; # 2. 二进制(0b),八进制(0o),十六进制(0x) (type: str) =&gt; `int(strNum,base=10)` =&gt; 十进制 (type: int) &gt;&gt;&gt; int(&#39;0b10010&#39;,2) &gt;&gt;&gt; int(&#39;0o22&#39;,8) &gt;&gt;&gt; int(&#39;0x12&#39;,16) # 3. 注：bin(x) 返回的是简写版`符号＋原码` &gt;&gt;&gt; bin(5) &#39;0b101&#39; &gt;&gt;&gt; bin(-5) &#39;-0b101&#39;</code></pre></li><li><p>位运算: <code>&amp;,|,^,~,&lt;&lt;,&gt;&gt;</code> 直接操作二进制,按位运算，省内存,效率高</p><pre><code class="lang-python"> # 1. &lt;&lt; : 左移 = x*(2^n) &gt;&gt;&gt; 0b0101&lt;&lt;1 10 &gt;&gt;&gt; 5&lt;&lt;1        # = 5*2^1 10 &gt;&gt;&gt; 0b0101&lt;&lt;2 20 &gt;&gt;&gt; 5&lt;&lt;2        # = 5*2^2 20 # 2. &gt;&gt; : 右移 = x//(2^n) &gt;&gt;&gt; 5&gt;&gt;1        # = 5//(2^1) 2 &gt;&gt;&gt; 5&gt;&gt;2        # = 5//(2^2) 1 &gt;&gt;&gt; -5&gt;&gt;1       # = -5//2 -3 # 3. &amp;：按位与（都为1则为1） &gt;&gt;&gt; 0b0101 &amp; 0b1111 5 &gt;&gt;&gt; 5&amp;15 5 # 4. |：按位或（有1则为1） &gt;&gt;&gt; 0b0101 | 0b1111 15 &gt;&gt;&gt; 5|15 15 # 5. ^：按位异或（不同则为1） &gt;&gt;&gt; 0b0101 ^ 0b1111     # =&gt; 0b1010 10 &gt;&gt;&gt; 5^15 10 # 6. ~：按位翻转，结果为：`-(x+1)` （注：包括符号位翻转，所以不是反码） # eg： # 5 补码（正数，与原码相同）：       0000,0101 # 运算~5（按位全部取反）：          1111,1010 # 转换为原码（除符号位，取反+1）：    1000,0110   =&gt; -6 &gt;&gt;&gt; ~0b0101 -6 &gt;&gt;&gt; ~5 -6 # 5取反+1=-5; -5取反+1=5 &gt;&gt;&gt; ~5+1 -5 &gt;&gt;&gt; ~5 -6 &gt;&gt;&gt; ~-5+1 5 &gt;&gt;&gt; bin(5) &#39;0b101&#39; &gt;&gt;&gt; bin(~5) &#39;-0b110&#39; &gt;&gt;&gt; bin(-5) &#39;-0b101&#39;</code></pre></li></ol><h3 id="header-20">str,tuple,list,set,dict</h3><p>常用方法总结：</p><ul><li>增<ul><li>str/tuple: <code>+</code>,<code>*n</code> – 不可改，生成新的</li><li>list: <code>+[...]</code>,<code>*n</code>,<code>.append(x)</code>,<code>.extend(iterable)</code>,<code>.insert(index,x)</code></li><li>set: <code>.add(key)</code>,<code>.update(iterable)</code></li><li>dict: <code>xxx[key]=value</code>,<code>.update({key:value,...})</code>,<code>.setdefault(key,default=None)</code></li></ul></li><li>删<ul><li>str/tuple: 不可改</li><li>list: <code>del xxx[index]</code>,<code>remove(item)</code>,<code>pop(index=-1)</code></li><li>set: <code>.remove(key)</code>,<code>.discard(key)</code>,<code>pop()</code></li><li>dict: <code>del xxx[key]</code>,<code>.pop(key)</code>,<code>.popitem()</code></li></ul></li><li>改<ul><li>str/tuple: ／</li><li>list: <code>xxx[index]=value</code></li><li>set: ／</li><li>dict: <code>xxx[key]=value</code>,<code>.update({key:value,...})</code>,<code>.setdefault(key,default=None)</code></li></ul></li><li>查<ul><li>str/tuple: <code>[index]</code>,<code>[start:end:step]</code>,<code>.index(x,start,end)</code>,<code>.count(x)</code></li><li>list: <code>[index]</code>,<code>[start:end:step]</code>,<code>.index(x,start,end)</code>,<code>.count(x)</code></li><li>set: /</li><li>dict: <code>xxx[key]</code>,<code>.get(key,default=None)</code>,<code>keys()</code>,<code>values()</code>,<code>items()</code></li></ul></li><li>公共方法<ul><li><code>in/not in</code> 存在与否 </li><li><code>.len(x)</code>,<code>.max(x)</code>,<code>.min(item)</code></li><li><code>for item in s</code>,<code>for index,item in enumerate(s)</code> 遍历 (对于dict，会遍历keys)</li></ul></li></ul><h3 id="header-21">str</h3><p><code>&quot;....&quot;</code>:</p><ul><li><code>find/rfind/index/rindex/count(str, start=0, end=len(mystr))</code> 注：index方法若是找不到会抛出一个异常</li><li><code>replace(str1,str2,count=-1)</code></li><li><code>split(sep=None, maxsplit=-1)</code>,<code>splitlines()</code>,<code>join(iterable)</code></li><li><code>capitalize/title()</code> 字符串的第一个/每个单词首字母大写</li><li><code>lower/upper()</code> 转换为小写／大写</li><li><code>startswith/endswith(prefix[, start[, end]])</code> 返回 True/False</li><li><code>ljust/rjust/center(width, fillchar=&#39; &#39;)</code> 原字符串左/右／居中对齐,并使用空格填充至长度 width 的新字符串</li><li><code>lstrip/rstrip/strip(chars=None)</code> 去除字符串左／右／两边的空白字符</li><li><code>rpartition/partition(seq)</code> 从右／左边开始以seq分割成三部分,seq前，seq和seq后</li><li><code>isalpha/isdigit/isalnum/isspace</code> 返回True/False</li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python">&gt;&gt;&gt; a=&quot;Hello Tom! How are you? Are you ok?&quot;# find/index/count&gt;&gt;&gt; a.find(&#39;you&#39;)19&gt;&gt;&gt; a.index(&#39;you&#39;)19&gt;&gt;&gt; a.count(&#39;you&#39;)2# title,lower&gt;&gt;&gt; a.title()&#39;Hello Tom! How Are You? Are You Ok?&#39;&gt;&gt;&gt; a.lower()&#39;hello tom! how are you? are you ok?&#39;&gt;&gt;&gt; a.strip(&#39;?&#39;)&#39;Hello Tom! How are you? Are you ok&#39;# split/partition&gt;&gt;&gt; a.split(&#39;you&#39;)[&#39;Hello Tom! How are &#39;, &#39;? Are &#39;, &#39; ok?&#39;]&gt;&gt;&gt; a.partition(&#39;you&#39;)(&#39;Hello Tom! How are &#39;, &#39;you&#39;, &#39;? Are you ok?&#39;)# startswith&gt;&gt;&gt; a.startswith(&quot;Hello&quot;)True&gt;&gt;&gt; a.startswith(&quot;You&quot;)False# isalpha&gt;&gt;&gt; a.isaa.isalnum(  a.isalpha(  a.isascii(&gt;&gt;&gt; a.isalpha()False# 下标索引&gt;&gt;&gt; a[0]&#39;H&#39;# 切片&gt;&gt;&gt; a[0:3]&#39;Hel&#39;# in,not in&gt;&gt;&gt; a=&quot;123&quot;&gt;&gt;&gt; &#39;1&#39; in aTrue&gt;&gt;&gt; &#39;b&#39; in aFalse# index,count&gt;&gt;&gt; a.index(&#39;2&#39;)1&gt;&gt;&gt; a.count(&#39;2&#39;)1</code></pre><h3 id="header-22">tuple</h3><p><code>(item1,item2,...)</code>:</p><ul><li>元素可以是不同类型的，可重复值，可嵌套 ( 与列表类似，不同之处在于元组创建后就不能修改 )</li><li>访问元素：<code>xxx[index]</code>，index从0开始</li><li>修改元素：不能修改元素，会抛出异常</li><li>查找元素：<code>index(item,start=0, stop=9223372036854775807)</code> 返回index，左闭右开 [start,end)，找不到抛出异常</li><li>查找某元素个数: <code>count(item)</code></li><li>可由元组,列表,字典(只取keys),集合,字符串创建元组: <code>tuple(s)</code></li><li>注：<ul><li>tuple所谓的“不变”是指tuple的每个元素指向不变</li><li>只有1个元素的tuple定义时须加一个逗号<code>,</code>，来消除歧义,eg:<code>a=(1,)</code></li></ul></li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python"># tuple：元素可以是不同类型的，可重复值&gt;&gt;&gt; a=(123,12.4,&#39;Hello&#39;,(&#39;a&#39;,&#39;b&#39;),[1,2,3],&#39;Hello&#39;)# len&gt;&gt;&gt; len(a)6# 访问元素：xxx[index]，index从0开始&gt;&gt;&gt; a[0]123# 修改元素：不能修改元素，会抛出异常&gt;&gt;&gt; a[1]=&#39;abc&#39;Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: &#39;tuple&#39; object does not support item assignment# 注：tuple所谓的“不变”是指tuple的每个元素指向不变&gt;&gt;&gt; a[4][1, 2, 3]&gt;&gt;&gt; a[4][1]=&quot;a&quot;        # 变的不是tuple的元素，而是list的元素&gt;&gt;&gt; a(123, 12.4, &#39;Hello&#39;, (&#39;a&#39;, &#39;b&#39;), [1, &#39;a&#39;, 3], &#39;Hello&#39;)# 查找元素：index(item,start,end) 返回index，左闭右开 [start,end)，找不到抛出异常&gt;&gt;&gt; a.index(&#39;Hello&#39;,2,6)2&gt;&gt;&gt; a.index(&#39;Hello&#39;,3,6)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;ValueError: tuple.index(x): x not in tuple# 查找元素个数: count(item)&gt;&gt;&gt; a.count(&#39;Hello&#39;)2&gt;&gt;&gt; a.count([1,2,3])1# tuple(s): 由元组,列表,字典(只取keys),集合,字符串创建元组&gt;&gt;&gt; tuple((1,2,3))(1,2,3)&gt;&gt;&gt; tuple([1,2,3])(1,2,3)&gt;&gt;&gt; tuple({&#39;a&#39;:1,&#39;b&#39;:2})(&#39;a&#39;, &#39;b&#39;)&gt;&gt;&gt; tuple({1, 23.0, &#39;ef&#39;})(1, 23.0, &#39;ef&#39;)&gt;&gt;&gt; tuple(&#39;123&#39;)(&#39;1&#39;, &#39;2&#39;, &#39;3&#39;)# 注：只有1个元素的tuple定义时必须加一个逗号,，来消除歧义&gt;&gt;&gt; a=(1)&gt;&gt;&gt; type(a)&lt;class &#39;int&#39;&gt;&gt;&gt;&gt; a=(1,)&gt;&gt;&gt; type(a)&lt;class &#39;tuple&#39;&gt;&gt;&gt;&gt;</code></pre><h3 id="header-23">list</h3><p><code>[item1,item2,...]</code>:</p><ul><li>元素可以是不同类型的，可重复值，可嵌套 ( 与元组类似，不同之处在于元组是不可变的，不能修改 )</li><li>访问/修改元素：<ul><li><code>xxx[index]</code> </li><li><code>xxx[index]=value</code> </li><li>注：index从0开始</li></ul></li><li>查找：<ul><li><code>index(item,start=0, stop=9223372036854775807)</code> 返回index，左闭右开 [start,end)，找不到抛出异常</li><li>查找某元素个数: <code>count(item)</code> </li><li>是否存在某元素：<code>item in xxx</code>, <code>item not in xxx</code><ul><li>添加元素：</li></ul><ul><li><code>append(item)</code></li><li><code>extend([item1,item2,...])</code></li><li><code>insert(index,item)</code></li></ul><ul><li>删除元素：</li></ul><ul><li><code>del xxx[index]</code></li><li><code>pop(index=-1)</code></li><li><code>remove(item)</code> 不能存在要移除元素，则会抛出异常</li></ul><ul><li>排序：</li></ul><ul><li><code>sort(reverse=False)</code></li><li><code>reverse()</code></li></ul></li></ul></li><li>可由元组,列表,字典(只取keys),集合,字符串创建list: <code>list(s)</code></li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python"># a=[123,12.4,&#39;Hello&#39;,(&#39;a&#39;,&#39;b&#39;),[1,2,3],&#39;Hello&#39;]# len&gt;&gt;&gt; len(a)6# 访问元素: xxx[index] index从0开始&gt;&gt;&gt; a[0]123&gt;&gt;&gt; a[2]&#39;Hello&#39;&gt;&gt;&gt; a[2][0]&#39;H&#39;&gt;&gt;&gt; a[3](&#39;a&#39;, &#39;b&#39;)&gt;&gt;&gt; a[3][0]&#39;a&#39;&gt;&gt;&gt; a[4][1, 2, 3]&gt;&gt;&gt; a[4][1]2# 修改元素: xxx[index]=value&gt;&gt;&gt; a[2]=&quot;Tom&quot;&gt;&gt;&gt; a[123, 12.4, &#39;Tom&#39;, (&#39;a&#39;, &#39;b&#39;), [1, 2, 3], &#39;Hello&#39;]# 查找元素：index,count&gt;&gt;&gt; a.index(&#39;Tom&#39;)2&gt;&gt;&gt; a.count(&#39;Hello&#39;)1# 是否存在某元素：in,not in&gt;&gt;&gt; &#39;Tom&#39; in aTrue&gt;&gt;&gt; 2 in aFalse&gt;&gt;&gt; (&#39;a&#39;,&#39;b&#39;) in aTrue&gt;&gt;&gt; &#39;Hi&#39; not in aTrue# 添加元素: append(x),extend([...]),insert(index,x)a = [5, 4, 2, 3]&gt;&gt;&gt; a.append(1)            # [5, 4, 2, 3, 1]&gt;&gt;&gt; a.extend([2,8])        # [5, 4, 2, 3, 1, 2, 8]&gt;&gt;&gt; a.insert(0,7)        # [7, 5, 4, 2, 3, 1, 2, 8]&gt;&gt;&gt; a.insert(-1,&#39;Tom&#39;)    # [7, 5, 4, 2, 3, 1, 2, &#39;Tom&#39;, 8]# 删除元素: del xxxx[index] , pop(index=-1), remove(item)&gt;&gt;&gt; a=[]&gt;&gt;&gt; del a[0]&gt;&gt;&gt; a[5, 4, 2, 3, 1, 2, &#39;Tom&#39;, 8]&gt;&gt;&gt; a.pop()8&gt;&gt;&gt; a[5, 4, 2, 3, 1, 2, &#39;Tom&#39;]&gt;&gt;&gt; a.pop(4)1&gt;&gt;&gt; a[5, 4, 2, 3, 2, &#39;Tom&#39;]&gt;&gt;&gt; a.remove(&#39;Tom&#39;)&gt;&gt;&gt; a[5, 4, 2, 3, 2]&gt;&gt;&gt; remove(1)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;NameError: name &#39;remove&#39; is not defined# 排序: sort reverse&gt;&gt;&gt; a.sort()&gt;&gt;&gt; a[2, 2, 3, 4, 5]&gt;&gt;&gt; a.sort(reverse=True)&gt;&gt;&gt; a[5, 4, 3, 2, 2]&gt;&gt;&gt; a.reverse()&gt;&gt;&gt; a[2, 2, 3, 4, 5]# list(s): 可由元组,列表,字典(只取keys),集合,字符串创建&gt;&gt;&gt; list([1,2,3])[1,2,3]&gt;&gt;&gt; list((1,2,3))[1,2,3]&gt;&gt;&gt; list({&#39;a&#39;:1,&#39;b&#39;:2})[&#39;a&#39;, &#39;b&#39;]&gt;&gt;&gt; list(&#39;123&#39;)[&#39;1&#39;,&#39;2&#39;,&#39;3&#39;]&gt;&gt;&gt; list(set([1,2,3]))[1,2,3]</code></pre><h3 id="header-24">set</h3><p><code>{key1,key2,...}</code>:</p><ul><li>无不可重复元素，可以是不同类型的，可嵌套</li><li>注：不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素”</li><li>添加元素： <ul><li><code>add(key)</code></li><li><code>update(iterable)</code></li></ul></li><li>删除元素：<ul><li><code>remove(key)</code> 找不到会报错</li><li><code>discard(key)</code> 找不到不会报错</li><li><code>pop()</code></li></ul></li><li>判断是否存在某元素: <ul><li><code>item in s1</code></li><li><code>item not in s1</code></li></ul></li><li>交,并,差,补集：<ul><li>交集: <code>s1&amp;s2</code>,<code>s1.intersection(s2)</code>,<code>s1.intersection_update(s2)</code>–取交集并更新自己</li><li>并集: <code>s1|s2</code>,<code>s1.union(s2)</code></li><li>差集: <code>s1-s2</code>,<code>s1.differenc(s2)</code>,<code>s1.difference_update(s2)</code> (注：s1-s2!=s2-s1)</li><li>补集: <code>s1^s2</code>,<code>s1.symmetric_difference(s2)</code>, <code>s1.symmetric_difference_update(s2)</code></li></ul></li><li>关系判断：相交不相交, 包含不包含<ul><li>是否不相交 <code>s1.isdisjoint(s2)</code></li><li>是否包含某集合 <code>s1.issuperset(s2)</code>,<code>s1&gt;=s2</code></li><li>是否被某集合包含 <code>s1.issubset(s2)</code>,<code>s1&lt;=s2</code></li></ul></li><li>不变集合: <code>frozenset(s)</code> </li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python">&gt;&gt;&gt; s1={1,5,9,3,9}&gt;&gt;&gt; len(s1)4&gt;&gt;&gt; s1{1, 3, 5, 9}# 注：不可以放入可变对象，因为无法判断两个可变对象是否相等，也就无法保证set内部“不会有重复元素”&gt;&gt;&gt; s2={1,2,(1,2)}&gt;&gt;&gt; s2{(1, 2), 1, 2}&gt;&gt;&gt; s2={1,2,[1,2]}Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: unhashable type: &#39;list&#39;# 添加元素 add(key),update(iterable)&gt;&gt;&gt; s1.add(2)&gt;&gt;&gt; s1{1, 2, 3, 5, 9}&gt;&gt;&gt; s1.add(&#39;Tom&#39;)&gt;&gt;&gt; s1{1, 2, 3, 5, 9, &#39;Tom&#39;} &gt;&gt;&gt; s1.add(9)&gt;&gt;&gt; s1{1, 2, 3, 5, 9}&gt;&gt;&gt; s1.update({7,10})&gt;&gt;&gt; s1{1, 2, 3, 5, 7, 9, 10}&gt;&gt;&gt; s1.update([1,4])&gt;&gt;&gt; s1{1, 2, 3, 4, 5, 7, 9, 10}&gt;&gt;&gt; s1.update(&#39;ef&#39;)&gt;&gt;&gt; s1{1, 2, 3, 4, 5, 7, 9, 10, &#39;f&#39;, &#39;e&#39;}&gt;&gt;&gt; s1.update(9)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: &#39;int&#39; object is not iterable# 删除元素 remove(key),discard(key)--不会报错,pop()&gt;&gt;&gt; s1.remove(&#39;Tom&#39;)&gt;&gt;&gt; s1{1, 2, 3, 5, 9}&gt;&gt;&gt; s1.remove(&#39;a&#39;)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;KeyError: &#39;a&#39; &gt;&gt;&gt; s1.discard(&#39;a&#39;)&gt;&gt;&gt; s1.pop()1&gt;&gt;&gt; s1{2, 3, 5, 9, &#39;Tom&#39;}# 判断是否存在某元素: in,not in&gt;&gt;&gt; s1{2, 3, 5, 9, &#39;Tom&#39;}&gt;&gt;&gt; 5 in s1True&gt;&gt;&gt; 7 not in s1True&gt;&gt;&gt; 1 in s1False# 交,并,差,补集&gt;&gt;&gt; s1={1,5,6,9}&gt;&gt;&gt; s2={3,5,9,10}&gt;&gt;&gt; s1&amp;s2     # 交集 s1.intersection(s2), s1.intersection_update(s2) -- 取交集并更新自己{9, 5}&gt;&gt;&gt; s1|s2      # 并集 s1.union(s2){1, 3, 5, 6, 9, 10}&gt;&gt;&gt; s1-s2     # 差集 differenc,difference_update{1, 6}&gt;&gt;&gt; s2-s1{10, 3}&gt;&gt;&gt; s1^s2    # 补集 symmetric_difference, symmetric_difference_update{1, 3, 6, 10}# 关系判断：相交不相交，包含不包含&gt;&gt;&gt; s1.isdisjoint(s2)     # 是否不相交False&gt;&gt;&gt; {1,3}.isdisjoint({2,5})True&gt;&gt;&gt; s1.issuperset(s2)  # 是否包含某集合（a&gt;=b）False&gt;&gt;&gt; {1,3,5}.issuperset({3,5})True &gt;&gt;&gt; {1,3,5} &gt;= {3,5}&gt;&gt;&gt; s1.issubset(s2)    # 是否被包含 （a&lt;=b）False&gt;&gt;&gt; {3,5}.issubset({1,3,5})True&gt;&gt;&gt; {3,5}&lt;={1,3,5}True# frozenset 不变集合&gt;&gt;&gt; a=frozenset({1,3,5})&gt;&gt;&gt; afrozenset({1, 3, 5})&gt;&gt;&gt; a.add(4)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;AttributeError: &#39;frozenset&#39; object has no attribute &#39;add&#39;# set(s): 可由元组,列表,字典(只取keys),集合,字符串创建&gt;&gt;&gt; set((1,2,3)){1,2,3}&gt;&gt;&gt; set({1,2,3}){1,2,3}&gt;&gt;&gt; set([1,2,2,3,1,2]){1,2,3}&gt;&gt;&gt; set({&#39;a&#39;:1,&#39;b&#39;:2}){&#39;a&#39;, &#39;b&#39;}&gt;&gt;&gt; set(&#39;123&#39;){&#39;2&#39;, &#39;3&#39;, &#39;1&#39;}</code></pre><h3 id="header-25">dict</h3><p><code>{key1:value1,key2:value2,...}</code>:</p><ul><li><code>key:value</code> 键值对，key需为不可改变类型，如int,float,str,tuple</li><li>访问元素: <ul><li><code>xxx[key]</code></li><li><code>.get(key,default=None)</code></li></ul></li><li>更新／添加元素: <ul><li><code>xxx[key]=value</code></li><li><code>.update({key:value,...})</code></li><li><code>.setdefault(key,default=None)</code></li></ul></li><li>删除元素:<ul><li><code>del xxx[key]</code></li><li><code>.pop(key)</code></li><li><code>.popitem()</code></li><li><code>.clear()</code></li></ul></li><li>获取对象<ul><li><code>keys()</code> 返回一个包含所有KEY的列表</li><li><code>values()</code> 返回一个包含所有value的列表</li><li><code>items()</code> 返回一个元组列表 <code>[(key,value),...]</code></li></ul></li><li>判断是非存在某key:<ul><li><code>key in d</code></li><li><code>key not in d</code></li></ul></li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python">&gt;&gt;&gt; d={&#39;a&#39;:1,&#39;b&#39;:2}&gt;&gt;&gt; len(d)2# 访问元素: xxxx[key],xxx.get(key,default=None)&gt;&gt;&gt; d[&#39;a&#39;]1&gt;&gt;&gt; d[&#39;b&#39;]2&gt;&gt;&gt; d.get(&#39;a&#39;)1&gt;&gt;&gt; d.get(&#39;c&#39;,&#39;N/A&#39;)&#39;N/A&#39;# 更新／插入元素: xxx[key]=value,.update({...}),.setdefault(key,default=None)&gt;&gt;&gt; d[&#39;a&#39;]=&#39;123&#39;&gt;&gt;&gt; d[&#39;c&#39;]=789&gt;&gt;&gt; d[&#39;e&#39;]=(1,2)&gt;&gt;&gt; d{&#39;a&#39;: &#39;123&#39;, &#39;b&#39;: 2, &#39;c&#39;: 789, &#39;e&#39;: (1, 2)}&gt;&gt;&gt; d.update({&#39;b&#39;:&#39;Hello&#39;,&#39;f&#39;:&#39;Tom&#39;})&gt;&gt;&gt; d{&#39;a&#39;: &#39;123&#39;, &#39;b&#39;: &#39;Hello&#39;, &#39;c&#39;: 789, &#39;e&#39;: (1, 2), &#39;f&#39;: &#39;Tom&#39;}&gt;&gt;&gt; d.setdefault(&#39;a&#39;,99)&#39;123&#39;&gt;&gt;&gt; d{&#39;a&#39;: &#39;123&#39;, &#39;b&#39;: &#39;Hello&#39;, &#39;c&#39;: 789, &#39;e&#39;: (1, 2), &#39;f&#39;: &#39;Tom&#39;}&gt;&gt;&gt; d.setdefault(&#39;g&#39;,99)99&gt;&gt;&gt; d{&#39;a&#39;: &#39;123&#39;, &#39;b&#39;: &#39;Hello&#39;, &#39;c&#39;: 789, &#39;e&#39;: (1, 2), &#39;f&#39;: &#39;Tom&#39;, &#39;g&#39;: 99}# 删除元素: del xxx[key],pop(key),popitem(),clear()&gt;&gt;&gt; del d[&#39;e&#39;]&gt;&gt;&gt; d{&#39;a&#39;: &#39;123&#39;, &#39;b&#39;: &#39;Hello&#39;, &#39;c&#39;: 789, &#39;f&#39;: &#39;Tom&#39;, &#39;g&#39;: 99}&gt;&gt;&gt; d.pop(&#39;a&#39;)&#39;123&#39;&gt;&gt;&gt; d{&#39;b&#39;: &#39;Hello&#39;, &#39;c&#39;: 789, &#39;f&#39;: &#39;Tom&#39;, &#39;g&#39;: 99}&gt;&gt;&gt; d.popitem()(&#39;g&#39;, 99)&gt;&gt;&gt; d{&#39;b&#39;: &#39;Hello&#39;, &#39;c&#39;: 789, &#39;f&#39;: &#39;Tom&#39;}# keys&gt;&gt;&gt; d.keys()dict_keys([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])# valuesdict_values([&#39;123&#39;, 2, 789])# items&gt;&gt;&gt; d.items()dict_items([(&#39;a&#39;, &#39;123&#39;), (&#39;b&#39;, 2), (&#39;c&#39;, 789)])# 判断key是否存在：key in d, key not in d&gt;&gt;&gt; &#39;c&#39; in dTrue&gt;&gt;&gt; &#39;g&#39; in dFalse&gt;&gt;&gt; &#39;a&#39; not in dTrue&gt;&gt;&gt; d.setdefault(&#39;k&#39;)&gt;&gt;&gt; d{&#39;b&#39;: &#39;Hello&#39;, &#39;c&#39;: 789, &#39;f&#39;: &#39;Tom&#39;, &#39;k&#39;: None}&gt;&gt;&gt; &#39;k&#39; in dTrue</code></pre><h2 id="header-26">函数</h2><pre><code class="lang-python">def test1():    passdef test2(step=1)    print(&quot;step=%s&quot; % step)def test3()    return [1,2,3]</code></pre><pre><code class="lang-bash">&gt;&gt;&gt; test1()&gt;&gt;&gt; test2(5)step=5&gt;&gt;&gt; test3()[1,2,3]</code></pre><h3 id="header-27">作用域</h3><ul><li>局部变量: <ul><li>在函数内部定义的变量，只能在本函数中用</li><li>可使用</li></ul></li><li>全局变量: <ul><li>在函数外定义的变量</li><li>使用：可以在所有的函数中使用</li><li>修改：在函数中不能修改全局变量的指向<ul><li>可变类型的全局变量 =&gt; 其指向的数据直接可以修改</li><li>不可类型的全局变量 =&gt; 使用global声明后可修改</li></ul></li></ul></li><li>注：<ul><li>可使用<code>globals()</code>、<code>locals()</code>列出当前作用域中所有全局／局部变量</li><li>函数中同名变量，局部变量优先全局变量</li><li>实际上，Python使用<code>LEGB顺序</code>规则来查找一个符号对应的对象<pre><code>  Locals（局部） -&gt; Enclosing function（嵌套函数）-&gt; Globals（全局） -&gt; Builtins（Python启动时会自动载入）</code></pre></li></ul></li></ul><p><strong>Sample1:查看全局／局部变量</strong></p><pre><code class="lang-python">import mathNumA=10NumB=20def testScope(*arg):    a=1    b=&#39;Hello&#39;    print(&quot;locals:&quot;,locals())         # print 局部变量 （注：函数参数也属于locals）    print(&quot;globals:&quot;,globals())        # print 全局变量 （注：包括python内建模块和手动import的）&gt;&gt;&gt; testScope(&#39;Tom&#39;)locals: {&#39;arg&#39;: (&#39;Tom&#39;,), &#39;a&#39;: 1, &#39;b&#39;: &#39;Hello&#39;}globals: {&#39;__name__&#39;: &#39;__main__&#39;, &#39;__doc__&#39;: None, &#39;__package__&#39;: None, &#39;__loader__&#39;: &lt;class &#39;_frozen_importlib.BuiltinImporter&#39;&gt;, &#39;__spec__&#39;: None, &#39;__annotations__&#39;: {}, &#39;__builtins__&#39;: &lt;module &#39;builtins&#39; (built-in)&gt;, &#39;NumA&#39;: 10, &#39;NumB&#39;: 20, &#39;testLocals&#39;: &lt;function testLocals at 0x10c7acf28&gt;, &#39;testScope&#39;: &lt;function testScope at 0x10c780950&gt;, &#39;math&#39;: &lt;module &#39;math&#39; from &#39;/anaconda3/lib/python3.7/lib-dynload/math.cpython-37m-darwin.so&#39;&gt;}</code></pre><p><strong>Sample2: 全局／局部变量优先级</strong></p><pre><code class="lang-python">Num=10# 1. 使用全局变量def testGlobalVar(step=1):    x=Num+step                # 使用全局变量    print(&quot;x=%s&quot; % x)&gt;&gt;&gt; testVar(3)x=13# 2. 使用局部变量def testLocalVar(step=1):    Num=20                    # 同名变量，局部变量优先级高于全局变量    x=Num+step    print(&quot;x=%s,Num=%s&quot; % (x,Num))&gt;&gt;&gt; testVar4(3)x=23,Num=20&gt;&gt;&gt; Num13</code></pre><p><strong>Sample3: 修改全局变量</strong></p><pre><code class="lang-python"># 1. 不可变类型的全局变量Num=10                        # 不可变类型def testVar(step=1):    x=Num+step    Num=x    print(&quot;x=%s,Num=%s&quot; % (x,Num))&gt;&gt;&gt; testVar(3)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;  File &quot;&lt;stdin&gt;&quot;, line 2, in testVar2UnboundLocalError: local variable &#39;Num&#39; referenced before assignmentdef testVar(step=1):    global Num                     # 使用global声明后可修改该全局变量    x=Num+step    Num=x    print(&quot;x=%s,Num=%s&quot; % (x,Num))&gt;&gt;&gt; testVar(3)x=13,Num=13&gt;&gt;&gt; Num                         # 全局变量Num已修改13# 2. 可变类型的全局变量A=[1,2,3]def testVar(step=1):    A.append(step)    print(A)&gt;&gt;&gt; testVar(4)[1, 2, 3, 4]&gt;&gt;&gt; A                            # 全局变量A已修改</code></pre><h3 id="header-28">函数参数</h3><ul><li>参数<ul><li>引用传参: 引用传递,不是值传递</li><li>不可变类型: 函数中运算不会影响到变量自身</li><li>可变类型: 函数中运算可能会影响到变量自身</li></ul></li><li>缺省参数(默认参数)<ul><li>一定要位于参数列表的最后面</li><li>(可在可变参数<code>*</code>前面或后面,但一定要在关键字参数<code>**</code>前面，不然会有歧义报错)</li></ul></li><li>不定长参数：<ul><li>用于处理比当初声明时更多的参数</li><li><code>*</code>变量：<ul><li>表示可变参数,tuple类型<ul><li>如: <code>*args</code> ，args用tuple存放未命名的变量参数</li><li>可直接传入,也可先组装list或tuple，再通过<code>*</code>传入,如：<code>func(*(1, 2, 3))</code></li></ul></li></ul></li><li><code>**</code>变量：<ul><li>表示关键字参数,dict类型,可以限制传入的参数名，同时提供默认值</li><li>如: <code>**kwargs</code>，kwargs用dict存放命名的参数(即key=value的参数)</li><li>可直接传入,也可先组装dict，再通过<code>**</code>传入,如：<code>func(**{&#39;a&#39;: 1, &#39;b&#39;: 2})</code></li><li>有<code>*</code>变量时，需在<code>*</code>变量后面（即最后面）</li></ul></li></ul></li></ul><p><strong>Sample1:传入不可变／可变参数</strong></p><pre><code class="lang-python"># 1. 传入不可变参数def testArg(a,b):    # a=a+b    a+=b    print(&quot;a=%s&quot; % a)&gt;&gt;&gt; a,b=3,5&gt;&gt;&gt; testArg(a,b)a=8&gt;&gt;&gt; a                     # a 未变3# 2. 传入可变参数def testArg(a,b):    a.append(b)    print(&#39;a=%s&#39; % a)&gt;&gt;&gt; a,b=[1,2,3],4&gt;&gt;&gt; testArg(a,b)a=[1, 2, 3, 4]&gt;&gt;&gt; a                  # a 变了[1, 2, 3, 4]</code></pre><p><strong>Sample2: 缺省参数(默认参数)</strong></p><pre><code class="lang-python"># 1. 单个缺省参数def testArg(a,b=1):    print(&#39;a=%s,b=%s,a+b=%s&#39; % (a,b,a+b))&gt;&gt;&gt; testArg(3,5)a=3,b=5,a+b=8&gt;&gt;&gt; testArg(3)a=3,b=1,a+b=4# 2.多个缺省参数(位于参数列表的最后面)def testArg(a,b=1,c=None,d=&#39;abc&#39;):    print(&#39;a=%s,b=%s,c=%s,d=%s&#39; % (a,b,c,d))&gt;&gt;&gt; testArg(1,2,3,4)a=1,b=2,c=3,d=4&gt;&gt;&gt; testArg(1,2,3)a=1,b=2,c=3,d=abc&gt;&gt;&gt; testArg(1,2)a=1,b=2,c=None,d=abc&gt;&gt;&gt; testArg(1)a=1,b=1,c=None,d=abc&gt;&gt;&gt; testArg(1,d=5,c=4)         # 指定传入参数a=1,b=1,c=4,d=5&gt;&gt;&gt; testArg(1,[2,3])        # 传入可变参数a=1,b=[2, 3],c=None,d=abc</code></pre><p><strong>Sample3: 不定长参数</strong></p><pre><code class="lang-python"># 1. *arg,**kwargsdef testArg(a,b,*args,**kwargs):    print(&quot;a=%s,b=%s,args=%s,kwargs=%s&quot; % (a,b,args,kwargs))&gt;&gt;&gt; testArg(1,2)a=1,b=2,args=(),kwargs={}&gt;&gt;&gt; testArg(1,2,3,4,x=&#39;001&#39;,y=&#39;002&#39;)    # 直接传入a=1,b=2,args=(3, 4),kwargs={&#39;x&#39;: &#39;001&#39;, &#39;y&#39;: &#39;002&#39;}&gt;&gt;&gt; m=(7,8,9)&gt;&gt;&gt; n={&#39;k&#39;:&#39;005&#39;,&#39;z&#39;:&#39;006&#39;}&gt;&gt;&gt; testArg(1,2,m,n)a=1,b=2,args=((7, 8, 9), {&#39;k&#39;: &#39;005&#39;, &#39;z&#39;: &#39;006&#39;}),kwargs={}&gt;&gt;&gt; testArg(1,2,*m,**n)                    # 组装后传入a=1,b=2,args=(7, 8, 9),kwargs={&#39;k&#39;: &#39;005&#39;, &#39;z&#39;: &#39;006&#39;}&gt;&gt;&gt; testArg(1,2,3,4,*m,**n,x=&#39;001&#39;,y=&#39;002&#39;)a=1,b=2,args=(3, 4, 7, 8, 9),kwargs={&#39;k&#39;: &#39;005&#39;, &#39;z&#39;: &#39;006&#39;, &#39;x&#39;: &#39;001&#39;, &#39;y&#39;: &#39;002&#39;}&gt;&gt;&gt; testArg(1,2,3,4,*m,**n,x=&#39;001&#39;,z=&#39;002&#39;)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: testArg() got multiple values for keyword argument &#39;z&#39;# 2. + default argdef testArg(a,b,c=&#39;abc&#39;,*args,**kwargs):    # 或 def testArg(a,b,*args,c=&#39;abc&#39;,**kwargs):    print(&quot;a=%s,b=%s,c=%s,args=%s,kwargs=%s&quot; % (a,b,c,args,kwargs))&gt;&gt;&gt; testArg(1,2)a=1,b=2,c=abc,args=(),kwargs={}&gt;&gt;&gt; testArg(1,2,3,x=&#39;001&#39;,y=&#39;002&#39;)a=1,b=2,c=3,args=(),kwargs={&#39;x&#39;: &#39;001&#39;, &#39;y&#39;: &#39;002&#39;}&gt;&gt;&gt; testArg(1,2,3,4,x=&#39;001&#39;,y=&#39;002&#39;)a=1,b=2,c=3,args=(4,),kwargs={&#39;x&#39;: &#39;001&#39;, &#39;y&#39;: &#39;002&#39;}&gt;&gt;&gt; testArg(1,2,x=&#39;001&#39;,y=&#39;002&#39;,c=4)a=1,b=2,c=4,args=(),kwargs={&#39;x&#39;: &#39;001&#39;, &#39;y&#39;: &#39;002&#39;}&gt;&gt;&gt; testArg(1,2,5,c=4,x=&#39;001&#39;,y=&#39;002&#39;)Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: testArg() got multiple values for argument &#39;c&#39;</code></pre><h3 id="header-29">函数返回值</h3><ul><li>无返回值</li><li>返回一个变量,eg: <code>return x</code></li><li>返回多个变量,eg: <code>return x,y</code> 本质是返回了一个元组</li><li>注意：变量也可以代表函数，所以也可返回函数</li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python"># 1. 无返回值def testReturn(a,b):    print(&quot;a+b=%s&quot; % (a+b))&gt;&gt;&gt; testReturn(1,3)a+b=4# 2. 返回一个变量def testReturn(a,b):    return a+b&gt;&gt;&gt; testReturn(1,3)4&gt;&gt;&gt; testReturn([1,2],[3,4])[1, 2, 3, 4]# 3. 返回多个变量def testReturn(a,b):    return a,b,a+b&gt;&gt;&gt; testReturn(2,3)(2, 3, 5)&gt;&gt;&gt; a,b,c=testReturn(2,3)&gt;&gt;&gt; a,b,c(2, 3, 5)&gt;&gt;&gt; a2&gt;&gt;&gt; b3&gt;&gt;&gt; c5&gt;&gt;&gt; a,b,c=testReturn([1,2],[3,4])&gt;&gt;&gt; a,b,c([1, 2], [3, 4], [1, 2, 3, 4])# 4. 返回函数def testReturn(a,b):    def test_in(c):        return a+b+c    return test_in&gt;&gt;&gt; f=testReturn(3,5)&gt;&gt;&gt; f&gt;&gt;&gt; f(1)9&gt;&gt;&gt; f(2)10</code></pre><h3 id="header-30">高级特性：闭包</h3><ul><li>返回内部函数，内部函数使用了外部包裹函数作用域里变量（非全局变量），则称内部函数为闭包</li><li>优点：<ul><li>可提高代码可复用性</li><li>似优化了变量，原来需要类对象完成的工作，闭包也可以完成</li></ul></li><li>缺点：<ul><li>由于闭包引用了外部函数的局部变量，则外部函数的局部变量没有及时释放，消耗内存</li></ul></li></ul><p><strong>Sample1:闭包</strong></p><pre><code class="lang-python">def test(a):    def test_in(b):        print(&quot;a=%s,b=%s,a+b=%s&quot; % (a,b,a+b))        return a+b    return test_in&gt;&gt;&gt; f=test(3)&gt;&gt;&gt; f&lt;function test.&lt;locals&gt;.test_in at 0x107af51e0&gt;&gt;&gt;&gt; f(5)a=3,b=5,a+b=88&gt;&gt;&gt; f(8)a=3,b=8,a+b=1111</code></pre><p><strong>Sample2:返回一个计数器</strong></p><pre><code class="lang-python">def counter(start=0):    global total    total=start    def incr():        total+=1                # total相对于incr()为外部变量，且为不可变类型，修改会报错        return total    return incr&gt;&gt;&gt; ct1=counter()&gt;&gt;&gt; a,b,c=ct1(),ct1(),ct1()Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;  File &quot;&lt;stdin&gt;&quot;, line 4, in incrUnboundLocalError: local variable &#39;total&#39; referenced before assignment# solution1: 使用可变型变量def counter(start=0):    total=[start]    def incr():        total[0] += 1        return total[0]    return incr# solution2: 使用nonlocal声明def counter(start=0):    total=start    def incr():        nonlocal total        total+=1        return total    return incr# 或者：def counter(start=0):    def incr():        nonlocal start        start+=1        return start    return incr# test:&gt;&gt;&gt; ct1=counter()&gt;&gt;&gt; ct2=counter(5)&gt;&gt;&gt; a,b,c=ct1(),ct1(),ct1()&gt;&gt;&gt; a,b,c&gt;&gt;&gt; (1,2,3)&gt;&gt;&gt; x,y,z=ct2(),ct2(),ct2()&gt;&gt;&gt; x,y,z(6, 7, 8)</code></pre><h3 id="header-31">高级特性: 列表生成式</h3><p>List Comprehensions： <code>[]</code> 列表生成式即用来创建list的生成式</p><pre><code class="lang-python"># &gt;&gt;&gt; list(range(1, 11))[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]&gt;&gt;&gt; [x * x for x in range(1, 11)][1, 4, 9, 16, 25, 36, 49, 64, 81, 100]&gt;&gt;&gt; [x * x for x in range(1, 11) if x % 2 == 0][4, 16, 36, 64, 100]&gt;&gt;&gt; d = {&#39;x&#39;: &#39;A&#39;, &#39;y&#39;: &#39;B&#39;, &#39;z&#39;: &#39;C&#39; }&gt;&gt;&gt; [k+&#39;=&#39;+v for k, v in d.items()][&#39;y=B&#39;, &#39;x=A&#39;, &#39;z=C&#39;]</code></pre><h3 id="header-32">高级特性：生成器(generator)</h3><ul><li>生成器: 一个不断产生值的函数,边计算边产出值</li><li>生成过程： 每次迭代从上一次返回时的函数体中的位置开始，所使用的参数都是第一次所保留下的,不是新创建的（生成器“记住”了数据状态和流程中的位置）</li><li>相比一次列出所有内容的优势: 节约内存，响应迅速，使用灵活</li><li>创建生成器：<ul><li>使用包含<code>yield</code>语句的函数, 生成器每调用一次，会在yield位置产生一个值, 直到函数执行结束</li><li>简单的生成器，可以通过将一个列表生成式的 <code>[ ]</code> 改成 <code>( )</code>直接生成</li></ul></li><li>获取生成器生成的元素：<ul><li>通过<code>next(g)</code>函数获得生成器的下一个返回值<ul><li>没有更多的元素时，抛出 <code>StopIteration</code> 的异常</li><li>生成器函数的返回值包含在StopIteration的value中，可通过捕获StopIteration错误获取返回值</li></ul></li><li>通过<code>for in</code> 循环<ul><li>没有更多的元素时，不会抛出 <code>StopIteration</code> 的异常</li><li>拿不到生成器函数的返回值（return语句的返回值）</li></ul></li><li>注：生成器中元素都取出后就无用了</li></ul></li></ul><p><strong>Sample1:</strong></p><pre><code class="lang-python"># 1. 普通函数: 一次列出所有（如果n=100M,1000M,...会很慢）def double(n):    return [i*2 for i in range(1,n)]# 2. 生成器函数: 用多少生成多少，效率高（更节约内存和快捷）def gen(n):    for i in range(1,n):        yield i*2# 3. 创建生成器，下面g1与g2效果相同g1 = gen(5)g2 = (x*2 for x in range(1,5))&gt;&gt;&gt; g1&lt;generator object &lt;genexpr&gt; at 0x1114b1e58&gt;&gt;&gt;&gt; g2# 4. 获取生成器生成的元素# Method1: 使用`next(g)`函数&gt;&gt;&gt; next(g1)2&gt;&gt;&gt; next(g1)4&gt;&gt;&gt; next(g1)8&gt;&gt;&gt; next(g1)---------------------------------------------------------------------------StopIteration                             Traceback (most recent call last)&lt;ipython-input-51-e734f8aca5ac&gt; in &lt;module&gt;----&gt; 1 next(g)StopIteration:# Method2: 使用`for in g`循环遍历for i in g2:...:     print(i,&quot; &quot;,end=&quot;&quot;)...:2 4 6 8</code></pre><p><strong>Sample2:</strong></p><pre><code class="lang-python"># 1. 定义生成器函数def odd():    print(&#39;step 1&#39;)    yield 1    print(&#39;step 2&#39;)    yield(3)    print(&#39;step 3&#39;)    yield(5)    return &quot;no more&quot;# 2. 定义遍历生成器函数def getAll_by_forin(g):    for i in g:        print(i)def getAll_by_next(g):    while True:        try:            print(&#39;x=%s&#39; % next(g))        except StopIteration as e:            print(&#39;Generator return value:&#39;, e.value)            break    print(&#39;finish!&#39;)# test1: 使用 for in 循环&gt;&gt;&gt; g1=odd()&gt;&gt;&gt; getAll_by_forin(g1)step 11step 23step 35# test2: 使用 next(g) &gt;&gt;&gt; g2=odd()&gt;&gt;&gt; getAll_by_next(g1)tep 1x=1step 2x=3step 3x=5Generator return value: no morefinish!</code></pre><h3 id="header-33">高级特性：迭代器(Iterator)</h3><ul><li>迭代器（Iterator）对象:<ul><li>可以被<code>next()</code>函数调用并不断返回下一个值的对象(直到没有数据时抛出<code>StopIteration</code>错误)</li><li><code>Iterator</code>对象表示的是一个惰性计算（即只有在需要获取下一个数据时它才会计算）的序列(即数据流，可以无限大，如全体自然数)</li><li>如：生成器generator对象</li></ul></li><li>可迭代对象（Iterable）:<ul><li>可以直接作用于<code>for in</code>循环的对象</li><li>如: list、tuple、dict、set、str,generator</li></ul></li><li>迭代器<code>Iterator</code>对象一定是可迭代对象<code>Iterable</code>(可以用<code>for in</code>循环)，反之不一定</li><li>可使用<code>iter()</code>函数将<code>Iterable</code>对象转换为<code>Iterator</code>对象</li><li>可以使用<code>isinstance()</code>判断一个对象类型，如：判断是否是<code>Iterable</code>对象，是否是<code>Iterator</code>对象</li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python">import collections# 1. list,tuple,dict,set,str等是`Iterable`对象但不是`Iterator`对象&gt;&gt;&gt; l=[1,2,3]&gt;&gt;&gt; isinstance(l,Iterable)True&gt;&gt;&gt; isinstance(l,Iterator)False&gt;&gt;&gt; next(l)next(l)---------------------------------------------------------------------------TypeError                                 Traceback (most recent call last)&lt;ipython-input-79-cdc8a39da60d&gt; in &lt;module&gt;----&gt; 1 next(l)TypeError: &#39;list&#39; object is not an iterator&gt;&gt;&gt; for i in l:...:     print(i)...:123# 2. 使用`iter(x)`函数将`Iterable`对象转换为`Iterator`对象&gt;&gt;&gt; a=iter(l)&gt;&gt;&gt; isinstance(a,Iterable)True&gt;&gt;&gt; isinstance(a,Iterator)True&gt;&gt;&gt; next(a)1&gt;&gt;&gt; next(a)2# 3. generator对象是`Iterator`对象&gt;&gt;&gt; g=(x*2 for x in range(1,5))&gt;&gt;&gt; isinstance(l,Iterable)True&gt;&gt;&gt; isinstance(l,Iterator)True&gt;&gt;&gt; next(g)2&gt;&gt;&gt; next(g)4</code></pre><h3 id="header-34">高级特性：装饰器(decorator)</h3><ul><li>增强函数功能（例如在函数调用前后自动打印日志），但不修改函数原本定义</li><li>本质上，decorator就是一个返回函数的高阶函数</li></ul><p><strong>Sample:</strong></p><ol><li><p>原始函数特性</p><pre><code class="lang-python"> def sum(a,b):     print(&quot;a+b=%s&quot; % (a+b)) # 查看函数名字`__name__` &gt;&gt;&gt; dir(sum) [&#39;__annotations__&#39;, &#39;__call__&#39;, &#39;__class__&#39;, &#39;__closure__&#39;, &#39;__code__&#39;, &#39;__defaults__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__get__&#39;, &#39;__getattribute__&#39;, &#39;__globals__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__kwdefaults__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__name__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__qualname__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;] &gt;&gt;&gt; sum.__name__ &#39;sum&#39; &gt;&gt;&gt; f=sum &gt;&gt;&gt; f.__name__ &#39;sum&#39; &gt;&gt;&gt; sum(3,5) a+b=8 &gt;&gt;&gt; f(3,5) a+b=8</code></pre></li><li><p>定义使用一个无参decorator</p><pre><code class="lang-python"> # 1. 定义decorator：log def log(func):     def func_wrapper(*args, **kw):         print(&#39;call %s(%s,%s):&#39; % (func.__name__,args,kw))         return func(*args, **kw)     return func_wrapper # 2. 在原函数上加上decorator: 使用`@` # 把`@log`放到`sum()`函数的定义处，相当于执行了:`sum = log(sum)` @log def sum(a,b):     print(&quot;a+b=%s&quot; % (a+b)) # 3. test: &gt;&gt;&gt; sum(3,5) call sum((3, 5),{}): a+b=8 &gt;&gt;&gt; sum.__name__ &#39;func_wrapper&#39;</code></pre></li><li><p>定义使用一个有参decorator</p><pre><code class="lang-python"> # 1. 定义decorator：log （decorator本身传入参数，需返回一个decorator的高阶函数） def log(text):     def log_wrapper(func):         def func_wrapper(*args, **kw):             print(&#39;%s %s(%s,%s):&#39; % (text,func.__name__,args,kw))             return func(*args, **kw)         return func_wrapper     return log_wrapper # 2. 使用decorator # 相当于执行了: `sum = log(&#39;execute:&#39;)(sum)` @log(&#39;execute:&#39;) def sum(a,b):     print(&quot;a+b=%s&quot; % (a+b)) # 3. test: &gt;&gt;&gt; sum(3,5) execute: sum((3, 5),{}): a+b=8 &gt;&gt;&gt; sum.__name__ &#39;func_wrapper&#39;</code></pre></li><li><p>Issue: 被装饰后的函数其实已经是另外一个函数了（函数名等函数属性会发生改变）,eg: 装饰后的函数<code>__name__</code>等不准确了</p><pre><code class="lang-python"> # 需要把原始函数的`__name__`等属性复制到`func_wraper()`函数 # 可使用functools.wraps(function)装饰器来消除这样的副作用 import functools def log(text):     def log_wrapper(func):         @functools.wraps(func)     # 添加functools.wraps(function)装饰器         def func_wrapper(*args, **kw):             print(&#39;%s %s(%s,%s):&#39; % (text,func.__name__,args,kw))             return func(*args, **kw)         return func_wrapper     return log_wrapper @log(&#39;execute:&#39;) def sum(a,b):     print(&quot;a+b=%s&quot; % (a+b)) # test: &gt;&gt;&gt; sum(3,5) execute: sum((3, 5),{}): a+b=8 &gt;&gt;&gt; sum.__name__ &#39;sum&#39;</code></pre></li></ol><h3 id="header-35">匿名函数</h3><ul><li>lambda函数：<code>lambda [arg1 [,arg2,.....argn]]:expression</code><ul><li><code>冒号</code>前面的表示函数参数，可以无参</li><li>只能有一个<code>表达式</code>，不用写<code>return</code>，返回值就是该表达式的结果</li></ul></li><li>应用: 函数作为参数,返回值传递</li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python"># 1. lambda函数&gt;&gt;&gt; sum=lambda a,b:a+b         # 相当于 def sum(a,b): return a+b&gt;&gt;&gt; sum&lt;function &lt;lambda&gt; at 0x10787c158&gt;&gt;&gt;&gt; sum(3,5)8# 2. 应用: 作为参数&gt;&gt;&gt; a=[3,1,5]&gt;&gt;&gt; a.sort()&gt;&gt;&gt; a[1, 3, 5]&gt;&gt;&gt; a=[... {&#39;name&#39;:&#39;Tom&#39;,&#39;age&#39;:18}... ,{&#39;name&#39;:&#39;Lucy&#39;,&#39;age&#39;:22}... ,{&#39;name&#39;:&#39;Andy&#39;,&#39;age&#39;:20}... ]&gt;&gt;&gt; a.sort()Traceback (most recent call last):  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;TypeError: &#39;&lt;&#39; not supported between instances of &#39;dict&#39; and &#39;dict&#39;&gt;&gt;&gt; k=lambda item:item[&#39;name&#39;]&gt;&gt;&gt; a.sort(key=k)&gt;&gt;&gt; a[{&#39;name&#39;: &#39;Andy&#39;, &#39;age&#39;: 20}, {&#39;name&#39;: &#39;Lucy&#39;, &#39;age&#39;: 22}, {&#39;name&#39;: &#39;Tom&#39;, &#39;age&#39;: 18}]&gt;&gt;&gt; a.sort(key=lambda x:x[&#39;age&#39;])&gt;&gt;&gt; a[{&#39;name&#39;: &#39;Tom&#39;, &#39;age&#39;: 18}, {&#39;name&#39;: &#39;Andy&#39;, &#39;age&#39;: 20}, {&#39;name&#39;: &#39;Lucy&#39;, &#39;age&#39;: 22}]</code></pre><h3 id="header-36">内建函数</h3><p>Build-in Function</p><ul><li>python解释器启动后默认加载</li><li>查看：<code>dir(__builtins__)</code></li><li>使用：<code>help(function)</code></li><li><p>常用的内建函数</p><ul><li><code>range(stop)</code>, <code>range(start stop[, step])</code> -&gt; integer list  (默认start=0,不包括stop,使用了惰性计算)<pre><code class="lang-python">  &gt;&gt;&gt; a = range(5)  &gt;&gt;&gt; a   range(0, 5)  &gt;&gt;&gt; list(a)  [0, 1, 2, 3, 4]  &gt;&gt;&gt; [x*2 for x in a]  [0, 2, 4, 6, 8]</code></pre></li><li><p><code>map(func, *iterables)</code> 根据提供的函数对指定序列做映射(使用了惰性计算)</p><pre><code class="lang-python">  &gt;&gt;&gt; a=[1,2,3]  &gt;&gt;&gt; b=map(lambda x:x*x,a)  &gt;&gt;&gt; list(b)  [1, 4, 9]  &gt;&gt;&gt; c=map(lambda x,y:(x,y),[1,2,3],[&#39;a,&#39;,&#39;b&#39;,&#39;c&#39;,&#39;d&#39;])  &gt;&gt;&gt; list(c)  [(1, &#39;a,&#39;), (2, &#39;b&#39;), (3, &#39;c&#39;)]  &gt;&gt;&gt; d=map(str,[1,2,3,&#39;a&#39;])  &gt;&gt;&gt; list(d)  [&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;a&#39;]  &gt;&gt;&gt; t=map(str,(1,2,3,&#39;a&#39;))  &gt;&gt;&gt; tuple(t)  (&#39;1&#39;, &#39;2&#39;, &#39;3&#39;, &#39;a&#39;)</code></pre></li><li><p><code>filter(function or None, iterable)</code> 从一个序列中筛出符合条件的元素(使用了惰性计算，所以只有在取<code>filter()</code>结果的时候,才会真正筛选并每次返回下一个筛出的元素)</p><pre><code class="lang-python">  &gt;&gt;&gt; a=filter(lambda x:x%2,[1,2,3,4])    # 参数 function 返回1／0 =&gt; 布尔值True/False  &gt;&gt;&gt; list(a)  [1, 3]  &gt;&gt;&gt; b=filter(lambda x:x%2,{1,2,3,4})  &gt;&gt;&gt; set(b)  {1, 3}</code></pre></li><li><p><code>sorted(iterable, cmp=None, key=None, reverse=False)</code>  -&gt; new sorted object</p><pre><code class="lang-python">  &gt;&gt;&gt; a=sorted([1,5,4,2,9])  &gt;&gt;&gt; a  [1, 2, 4, 5, 9]  &gt;&gt;&gt; a=[{&#39;name&#39;:&#39;Tom&#39;,&#39;age&#39;:18},{&#39;name&#39;:&#39;Lucy&#39;,&#39;age&#39;:22},{&#39;name&#39;:&#39;Andy&#39;,&#39;age&#39;:20}]  &gt;&gt;&gt; result=sorted(a,key=lambda x:x[&#39;age&#39;])  &gt;&gt;&gt; result  [{&#39;name&#39;: &#39;Tom&#39;, &#39;age&#39;: 18}, {&#39;name&#39;: &#39;Andy&#39;, &#39;age&#39;: 20}, {&#39;name&#39;: &#39;Lucy&#39;, &#39;age&#39;: 22}]</code></pre></li></ul></li><li><p><code>functools</code> 工具函数包</p><pre><code class="lang-python">  &gt;&gt;&gt; import functools  &gt;&gt;&gt; dir(functools)  [&#39;RLock&#39;, &#39;WRAPPER_ASSIGNMENTS&#39;, &#39;WRAPPER_UPDATES&#39;, &#39;_CacheInfo&#39;, &#39;_HashedSeq&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;_c3_merge&#39;, &#39;_c3_mro&#39;, &#39;_compose_mro&#39;, &#39;_convert&#39;, &#39;_find_impl&#39;, &#39;_ge_from_gt&#39;, &#39;_ge_from_le&#39;, &#39;_ge_from_lt&#39;, &#39;_gt_from_ge&#39;, &#39;_gt_from_le&#39;, &#39;_gt_from_lt&#39;, &#39;_le_from_ge&#39;, &#39;_le_from_gt&#39;, &#39;_le_from_lt&#39;, &#39;_lru_cache_wrapper&#39;, &#39;_lt_from_ge&#39;, &#39;_lt_from_gt&#39;, &#39;_lt_from_le&#39;, &#39;_make_key&#39;, &#39;cmp_to_key&#39;, &#39;get_cache_token&#39;, &#39;lru_cache&#39;, &#39;namedtuple&#39;, &#39;partial&#39;, &#39;partialmethod&#39;, &#39;recursive_repr&#39;, &#39;reduce&#39;, &#39;singledispatch&#39;, &#39;total_ordering&#39;, &#39;update_wrapper&#39;, &#39;wraps&#39;]</code></pre><ul><li><p><code>reduce(function, sequence[, initial])</code> -&gt; value</p><pre><code class="lang-python">  &gt;&gt;&gt; a=functools.reduce(lambda x, y: x+y, [1,2,3,4])  &gt;&gt;&gt; a  10  &gt;&gt;&gt; a=functools.reduce(lambda x, y: x+y, [1,2,3,4],10)  &gt;&gt;&gt; a  20</code></pre></li><li><p><code>partial(func, *args, **keywords)</code> 偏函数:简化func,设置默认值 -&gt; new function 这样调用这个新函数会更简单</p><pre><code class="lang-python">  &gt;&gt;&gt; int2 = functools.partial(int, base=2)  &gt;&gt;&gt; int2(&#39;1000000&#39;)            # 等同：int(&#39;1000000&#39;,base=2)  64  &gt;&gt;&gt; def showarg(*args, **kw):  ...     print(&quot;args=%s,kw=%s&quot; % (args,kw))  ...  &gt;&gt;&gt; f=functools.partial(showarg, 1,2,3,a=3,b=&#39;linux&#39;)  &gt;&gt;&gt; f()  args=(1, 2, 3),kw={&#39;a&#39;: 3, &#39;b&#39;: &#39;linux&#39;}  &gt;&gt;&gt; f(4,5,c=&#39;hello&#39;)  args=(1, 2, 3, 4, 5),kw={&#39;a&#39;: 3, &#39;b&#39;: &#39;linux&#39;, &#39;c&#39;: &#39;hello&#39;}</code></pre></li><li><p><code>wraps(func)</code>装饰器: 消除被装饰函数的函数名等函数属性发生改变的副作用</p><pre><code class="lang-python">  def note(func):      &quot;note function&quot;      @functools.wraps(func)      def func_wrapper(*args,**kw):          &quot;wrapper function&quot;          print(&#39;call %s(%s,%s):&#39; % (func.__name__,args,kw))          return func(*args,*kw)      return func_wrapper  @note  def test(a,b):      &#39;test function&#39;      print(&#39;a=%s,b=%s&#39; % (a,b))  &gt;&gt;&gt; test(3,5)  call test((3, 5),{}):  a=3,b=5  &gt;&gt;&gt; test.__name__  &#39;test&#39;  &gt;&gt;&gt; test.__doc__  &#39;test function&#39;</code></pre></li></ul></li></ul><h2 id="header-37">类与实例</h2><pre><code class="lang-python">class Cat:            # 定义类    pass&gt;&gt;&gt; c=Cat()            # 创建实例# 1. 类对象&gt;&gt;&gt; Cat             __main__.Cat&gt;&gt;&gt; type(Cat)type# 2. 实例对象&gt;&gt;&gt; c                 &lt;__main__.Cat at 0x104f875f8&gt;&gt;&gt;&gt; type(c)__main__.Cat</code></pre><ol><li><p>类对象与实例对象</p><ul><li>类对象(class) : 模版</li><li>实例对象(instance) : 根据类创建的对象</li><li>获取对象信息：<ul><li><code>type(x)</code> : 获取对象类型</li><li><code>isinstance(x,class_or_tuple)</code> : 判断class的类型</li><li><code>dir(x)</code> : 查看一个对象的所有属性和方法(包括私有)</li></ul></li></ul></li><li><p>特性：</p><ul><li>类的三大特性：封装，继承，多态 （注：python类不仅支持单继承，还支持多继承）</li><li>python是动态语言，可动态给类／对象增删改属性和方法<ul><li>增/改：<code>类／实例对象.xxx=...</code></li><li>删除：<code>del 类／实例对象.xxx</code>,<code>delattr(类／实例对象,name)</code></li></ul></li></ul></li><li><p>访问限制</p><ul><li>公有: 默认</li><li>保护：以<code>_</code>开头，自己内部和子类可访问，不能用<code>from module import *</code>导入(即不可跨包)</li><li>私有: 以<code>__</code>开头，只有自己内部可以访问，外部（包括子类，实例对象等）不能访问</li><li>注：<ul><li>一般将属性私有化，以防止外部随意访问修改</li><li>可通过编写<code>getXxx/setXxx</code>方法或<code>@property</code>控制对外开放接口</li></ul></li></ul></li><li><p>访问</p><ul><li>属性／方法： <code>类.xxx</code>,<code>实例.xxx</code></li><li>方法调用：<code>类.xxx(...)</code>,<code>实例.xxx(...)</code></li><li>python也提供了内置函数判断获取对象属性或方法（无法判断或调用私有属性／方法）<ul><li><code>getattr(obj,name)</code></li><li><code>setattr(obj,name,value)</code></li><li><code>hasattr(obj,name)</code></li></ul></li></ul></li></ol><h3 id="header-38">类成员：属性</h3><pre><code class="lang-python">class Cat:    name=&#39;cls_cat&#39;                # 类属性    def __init__(self):        self.age=1                # 实例属性c=Cat()&gt;&gt;&gt; Cat.name,c.name(&#39;cls_cat&#39;, &#39;cls_cat&#39;)&gt;&gt;&gt; c.name=&#39;self_cat&#39;            # 添加同名实例属性&gt;&gt;&gt; Cat.name,c.name             # 实例属性会屏蔽掉同名的类属性(&#39;cls_cat&#39;, &#39;self_cat&#39;)&gt;&gt;&gt; del c.name                     # 删除实例属性&gt;&gt;&gt; Cat.name,c.name(&#39;cls_cat&#39;, &#39;cls_cat&#39;)&gt;&gt;&gt; c.age1</code></pre><ul><li>类属性：<ul><li>类所有，所有实例共享一个属性，在内存中只存在一个副本</li><li>在类外访问：可通过类和实例对象访问公有类属性 <code>类名.xxx</code>,<code>实例名.xxx</code></li><li>在类外添加：<code>类名.xxx=...</code></li></ul></li><li>实例属性：<ul><li>实例所有，各个实例各自维护，互不影响</li><li>在类外访问：通过实例对象访问 <code>实例名.xxx</code></li><li>在类外添加：<code>实例名.xxx=...</code></li></ul></li><li>注： 使用<code>实例名.xxx</code>访问属性时，先找实例属性，没有再找类属性，所以：<ul><li>类属性和实例属性同名，用<code>实例名.xxx</code>访问时,实例属性会屏蔽掉同名的类属性</li><li>在类外修改类属性，必须通过类对象（如果通过实例对象，会产生一个同名的实例属性）</li></ul></li><li>高级<ul><li>属性私有化： 一般将属性私有化，以防止外部随意访问修改<ul><li>法一：编写<code>getXxx/setXxx</code>方法</li><li>法二：使用<code>@property</code>标示为属性函数(即将一个方法变成属性调用)</li></ul></li><li>限制动态添加实例属性： <ul><li>定义class的时候，定义一个特殊的<code>__slots__</code>变量，来限制该class实例能添加的属性</li><li>用<code>tuple</code>定义允许绑定的属性名称: <code>__slots__=(...)</code></li><li>注: <code>__slots__</code>仅对当前类实例起作用，对继承的子类无用,除非在子类中也定义，这样子类实例允许定义的属性就是自身的<code>__slots__</code>加上父类的<code>__slots__</code></li></ul></li></ul></li></ul><p><strong>Sample1: 属性私有化</strong></p><ul><li><p>法一：编写<code>getXxx/setXxx</code>方法开放端口</p><pre><code class="lang-python">  class Cat:      def __init__(self):          self.__age=0      def getAge(self):          return self.__age      def setAge(self,value):          if not isinstance(value, int):              raise ValueError(&#39;age must be an integer!&#39;)          if value &lt; 0 or value &gt; 100:              raise ValueError(&#39;age must between 0 ~ 100!&#39;)          self.__age = value  c=Cat()  &gt;&gt;&gt; c.age  --------------------------------------------------------------------------  AttributeError                            Traceback (most recent call last)  &lt;ipython-input-257-4dd7fde137b3&gt; in &lt;module&gt;  ----&gt; 1 c.age  AttributeError: &#39;Cat&#39; object has no attribute &#39;age&#39;  &gt;&gt;&gt; c.setAge(3)  &gt;&gt;&gt; c.getAge()  3</code></pre></li><li><p>法二：使用<code>@property</code>标示为属性函数</p><pre><code class="lang-python">  class Cat:      def __init__(self):          self.__age=0      @property                     # getter      def age(self):          return self.__age      @age.setter                 # setter      def age(self,value):          if not isinstance(value, int):              raise ValueError(&#39;age must be an integer!&#39;)          if value &lt; 0 or value &gt; 100:              raise ValueError(&#39;age must between 0 ~ 100!&#39;)          self.__age = value  c=Cat()  &gt;&gt;&gt; c.age＝5  &gt;&gt;&gt; c.age  5</code></pre></li></ul><p><strong>Sample2:限制动态添加实例属性</strong></p><pre><code class="lang-python">class Cat:    __slots__=(&#39;name&#39;,&#39;age&#39;)     # 用tuple定义允许绑定的属性名称class ColorfulCat(Cat):    passclass PureCat(Cat):    __slots__=(&#39;color&#39;)# 1. test 父：Cat&gt;&gt;&gt; c=Cat()                      # 父类实例对象 -- 只允许属性：name,age&gt;&gt;&gt; c.name=&#39;Tom&#39;&gt;&gt;&gt; c.age=3&gt;&gt;&gt; c.country=&#39;China&#39;c.country=&quot;China&quot;---------------------------------------------------------------------------AttributeError                            Traceback (most recent call last)&lt;ipython-input-269-64570eaae7be&gt; in &lt;module&gt;----&gt; 1 c.country=&quot;China&quot;AttributeError: &#39;Cat&#39; object has no attribute &#39;country&#39;# 2. test 子：ColorfulCat&gt;&gt;&gt; e=ColorfulCat()                # 子类实例对象－－无限制&gt;&gt;&gt; e.name=&#39;Tom&#39;&gt;&gt;&gt; e.name&#39;Tom&#39;&gt;&gt;&gt; e.country=&#39;China&#39;    &gt;&gt;&gt; e.country&#39;China&#39;# 3. test 子：PureCat&gt;&gt;&gt; p=PureCat()                 # 子类实例对象－－允许属性：父(name,age)＋ 子(color)&gt;&gt;&gt; p.color=&#39;White&#39;&gt;&gt;&gt; p.name=&#39;Tom&#39;&gt;&gt;&gt; p.age=1&gt;&gt;&gt; p.country=&#39;China&#39;---------------------------------------------------------------------------AttributeError                            Traceback (most recent call last)&lt;ipython-input-281-3661a6a00d34&gt; in &lt;module&gt;----&gt; 1 p.country=&#39;China&#39;AttributeError: &#39;PureCat&#39; object has no attribute &#39;country&#39;</code></pre><h3 id="header-39">类成员：方法</h3><pre><code class="lang-python">class Cat:    name=&#39;cls_cat&#39;    def eat(self):                # 实例方法        print(&#39;%s is eating&#39; % self.name)    @classmethod    def from_setting(cls):        # 类方法        cls.name=&#39;cls_cat_fresh&#39;        # 可添加类方法（第一个参数代表类）:        @classmethod        def say_cls(x,y):            return &quot;%s say %s&quot; % (x.name,y)        cls.say_cls=say_cls        # 可添加实例方法（第一个参数代表实例）:        cls.say_self=lambda x,y:&quot;%s say %s&quot; % (x.name,y)    @staticmethod                 # 静态方法    def play():        print(&quot;%s is playing&quot; % Cat.name)c=Cat()&gt;&gt;&gt; Cat.name,c.name(&#39;cls_cat&#39;, &#39;cls_cat&#39;)# 1. 调用类方法&gt;&gt;&gt; Cat.from_setting()          # or use: c.from_setting()&gt;&gt;&gt; Cat.name,c.name(&#39;cls_cat_fresh&#39;, &#39;cls_cat_fresh&#39;)# 2. 调用静态方法&gt;&gt;&gt; Cat.play()                 # or use: c.play()cls_cat_fresh is playing# 3. 调用实例方法&gt;&gt;&gt; c.eat()                 # can&#39;t use: Cat.eat()cls_cat_fresh is eating&gt;&gt;&gt; c.name=&#39;self_cat&#39;&gt;&gt;&gt; c.eat()self_cat is eating# 4. 调用from_setting()后添加的方法&gt;&gt;&gt; c.say_self(&#39;Hello&#39;) &#39;self_cat say Hello&#39;&gt;&gt;&gt; c.say_cls(&#39;Hello&#39;)&#39;cls_cat_fresh say Hello&#39;</code></pre><ul><li>类方法:<ul><li>需用修饰器<code>@classmethod</code>标识,第一个参数(习惯用变量名<code>cls</code>)必须是类对象（类外调用时，不用传递该参数，Python解释器会自己把类对象传入）</li><li>方法中：可修改类定义</li><li>在类外访问：可通过实例和类访问 <code>类名.xxx(...)</code>,<code>实例名.xxx(...)</code></li></ul></li><li>实例方法：<ul><li>不用修饰，第一参数(习惯用变量名<code>self</code>)必须是实例对象本身（类外调用时，不用传递该参数，Python解释器会自己把实例对象传入）</li><li>方法中：可修改实例属性（eg: <code>self.xxx</code>)</li><li>在类外访问：通过实例访问<code>实例名.xxx(...)</code> （不可使用类访问）</li></ul></li><li>静态方法：<ul><li>需用修饰器<code>@staticmethod</code>标识,无参数限制</li><li>方法中：可通过类调用类属性,类方法,静态方法 <code>类名.xxx</code>,<code>类名.xxx(...)</code></li><li>在类外调用：可通过实例和类访问 <code>类名.xxx(...)</code>,<code>实例名.xxx(...)</code></li></ul></li></ul><h3 id="header-40">继承与多态</h3><ul><li><p>继承：</p><ul><li>子类创建过程：<ul><li>子类<code>__new__</code>，无则调用父类 <code>__new__</code></li><li>子类<code>__init__</code>，无则父类 <code>__init__</code></li></ul></li><li>父类使用了有参<code>__init__</code>，则子类创建时也要有参</li><li>子类无法访问父类的私有属性和方法</li><li>重写: 子类会覆盖父类中同名的方法<ul><li>子类中调用父类方法<code>super().xxx</code>,<code>父类.xxx</code></li><li><code>类.__mro__</code> 可以查看类搜索方法时的先后顺序</li></ul></li></ul></li><li><p>单继承</p><pre><code class="lang-python">  class Animal:      def eat(self):          print(&#39;eating...&#39;)  class Cat(Animal):      pass</code></pre></li><li><p>多继承(MixIn)</p><pre><code class="lang-python">  class Runnable:      def run(self):          print(&#39;runing...&#39;)  class Cat(Animal,Runnable):      pass</code></pre></li><li><p>多态：自动调用实际类型的方法</p></li></ul><p><strong>Sample1:继承</strong></p><pre><code class="lang-python">class Animal:    def __init__(self,name):        self.name=name        print(&quot;Animal %s init.&quot; % name)    def eat(self):        print(&#39;Animal is eating...&#39;)class Cat(Animal):    def eat(self):        print(&quot;Cat is eating...&quot;)    def play(self):        print(&quot;Cat is playing...&quot;)    def father(self):        print(&quot;call father eat func:&quot;)        super().eat()        print(&quot;call self eat func:&quot;)        self.eat()&gt;&gt;&gt; c=Cat(&quot;Tom&quot;)Animal Tom init.&gt;&gt;&gt; c.eat()Cat is eating...&gt;&gt;&gt; c.play()Cat is playing... &gt;&gt;&gt; c.father()call father eat func:Animal is eating...call self eat func:Cat is eating...&gt;&gt;&gt; Cat.__mro__(__main__.Cat, __main__.Animal, object)&gt;&gt;&gt; isinstance(c,Cat)True&gt;&gt;&gt; isinstance(c,Animal)True</code></pre><p><strong>Sample2:多态</strong></p><pre><code class="lang-python">class Animal:    def eat():        print(&#39;Animal is eating...&#39;)class Cat(Animal):    def eat():        print(&quot;Cat is eating...&quot;)class Dog(Animal):    def eat():        print(&quot;Dog is eating...&quot;)def do_eat(obj):    obj.eat()&gt;&gt;&gt; do_eat(Animal())Animal is eating...&gt;&gt;&gt; do_eat(Cat())Cat is eating...&gt;&gt;&gt; do_eat(Dog())Dog is eating...</code></pre><h3 id="header-41">高阶：元类metaclass</h3><ul><li>类拥有创建实例对象的能力，而类本身也是对象，可动态地创建（Python是动态语言，函数和类，不是编译时定义的，而是运行时动态创建的）</li><li>元类即用来创建类的“东西”，实现方式：<ul><li>直接使用<code>type</code>元类</li><li>自定义一个元类：创建一个函数或类，使用<code>class</code>关键字或<code>type(...)</code>创建类</li></ul></li><li><code>type(object_or_name, bases, dict)</code>: Python内建的可以用来创建所有类的元类<ul><li>type(object) -&gt; the object’s type 查看某个对象的类型</li><li>type(name, bases, dict) -&gt; a new type 创建一个新的类型<ul><li>name: 类名，str</li><li>bases: 父类名，tuple</li><li>dict: 类属性，成员方法，dict</li></ul></li></ul></li><li><p><code>metaclass</code>/<code>__metaclass__</code>: 类定义时指定元类</p><pre><code class="lang-python">  # metaclass元类查找顺序：Foo -&gt; Bar -&gt; Module -&gt; type  # 1. python2写法:  class Foo(Bar):              __metaclass__=xxx      pass  # 2. python3写法:  class Foo(Bar,metaclass=xxx):      pass</code></pre><ul><li><code>metaclass=函数／类</code>，参数同<code>type</code>：name, bases, dict</li><li>应用：创建类时动态修改类定义（元类：拦截类的创建 -&gt; 修改类 -&gt; 返回修改之后的类）<ul><li>例如：ORM框架，一个类对应一个表，类／实例对象操作对应数据库表／记录操作</li></ul></li><li>Python会使用当前类中<code>metaclass</code>指定的元类创造类对象，没有则找父类的，父类没有则去模块层次中找，还找不到则用内置的<code>type</code>来创建这个类对象</li></ul></li></ul><p><strong>Sample1: 使用元类<code>type</code>创建类</strong></p><pre><code class="lang-python">def eat(self):    print(&#39;Cat is eating...&#39;)&gt;&gt;&gt; cls=type(&#39;Cat&#39;,(),{&#39;name&#39;:&#39;Cat&#39;,&#39;age&#39;:1,&#39;eat&#39;:eat})&gt;&gt;&gt; cls.name,cls.age(&#39;Cat&#39;,1)&gt;&gt;&gt; c=cls()&gt;&gt;&gt; c.name=&#39;Tom&#39;&gt;&gt;&gt; cls.name,c.name (&#39;Cat&#39;, &#39;Tom&#39;)&gt;&gt;&gt; c.eat()Cat is eating...</code></pre><p><strong>Sample2: 自定义一个函数作为元类来创建类</strong></p><pre><code class="lang-python"># 自定义一个函数，使用`class`关键字创建类（也可使用`type`创建类）def choose_animal(name):    if name==&#39;Cat&#39;:        class Cat:            def eat(self):                print(&quot;Cat is eating...&quot;)        return Cat    else:        class Animal:            def eat(self):                print(&#39;Animal is eating...&#39;)        return Animal&gt;&gt;&gt; cls=choose_animal(&#39;Cat&#39;)    # __main__.choose_animal.&lt;locals&gt;.Cat&gt;&gt;&gt; c=cls()                     # &lt;__main__.choose_animal.&lt;locals&gt;.Cat at 0x1050e7ac8&gt;&gt;&gt;&gt; c.eat()Cat is eating...</code></pre><p><strong>Sample3:通过<code>__metaclass__</code>属性指定元类，动态改变类定义</strong></p><pre><code class="lang-python"># 1. 自定义一个元类# 使用函数def animalMetaCls(clsName,bases,attrs):    print(&#39;call animalMetaCls&#39;,clsName)    if clsName==&#39;Cat&#39;:        def eat(self):            print(&#39;Cat is eating...&#39;)        attrs[&#39;eat&#39;]=eat        attrs[&#39;name&#39;]=&#39;Cat&#39;    return type(clsName,bases,attrs)# 或使用类class animalMetaCls:    def __new__(cls,clsName,bases,attrs):        print(&#39;call animalMetaCls&#39;,clsName)        if clsName==&#39;Cat&#39;:            def eat(self):                print(&#39;Cat is eating...&#39;)            attrs[&#39;eat&#39;]=eat            attrs[&#39;name&#39;]=&#39;Cat&#39;        return type(clsName,bases,attrs)# 2. 通过metaclass指定元类&gt;&gt;&gt; class Cat(metaclass=animalMetaCls):...     pass...call animalMetaCls Cat                 # 创建类时，就会触发metaclass# 3. verify:&gt;&gt;&gt; c=Cat()&gt;&gt;&gt; c.eat()Cat is eating...&gt;&gt;&gt; Cat.name&#39;Cat&#39;</code></pre><h3 id="header-42">高阶：枚举类Enum</h3><p>Refer <a href="https://docs.python.org/3/library/enum.html" target="_blank" rel="noopener">Doc</a></p><ul><li>可以把一组相关常量定义在一个class中，class不可变，成员可以等值比较</li><li><code>Enum(value, names=None, *, module=None, qualname=None, type=None, start=1)</code><ul><li>value: What the new Enum class will record as its name.</li><li>names: The Enum members. This can be a whitespace or comma separated string (values will start at 1 unless otherwise specified)<ul><li><code>&#39;RED GREEN BLUE&#39; | &#39;RED,GREEN,BLUE&#39; | &#39;RED, GREEN, BLUE&#39;</code></li><li><code>[&#39;RED&#39;, &#39;GREEN&#39;, &#39;BLUE&#39;]</code></li><li><code>[(&#39;CYAN&#39;, 4), (&#39;MAGENTA&#39;, 5), (&#39;YELLOW&#39;, 6)]</code></li><li><code>{&#39;CHARTREUSE&#39;: 7, &#39;SEA_GREEN&#39;: 11, &#39;ROSEMARY&#39;: 42}</code></li></ul></li><li>module: name of module where new Enum class can be found.</li><li>qualname: where in module new Enum class can be found.</li><li>type: type to mix in to new Enum class</li><li>start: number to start counting at if only names are passed i</li></ul></li><li>注：Enum的value属性是自动赋给成员的int常量，默认从1开始计数</li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python">from enum import Enum,auto# 1.创建枚举类对象# 法一：直接使用`Enum(变量统称名，(变量1，变量2....))`Month = Enum(&#39;Month&#39;, (&#39;Jan&#39;, &#39;Feb&#39;, &#39;Mar&#39;, &#39;Apr&#39;, &#39;May&#39;, &#39;Jun&#39;, &#39;Jul&#39;, &#39;Aug&#39;, &#39;Sep&#39;, &#39;Oct&#39;, &#39;Nov&#39;, &#39;Dec&#39;))# 法二：继承自Enum类@unique                     # optional: @unique装饰器--检查保证没有重复值class Month(Enum):    Jan=1    Feb=auto()    Mar=auto()    Apr=auto()    May=auto()    Jun=auto()    Jul=auto()    Aug=auto()    Sep=auto()    Oct=auto()    Nov=auto()    Dec=auto()# 2. test:&gt;&gt;&gt; Month&lt;enum &#39;Month&#39;&gt;&gt;&gt;&gt; type(Month)enum.EnumMeta&gt;&gt;&gt; Month.Feb                         # 枚举&lt;Month.Feb: 2&gt;&gt;&gt;&gt; type(Month.Feb)&lt;enum &#39;Month&#39;&gt;&gt;&gt;&gt; Month.Feb.name                     # 获取枚举名&#39;Feb&#39;&gt;&gt;&gt; Month.Feb.value                 # 获取枚举名2&gt;&gt;&gt; Month[&#39;Feb&#39;]                     # 获取枚举名为&#39;Feb&#39;的枚举，返回枚举类型&lt;Month.Feb: 2&gt; &gt;&gt;&gt; Month(2)                         # 获取枚举值为2的枚举，返回枚举类型&lt;Month.Feb: 2&gt;&gt;&gt;&gt; Month.Feb==Month.Feb             # 枚举等值比较（注：无法直接进行大小比较）True&gt;&gt;&gt; Month.Feb!=Month.JanTrue&gt;&gt;&gt; Month.Feb is Month.JanFalse&gt;&gt;&gt; for item in Month:                 # 遍历枚举，列出所有枚举成员...     print(item)Month.JanMonth.FebMonth.MarMonth.AprMonth.MayMonth.JunMonth.JulMonth.AugMonth.SepMonth.OctMonth.NovMonth.Dec&gt;&gt;&gt; list(Month)[&lt;Month.Jan: 1&gt;, &lt;Month.Feb: 2&gt;, &lt;Month.Mar: 3&gt;, &lt;Month.Apr: 4&gt;, &lt;Month.May: 5&gt;, &lt;Month.Jun: 6&gt;, &lt;Month.Jul: 7&gt;, &lt;Month.Aug: 8&gt;, &lt;Month.Sep: 9&gt;, &lt;Month.Oct: 10&gt;, &lt;Month.Nov: 11&gt;, &lt;Month.Dec: 12&gt;]&gt;&gt;&gt; Month.__members__                     # __members__mappingproxy({&#39;Jan&#39;: &lt;Month.Jan: 1&gt;,              &#39;Feb&#39;: &lt;Month.Feb: 2&gt;,              &#39;Mar&#39;: &lt;Month.Mar: 3&gt;,              &#39;Apr&#39;: &lt;Month.Apr: 4&gt;,              &#39;May&#39;: &lt;Month.May: 5&gt;,              &#39;Jun&#39;: &lt;Month.Jun: 6&gt;,              &#39;Jul&#39;: &lt;Month.Jul: 7&gt;,              &#39;Aug&#39;: &lt;Month.Aug: 8&gt;,              &#39;Sep&#39;: &lt;Month.Sep: 9&gt;,              &#39;Oct&#39;: &lt;Month.Oct: 10&gt;,              &#39;Nov&#39;: &lt;Month.Nov: 11&gt;,              &#39;Dec&#39;: &lt;Month.Dec: 12&gt;})&gt;&gt;&gt; Month.__members__.keys()Out[35]: odict_keys([&#39;Jan&#39;, &#39;Feb&#39;, &#39;Mar&#39;, &#39;Apr&#39;, &#39;May&#39;, &#39;Jun&#39;, &#39;Jul&#39;, &#39;Aug&#39;, &#39;Sep&#39;, &#39;Oct&#39;, &#39;Nov&#39;, &#39;Dec&#39;])&gt;&gt;&gt; Month.__members__.values()odict_values([&lt;Month.Jan: 1&gt;, &lt;Month.Feb: 2&gt;, &lt;Month.Mar: 3&gt;, &lt;Month.Apr: 4&gt;, &lt;Month.May: 5&gt;, &lt;Month.Jun: 6&gt;, &lt;Month.Jul: 7&gt;, &lt;Month.Aug: 8&gt;, &lt;Month.Sep: 9&gt;, &lt;Month.Oct: 10&gt;, &lt;Month.Nov: 11&gt;, &lt;Month.Dec: 12&gt;])&gt;&gt;&gt; Month.__members__.items()Out[5]: odict_items([(&#39;Jan&#39;, &lt;Month.Jan: 1&gt;), (&#39;Feb&#39;, &lt;Month.Feb: 2&gt;), (&#39;Mar&#39;, &lt;Month.Mar: 3&gt;), (&#39;Apr&#39;, &lt;Month.Apr: 4&gt;), (&#39;May&#39;, &lt;Month.May: 5&gt;), (&#39;Jun&#39;, &lt;Month.Jun: 6&gt;), (&#39;Jul&#39;, &lt;Month.Jul: 7&gt;), (&#39;Aug&#39;, &lt;Month.Aug: 8&gt;), (&#39;Sep&#39;, &lt;Month.Sep: 9&gt;), (&#39;Oct&#39;, &lt;Month.Oct: 10&gt;), (&#39;Nov&#39;, &lt;Month.Nov: 11&gt;), (&#39;Dec&#39;, &lt;Month.Dec: 12&gt;)])&gt;&gt;&gt; for name, member in Month.__members__.items():...    print(name, &#39;=&gt;&#39;, member, &#39;,&#39;, member.value)...Jan =&gt; Month.Jan , 1Feb =&gt; Month.Feb , 2Mar =&gt; Month.Mar , 3Apr =&gt; Month.Apr , 4May =&gt; Month.May , 5</code></pre><h3 id="header-43">高阶：单例模式</h3><p>Singleton 确保某一个类只有一个实例</p><pre><code class="lang-python">class Cat:    __instance=None    __first_init = True         # optional:用来保证只初始化一次    def __new__(cls,name,age):        if not cls.__instance:            cls.__instance=object.__new__(cls)        return cls.__instance    def __init__(self,name,age):        if self.__first_init:            print(&#39;init&#39;)            self.name=name            self.age=age            Cat.__first_init=False&gt;&gt;&gt; c1=Cat(&#39;Tom&#39;,2)init&gt;&gt;&gt; c2=Cat(&#39;Andy&#39;,3)&gt;&gt;&gt; c1==c2True&gt;&gt;&gt; id(c1),id(c2)(4559954776, 4559954776)&gt;&gt;&gt; c1.name,c2.name(&#39;Tom&#39;, &#39;Tom&#39;)</code></pre><p>实际<code>Enum</code>就是个单例：</p><pre><code class="lang-python">class Cat(Enum):    Instance=1&gt;&gt;&gt; c1=Cat.Instance&gt;&gt;&gt; c2=Cat.Instance&gt;&gt;&gt; c1==c2True&gt;&gt;&gt; id(c1),id(c2)(4560045560, 4560045560)&gt;&gt;&gt; c1.name,c2.name(&#39;Instance&#39;, &#39;Instance&#39;)&gt;&gt;&gt; c2.age=3&gt;&gt;&gt; c1.age,c2.age(3,3)</code></pre><h3 id="header-44">高阶：内置类属性</h3><p>可通过<code>dir(obj)</code>查看某对象的所有方法和属性，eg:</p><pre><code class="lang-python">class Cat:    def eat(self):        print(&#39;eating...&#39;)&gt;&gt;&gt; dir(Cat)[&#39;__class__&#39;, &#39;__delattr__&#39;, &#39;__dict__&#39;, &#39;__dir__&#39;, &#39;__doc__&#39;, &#39;__eq__&#39;, &#39;__format__&#39;, &#39;__ge__&#39;, &#39;__getattribute__&#39;, &#39;__gt__&#39;, &#39;__hash__&#39;, &#39;__init__&#39;, &#39;__init_subclass__&#39;, &#39;__le__&#39;, &#39;__lt__&#39;, &#39;__module__&#39;, &#39;__ne__&#39;, &#39;__new__&#39;, &#39;__reduce__&#39;, &#39;__reduce_ex__&#39;, &#39;__repr__&#39;, &#39;__setattr__&#39;, &#39;__sizeof__&#39;, &#39;__str__&#39;, &#39;__subclasshook__&#39;, &#39;__weakref__&#39;]</code></pre><p>一些常用的内置类属性和方法说明：</p><ul><li>方法：<ul><li><code>__new__</code> 创建实例时触发调用</li><li><code>__init__</code> 创建实例后触发调用</li><li><code>__str__</code> 返回用户看到的字符串，若没实现，使用repr结果，print时调用</li><li><code>__repr__</code> 返回程序开发者看到的字符串（为调试服务的），直接输出时调用</li><li><code>__getattribute__</code> 属性访问拦截器,触发访问实例属性时</li></ul></li><li>属性：<ul><li><code>__class__</code> 实例的类,触发方式:<code>实例.__class__</code></li><li><code>__doc__</code> 类文档,子类不继承,触发方式: <code>help(类或实例)</code></li><li><code>__module__</code> 类定义所在的模块</li><li><code>__dict__</code> 对象的属性字典</li></ul></li></ul><pre><code class="lang-python">class Cat:    age=1    def __new__(cls,name):                 # 要有一个参数cls，代表要实例化的类，此参数在实例化时由Python解释器自动提供        print(&#39;new Cat %s&#39; % name)        return object.__new__(cls)      # 返回实例化出来的实例    def __init__(self,name):             # 参数self，就是__new__返回的实例        self.name=name        print(&#39;%s init.&#39; % name)         def __del__(self):        print(&#39;%s del.&#39; % self.name)    def __str__(self):        return &quot;Cat [name=%s]&quot; % self.name    def __getattribute__(self,attr): # 注意：不要这个方法中调用self.xxxx，会进入死循环        print(&#39;get attr: %s&#39; % attr)        return object.__getattribute__(self,attr) &gt;&gt;&gt; c=Cat(&#39;Tom&#39;)         # 触发调用 __new__ =&gt; __init__new Cat TomTom init.&gt;&gt;&gt; c                     # 触发调用__repr__&lt;__main__.Cat at 0x104b83208&gt;&gt;&gt;&gt; print(c)             # 触发调用__str__Cat [name=Tom]&gt;&gt;&gt; c.name                 # 触发__getattribute__get attr: name&#39;tom&#39;&gt;&gt;&gt; c.__class____main__.Cat&gt;&gt;&gt; c.__dict__{&#39;name&#39;: &#39;Tom&#39;}&gt;&gt;&gt; del c                 # 触发调用__del__Tom del.</code></pre><h3 id="header-45">高阶：定制类</h3><p>定制类：通过在类中定义python内建的特殊方法<code>__xxx__</code>，可为类实现一些特殊的操作</p><p><strong>一些常见的python内建的特殊方法<code>__xxx__</code>：</strong></p><ul><li>基础方法:<ul><li><code>__new__(self[,arg1,…])</code>,<code>__init__(self[,arg1,…])</code>,<code>__del__(self)</code></li><li><code>__str__(self)</code> 可打印的字符串输出；内建 <code>str()</code> 及 <code>print()</code> 函数</li><li><code>__repr__(self)</code> 运行时的字符串输出；内建 <code>repr()</code> 函数及 <code>&#39; &#39;</code> 操作符</li><li><code>__len__(self)</code> 长度；内建 <code>len()</code></li><li><code>__nonezero__(self)</code> 为实例定义 False 值；内建 <code>bool()</code> 函数</li><li><code>__call__(self,*args)</code> 用于可调用的实例；可以用来替代闭包的实现</li></ul></li><li>值比较:<ul><li><code>__cmp__(self,obj)</code> 对象比较；内建 <code>cmp()</code></li><li><code>__lt__(self,obj)</code>,<code>__le__(self,obj)</code>  小于 &amp; 小于等于；内建<code>&lt;</code> &amp; <code>&lt;=</code></li><li><code>__gt__(self,obj)</code>,<code>__ge__(self,obj)</code>  大于 &amp; 大于等于；内建 <code>&gt;</code> &amp; <code>&gt;=</code></li><li><code>__eq__(self,obj)</code>,<code>__ne__(self,obj)</code>  等于 &amp; 不等于；内建 <code>=</code> &amp; <code>!=</code></li></ul></li><li>类的属性:<ul><li><code>__getattr/setattr/delattr__(self,attr)</code> 获取/设置/删除属性；注：<code>__getattr__</code>内建 <code>getattr()</code>，仅在属性没有找到时调用</li><li><code>__getattribute__(self,attr)</code> 获取属性；内建 <code>getattr()</code>；总是被调用</li><li><code>__get/set/delete__(self,attr)</code> （描述符）获取／设置／删除属性    </li></ul></li><li>数值类型：<ul><li><code>__complex__(self, com)</code> 内建 <code>complex()</code></li><li><code>__int__(self)</code>  内建 <code>int()</code></li><li><code>__float__(self)</code> 内建 <code>float()</code></li><li><code>__index__(self)</code> 在有必要时，压缩可选的数值类型为整型（比如用于切片索引时等）</li><li><code>__neg/pos/abs/invert__(self)</code> 一元负/一元正/绝对值/按位求反(内建 ~ 操作符)</li><li><code>__add/sub/mul/dev/mod/pow__(self,obj)</code> : <code>+,-,*,/,%,**</code></li><li><code>__lshift/rshift/and/or/xor__(self,obj)</code> : <code>&lt;&lt;,&gt;&gt;,&amp;,|,^</code></li></ul></li><li>序列类型:<ul><li><code>__len__(self)</code> 序列中的项目数</li><li><code>__getitem__(self, ind)</code>,<code>__setitem__(self, ind,val)</code>,<code>__delitem__(self, ind)</code> 获取／设置／删除元素</li><li><code>__getslice__(self, ind1,ind2)</code>,<code>__setslice__(self, i1, i2,val)</code>,<code>__delslice__(self, ind1,ind2)</code> 获取／设置/删除切片元素</li><li><code>__contains__(self, val)</code> 含有成员；内建 in 关键字</li><li><code>__*add__(self,obj)</code> 串联；<code>+</code> 操作符</li><li><code>__*mul__(self,obj)</code> 重复；<code>*</code>操作符</li><li><code>__iter__(self)</code> 生成迭代器；内建 <code>iter()</code> 函数</li></ul></li><li>映射类型：<ul><li><code>__len__(self)</code> 类中的项目数</li><li><code>__hash__(self)</code> 散列（hash）函数值</li><li><code>__getitem__(self,key)</code>,<code>__setitem__(self,key,val)</code>,<code>__delitem__(self,key)</code> 获取/设置/删除某个值</li><li><code>__missing__(self,key)</code>        给定键若不存在，则返回一个默认值</li></ul></li></ul><p><strong>Sample1:使用<code>__call__</code>实现：为可调用对象</strong></p><ul><li>使用了<code>__call__</code>后，对实例进行直接调用就好比对一个函数进行调用一样，<br>除了用<code>instance.method(...)</code>调用实例方法，可以直接对实例进行调用<code>instance(...)</code></li><li>能被调用的对象就是一个<code>Callable</code>对象通过<code>callable()</code>函数判断一个对象是否是“可调用”对象</li></ul><pre><code class="lang-python">class Cat:    def __init__(self,name):        self.name=&#39;Cat&#39;    def __call__(self):        print(&quot;I am %s.&quot; % self.name)    def eat(self):        print(&#39;%s is eating...&#39; % self.name)&gt;&gt;&gt; c=Cat(&#39;Tom&#39;)&gt;&gt;&gt; c()                 # 可直接对实例进行调用I am Cat.&gt;&gt;&gt; callable(c)True&gt;&gt;&gt; c.eat()Tom is eating...</code></pre><p><strong>Sample2:使用<code>__getattr__</code>实现：动态返回一个属性值</strong></p><p><code>__getattr__</code> 特性：</p><ul><li>获取属性，只有在没有找到属性的情况下，才调用</li><li>实现若不写返回值则表示返回None，不会再抛出AttributeError</li></ul><pre><code class="lang-python">class Cat:    def __init__(self,name):        self.name=&#39;Cat&#39;    def __getattr__(self,attr):        if attr==&#39;age&#39;:            return 0        elif attr==&#39;color&#39;:            return lambda:&#39;Red&#39;        #raise AttributeError(&#39;This object has no attribute \&#39;%s\&#39;&#39; % attr)        return &#39;N/A&#39;&gt;&gt;&gt; c=Cat(&#39;Tom&#39;)&gt;&gt;&gt; c.age0&gt;&gt;&gt; c.color()&#39;Red&#39;&gt;&gt;&gt; c.sex&#39;N/A&#39;&gt;&gt;&gt; c.country&#39;N/A&#39;</code></pre><p><strong>应用：链式调用组建path</strong></p><pre><code class="lang-python">class PathChain:    def __init__(self,path=&#39;&#39;):        self.path=path    def __getattr__(self,attr):        return PathChain(&#39;%s/%s&#39; % (self.path,attr))    def __str__(self):        return self.path    __repr__=__str__    def __call__(self,path):        return PathChain(&#39;%s/%s&#39; % (self.path,path))&gt;&gt;&gt; PathChain().users.roles/users/roles&gt;&gt;&gt; PathChain().users(&#39;Tom&#39;).roles/users/Tom/roles</code></pre><p><strong>Sample3:使用<code>__iter__</code>&amp;<code>__next__</code>实现迭代</strong></p><p><code>__iter__</code>返回一个迭代对象，for循环不断调用该迭代对象的<code>__next__</code>方法拿到循环的下一个值，直到遇到<code>StopIteration</code>错误时退出循环</p><pre><code class="lang-python"># f(n)=f(n-2)+f(n-1),f(0)=0,f(1)=1# a=f(n-2),b=f(n-1)# n: 0,1,2,3,4,5,6,7 ,8# v: 0,1,1,2,3,5,8,13,21class Fib:    def __init__(self,n):    # n&gt;=1        self.a,self.b=0,1        self.i,self.n=0,n    def __iter__(self):        return self    def __next__(self):        if self.i==0:            self.i+=1            return self.a        self.a,self.b=self.b,self.a+self.b        self.i+=1        if self.i &gt; self.n:            raise StopIteration()        return self.a&gt;&gt;&gt; for i in Fib(9):...     print(i) 01123581321&gt;&gt;&gt; list(Fib(9))[0, 1, 1, 2, 3, 5, 8, 13, 21]&gt;&gt;&gt; f=Fib(5)&gt;&gt;&gt; next(f)0&gt;&gt;&gt; next(f)1&gt;&gt;&gt; next(f)1&gt;&gt;&gt; next(f)2&gt;&gt;&gt; next(f)3&gt;&gt;&gt; next(f)StopIteration                             Traceback (most recent call last)&lt;ipython-input-34-aff1dd02a623&gt; in &lt;module&gt;----&gt; 1 next(f)...</code></pre><p><strong>Sample4:使用<code>__getitem__</code>实现按照下标／切片取出元素</strong></p><pre><code class="lang-python">class Fib(object):    def __getitem__(self, n):        if isinstance(n, int): # n是索引            a, b = 0, 1            for x in range(n):                a, b = b, a + b            return a        if isinstance(n, slice): # n是切片            a, b = 0, 1            start,stop = n.start or 0, n.stop            result = []            for x in range(stop):                if x&gt;=start:                    result.append(a)                a, b = b, a + b            return result&gt;&gt;&gt; f=Fib()&gt;&gt;&gt; f[0]&gt;&gt;&gt; f[8]21&gt;&gt;&gt; f[0:9]                             # [start,end)[0, 1, 1, 2, 3, 5, 8, 13,21]&gt;&gt;&gt; f[3:8][2, 3, 5, 8, 13]</code></pre><h2 id="header-46">模块与包</h2><h3 id="header-47">导入</h3><ol><li><p><code>import ... [as ...]</code></p><pre><code class="lang-python"> import math,time math.sqrt(2) time.sleep(3) import math as mt,time as tt mt.sqrt(2) tt.sleep(3)</code></pre></li><li><p><code>from ... import ...</code></p><pre><code class="lang-python"> from math import sqrt,pow sqrt(2) pow(2,3) from math import *     # 注：无法使用as重命名 sqrt(2) pow(2,3) from math import sqrt as st,pow as pw st(2) pw(2,3)</code></pre></li><li><p>模块定位顺序(存储在<code>system</code>模块的<code>sys.path</code>变量中):</p><pre><code class="lang-python"> &gt;&gt;&gt; import sys &gt;&gt;&gt; sys.path [&#39;&#39;, &#39;/anaconda3/lib/python37.zip&#39;, &#39;/anaconda3/lib/python3.7&#39;, &#39;/anaconda3/lib/python3.7/lib-dynload&#39;, &#39;/anaconda3/lib/python3.7/site-packages&#39;, &#39;/anaconda3/lib/python3.7/site-packages/aeosa&#39;]</code></pre><ul><li>从上面列出的目录里依次查找要导入的模块文件</li><li>搜索顺序：<ul><li>当前目录（上面<code>&#39;&#39;</code> 即表示当前目录）</li><li>shell变量<code>PYTHONPATH</code>下的每个目录</li><li>python安装路径</li></ul></li><li>添加搜索目录:<ul><li>法一：直接修改<code>sys.path</code>,动态添加，运行结束后就失效. eg: <code>sys.path.insert(0, xxx)</code> 可以确保先搜索xxx这个路径</li><li>法二：设置环境变量<code>PYTHONPATH</code></li></ul></li></ul></li><li><p>一个程序进程下，模块被导入后，<code>import...</code>/<code>from...import...</code> 并不能重新导入模块，重新导入需先<code>import importlib</code>，<code>importlib.reload(moduleName)</code></p><pre><code class="lang-bash"> # 1. initial: $ mkdir First $ vi First/hello.py def say():     print(&#39;say hello&#39;) # 2. run: $ python3 &gt;&gt;&gt; import First.hello &gt;&gt;&gt; First.hello.say() say hello # 3. update module function: $ vi First/hello.py def say():     print(&#39;say hello again&#39;) # 4. back to previous process,re-import and test: &gt;&gt;&gt; import First.hello &gt;&gt;&gt; First.hello.say()  say hello                     # no change! # 5. use importlib reload the module &gt;&gt;&gt; import importlib &gt;&gt;&gt; importlib.reload(First.hello) &gt;&gt;&gt; First.hello.say() say hello again             # changed!</code></pre></li></ol><h3 id="header-48">自定义库</h3><ol><li><p>库：包／模块 =&gt; 根目录：文件夹/文件 (命名空间隔离的执行者)</p><ul><li>包：文件夹，树状结构，可放入多个层级包／模块</li><li>模块：文件，一个python文件本身就可以作为一个Module导入，此时模块名＝文件名    </li></ul></li><li><p>包初始化文件：<code>__init__.py</code> =&gt; 代表可执行包（导入包时会执行它对应的<code>__init__.py</code>文件）</p><ul><li>暴露当前包对外的API，以控制这个包的导入行为</li><li>同module一样，导入时，此文件里的语句就会被执行: <ul><li>module =&gt; module.py(like: module/<strong>init</strong>.py)</li><li>package =&gt; package/<strong>init</strong>.py</li></ul></li><li>无此文件时，无法配置包的特殊变量<code>__all__</code>，则<code>import *</code>时无内容开放</li><li>注：只能控制此文件中的变量 &amp; 当前目录下的模块或包的开放（不包括子目录下内容的控制）</li></ul></li><li><p>特殊变量：</p><ul><li><code>__name__</code><ul><li>直接运行此<code>.py</code>时，此属性值=<code>&#39;__main__&#39;</code></li><li>以模块形式被导入时，此属性值=<code>&#39;文件名&#39;</code></li><li>可根据此变量的结果判断是直接执行的python脚本还是被引入执行的，从而能够有选择性的执行测试代码</li></ul></li><li>私有化变量：<code>_xxx</code>,<code>__xxx</code><ul><li>只对<code>import *</code>方式的导入有制约效果，对<code>import xxx</code>的导入无效</li></ul></li><li><code>__all__</code><ul><li>可设置<code>__all__=[&#39;..&#39;,&#39;..&#39;,...]</code>，列出可对外公开的内容（即外面可导入使用的内容）<ul><li>在<code>package/__init__.py</code>中，控制此package（一级）目录下开放的模块 &amp; 子包 &amp; package包本身init文件中定义的变量，即控制<code>package/*</code>内容的开放</li><li>在<code>module.py</code>中，控制此module下开放的变量（此module.py可看做是module的<code>__init__.py</code>),即控制<code>module/*</code>内容的开放</li></ul></li><li>只对<code>import *</code>方式的导入有用，对<code>import xxx</code>的导入无效</li><li>配置的优先级高于私有化变量，即配置后，私有化变量<code>_xxx</code>,<code>__xxx</code>的制约效果无效了，只受<code>__all__</code>约束</li></ul></li></ul></li><li><p>导入: </p><ul><li>导入时使用<code>.</code>表路径层级,eg:<code>p1/p2/hello.py</code><ul><li>导入包：<code>import p1</code>,<code>import p1.p2</code></li><li>导入模块： <code>import p1.p2.hello</code>,<code>from p1.p2 import hello</code></li><li>导入模块中的变量：<code>from p1.p2.hello import v1,v2,...</code></li><li>导入包下一级开放内容：<code>from p1 import *</code></li><li>导入模块中开放内容：<code>from p1.p2.hello import *</code></li><li>可混合导入包和模块</li><li>注：不可以<code>from p1 import p2.hello</code></li></ul></li><li>导入时就会依次执行对应的<code>.py</code>文件<ul><li><code>import path</code>: <ul><li>step: 沿路径搜索，并沿途执行初始化(即执行<code>path</code>经过的包<code>__init__.py</code>&amp; 模块<code>module.py</code>)，导入所有变量</li><li>止于此<code>path</code>，会执行<code>path/__init__.py</code> or <code>path.py</code>,<code>__all__</code>配置不会起作用（因为并未导入<code>path/*.py</code>）</li></ul></li><li><code>from path import *</code>: <ul><li>step1: <code>from path</code> =&gt; 沿路径搜索，并沿途执行初始化（即执行<code>path</code>经过的包<code>__init__.py</code> &amp; 模块<code>module.py</code>），但不会导入这些变量</li><li>step2: <code>import *</code> =&gt; 执行<code>path/*</code>下直属py文件并导入变量<ul><li><code>path/__init__.py</code>先执行，会根据其中定义的<code>__all__</code>控制可导入变量；</li><li>若path代表的是module,则<code>module.py</code>即相当于它的<code>__init__.py</code></li></ul></li><li>止于<code>path/*</code>，会执行<code>path/*.py</code>,根据<code>path/__init__.py</code>中配置的<code>__all__</code>导入变量</li></ul></li></ul></li><li>总结: <ul><li><code>import</code>部分导入变量，<code>from</code>部分不导入变量;</li><li><code>path</code>：代表到此文件（包或模块）,<code>*</code>：代表<code>path/*.py</code>（受<code>path/__init__.py</code>中<code>__all__</code>限制）</li></ul></li><li>eg: <code>import path</code><ul><li>导入包：<code>import First.sub</code> =&gt; import first initial vars + sub initial vars</li><li>导入包：<code>from First import sub</code> =&gt; import sub initial vars</li><li>导入模块：<code>from First import hello</code> =&gt; import hello initial vars</li><li>导入模块：<code>import First.hello</code> =&gt; import first initial vars + hello initial vars</li><li>导入变量：<code>from First.hello import A,_B,__C,Cat</code> =&gt; import A,_B,__C,Cat</li></ul></li><li>eg: <code>from path import *</code>    <ul><li>导入包：<code>from First import *</code> =&gt; depends on the <code>__all__</code> in first initial py: <code>[&#39;hello&#39;,&#39;MCount&#39;,&#39;sub&#39;]</code> =&gt;  first opened initial vars: <code>MCount</code> + hello initial vars: <code>hello.*</code> + sub initial vars <code>sub.*</code></li><li>导入包：<code>from First.sub import *</code> =&gt; depends on the <code>__all__</code> in first initial py: <code>[&#39;aa&#39;]</code> =&gt; aa initial vars</li><li>导入变量：<code>from First.hello import *</code> =&gt; depends on the <code>__all__</code> in <code>hello.py</code>: <code>[&#39;A&#39;,&#39;__C&#39;,&#39;Cat&#39;]</code> =&gt; hello opened initial vars:<code>A</code>,<code>__C</code>,<code>Cat</code></li><li>注：无法使用<code>from First import sub.aa</code>，<code>from First import sub.*</code></li></ul></li></ul></li></ol><p><strong>Sample:</strong></p><pre><code class="lang-bash">First├── __init__.py             # __all__=[&#39;hello&#39;,&#39;MCount&#39;,&#39;sub&#39;]│                              # MCount=2,MNum=3│├── hello.py                 # __all__=[&#39;A&#39;,&#39;__C&#39;,&#39;Cat&#39;]│                              # A=[1,2,3],_B=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;],__C=(&#39;Hello&#39;,&#39;Tom&#39;)│                              # def say():..., class Cat: ...├── world.py│ ├── sub│   ├── __init__.py         # __all__=[&#39;aa&#39;],sub_var=1│   ├── aa.py                 # colorA=&#39;Red&#39;│   └── bb.py                 # colorB=&#39;Green&#39;</code></pre><ol><li><p>单独测试某个模块的功能（使用<code>__name__</code>区分状态）</p><pre><code class="lang-bash"> $ cat First/hello.py print(&#39;hello.py init&#39;) __all__=[&#39;A&#39;,&#39;__C&#39;,&#39;Cat&#39;] A=[1,2,3] _B=[&#39;a&#39;,&#39;b&#39;,&#39;c&#39;] __C=(&#39;Hello&#39;,&#39;Tom&#39;) def say():     print(&#39;say hello again&#39;) class Cat:     def eat(self):         print(&#39;Cat is eating...&#39;) if __name__ == &#39;__main__&#39;:     # do test:     say()     c=Cat()     c.eat() # 单独测试验证hello.py功能： $ python3 First/hello.py hello.py init A=[1, 2, 3],_B=[&#39;a&#39;, &#39;b&#39;, &#39;c&#39;],__C=(&#39;Hello&#39;, &#39;Tom&#39;) say hello again Cat is eating...</code></pre></li><li><p>使用<code>import xxx</code> =&gt; 不受<code>xxx</code>的<code>__all__</code>控制</p><ul><li>xxx最终为包 <code>import First</code>,<code>import First.sub</code><pre><code class="lang-python">  &gt;&gt;&gt; import First             # 会执行First的__init__.py，导入其中所有变量  First package init.  &gt;&gt;&gt; dir()  [&#39;First&#39;, &#39;__annotations__&#39;, &#39;__builtins__&#39;, &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;]  &gt;&gt;&gt; dir(First)  [&#39;MCount&#39;, &#39;MNum&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;]</code></pre><pre><code class="lang-python">  &gt;&gt;&gt; import First.sub         # 会执行First的__init__.py &amp; sub的__init__.py，导入其中所有变量  First package init.  sub package init.  &gt;&gt;&gt; dir()  [&#39;First&#39;, &#39;__annotations__&#39;, &#39;__builtins__&#39;, &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;]  &gt;&gt;&gt; dir(First)  [&#39;MCount&#39;, &#39;MNum&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;sub&#39;]  &gt;&gt;&gt; dir(First.sub)  [&#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;sub_var&#39;]</code></pre></li><li>xxx最终为模块 <code>import First.hello</code>,<code>from First import hello</code><pre><code class="lang-python">  &gt;&gt;&gt; import First.hello         # 会执行 First的__init__.py &amp; hello.py，导入其中所有变量  First package init.  hello.py init  &gt;&gt;&gt; dir()  [&#39;First&#39;, &#39;__annotations__&#39;, &#39;__builtins__&#39;, &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;]  &gt;&gt;&gt; dir(First)  [&#39;MCount&#39;, &#39;MNum&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;hello&#39;]  &gt;&gt;&gt; dir(First.hello)  [&#39;A&#39;, &#39;Cat&#39;, &#39;_B&#39;, &#39;__C&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;say&#39;]</code></pre><pre><code class="lang-python">  &gt;&gt;&gt; from First import hello # 执行hello.py，导入其中所有变量  First package init.  hello.py init  &gt;&gt;&gt; dir()  [&#39;__annotations__&#39;, &#39;__builtins__&#39;, &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;hello&#39;]  &gt;&gt;&gt; dir(hello)  [&#39;A&#39;, &#39;Cat&#39;, &#39;_B&#39;, &#39;__C&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;say&#39;]</code></pre></li><li>xxx最终为变量 <code>from First.hello import A,_B,__C,say,Cat</code><pre><code class="lang-python">  &gt;&gt;&gt; from First.hello import A,_B,__C,say,Cat  First package init.  hello.py init  &gt;&gt;&gt; dir()  [&#39;A&#39;, &#39;Cat&#39;, &#39;_B&#39;, &#39;__C&#39;, &#39;__annotations__&#39;, &#39;__builtins__&#39;, &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;say&#39;]</code></pre></li></ul></li><li><p>使用<code>from xxx import *</code> =&gt; 受<code>xxx/__init__.py</code>中<code>__all__</code>的控制</p><ul><li>xxx为包 <code>from First import *</code>，<code>from First.sub import *</code><pre><code class="lang-python">  &gt;&gt;&gt; from First import *         # = from First import hello,sub  First package init.  hello.py init  sub package init.  &gt;&gt;&gt; dir()                         # 受First/__init__.py 中`__all__`控制  [&#39;MCount&#39;, &#39;__annotations__&#39;, &#39;__builtins__&#39;, &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;hello&#39;, &#39;sub&#39;]  &gt;&gt;&gt; dir(hello)                     # 不受hello.py 中`__all__`控制  [&#39;A&#39;, &#39;Cat&#39;, &#39;_B&#39;, &#39;__C&#39;, &#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;say&#39;]  &gt;&gt;&gt; dir(sub)                # 不受sub/__init__.py 中`__all__`控制  [&#39;__all__&#39;, &#39;__builtins__&#39;, &#39;__cached__&#39;, &#39;__doc__&#39;, &#39;__file__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__path__&#39;, &#39;__spec__&#39;, &#39;sub_var&#39;]</code></pre><pre><code class="lang-python">  &gt;&gt;&gt; from First.sub import *       First package init.  sub package init.  sub/aa.py init.  &gt;&gt;&gt; dir()                         # 受sub/__init__.py 中`__all__`控制  [&#39;__annotations__&#39;, &#39;__builtins__&#39;, &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;aa&#39;]</code></pre></li><li>xxx为模块 <code>from First.hello import *</code><pre><code class="lang-python">  &gt;&gt;&gt; from First.hello import *     # = from First.hello import A,Cat,__C  First package init.  hello.py init  &gt;&gt;&gt; dir()                         # 受hello.py 中`__all__`控制  [&#39;A&#39;, &#39;Cat&#39;, &#39;__C&#39;, &#39;__annotations__&#39;, &#39;__builtins__&#39;, &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;]</code></pre></li></ul></li></ol><h3 id="header-49">发布/安装包</h3><ul><li>发布：<ul><li>编辑<code>setup.py</code>文件</li><li>构建模块 <code>python setup.py build</code></li><li>生成发布压缩包 <code>python setup.py sdist</code></li></ul></li><li>安装：<ul><li>解压获得的压缩包</li><li>进入文件夹，执行<code>python setup.py install</code> (可加参数指定安装路径：<code>--prefix=安装路径</code>)</li></ul></li><li>使用：<code>from ... import ...</code>，<code>import package.module</code> 导入</li></ul><p><strong>Sample:</strong></p><pre><code class="lang-bash">Second├── setup.py├── subA│   ├── __init__.py│   ├── aa.py│   └── bb.py└── subB    ├── __init__.py    ├── cc.py    └── dd.py</code></pre><p>发布：</p><pre><code class="lang-bash"># 1. setup.py:$ cd Second$ vi setup.pyfrom distutils.core import setupsetup(name=&quot;SecondPkg&quot;,     version=&quot;1.0&quot;,     description=&quot;Second module&quot;,     author=&quot;dongGe&quot;,     py_modules=[&#39;subA.aa&#39;, &#39;subA.bb&#39;, &#39;subB.cc&#39;,&#39;subB.dd&#39;])     # py_modules 需指明所需包含的py文件# 2. build: 构建 (发布的包下一定要有`__init__.py`文件，不然会build失败)$ python setup.py buildrunning buildrunning build_pycopying subA/__init__.py -&gt; build/lib/subAcopying subB/__init__.py -&gt; build/lib/subB# 3. 查看（实际就是copy了一份到`build/lib`下）$ tree.├── build│   └── lib│       ├── subA│       │   ├── __init__.py│       │   ├── aa.py│       │   └── bb.py│       └── subB│           ├── __init__.py│           ├── cc.py│           └── dd.py├── setup.py├── subA│   ├── __init__.py│   ├── aa.py│   └── bb.py└── subB    ├── __init__.py    ├── cc.py    └── dd.py# 4. sdist: 生成发布压缩包 (产生`MANIFEST`文件，`dist/SecondPkg-1.0.tar.gz`压缩包)$ python setup.py sdist$ tree.├── MANIFEST├── build│   └── lib│       ├── subA│       │   ├── __init__.py│       │   ├── aa.py│       │   └── bb.py│       └── subB│           ├── __init__.py│           ├── cc.py│           └── dd.py├── dist│   └── SecondPkg-1.0.tar.gz├── setup.py├── subA│   ├── __init__.py│   ├── aa.py│   └── bb.py└── subB    ├── __init__.py    ├── cc.py    └── dd.py</code></pre><p>安装：</p><pre><code class="lang-bash"># 1. 解压$ tar -xvf SecondPkg-1.0.tar.gz# 2. 进入文件夹$ cd SecondPkg-1.0$ tree.├── PKG-INFO├── setup.py├── subA│   ├── __init__.py│   ├── aa.py│   └── bb.py└── subB    ├── __init__.py    ├── cc.py    └── dd.py# 3. 安装$ python setup.py install...creating /anaconda3/lib/python3.7/site-packages/subA...creating /anaconda3/lib/python3.7/site-packages/subB...running install_egg_infoWriting /anaconda3/lib/python3.7/site-packages/SecondPkg-1.0-py3.7.egg-info# 4. 查看安装的包$ pip list | grep SecondSecondPkg                          1.0# 5. 使用$ cd ~/space$ python3# 导入包：&gt;&gt;&gt; from subB import *             # 注意：不要使用 `import subA,subB` -- 不会导入包下的任何模块subB init.This subB/cc.pyThis subB/dd.py&gt;&gt;&gt; dir()[&#39;__annotations__&#39;, &#39;__builtins__&#39;, &#39;__doc__&#39;, &#39;__loader__&#39;, &#39;__name__&#39;, &#39;__package__&#39;, &#39;__spec__&#39;, &#39;cc&#39;, &#39;dd&#39;]# 导入模块：&gt;&gt;&gt; from subA.aa import *  # 或 `from subA import aa` 或 `import subA.aa`subA init.This subA/aa.py</code></pre><h3 id="header-50">常用标准库</h3><p>Python的一个组成部分，随着Python解释器，一起安装在电脑中的</p><table class="table"><thead><tr><th style="text-align:left">标准库</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">builtins</td><td style="text-align:left">内建函数默认加载</td></tr><tr><td style="text-align:left">os</td><td style="text-align:left">操作系统接口</td></tr><tr><td style="text-align:left">sys</td><td style="text-align:left">Python自身的运行环境</td></tr><tr><td style="text-align:left">functools</td><td style="text-align:left">常用的工具</td></tr><tr><td style="text-align:left">json</td><td style="text-align:left">编码和解码JSON对象</td></tr><tr><td style="text-align:left">logging</td><td style="text-align:left">记录日志，调试</td></tr><tr><td style="text-align:left">multiprocessing</td><td style="text-align:left">多进程</td></tr><tr><td style="text-align:left">threading</td><td style="text-align:left">多线程</td></tr><tr><td style="text-align:left">copy</td><td style="text-align:left">拷贝</td></tr><tr><td style="text-align:left">time</td><td style="text-align:left">时间</td></tr><tr><td style="text-align:left">datetime</td><td style="text-align:left">日期和时间</td></tr><tr><td style="text-align:left">calendar</td><td style="text-align:left">日历</td></tr><tr><td style="text-align:left">hashlib</td><td style="text-align:left">加密算法</td></tr><tr><td style="text-align:left">random</td><td style="text-align:left">生成随机数</td></tr><tr><td style="text-align:left">re</td><td style="text-align:left">字符串正则匹配</td></tr><tr><td style="text-align:left">socket</td><td style="text-align:left">标准的 BSD Sockets API</td></tr><tr><td style="text-align:left">shutil</td><td style="text-align:left">文件和目录管理</td></tr><tr><td style="text-align:left">glob</td><td style="text-align:left">基于文件通配符搜索</td></tr><tr><td style="text-align:left">collections</td><td style="text-align:left">一个集合模块，提供了许多有用的集合类</td></tr></tbody></table><p><strong>Sample:datetime</strong></p><pre><code class="lang-python">&gt;&gt;&gt; from datetime import datetime&gt;&gt;&gt; datetime.now()                         # 1. 获取当前datetimedatetime.datetime(2019, 3, 17, 11, 58, 22, 874984)&gt;&gt;&gt; type(datetime.now())&lt;class &#39;datetime.datetime&#39;&gt;&gt;&gt;&gt; dt=datetime(2018, 5, 19, 13, 10)     # 2. 指定某个日期和时间的datetime&gt;&gt;&gt; print(dt)2018-05-19 13:10:00&gt;&gt;&gt; ts=dt.timestamp()                     # 3.1: datetime -&gt; timestamp&gt;&gt;&gt; ts1526706600.0&gt;&gt;&gt; datetime.fromtimestamp(ts)             # 3.2: timestamp -&gt; datetime 本地时间datetime.datetime(2018, 5, 19, 13, 10)&gt;&gt;&gt; datetime.utcfromtimestamp(ts)         # 3.2: timestamp -&gt; datetime UTC时间datetime.datetime(2018, 5, 19, 5, 10)&gt;&gt;&gt; dt.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;)     # 4.1: datetime -&gt; str&#39;2018-05-19 13:10:00&#39;&gt;&gt;&gt; str(dt)&#39;2018-05-19 13:10:00&#39;&gt;&gt;&gt; datetime.strptime(&#39;2018-05-19 13:10:00&#39;,&#39;%Y-%m-%d %H:%M:%S&#39;)     # 4.2: str -&gt; datetimedatetime.datetime(2018, 5, 19, 13, 10)&gt;&gt;&gt; from datetime import timedelta         # 5. datetime +/-&gt;&gt;&gt; dt+timedelta(hours=10)datetime.datetime(2018, 5, 19, 23, 10)&gt;&gt;&gt; dt-timedelta(days=2, hours=12)datetime.datetime(2018, 5, 17, 1, 10)&gt;&gt;&gt; from datetime import timezone                     # 6. 时区转换&gt;&gt;&gt; dt_utc=dt.replace(tzinfo=timezone.utc)            # 6.1 强制设置为utc时区，作为基准时间&gt;&gt;&gt; dt_utcdatetime.datetime(2018, 5, 19, 13, 10, tzinfo=datetime.timezone.utc)&gt;&gt;&gt; print(dt_utc)2018-05-19 13:10:00+00:00&gt;&gt;&gt; dt_utc.astimezone(timezone(timedelta(hours=8))) # 转换北京时区(UTC+8)datetime.datetime(2018, 5, 19, 21, 10, tzinfo=datetime.timezone(datetime.timedelta(seconds=28800)))&gt;&gt;&gt; dt_utc.astimezone(timezone(timedelta(hours=9))) # 转换东京时区(UTC+9)datetime.datetime(2018, 5, 19, 22, 10, tzinfo=datetime.timezone(datetime.timedelta(seconds=32400)))&gt;&gt;&gt; dt_bj=dt_utc.astimezone(timezone(timedelta(hours=8)))&gt;&gt;&gt; dt_bj.astimezone(timezone(timedelta(hours=9)))    # 北京时间转换为东京时间(UTC+9)datetime.datetime(2018, 5, 19, 22, 10, tzinfo=datetime.timezone(datetime.timedelta(seconds=32400)))</code></pre><ul><li><code>datetime</code>表示的时间需要时区信息才能确定一个特定的时间，默认视为本地时区时间</li><li>时区转换: 确定一个<code>datetime</code>的时区（可强制设置时区，作为基准时间），利用带时区的<code>datetime</code>，通过<code>astimezone()</code>方法，可以转换到任意时区</li><li>存储<code>datetime</code>，最佳方法是将其转换为<code>timestamp</code>再存储，因为<code>timestamp</code>的值与时区完全无关</li></ul><p><strong>Sample:Collections</strong></p><ul><li>namedtuple : tuple子类，可用属性而不是索引来引用tuple的元素</li><li>deque : 双向列表（list是线性存储，数据量大时，插入和删除效率低），注：不是list子类</li><li>defaultdict : dict子类，key不存在时，不会报错而是返回一个默认值</li><li>OrderedDict : dict子类，Key会按照插入的顺序排列 （应用：可用来实现一个FIFO（先进先出）的dict，当容量超出限制时，先删除最早添加的Key）</li><li>ChainMap : 把一组dict串起来并组成一个逻辑上的dict，查找时按顺序在内部的dict中依次查找（应用：可用来实现参数的优先级查找），注：不是dict子类</li><li>Counter: dict子类，可实现一个简单的计数器</li></ul><pre><code class="lang-python"># 1. namedtuple&gt;&gt;&gt; from collections import namedtuple&gt;&gt;&gt; Point = namedtuple(&#39;Point&#39;, [&#39;x&#39;, &#39;y&#39;])&gt;&gt;&gt; p = Point(1, 2)&gt;&gt;&gt; pPoint(x=1, y=2)&gt;&gt;&gt; p.x,p.y                         # 可用属性访问(1, 2)&gt;&gt;&gt; isinstance(p, Point),isinstance(p, tuple)(True, True)# 2. deque&gt;&gt;&gt; from collections import deque&gt;&gt;&gt; q = deque([&#39;a&#39;, &#39;b&#39;, &#39;c&#39;])&gt;&gt;&gt; q.append(&#39;x&#39;)                     # append(),pop()&gt;&gt;&gt; q.appendleft(&#39;y&#39;)                 # appendleft(),popleft()&gt;&gt;&gt; qdeque([&#39;y&#39;, &#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;x&#39;])&gt;&gt;&gt; isinstance(q,list)False# 3. defaultdict&gt;&gt;&gt; from collections import defaultdict&gt;&gt;&gt; d = defaultdict(lambda: &#39;N/A&#39;)&gt;&gt;&gt; d[&#39;a&#39;] = 123&gt;&gt;&gt; d[&#39;a&#39;]123&gt;&gt;&gt; d[&#39;b&#39;]                         # 访问存在key,返回设置的默认值，不会报错&#39;N/A&#39;&gt;&gt;&gt; isinstance(d,dict)True# 4. ChainMap&gt;&gt;&gt; from collections import ChainMap&gt;&gt;&gt; m=ChainMap({&#39;a&#39;:1,&#39;b&#39;:2},{&#39;b&#39;:3,&#39;c&#39;:4})&gt;&gt;&gt; m[&#39;a&#39;],m[&#39;b&#39;],m[&#39;c&#39;](1, 2, 4)&gt;&gt;&gt; isinstance(m,dict)False# 5. Counter&gt;&gt;&gt; from collections import Counter&gt;&gt;&gt; c = Counter()&gt;&gt;&gt; for i in &#39;programming&#39;:     # 统计字符出现的个数，效果同：c={},c[i]=c.get(i,0)+1...  c[i] += 1...&gt;&gt;&gt; cCounter({&#39;r&#39;: 2, &#39;g&#39;: 2, &#39;m&#39;: 2, &#39;p&#39;: 1, &#39;o&#39;: 1, &#39;a&#39;: 1, &#39;i&#39;: 1, &#39;n&#39;: 1})&gt;&gt;&gt; isinstance(c,dict)True</code></pre><p><strong>Sample:hashlib</strong></p><pre><code class="lang-python">&gt;&gt;&gt; import hashlib&gt;&gt;&gt; m=hashlib.md5()&gt;&gt;&gt; m.update(b&#39;Hello&#39;)&gt;&gt;&gt; m.hexdigest()&#39;8b1a9953c4611296a827abf8c47804d7&#39;</code></pre><h3 id="header-51">常用扩展库</h3><table class="table"><thead><tr><th style="text-align:left">扩展库</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">requests</td><td style="text-align:left">使用的是urllib3，继承了urllib2的所有特性</td></tr><tr><td style="text-align:left">urllib</td><td style="text-align:left">基于http的高层库</td></tr><tr><td style="text-align:left">scrapy</td><td style="text-align:left">爬虫</td></tr><tr><td style="text-align:left">beautifulsoup4</td><td style="text-align:left">HTML/XML的解析器</td></tr><tr><td style="text-align:left">celery</td><td style="text-align:left">分布式任务调度模块</td></tr><tr><td style="text-align:left">redis</td><td style="text-align:left">缓存</td></tr><tr><td style="text-align:left">Pillow(PIL)</td><td style="text-align:left">图像处理</td></tr><tr><td style="text-align:left">xlsxwriter</td><td style="text-align:left">仅写excle功能,支持xlsx</td></tr><tr><td style="text-align:left">xlwt</td><td style="text-align:left">仅写excle功能,支持xls ,2013或更早版office</td></tr><tr><td style="text-align:left">xlrd</td><td style="text-align:left">仅读excle功能</td></tr><tr><td style="text-align:left">elasticsearch</td><td style="text-align:left">全文搜索引擎</td></tr><tr><td style="text-align:left">pymysql</td><td style="text-align:left">数据库连接库</td></tr><tr><td style="text-align:left">mongoengine/pymongo</td><td style="text-align:left">mongodbpython接口</td></tr><tr><td style="text-align:left">matplotlib</td><td style="text-align:left">画图</td></tr><tr><td style="text-align:left">numpy/scipy</td><td style="text-align:left">科学计算</td></tr><tr><td style="text-align:left">django/tornado/flask</td><td style="text-align:left">web框架</td></tr><tr><td style="text-align:left">xmltodict</td><td style="text-align:left">xml转dict</td></tr><tr><td style="text-align:left">SimpleHTTPServer</td><td style="text-align:left">简单地HTTP Server,不使用Web框架</td></tr><tr><td style="text-align:left">gevent</td><td style="text-align:left">基于协程的Python网络库</td></tr><tr><td style="text-align:left">fabric</td><td style="text-align:left">系统管理</td></tr><tr><td style="text-align:left">pandas</td><td style="text-align:left">数据处理库</td></tr><tr><td style="text-align:left">scikit-learn</td><td style="text-align:left">机器学习库</td></tr></tbody></table><p><strong>Sample:SimpleHTTPServer</strong></p><ol><li>运行一个静态（目录）服务器<pre><code class="lang-bash"> $ cd Second $ python -m http.server 8000 Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...</code></pre></li><li>visit <code>http://localhost:8000</code> 就可以看到列出了当前目录的页面，可方便的查看文件<pre><code class="lang-bash"> $ curl http://localhost:8000 &lt;!DOCTYPE HTML PUBLIC &quot;-//W3C//DTD HTML 4.01//EN&quot; &quot;http://www.w3.org/TR/html4/strict.dtd&quot;&gt; &lt;html&gt; &lt;head&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=utf-8&quot;&gt; &lt;title&gt;Directory listing for /&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;Directory listing for /&lt;/h1&gt; &lt;hr&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;build/&quot;&gt;build/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;dist/&quot;&gt;dist/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;MANIFEST&quot;&gt;MANIFEST&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;setup.py&quot;&gt;setup.py&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;subA/&quot;&gt;subA/&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;subB/&quot;&gt;subB/&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;hr&gt; &lt;/body&gt; &lt;/html&gt;</code></pre></li></ol><h2 id="header-52">文件IO</h2><h3 id="header-53">读写文件</h3><ul><li>打开文件：<code>f=open(filename,mode=&#39;r&#39;,encoding=None)</code></li><li>关闭文件：<code>f.close()</code></li><li>用<code>with</code>语句包裹打开文件，不管是否异常，自动关闭文件，更保险（或使用<code>try...finally</code>）</li><li>读：<ul><li><code>content=f.read(128)</code> =&gt; str</li><li><code>content=f.readline()</code> =&gt; str</li><li><code>content=f.readlines()</code> =&gt; list</li></ul></li><li>写：<ul><li><code>f.write(&#39;...&#39;)</code> =&gt; int: length</li><li><code>f.writelines(...)</code></li><li><code>f.flush()</code> 缓冲区内容刷新到文件中</li></ul></li><li>查看当前位置：<code>position = f.tell()</code></li><li>定位到某个位置：<code>f.seek(offset, from)</code>  <ul><li>offset: 偏移量</li><li>from: 0 文件开头/ 1 当前位置 / 2 文件末尾</li><li>eg: <code>f.seek(2, 1)</code>: 从头开始，偏移2个字节; <code>f.seek(-3,2)</code>: 离文件末尾，3字节处</li></ul></li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python"># 写f = open(&#39;test.txt&#39;, &#39;w&#39;)      # 追加可用af.write(&#39;hello world, i am here!&#39;)f.close()# 读f = open(&#39;test.txt&#39;, &#39;r&#39;)content = f.read(128) # content = f.readline(),contentlst = f.readlines()position = f.tell()f.close()# 使用with语句，会自动关闭with open(&#39;test.txt&#39;, &#39;w&#39;) as f    f.write(&#39;Hello world&#39;)</code></pre><h3 id="header-54">操作文件／目录</h3><ul><li><code>import os</code>,<code>import shutil</code>(可以看做是os模块的补充，有更多方便的操作命令)</li><li>系统相关：<ul><li><code>os.name</code> 查看操作系统类型（posix：Linux、Unix或Mac OS X；nt：Windows）</li><li><code>os.uname()</code> 获取详细的系统信息（Windows上不提供）</li><li><code>os.environ</code> 获取环境变量（dict,os.environ.get(‘PATH’)）</li></ul></li><li>路径相关：<code>os.path</code><ul><li>查看绝对路径 <code>os.path.abspath(path)</code></li><li>合成路径 <code>os.path.join(p1,p2,...)</code></li><li>拆分路径 <code>os.path.split(path)</code></li><li>文件扩展名 <code>os.path.splitext(path)</code></li><li>是否是文件 <code>os.path.isfile(x)</code></li><li>是否是文件夹 <code>os.path.isdir(x)</code><br>－ 操作文件/文件夹：</li><li>获取当前路径 <code>os.getcwd()</code></li><li>改变当前路径 <code>os.chdir(path)</code></li><li>列出文件／文件夹(<code>ls</code>) <code>os.listdir(path)</code></li><li>创建文件夹 <code>os.mkdir(dir)</code></li><li>删除空文件夹 <code>os.rmdir(dir)</code></li><li>重命名／移动文件／文件夹（<code>mv</code>） <code>os.rename(src,dist)</code></li><li>删除文件 <code>os.remove(file)</code></li><li>拷贝文件：<code>shutil.copyfile(src,dist)</code></li></ul></li></ul><h2 id="header-55">多任务</h2><ol><li><p>同步(Sync) &amp; 异步(Async)：消息通知机制</p><ul><li>同步：主动等</li><li>异步：被动听</li></ul></li><li><p>阻塞(Blocking) &amp; 非阻塞(UnBlocking)：等待消息通知时的调用者状态</p><ul><li>阻塞：等待 （one thread do one task)</li><li>非阻塞：继续做其他事 (one thread do many tasks,高吞吐量)</li></ul></li><li><p>并发(Concurrent) &amp; 并行 (Parallel)：多任务处理能力</p><ul><li>并发：交替运行</li><li>并行：同时运行</li></ul></li><li><p>进程(Process) &amp; 线程(Thread)：多任务处理手段</p><ul><li>进程：独立地址空间，进程间独立运行（eg: 多核CPU，并行运行）</li><li>线程：进程内，多线程共享同一段地址空间，但有自己独立的堆栈和局部变量（eg: 单核CPU多线程，并发运行）</li></ul></li><li><p>组合（举例 Task：烧水 &amp; 看电视）</p><ul><li>阻塞 &amp; 同步<ul><li>烧水 -&gt; 等水开（主动看）-&gt; 看电视 ：效率低</li></ul></li><li>阻塞 &amp; 异步  <ul><li>烧水 -&gt; 水壶响（被动听）-&gt; 看电视：效率低</li></ul></li><li>非阻塞 &amp; 同步<ul><li>烧水 &amp; 看电视 &amp; 时不时看下水（主动看）: 来回切换，效率低</li></ul></li><li>非阻塞 &amp; 异步<ul><li>烧水 &amp; 看电视 &amp; 水壶响了再去关（被动听）：减少切换，效率高</li></ul></li></ul></li></ol><h3 id="header-56">进程 Process</h3><ol><li><p><code>os.fork()</code>: 只在Unix/Linux/Mac上运行，windows不可以</p><pre><code class="lang-python"> $ cat fork-demo.py import os,time num=1 ret = os.fork() if ret==0:      # sub-process do:     num=num-1   # should be 0     print(&quot;sub-process:%s,pid:%s,ppid:%s num:%s&quot; % (ret,os.getpid(),os.getppid(),num)) else:           # main-process do:     num=num+1   # should be 2     print(&quot;main-process:%s,pid:%s,ppid:%s num:%s&quot; % (ret,os.getpid(),os.getppid(),num)) time.sleep(3) print(&#39;End&#39;) $ python fork-demo.py main-process:30929,pid:30928,ppid:6855 num:2 sub-process:0,pid:30929,ppid:30928 num:0 End End $ ps    PID TTY           TIME CMD  6855 ttys001    0:00.03 -bash 30928 ttys001    0:00.02 python fork-demo.py 30929 ttys001    0:00.00 python fork-demo.py 28023 ttys002    0:00.02 -bash</code></pre><ul><li>分出一个子进程，后面的代码会分别在原有进程和新创建进程运行</li><li>返回0: 代表当前是新创建的子进程</li><li>返回非0: 代表当前是原本的父进程（返回的数字＝子进程pid）</li><li>即子进程永远返回0，父进程返回子进程的ID</li><li>每个进程中所有数据（包括全局变量）都各有拥有一份，互不影响</li><li>父子进程互补影响，父进程结束不会导致子进程结束</li><li>1次fork-&gt;2个进程，2次fork－&gt;4个进程，…</li></ul></li><li><p><code>multiprocessing.Process</code>: 通用</p><pre><code class="lang-python"> $ cat process-demo.py from multiprocessing import Process import os,time,random # 法一 def task(name):     print(&quot;子进程(%s) task %s start&quot; % (os.getpid(),name))     time.sleep(random.random()*2)      print(&quot;子进程(%s) task %s end&quot; % (os.getpid(),name)) # 法二 class MyProcess(Process):     def __init__(self,name):         Process.__init__(self)         self.name=name     def run(self):         print(&quot;子进程(%s) task %s start&quot; % (os.getpid(),self.name))         time.sleep(random.random()*2)          print(&quot;子进程(%s) task %s end&quot; % (os.getpid(),self.name)) if __name__==&#39;__main__&#39;:     print(&#39;父进程(%s) 开始&#39; % os.getpid())     # p = Process(target=task, args=(&#39;test&#39;,))   # 创建子进程，法一：创建一个Process实例     p = MyProcess(&#39;test&#39;)                       # 创建子进程，法二：创建一个自定义的继承自Process类的实例     p.start()   # 启动子进程     p.join()    # 父进程阻塞等待子进程结束后再继续往下运行，非必需     print(&#39;子进程(%s) 结束&#39; % p.name)     print(&#39;父进程(%s) 结束&#39; % os.getpid()) $ python process-demo.py 父进程(39487) 开始 子进程(39488) task test start 子进程(39488) task test end 子进程(test) 结束 父进程(39487) 结束</code></pre><ul><li>创建<ul><li>法一：创建一个Process实例</li><li>法二：自定义一个类，继承<code>Process</code>类，重写<code>run</code>方法</li></ul></li><li>启动：<code>p.start()</code> 内部调用<code>run</code>方法</li><li>等待结束：<code>p.join([timeout])</code></li><li>终止：<code>p.terminate()</code></li><li>判断是否还在执行：<code>is_alive()</code></li><li>常用属性：<ul><li><code>name</code>：当前进程实例别名，默认为Process-N，N为从1开始递增的整数</li><li><code>pid</code>：当前进程实例的PID值</li></ul></li><li>注：<ul><li>父进程结束不影响子进程</li><li>子进程无法访问父进程创建的全局变量</li><li>变量可通过参数传递</li></ul></li></ul></li><li><p><code>multiprocessing.Pool</code>: 进程池</p><pre><code class="lang-python"> from multiprocessing import Pool import os,time,random def task(name):     print(&quot;子进程(%s): task %s =&gt; start&quot; % (os.getpid(),name))     t=random.random()*2     time.sleep(t)      print(&quot;子进程(%s): task %s =&gt; end(sleep:%.2f)&quot; % (os.getpid(),name,t))     return os.getpid(),name def task_callback(arg):         # 父进程中执行，以元组方式获取task return值     print(&quot;父进程(%s): 获取子进程(%s) task %s =&gt; callback&quot; % (os.getpid(),arg[0],arg[1])) if __name__==&#39;__main__&#39;:     print(&#39;父进程(%s): =&gt; 开始&#39; % os.getpid())     p=Pool(3)     for i in range(0,5):         # p.apply(task,(i,))      # 阻塞方式发配任务(等一个任务完成后，再发布下一个)         p.apply_async(task,(i,),callback=task_callback)  # 非阻塞方式发配任务（一次性发布3个，等空出进程后，再发布下一）     p.close()   # 关闭进程池，是以不再接收新的请求     p.join()    # 父进程阻塞等待所有子进程执行完成，必须放在close语句之后（不加join的话可能子进程还未完成就整个退出了）     print(&#39;所有子进程结束&#39;)     print(&#39;父进程(%s): =&gt; 结束&#39; % os.getpid()) # 阻塞方式结果： $ python pool-demo.py 父进程(44350): =&gt; 开始 子进程(44351): task 0 =&gt; start 子进程(44351): task 0 =&gt; end(sleep:1.30) 子进程(44352): task 1 =&gt; start 子进程(44352): task 1 =&gt; end(sleep:0.27) 子进程(44353): task 2 =&gt; start 子进程(44353): task 2 =&gt; end(sleep:0.53) 子进程(44351): task 3 =&gt; start 子进程(44351): task 3 =&gt; end(sleep:1.68) 子进程(44352): task 4 =&gt; start 子进程(44352): task 4 =&gt; end(sleep:0.53) 所有子进程结束 父进程(44350): =&gt; 结束 # 非阻塞方式结果： $ python pool-demo.py 父进程(44306): =&gt; 开始 子进程(44307): task 0 =&gt; start 子进程(44308): task 1 =&gt; start 子进程(44309): task 2 =&gt; start 子进程(44309): task 2 =&gt; end(sleep:0.89) 子进程(44309): task 3 =&gt; start 父进程(44306): 获取子进程(44309) task 2 =&gt; callback 子进程(44307): task 0 =&gt; end(sleep:1.14) 子进程(44307): task 4 =&gt; start 父进程(44306): 获取子进程(44307) task 0 =&gt; callback 子进程(44308): task 1 =&gt; end(sleep:1.50) 父进程(44306): 获取子进程(44308) task 1 =&gt; callback 子进程(44309): task 3 =&gt; end(sleep:0.92) 父进程(44306): 获取子进程(44309) task 3 =&gt; callback 子进程(44307): task 4 =&gt; end(sleep:1.36) 父进程(44306): 获取子进程(44307) task 4 =&gt; callback 所有子进程结束 父进程(44306): =&gt; 结束</code></pre><ul><li>初始化Pool时，可以指定一个最大进程数</li><li>若进程数达到指定的最大值，直到池中有进程任务结束，下一个任务请求才会发布给空闲进程执行</li><li><code>apply(func, args=(), kwds={})</code> 阻塞方式发布任务给一个进程，必须等待上一个进程任务结束才能执行下一个</li><li><code>apply_async(func, args=(), kwds={}, callback=None, error_callback=None)</code> 非阻塞方式，有空闲进程即可发布执行 </li><li><code>close()</code> 关闭进程池，使其不再接受新的任务</li><li><code>terminate()</code> 不管任务是否完成，立即终止</li><li><code>join()</code> 主进程阻塞等待子进程们结束，必须在<code>close</code>或<code>terminate</code>之后使用</li><li>注：<ul><li>父进程结束会影响子进程</li><li>变量可通过参数传递</li></ul></li></ul></li><li><p><code>Queue</code>: 消息列队</p><pre><code class="lang-python"> $ cat process-queue.py from multiprocessing import Process, Queue from multiprocessing import Manager,Pool import os, time, random def produce_task(q):     while True:         if not q.full():             t=random.random()             q.put(t)             print(&#39;produce:%.2f&#39; % t)             time.sleep(t)         else:             print(&#39;stop produce!&#39;)             break def consume_task(q):     while True:         if not q.empty():             t=q.get()             print(&#39;consume:%.2f&#39; % t)             time.sleep(t)         else:             print(&#39;stop consume!&#39;)             break def process_test():     q=Queue(5)     p_produce=Process(target=produce_task,args=(q,))     p_consume=Process(target=consume_task,args=(q,))     p_produce.start()     p_consume.start()     p_produce.join()     p_consume.join()     print(&quot;Done!&quot;) def pool_test():     q=Manager().Queue(5)     p=Pool(2)     p.apply_async(produce_task,(q,))     p.apply_async(consume_task,(q,))     p.close()     p.join()     print(&quot;Done!&quot;) if __name__==&#39;__main__&#39;:     # process_test()     pool_test() $ python process-queue.py produce:0.04 consume:0.04 produce:0.99 consume:0.99 stop consume! produce:0.07 produce:0.13 produce:0.96 produce:0.86 produce:0.27 stop produce! Done!</code></pre><ul><li>进程间通信，可使用<code>multiprocessing.Queue()</code></li><li>进程池进程通讯，可使用<code>multiprocessing.Manager().Queue()</code></li><li><code>get(block=True,timeout=None)</code> 从队列中弹出一个消息（无消息则阻塞或抛出Queue.Empty异常）</li><li><code>get_nowait()</code> = <code>get(False)</code></li><li><code>put(item,block=True,timeout=None)</code> 将一个消息写入队列（队列满了则阻塞或抛出Queue.Full异常）</li><li><code>put_nowait(item)</code> = <code>put(item,False)</code></li><li><code>qsize()</code> 当前队列包含的消息数量 =&gt; 效果不好，可能会报NotImplementedError</li><li><code>empty()</code> 判断当前队列是否为空</li><li><code>full()</code> 判断当前队列是否满了</li></ul></li></ol><h3 id="header-57">线程 Thread</h3><p>threading模块</p><ul><li>Python的thread模块较底层，threading模块对thread做了一些包装，更方便</li><li>Python解释器（CPython）在解析多线程时，会使用<code>GIL</code>全局排他锁（<code>Global Interpreter Lock</code>），不管几核CPU，同一时刻只有一个线程能使用到CPU，从而导致多线程无法利用多核，解决方法有<ul><li>用多进程<code>multiprocess</code>代替多线程</li><li>使用其他解析器（GIL只是CPython的产物）</li><li>使用c语言实现多线程（利用<code>ctypes</code>模块直接调用任意的C动态库的导出函数）</li></ul></li><li>使用：<ul><li>创建线程：<ul><li>法一：创建一个Thread实例 <code>Thread(group=None, target=None, name=None, args=(), kwargs=None, *, daemon=None)</code></li><li>法二：自定义一个类，继承<code>Thread</code>类，重写<code>run</code>方法</li></ul></li><li><code>start()</code> 启动</li><li><code>join()</code> 主线程阻塞等待子线程结束后再继续，非必需</li><li><code>is_alive()</code> 判断线程是否活着</li><li><code>name</code> 线程名字，默认<code>Thread-1</code>,<code>Thread-2</code>,…</li></ul></li><li>线程同步<ul><li>多个线程有序协同工作</li><li>场景：<ul><li>多个线程共同争夺修改某个共享数据，如全局变量，一个进程内的所有线程共享全局变量（各线程可修改，线程非安全）</li><li>生产-消费者，速度不匹配，需要一个缓冲协同</li></ul></li><li>实现方式：<ul><li>互斥锁 Mutex<ul><li>每次只有一个线程可以上锁，其他需要获得这个锁的线程变为<code>blocked</code>状态</li><li>线程调度程序从处于同步阻塞状态的线程中选择一个来获得锁，并使得该线程进入运行<code>running</code>状态</li><li>锁：相当于一块独占空间，一次只能进一个人（线程）</li><li>创建锁: <code>mutex=threading.Lock()</code></li><li>锁住：<code>mutex.acquire(blocking=True, timeout=-1)</code> =&gt; 锁状态：<code>locked</code>,锁住的那个线程：<code>running</code>,其他需要这个锁的线程：<code>blocked</code></li><li>开锁：<code>mutex.release()</code> =&gt; 锁状态:<code>unlocked</code>,需要这个锁的线程开始争夺这个锁，获这个锁的线程状态从<code>blocked</code>变成<code>runing</code></li><li>死锁：不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁 =&gt; 需尽量避免，如添加超时时间等</li></ul></li><li>队列 Queue<ul><li><code>from queue import Queue</code></li><li><code>q=Queue(maxsize＝0)</code></li><li><code>.get(block=True,timeout=None)</code>,<code>.put(item,block=True,timeout=None)</code></li><li><code>.qsize()</code>,<code>.full()</code>,<code>.empty()</code>,<code>.join()</code></li></ul></li></ul></li></ul></li><li>注：<ul><li>主进程，一个主线程运行</li><li>主线程结束，不会导致子线程结束</li><li>线程间传递数据：<ul><li>全局变量</li><li>传参</li></ul></li><li>线程自己的数据：<ul><li>局部变量</li><li>ThreadLocal<ul><li>定义一个全局变量 <code>l=threading.local()</code></li><li>每个Thread对它的读写互不影响 <code>l.xxx</code>,<code>l.xxx=xxx</code></li><li>类似一个dict</li><li>虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰</li><li>解决了参数在一个线程中各个函数之间互相传递的问题</li></ul></li></ul></li></ul></li></ul><p><strong>Sample1:Thread</strong></p><pre><code class="lang-python">from threading import Threadimport threadingimport os,time,randomdef task(name):    print(&quot;%s do task %s start&quot; % (threading.current_thread().name,name))    start = time.time()    time.sleep(random.random() * 3)    end = time.time()    print(&quot;%s do task %s end (%.2f)&quot; % (threading.current_thread().name,name,end-start))class MyThread(Thread):    def __init__(self,taskName):        Thread.__init__(self)        self.taskName=taskName    def run(self):        print(&quot;%s do task %s start&quot; % (self.name,self.taskName)) # name属性中保存的是当前线程的名字        start = time.time()        time.sleep(random.random() * 3)        end = time.time()        print(&quot;%s do task %s end (%.2f)&quot; % (self.name,self.taskName,end-start))def thread_inst_test():    t=Thread(target=task,args=(&#39;test&#39;,))    t.start()def thread_class_test():    t=MyThread(&#39;test&#39;)    t.start()if __name__==&#39;__main__&#39;:    print(&quot;%s thread start&quot; % threading.current_thread().name)    # thread_inst_test()    thread_class_test()    print(&quot;%s thread end&quot; % threading.current_thread().name)</code></pre><pre><code class="lang-bash">$ python thread-demo.pyMainThread thread startThread-1 do task test startMainThread thread endThread-1 do task test end (0.47)</code></pre><p><strong>Sample2: Multiple tasks</strong></p><pre><code class="lang-python"># test1: 异步,多线程交错打印# result sample:# Thread-1 print 1# Thread-2 print 1# Thread-1 print 2# Thread-1 print 3# Thread-1 done!# Thread-2 print 2# Thread-2 print 3# Thread-2 done!def test_multi_tasks_async():    def async_task():        for i in range(1,4):            print(&quot;%s print %d &quot; % (threading.current_thread().name,i))            time.sleep(random.random())        print(&quot;%s done!&quot; % threading.current_thread().name)    t1=Thread(target=async_task)    t2=Thread(target=async_task)    t1.start()    t2.start()# test2: 同步,多线程顺序打印# result sample:# Thread-1 print 1# Thread-1 print 2# Thread-1 print 3# Thread-1 done!# Thread-2 print 1# Thread-2 print 2# Thread-2 print 3# Thread-2 done!def test_multi_tasks_sync():    mutex=threading.Lock()    def sync_task():        if mutex.acquire():            for i in range(1,4):                print(&quot;%s print %d &quot; % (threading.current_thread().name,i))                time.sleep(random.random())            print(&quot;%s done!&quot; % threading.current_thread().name)            mutex.release()    t1=Thread(target=sync_task)    t2=Thread(target=sync_task)    t1.start()    t2.start()</code></pre><p><strong>Sample3:Mutex</strong></p><pre><code class="lang-python"># test: 操作共享资源，不加锁，结果不正确,shoud be 0# result sample:# Done Thread-1 do add,num = 208671# Done Thread-2 do sub,num = -102681def test_multi_tasks_global_val():    num=0    def add_task():        global num        for i in range(0,1000000):            num+=1        print(&quot;Done %s do add,num = %d &quot; % (threading.current_thread().name,num))    def sub_task():        global num        for i in range(0,1000000):            num-=1        print(&quot;Done %s do sub,num = %d &quot; % (threading.current_thread().name,num))    t1=Thread(target=add_task)    t2=Thread(target=sub_task)    t1.start()    t2.start()# test: 操作共享资源，加锁，得正确结果,be 0# result sample:# Done Thread-2 do sub,num = -36334# Done Thread-1 do add,num = 0def test_multi_tasks_global_val_mutex():    lock=threading.Lock()    num=0    def add_task():        nonlocal num        for i in range(0,1000000):            lock.acquire()            num+=1            lock.release()        print(&quot;Done %s do add,num = %d &quot; % (threading.current_thread().name,num))    def sub_task():        nonlocal num        for i in range(0,1000000):            lock.acquire()            num-=1            lock.release()        print(&quot;Done %s do sub,num = %d &quot; % (threading.current_thread().name,num))    t1=Thread(target=add_task)    t2=Thread(target=sub_task)    t1.start()    t2.start()</code></pre><p><strong>Sample4:Queue</strong></p><pre><code class="lang-python">Queue# result sample:# Consumer [0] Begin# Consumer [0] handle item: 5.77# Consumer [1] Begin# Consumer [2] Begin# Waiting for all threads done...# Consumer [2] handle item: 4.51# Consumer [1] handle item: 3.87# Consumer [0] handle item: 1.61# Consumer [1] handle item: 6.42# Consumer [2] handle item: 0.17# Consumer [1] handle item: 9.36# Consumer [0] handle item: 4.88# Consumer [1] handle item: 8.63# Consumer [1] handle item: 0.27# Consumer [2] Done# Consumer [0] Done# Consumer [1] Done# All threads done.def test_thread_queue():    import queue    def queue_consumer(index,q):        print(&quot;Consumer [%s] Begin&quot; % index)        while not q.empty():            item = q.get()            if not item:                time.sleep(1)                continue            do_task(index,item)        print(&#39;Consumer [%s] Done&#39; % index)    def do_task(index,item):        print(&quot;Consumer [%s] handle item: %s&quot; % (index,item))        time.sleep(random.random())    q=queue.Queue()    [q.put(&quot;%.2f&quot; % (random.random()*10)) for i in range(10)]    t_list=[]    for i in range(3):        t=threading.Thread(target=queue_consumer,args=(i,q,))        t.start()        t_list.append(t)    print(&#39;Waiting for all threads done...&#39;)    for t in t_list:        t.join()    print(&#39;All threads done.&#39;)</code></pre><p><strong>Sample5:ThreadLocal</strong></p><pre><code class="lang-python">ThreadLocal# result sample:# Done Thread-1 task: step=0# Done Thread-5 task: step=40# Done Thread-2 task: step=10# Done Thread-3 task: step=20# Done Thread-4 task: step=30def test_thread_dict():    thread_dict = {}    def task(step):        thread_dict[threading.current_thread()]=step        do_task()    def do_task():        currentThread=threading.current_thread()        step=thread_dict[currentThread]        time.sleep(random.random())        print(&quot;Done %s task: step=%s&quot; % (currentThread.name,step))    for i in range(5):        t=Thread(target=task,args=(i*10,))        t.start()def test_thread_local():    #thread_dict = {}    thread_local = threading.local()    def task(step):        #thread_dict[threading.current_thread()]=step        thread_local.step=step        do_task()    def do_task():        currentThread=threading.current_thread()        #step=thread_dict[currentThread]        step=thread_local.step        time.sleep(random.random())        print(&quot;Done %s task: step=%s&quot; % (currentThread.name,step))    for i in range(5):        t=Thread(target=task,args=(i*10,))        t.start()</code></pre><h3 id="header-58">协程 Coroutine</h3><blockquote><p>Async programming allows you to write concurrent code that runs in a single thread. The first advantage compared to multiple threads is that you decide where the scheduler will switch from one task to another, which means that sharing data between tasks it’s safer and easier.<br>With asynchronous programming, you allow your code to handle other tasks while waiting for these other resources to respond.</p></blockquote><ul><li>async IO，被动通知，单线程多任务（非阻塞），执行效率高</li><li>与多线程对比优势：<ul><li>没有线程切换的开销</li><li>共享资源无需加锁也不会发生冲突（判断状态即可）</li></ul></li></ul><p>使用Python标准库：<code>asyncio</code> （Python 3.4引入）<br>编程模型: 一个消息循环，从<code>asyncio</code>模块中获取一个<code>EventLoop</code>的引用，把需要执行的协程扔到<code>EventLoop</code>中执行</p><ol><li><p><code>Coroutine</code> 协同任务</p><pre><code class="lang-python"> # method1: use `@asyncio.coroutine` @asyncio.coroutine def my_task(args):     print(&#39;start&#39;)     yield from asyncio.sleep(3)  # 用`yield from`调用另一个`coroutine`实现异步操作     print(&#39;end&#39;) # method2: use `async` async def my_task(args):     print(&#39;start&#39;)     await asyncio.sleep(3)     # 用`await`调用另一个`coroutine`实现异步操作     print(&#39;end&#39;) # return a coroutine object my_coroutine = my_task(args)</code></pre><ul><li>一个用<code>@asyncio.coroutine</code>或<code>async</code>标注的function</li><li><code>xxx(args)</code>,不会执行方法体中的语句，只是返回一个coroutine object</li><li><code>async</code>&amp;<code>await</code>是Python 3.5引入的语法糖，<code>async</code>代替<code>@asyncio.coroutine</code>,<code>await</code>代替<code>yield from</code>（Note: <code>await</code> keyword can only be used inside an <code>async def function</code>）</li></ul></li><li><p><code>EventLoop</code> 事件循环（事件池）</p><pre><code class="lang-python"> # 1. create loop： 从`asyncio`模块中获取一个`EventLoop`的引用 loop = asyncio.new_event_loop() # 2. add coroutine to the loop,return a future object future = loop.create_task(my_coroutine) # 3. execute all coroutine added to the loop concurrently # method1: loop.run_until_complete(my_coroutine) # method2: loop.run_until_complete(future) loop.close()</code></pre><ul><li>组织协调执行加入的协同任务</li><li>execute our asyncronous code and decide how to switch between async functions</li></ul></li><li><p>Running Tasks Concurrently(一个事件循环中执行多个task , 并发执行)</p><ul><li><code>asyncio.wait(fs, *, loop=None, timeout=None, return_when=&#39;ALL_COMPLETED&#39;)</code><ul><li>等待任务完成，支持在完成第一个任务后或在指定的超时之后停止等待</li><li>return: two sets of Future: <code>(done, pending)</code><ul><li><code>done</code> : 已完成的协程Task集合 <code>{asyncio.Task,asyncio.Task,...}</code></li><li><code>pending</code> : 超时未完成的协程Task集合</li><li><code>asyncio.Task</code> : extends Future, could use <code>.result()</code> get task return value</li></ul></li><li>usage:<ul><li><code>done, pending = await asyncio.wait(coros_or_futures)</code> －－ in async func</li><li><code>done, pending = loop.run_until_complete(async.wait(coros_or_futures))</code> －－ in normal func</li></ul></li></ul></li><li><code>asyncio.gather</code><ul><li>等待并按给定的顺序返回完成的任务结果</li><li>return：已完成的协程Task的结果值列表 <code>[taskReturnValue1,taskReturnValue2,...]</code></li><li>usage:<ul><li><code>results=await asyncio.gather(*coros_or_futures)</code></li><li><code>results=loop.run_until_complete(async.gather(*coros_or_futures))</code></li><li>还可对任务进行高级别分组<pre><code class="lang-python">  group1 = asyncio.gather(*[task1,task2])  group2 = asyncio.gather(*[task3,task4])  all_groups = asyncio.gather(group1, group2)  results = loop.run_until_complete(all_groups)</code></pre></li></ul></li></ul></li><li>总结 <code>asyncio.wait</code> vs. <code>asyncio.gather</code> :<ul><li>都是用于获取结果的,且都不阻塞,直接返回一个生成器对象可用于 <code>yield from</code> / <code>await</code></li><li>都是两种用法<ul><li><code>results = asyncio.run_until_completed(asyncio.wait/gather)</code> 执行所有完成之后获取</li><li><code>results = await asyncio.wait/gather</code> 在一个协程内获取结果</li></ul></li><li>但返回结果不一样<ul><li><code>asyncio.wait</code> 返回 tuple: <code>(doneSet,pendingSet)</code></li><li><code>asyncio.gather</code> 返回 list: <code>[taskReturnValue1,taskReturnValue2,...]</code></li></ul></li></ul></li></ul></li><li><p><code>Task</code>/<code>Future</code>(注: <code>class Task(Future)</code>): </p><pre><code class="lang-python"> # method1: add a coroutine to the loop and returns a `Task` which is a subtype of `Future` future = loop.create_task(my_coroutine) # method2: adds a coroutine to the default loop future = asyncio.ensure_future(my_coroutine) # could add call back for the future object future.add_done_callback(result_handler())</code></pre><ul><li>works as a placeholder for the output of an asynchronous function </li><li>and it gives us information about the function state,</li><li>A future is created when we add a corutine to an event loop</li></ul></li><li><p>Run Result: </p><pre><code class="lang-python"> # method1: use the `yield from` or `await` result=await my_coroutine # method2: add it to an event loop future=loop.create_task(my_coroutine) result=future.result()</code></pre><ul><li>Get the output of an async function from a coroutine</li></ul></li><li><p>Exception handling: </p><pre><code class="lang-python"> # method1: try catch the exception try:         future.result() # this will re-raise the exception raised during the coroutine execution except Exception:     pass # method2: get the exception information future.exception()</code></pre><ul><li>method1: <code>try...except...</code> 捕获异常</li><li>method2: 调用<code>future.exception()</code>异常信息</li><li>Note：unhandled exception raised inside a coroutine doesn’t break the program,it will be stored inside the future and get <code>Task exception was never retrieved</code> error before program exit.</li></ul></li></ol><p><strong>Sample1:<code>@asyncio.coroutine</code> &amp; <code>yield from</code> vs. <code>async</code> &amp; <code>await</code></strong></p><ol><li><p><code>@asyncio.coroutine</code> &amp; <code>yield from</code></p><pre><code class="lang-python"> import asyncio import random @asyncio.coroutine def hello(name):     r=random.random()*3     print(&#39;Hello %s, sleep %s&#39; % (name,r))     yield from asyncio.sleep(r)     print(&#39;Hello %s wake up!&#39; % name) if __name__ == &#39;__main__&#39;:     loop = asyncio.get_event_loop()                 # 获取EventLoop     #tasks = [hello(&quot;Tom&quot;), hello(&quot;Lucy&quot;)]     t1=loop.create_task(hello(&quot;Tom&quot;))     t2=loop.create_task(hello(&quot;Lucy&quot;))     tasks=[t1,t2]                                   # t1,t2 is future     loop.run_until_complete(asyncio.wait(tasks))    # 执行     loop.close()</code></pre></li><li><p><code>async</code> &amp; <code>await</code></p><pre><code class="lang-python"> import asyncio import random async def hello(name):                                # 使用`async` 代替`@asyncio.coroutine`     r=random.random()*3     print(&#39;Hello %s, sleep %s&#39; % (name,r))     await asyncio.sleep(r)                            # 使用`await` 代替`yield from`     print(&#39;Hello %s wake up!&#39; % name) if __name__ == &#39;__main__&#39;:     loop = asyncio.get_event_loop()     # tasks = [hello(&quot;Tom&quot;), hello(&quot;Lucy&quot;)]     t1=loop.create_task(hello(&quot;Tom&quot;))     t2=loop.create_task(hello(&quot;Lucy&quot;))     tasks=[t1,t2]     loop.run_until_complete(asyncio.wait(tasks))     loop.close()</code></pre></li></ol><p><strong>Sample2: <code>coroutine</code> vs. <code>future</code>, <code>asyncio.wait</code> vs. <code>asyncio.gather</code></strong></p><ol><li><p><code>coroutine</code></p><pre><code class="lang-python"> import asyncio import time,random async def do_async_task(index,item):     print(&#39;[start]\t %s:\t %s&#39; % (index,item))     start=time.time()     await asyncio.sleep(random.random())     end=time.time()     result =&#39;[end]\t %s:\t %s (spent:%.2f)&#39; % (index,item,(end-start))     return result if __name__==&#39;__main__&#39;:     loop = asyncio.get_event_loop()     task_list=[]     for i in range(10):         item=&quot;%.2f&quot; % (random.random()*10)         t=do_async_task(i,item)                 # t is coroutine         task_list.append(t)     print(&#39;Waiting for all sub-proc done...&#39;)     # method1: use asyncio.wait     done,pending=loop.run_until_complete(asyncio.wait(task_list))     print(done,pending)     for r in done:         print(&quot;get result:&quot;,r.result())     # method2: use asyncio.gather     # results=loop.run_until_complete(asyncio.gather(*task_list))     # print(results)     # for r in result:     #     print(&quot;get result:&quot;,r)     loop.close()     print(&#39;All sub-procs done.&#39;)     # for task in task_list:     #     # task:     #     # type: coroutine     #     # sample: &lt;coroutine object do_async_task at 0x10f24c8c8&gt;     #     print(task)</code></pre></li><li><p><code>future</code></p><pre><code class="lang-python"> import asyncio import time,random async def do_async_task(index,item):     print(&#39;[start]\t %s:\t %s&#39; % (index,item))     start=time.time()     await asyncio.sleep(random.random())     end=time.time()     result =&#39;[end]\t %s:\t %s (spent:%.2f)&#39; % (index,item,(end-start))     return result def handle_result(future):     print(&quot;callback:&quot;,future.result()) if __name__==&#39;__main__&#39;:     loop = asyncio.get_event_loop()     task_list=[]     for i in range(10):         item=&quot;%.2f&quot; % (random.random()*10)         t=do_async_task(i,item)                 # t is coroutine         f=loop.create_task(t)                   # f is future         f.add_done_callback(handle_result)         task_list.append(f)     print(&#39;Waiting for all sub-proc done...&#39;)     # method1: use asyncio.wait     done,pending=loop.run_until_complete(asyncio.wait(task_list))     print(done,pending)     for r in done:         print(&quot;get result:&quot;,r.result())     # method2: use asyncio.gather     # results=loop.run_until_complete(asyncio.gather(*task_list))     # print(results)     # for r in result:     #     print(&quot;get result:&quot;,r)     loop.close()     print(&#39;All sub-procs done.&#39;)     # for task in task_list:      #     # task:     #     # type: _asyncio.Task,subtype of `Future`     #     # sample: &lt;Task finished      #     # coro=&lt;do_async_task() done, defined at asyncio-demo.py:5&gt;      #     # result=&#39;[end]\t 7:\t... (spent:0.36)&#39;&gt;     #     print(&quot;get task result:&quot;,task.result())</code></pre></li><li><p>Result sample:</p><pre><code> Waiting for all sub-proc done... [start]  0:  6.28 [start]  1:  6.02 [start]  2:  5.86 [start]  3:  1.32 [start]  4:  8.29 [start]  5:  6.30 [start]  6:  2.07 [start]  7:  3.41 [start]  8:  8.47 [start]  9:  3.76 callback: [end]  4:  8.29 (spent:0.11) callback: [end]  0:  6.28 (spent:0.18) callback: [end]  3:  1.32 (spent:0.20) callback: [end]  6:  2.07 (spent:0.31) callback: [end]  1:  6.02 (spent:0.51) callback: [end]  9:  3.76 (spent:0.51) callback: [end]  7:  3.41 (spent:0.75) callback: [end]  8:  8.47 (spent:0.78) callback: [end]  5:  6.30 (spent:0.79) callback: [end]  2:  5.86 (spent:1.00) get result: [end]    5:  6.30 (spent:0.79) get result: [end]    2:  5.86 (spent:1.00) get result: [end]    8:  8.47 (spent:0.78) get result: [end]    6:  2.07 (spent:0.31) get result: [end]    3:  1.32 (spent:0.20) get result: [end]    0:  6.28 (spent:0.18) get result: [end]    9:  3.76 (spent:0.51) get result: [end]    7:  3.41 (spent:0.75) get result: [end]    4:  8.29 (spent:0.11) get result: [end]    1:  6.02 (spent:0.51) All sub-procs done.</code></pre></li></ol><p><strong>Sample3:queue</strong></p><pre><code class="lang-python">async def do_async_task(index,item):    print(&#39;do task %s: Consumer[%s] %s&#39; % (item[0],index,item[1]))    start=time.time()    await asyncio.sleep(random.random())    end=time.time()    result =&#39;do task %s: Consumer[%s] %s (spent:%.2f)&#39; % (item[0],index,item[1],(end-start))    return resultdef handle_result(future):    print(future.result())async def async_queue_consumer(index,q):    print(&quot;Consumer[%s] Begin&quot; % index)    while not q.empty():        item = await q.get()        if not item:            await asyncio.sleep(1)            continue        task=asyncio.create_task(do_async_task(index,item))        task.add_done_callback(handle_result)        await asyncio.gather(task)    print(&#39;Consumer[%s] Done&#39; % index)if __name__==&#39;__main__&#39;:       print(&quot;--- Test: asyncio queue ---&quot;)    q=asyncio.Queue()    [q.put_nowait((i,&quot;%.2f&quot; % (random.random()*10))) for i in range(10)]    tasks = [async_queue_consumer(i,q) for i in range(3)]    loop = asyncio.get_event_loop()    print(&#39;Waiting for all sub-proc done...&#39;)    loop.run_until_complete(asyncio.wait(tasks))    loop.close()    print(&#39;All sub-procs done.&#39;)</code></pre><p>Result sample:</p><pre><code>--- Test: asyncio queue ---Waiting for all sub-proc done...Consumer[1] BeginConsumer[0] BeginConsumer[2] Begindo task 0: Consumer[1] 5.87do task 1: Consumer[0] 7.46do task 2: Consumer[2] 7.20do task 1: Consumer[0] 7.46 (spent:0.05)do task 3: Consumer[0] 7.28do task 2: Consumer[2] 7.20 (spent:0.61)do task 4: Consumer[2] 7.07do task 0: Consumer[1] 5.87 (spent:0.72)do task 5: Consumer[1] 9.09do task 3: Consumer[0] 7.28 (spent:0.67)do task 6: Consumer[0] 9.65do task 4: Consumer[2] 7.07 (spent:0.33)do task 7: Consumer[2] 6.64do task 6: Consumer[0] 9.65 (spent:0.89)do task 8: Consumer[0] 3.21do task 7: Consumer[2] 6.64 (spent:0.74)do task 9: Consumer[2] 1.78do task 5: Consumer[1] 9.09 (spent:0.98)Consumer[1] Donedo task 9: Consumer[2] 1.78 (spent:0.13)Consumer[2] Donedo task 8: Consumer[0] 3.21 (spent:0.62)Consumer[0] DoneAll sub-procs done.</code></pre><h2 id="header-59">访问数据库</h2><h3 id="header-60">SQLite</h3><ul><li>SQLite是一种嵌入式数据库,它的数据库就是一个文件</li><li>Python就内置了SQLite3,可直接使用</li><li>操作：建立连接Connection，打开游标，通过Cursor执行SQL语句，获得执行结果，关闭游标，提交事物，关闭连接<ul><li><code>Cursor</code>对象通过<code>execute</code>方法执行SQL语句（可使用<code>?</code>占位符）</li><li>执行<code>insert</code>/<code>update</code>/<code>delete</code>后，可通过<code>cursor.rowcount</code>获取影响的行数</li><li>执行<code>select</code>后，可通过<code>cursor.featchall()</code>获取结果集列表，每个元素都是一个tuple，对应一行记录</li></ul></li></ul><p><strong>Sample:</strong></p><pre><code class="lang-python">import sqlite3import os# delte test.dbdb_file = os.path.join(os.path.dirname(__file__), &#39;test.db&#39;)if os.path.isfile(db_file):    os.remove(db_file)conn = sqlite3.connect(&#39;test.db&#39;)   # 建立连接（数据库文件不存在时，会创建）cursor = conn.cursor()              # 创建并打开一个Cursortry:    # 执行SQL语句: create    cursor.execute(&#39;create table user(id varchar(20) primary key, name varchar(20), score int)&#39;)    # 执行SQL语句: insert    cursor.execute(r&quot;insert into user values (&#39;A-001&#39;, &#39;Adam&#39;, 95)&quot;)    print(cursor.rowcount)    cursor.execute(r&quot;insert into user values (&#39;A-002&#39;, &#39;Bart&#39;, 62)&quot;)    print(cursor.rowcount)    cursor.execute(r&quot;insert into user values (&#39;A-003&#39;, &#39;Lisa&#39;, 78)&quot;)    print(cursor.rowcount)    # 提交事务    conn.commit()    # 执行SQL语句: select    cursor.execute(&#39;select * from user where id=?&#39;, (&#39;A-001&#39;,))    records = cursor.fetchall()    print(records)finally:    cursor.close()                  # 关闭Cursor    conn.close()                    # 关闭连接</code></pre><h3 id="header-61">MySQL</h3><p><code>pip install mysql-connector-python</code> or <code>pip install pymysql</code></p><pre><code class="lang-python">#import mysql.connector as pymysqlimport pymysqlconn=pymysql.connect(host=&quot;localhost&quot;,port=3316,user=&#39;root&#39;,password=&#39;123456&#39;,database=&#39;demo1&#39;)cursor=conn.cursor()try:    # 执行SQL语句: drop    cursor.execute(&#39;drop table if exists user&#39;)    # 执行SQL语句: create    cursor.execute(&#39;create table user(id varchar(20) primary key, name varchar(20), score int)&#39;)    # 执行SQL语句: insert    cursor.execute(r&quot;insert into user values (&#39;A-001&#39;, &#39;Adam&#39;, 95)&quot;)    print(cursor.rowcount)    cursor.execute(r&quot;insert into user values (&#39;A-002&#39;, &#39;Bart&#39;, 62)&quot;)    print(cursor.rowcount)    cursor.execute(r&quot;insert into user values (&#39;A-003&#39;, &#39;Lisa&#39;, 78)&quot;)    print(cursor.rowcount)    # 提交事务    conn.commit()    # 执行SQL语句: select    # 注：这里占位符是&#39;%&#39;，不是&#39;?&#39;    cursor.execute(&#39;select * from user where id=%s&#39;, (&#39;A-001&#39;,))    records = cursor.fetchall()    print(records)finally:    cursor.close()    conn.close()</code></pre><p>check result:</p><pre><code class="lang-bash">mysql&gt; use demo1Database changedmysql&gt; select * from user;+-------+------+-------+| id    | name | score |+-------+------+-------+| A-001 | Adam |    95 || A-002 | Bart |    62 || A-003 | Lisa |    78 |+-------+------+-------+3 rows in set (0.00 sec)</code></pre><h3 id="header-62">Redis</h3><p><code>pip install redis</code></p><ol><li><p>连接Redis数据库</p><pre><code class="lang-python"> import redis # 1. 连接Redis数据库 # method1: 直接连接 # client=redis.Redis(host=&#39;127.0.0.1&#39;,port=6379,password=&#39;123456&#39;) # method2: 连接池连接(预先创建多个连接, 进行redis操作时, 直接获取已经创建的连接进行操作, 完成后,不会释放, 用于后续的其他redis操作) pool = redis.ConnectionPool(host=&#39;localhost&#39;, port=6379,password=&#39;123456&#39;) client = redis.Redis(connection_pool=pool) # check exist keys: # results=client.keys(&#39;*&#39;) # print(&quot;list keys * :&quot;,results)</code></pre></li><li><p>基础数据操作: 基本redis的命令名与redis模块中的函数名一致</p><ul><li><p>String: <code>key -&gt; value</code></p><pre><code class="lang-python">  # 设置：  # set(key, value, ex=None, px=None, nx=False, xx=False)  # setnx(key, value)　            只有key不存在时设置  # setex(key, value, time)        设置过期时间（秒）  # mset({key:value,...})          批量设置值  #  # 获取：  # get(key)  # mget(key1,key2,...)  # strlen(key)                   key对应值的字节长度  #  # 值追加内容:  # append(key,addValue)  def test_string():      print(&quot;Test String:&quot;)      result=client.set(&#39;a&#39;,1)      print(result)                   # True      result=client.get(&#39;a&#39;)      print(result)                   # b&#39;1&#39;      result=client.append(&#39;a&#39;,23)      print(result)                   # 3      result=client.get(&#39;a&#39;)      print(result)                   # b&#39;123&#39;</code></pre></li><li><p>Hash: 一个name对应一个dic字典 <code>n1 -&gt; k1:v1,k2,v2</code>,<code>n2 -&gt; kx:vx,..</code></p><pre><code class="lang-python">  # hset(name, key, value)  # hget(name, key)  # hgetall(name)  # hmset(name, mapping)  # hmget(name, keys, *args)  #  # hlen(name)  # hkeys(name)  # hvals(name)  #  # hexists(name, key)  # hdel(name, *keys)  # hincrby(name, key, amount=1)  def test_hash():      print(&quot;Test Hash:&quot;)      result = client.hset(&#39;stu-001&#39;,&#39;name&#39;,&#39;Tom&#39;)      print(result)                       # 1      result = client.hmset(&#39;stu-001&#39;,{&#39;age&#39;:19,&#39;gender&#39;:&#39;male&#39;})      print(result)                       # True      result = client.hgetall(&#39;stu-001&#39;)      print(result)                       # {b&#39;name&#39;: b&#39;Tom&#39;, b&#39;age&#39;: b&#39;19&#39;, b&#39;gender&#39;: b&#39;male&#39;}      result = client.hmset(&#39;stu-002&#39;,{&#39;name&#39;:&#39;Lucy&#39;,&#39;age&#39;:16,&#39;gender&#39;:&#39;Female&#39;})      print(result)                       # True      result = client.hgetall(&#39;stu-002&#39;)      print(result)                       # {b&#39;name&#39;: b&#39;Lucy&#39;, b&#39;age&#39;: b&#39;16&#39;, b&#39;gender&#39;: b&#39;Female&#39;}      result = client.hlen(&#39;stu-001&#39;)      print(result)                       # 3      result = client.hkeys(&#39;stu-001&#39;)      print(result)                       # [b&#39;name&#39;, b&#39;age&#39;, b&#39;gender&#39;]      result = client.hvals(&#39;stu-001&#39;)      print(result)                       # [b&#39;Tom&#39;, b&#39;19&#39;, b&#39;male&#39;]      result = client.hincrby(&#39;stu-001&#39;,&#39;age&#39;,amount=5)      print(result)                       # 24      result = client.hgetall(&#39;stu-001&#39;)      print(result)                       # {b&#39;name&#39;: b&#39;Tom&#39;, b&#39;age&#39;: b&#39;24&#39;, b&#39;gender&#39;: b&#39;male&#39;}</code></pre></li><li><p>List: 一个name对应一个列表存储,<code>n1 -&gt; [v1,v2,...]</code>,<code>n2 -&gt; [...]</code></p><pre><code class="lang-python"> # lpush(name, *values),rpush(name, *values)  # lpushx(name, *values),rpushx(name, *values)  name存在时，才能加入 # linsert(name, where, refvalue, value)        name对应的列表的refValue值的前或后where插入一个value # # llen(name)                        name列表长度 # lindex(name, index)               索引获取元素 # lrange(name, start, end)          分片获取元素 # # lset(name, index, value)          索引位置重新赋值 # lpop(name)                        移除列表的左侧第一个元素，返回值则是第一个元素 # lrem(name, value, num=0)          删除name对应的list中的指定值 # ltrim(name, start, end)           移除列表内没有在该索引之内的值 def test_list():     print(&quot;Test List:&quot;)     result = client.lpush(&#39;group1&#39;,&#39;stu-A&#39;,&#39;stu-B&#39;,&#39;stu-C&#39;,&#39;stu-D&#39;,&#39;stu-E&#39;)     print(result)                      # 5     result = client.lpush(&#39;group2&#39;,&#39;child-A&#39;,&#39;child-B&#39;)     print(result)                       # 3     result = client.llen(&#39;group1&#39;)     print(result)                       # 5     result = client.lrange(&#39;group1&#39;,2,5)     print(result)                       # [b&#39;stu-C&#39;, b&#39;stu-B&#39;, b&#39;stu-A&#39;]</code></pre></li><li><p>Set: 不允许有重复的集合，<code>n1 -&gt; {v1,v2,...}</code>,<code>n2 -&gt; {...}</code></p><pre><code class="lang-python">  # sadd(name, *values)           添加元素  # srem(name,*values)            删除元素  # smembers(name)                列出集合所有元素  # scard(name)                   获取元素个数  # sismember(name, value)        测试素是否在  # spop(name)                    从集合中随机弹出一个元素  # smove(src, dst, value)        将一个元素从集合1移到集合2  # sdiff/sdiffstore(keys, *args) 差集（以前一个集合为标准）  # sinter(keys, *args)           交集  # sunion(keys, *args)           并集  def test_set():      print(&quot;Test Set:&quot;)      result = client.sadd(&#39;stdGrp1&#39;,&#39;stu-A&#39;,&#39;stu-B&#39;,&#39;stu-B&#39;,&#39;stu-C&#39;)      print(result)                       # 3      result = client.smembers(&#39;stdGrp1&#39;)      print(result)                       # {b&#39;stu-B&#39;, b&#39;stu-C&#39;, b&#39;stu-A&#39;}      result = client.scard(&#39;stdGrp1&#39;)      print(result)                       # 3      result = client.sadd(&#39;stdGrp2&#39;,*(&#39;stu-A&#39;,&#39;stu-C&#39;,&#39;stu-D&#39;))      print(result)                       # 3      result = client.sdiff(&#39;stdGrp1&#39;,&#39;stdGrp2&#39;)      print(result)                       # {b&#39;stu-B&#39;}      result = client.sinter(&#39;stdGrp1&#39;,&#39;stdGrp2&#39;)      print(result)                       # {b&#39;stu-C&#39;, b&#39;stu-A&#39;}      result = client.sunion(&#39;stdGrp1&#39;,&#39;stdGrp2&#39;)      print(result)                       # {b&#39;stu-B&#39;, b&#39;stu-C&#39;, b&#39;stu-A&#39;, b&#39;stu-D&#39;}</code></pre></li><li><p>ZSet: 有序集合(set的升级), 每次添加修改元素后会自动重新排序,<code>n1 -&gt; {(value1,score1),(value2,score2),...}</code></p><pre><code class="lang-python">  # 每一个元素有两个值，值value和分数score(专门用来做排序)  # 元素rank(表index，即下标索引)  # lexicographical: 相同的分值时，有序集合的元素会根据成员的值逐字节对比  # zadd(name, mapping, nx=False, xx=False, ch=False, incr=False) 添加  # zrem(name, values)                                            删除  # zremrangebyrank(name, start, end)  # zremrangebyscore(name, minscore, maxscore)  # zscan(name, cursor=0, match=None, count=None, score_cast_func=float) 查看  # zscan_iter(name, match=None, count=None,score_cast_func=float)  # zrange/zrevrange(name, start, end, desc=False, withscores=False, score_cast_func=float) 获取rank范围内的元素  # zrangebyscore(name,minscore,maxscore,...)   获取score范围内的元素  # zrank/zrevrank(name, value)                  获取元素rank  # zscore(name, value)                          获取元素score  # zcard(name)                         所有元素个数  # zcount(name, minscore, maxscore)    指定score范围内的元素数量  # zincrby(name, value, amount)                自增  # zinterstore(dest, keys, aggregate=None)     交集(相同值不同分数，则按照 aggregate=SUM/MIN/MAX 进行操作)  # zunionstore(dest, keys, aggregate=None)     并集  def test_zset():      print(&quot;Test ZSet:&quot;)      # 创建      result = client.zadd(&#39;car1&#39;,{&#39;car-A&#39;:10,&#39;car-B&#39;:20,&#39;car-C&#39;:30,&#39;car-D&#39;:40})       print(result)                    # 4      # 列出      result = client.zscan(&#39;car1&#39;)      print(result)                   # (0, [(b&#39;car-A&#39;, 10.0), (b&#39;car-B&#39;, 20.0), (b&#39;car-C&#39;, 30.0), (b&#39;car-D&#39;, 40.0)])      # 切片，获取元素列表      result = client.zrange(&#39;car1&#39;,1,3)      print(result)                   # [b&#39;car-B&#39;, b&#39;car-C&#39;, b&#39;car-D&#39;]      result = client.zrangebyscore(&#39;car1&#39;,15,35)      print(result)                   # [b&#39;car-B&#39;, b&#39;car-C&#39;]      # 统计数量      result = client.zcard(&#39;car1&#39;)      print(result)                   # 4      result = client.zcount(&#39;car1&#39;,15,35)      print(result)                   # 2      # 获取元素属性：rank,score      result = client.zrank(&#39;car1&#39;,&#39;car-C&#39;)      print(result)                   # 2      result = client.zscore(&#39;car1&#39;,&#39;car-C&#39;)      print(result)                   # 30.0      # 交集      result = client.zadd(&#39;car2&#39;,{&#39;car-B&#39;:25,&#39;car-D&#39;:45,&#39;car-E&#39;:55})      print(result)                   # 3      result = client.zinterstore(&#39;car-inter&#39;,(&#39;car1&#39;,&#39;car2&#39;))      print(result)                   # 2      result = client.zscan(&#39;car-inter&#39;)      print(result)                   # (0, [(b&#39;car-B&#39;, 45.0), (b&#39;car-D&#39;, 85.0)])      result = client.zinterstore(&#39;car-inter&#39;,(&#39;car1&#39;,&#39;car2&#39;),aggregate=&#39;MAX&#39;)      print(result)                   # 2      result = client.zscan(&#39;car-inter&#39;)      print(result)                   # (0, [(b&#39;car-B&#39;, 25.0), (b&#39;car-D&#39;, 45.0)])</code></pre></li></ul></li><li><p>其他常用操作</p><pre><code class="lang-python"> # flushdb(asynchronous=False) # flushall(asynchronous=False) # delete( *names) # exists( name) # keys( pattern=&#39;*&#39;) # expire(name ,time) # rename( src, dst) # move( name, db) # randomkey() # type(name) def test_others():     result = client.keys()     print(result)     # [b&#39;car-inter&#39;, b&#39;car1&#39;, b&#39;car2&#39;, b&#39;car&#39;, b&#39;stdGrp1&#39;, b&#39;stdGrp2&#39;, b&#39;stu-001&#39;, b&#39;a&#39;, b&#39;top:dupefilter&#39;, b&#39;stu-002&#39;, b&#39;top:items&#39;, b&#39;group1&#39;, b&#39;tt&#39;]     result = client.delete(&#39;car&#39;)     print(result)       # 1     result = client.exists(&#39;car&#39;)     print(result)       # 0     result = client.type(&#39;car-inter&#39;)     print(result)       # b&#39;zset&#39;</code></pre></li><li><p>管道: 批量提交命令,还可用来实现事务transation</p><pre><code class="lang-python"> # pipeline(transaction=True,shard_hint=None) 默认情况下一次pipline是原子性操作 # pipe.watch(name) -- 乐观锁，watch的对象不可改 # pipe.unwatch() def test_pipeline():     import time     client.set(&#39;cnt&#39;,10)     result=client.get(&#39;cnt&#39;)     print(&#39;initial cnt:&#39;,result)     pipe=client.pipeline(transaction=True)     pipe.watch(&#39;cnt&#39;)               # 加锁     try:         pipe.multi()         cnt=int(client.get(&#39;cnt&#39;))         pipe.set(&#39;a&#39;, 1)         pipe.set(&#39;cnt&#39;,cnt+1)         pipe.set(&#39;b&#39;,2)         print(&#39;sleep...&#39;)         time.sleep(5)               # 此时，若另一个客户端修改了cnt，则这段操作提交（执行execute）时会报错         print(&#39;execute...&#39;)         pipe.execute()     except redis.exceptions.WatchError as ex:         print(&quot;pipe fail:&quot;,ex)     else:         print(&quot;pipe success&quot;)     finally:         print(&quot;finally: a=%s,cnt=%s,b=%s&quot; % (client.get(&#39;a&#39;),client.get(&#39;cnt&#39;),client.get(&#39;b&#39;)))         pipe.unwatch()              # 解锁</code></pre></li><li><p>发布／订阅 －－ 不推荐使用</p><pre><code class="lang-python"> # 发布：  #   publish(channel,msg)      #   =&gt; redis client execute : `publish channel msg`  # 订阅：  #   pubsub().subscribe(channel).parse_response(block,timeout)   #   =&gt; redis client execute : `subscribe channel` (取消使用命令punsubscribe/unsubscribe) def test_publish():     result=client.publish(&quot;channel-1&quot;,&quot;Hello!&quot;)     print(&quot;result:&quot;,result)     # 0     while True:         msg = &quot;This is %.2f&quot; % (random.random()*10)         print(&#39;sending...&#39;,msg)         result=client.publish(&quot;channel-1&quot;,msg)         if result==1:             print(&#39;send success&#39;)         else:             print(&#39;send fail&#39;)         isCondinue=input(&quot;continue?(y/n)&quot;)         if isCondinue==&#39;n&#39;:             break;     print(&#39;Done!&#39;) def test_subscribe():     subscribeObj = client.pubsub()     result=subscribeObj.subscribe(&quot;channel-1&quot;)     print(result)           # None     while True:         print(&#39;receiving...&#39;)         msg=subscribeObj.parse_response(block=False,timeout=60)         # 第一次收到：[b&#39;subscribe&#39;, b&#39;channel-1&#39;, 1]         # 当另一个客户端向此channel发布消息时（eg: `publish channel-1 &quot;Hello World&quot;`）         # 这里会收到： [b&#39;message&#39;, b&#39;channel-1&#39;, b&#39;Hello World&#39;]         print(&quot;receive msg:&quot;,msg)            isCondinue=input(&quot;continue?(y/n)&quot;)         if isCondinue==&#39;n&#39;:             break;     print(&quot;Done!&quot;) if __name__==&#39;__main__&#39;:     # test_publish()     # test_subscribe()</code></pre></li></ol><h3 id="header-63">MongoDB</h3><p><code>pip install pymongo</code></p><pre><code class="lang-python">import pymongoimport jsonfrom datetime import datetime# 1. 建立连接mongoConnStr=&quot;mongodb://cj:123456@localhost:27017/?authSource=admin&quot;client=pymongo.MongoClient(mongoConnStr)    print(&quot;list dbs:&quot;,client.list_database_names())                         # 列出dbsdb=client[&#39;mg_test&#39;]print(&quot;list collections of mg_test db:&quot;,db.list_collection_names())     # 列出collections(类似表)collection=db[&#39;movies&#39;]print(&quot;get collection:movies count:&quot;,collection.estimated_document_count())# 2. clear:# ret=collection.delete_many({})           # print(ret.deleted_count,ret.acknowledged,ret.raw_result)# 3. update_one -- update or insert recordcontents=json.load(open(&#39;test.json&#39;,&#39;r&#39;))           # load: file -&gt; string -&gt; python objprint(&#39;update or insert records:&#39;)for record in contents:    id=record.pop(&#39;id&#39;)    t=datetime.now()    print(&quot;to store record...id=%s,title=%s&quot; % (id,record[&#39;title&#39;]))    record[&#39;last_update_time&#39;]=t    ret=collection.update_one({&#39;_id&#39;:id}            ,{&#39;$setOnInsert&#39;:{&#39;create_time&#39;:t},&#39;$set&#39;:record}            ,upsert=True)    print(ret.matched_count,ret.modified_count,ret.upserted_id,ret.acknowledged,ret.raw_result)# 4. find -- list recordsprint(&#39;list stored records:&#39;)results=collection.find({},{&#39;_id&#39;:1,&#39;title&#39;:1,&#39;rate&#39;:1})for result in results:    print(result)# results sample:# {&#39;_id&#39;: &#39;27109879&#39;, &#39;rate&#39;: &#39;6.5&#39;, &#39;title&#39;: &#39;硬核&#39;}# {&#39;_id&#39;: &#39;26707088&#39;, &#39;rate&#39;: &#39;7.1&#39;, &#39;title&#39;: &#39;奎迪：英雄再起&#39;}# {&#39;_id&#39;: &#39;30334122&#39;, &#39;rate&#39;: &#39;6.1&#39;, &#39;title&#39;: &#39;芳龄十六&#39;}# {&#39;_id&#39;: &#39;1945750&#39;, &#39;rate&#39;: &#39;7.7&#39;, &#39;title&#39;: &#39;污垢&#39;}# {&#39;_id&#39;: &#39;26611891&#39;, &#39;rate&#39;: &#39;6.8&#39;, &#39;title&#39;: &#39;欢乐满人间2&#39;}print(&#39;list rate&gt;=7 records:&#39;)results=collection.find({&#39;rate&#39;:{&#39;$gte&#39;:&quot;7&quot;}},{&#39;_id&#39;:1,&#39;title&#39;:1,&#39;rate&#39;:1}).limit(5)for record in results:    print(record)# results sample:# {&#39;_id&#39;: &#39;26707088&#39;, &#39;rate&#39;: &#39;7.1&#39;, &#39;title&#39;: &#39;奎迪：英雄再起&#39;}# {&#39;_id&#39;: &#39;1945750&#39;, &#39;rate&#39;: &#39;7.7&#39;, &#39;title&#39;: &#39;污垢&#39;}# 5. aggregate -- summary recordsprint(&#39;list summary by rate level&#39;)# $cond:{if:{$gte:[&#39;$rating&#39;,8]},then:1,else:0} # $addFields:{&#39;rate_number&#39;:{$convert:{input:&quot;$rate&quot;,to:&quot;int&quot;}}} # use $project also could add fieldsresults=collection.aggregate([    {&#39;$addFields&#39;:{        &#39;rate_number&#39;:{&#39;$convert&#39;:{&#39;input&#39;:&quot;$rate&quot;,&#39;to&#39;:&quot;double&quot;}}        ,&#39;rate_level&#39;:{&#39;$cond&#39;:[            {&#39;$lt&#39;:[&#39;$rate&#39;,&#39;7.5&#39;]}            ,{&#39;$cond&#39;:[{&#39;$gte&#39;:[&#39;$rate&#39;,&#39;6.5&#39;]},&#39;Middle&#39;,&#39;Low&#39;]}            ,&#39;High&#39;        ]}    }}    # ,{&#39;$project&#39;:{    #     &#39;_id&#39;:1    #     ,&#39;rate&#39;:1    #     ,&#39;title&#39;:1    #     # ,&#39;rate_level&#39;:{&#39;$cond&#39;:[    #     #     {&#39;$lt&#39;:[&#39;$rate&#39;,&#39;7.5&#39;]}    #     #     ,{&#39;$cond&#39;:[{&#39;$gte&#39;:[&#39;$rate&#39;,&#39;6.5&#39;]},&#39;Middle&#39;,&#39;Low&#39;]}    #     #     ,&#39;High&#39;    #     # ]}    # }}    ,{&#39;$group&#39;:{        &#39;_id&#39;:&quot;$rate_level&quot;        ,&#39;count&#39;:{&#39;$sum&#39;:1}        ,&#39;avg_rate&#39;:{&#39;$avg&#39;:&#39;$rate_number&#39;}        #,&#39;rate_list&#39;:{&#39;$push&#39;:&#39;$rate_number&#39;}        ,&#39;rate_list&#39;:{&#39;$push&#39;:{&#39;$concat&#39;:[&#39;$title&#39;,&#39;:&#39;,&#39;$rate&#39;]}}    }}    ,{&#39;$sort&#39;:{&#39;count&#39;:-1}}    #,{&#39;$limit&#39;:10}])for record in results:    print(record)# results sample:# {&#39;_id&#39;: &#39;Middle&#39;, &#39;count&#39;: 3, &#39;avg_rate&#39;: 6.8, &#39;rate_list&#39;: [&#39;硬核:6.5&#39;, &#39;奎迪：英雄再起:7.1&#39;, &#39;欢乐满人间2:6.8&#39;]}# {&#39;_id&#39;: &#39;Low&#39;, &#39;count&#39;: 1, &#39;avg_rate&#39;: 6.1, &#39;rate_list&#39;: [&#39;芳龄十六:6.1&#39;]}# {&#39;_id&#39;: &#39;High&#39;, &#39;count&#39;: 1, &#39;avg_rate&#39;: 7.7, &#39;rate_list&#39;: [&#39;污垢:7.7&#39;]}print(&quot;Done!&quot;)</code></pre><h2 id="header-64">Reference</h2><ul><li><a href="https://python3-cookbook.readthedocs.io/zh_CN/latest/" target="_blank" rel="noopener">Python3-cookbook</a></li><li><a href="https://docs.python.org/zh-cn/3/library/index.html" target="_blank" rel="noopener">Python 标准库</a></li><li><a href="https://docs.python.org/zh-cn/3/library/asyncio-task.html?highlight=coroutine#" target="_blank" rel="noopener">Python 标准库:协程与任务</a></li><li><a href="https://dev.to/welldone2094/async-programming-in-python-with-asyncio-12dl" target="_blank" rel="noopener">Async programming in Python with asyncio</a></li><li><a href="https://www.datacamp.com/community/tutorials/asyncio-introduction" target="_blank" rel="noopener">Asyncio: An Introduction</a></li><li><a href="https://stackabuse.com/python-async-await-tutorial/" target="_blank" rel="noopener">Python async/await Tutorial</a></li><li><a href="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/chapter4/index.html" target="_blank" rel="noopener">python parallel programmning cookbook: 第四章 异步编程</a></li><li><a href="https://my.oschina.net/lionets/blog/189326" target="_blank" rel="noopener">Python定制类的特殊方法与授权</a></li><li><a href="http://zhuoqiang.me/python-thread-gil-and-ctypes.html" target="_blank" rel="noopener">CPython GIL</a></li><li><a href="https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000" target="_blank" rel="noopener">Python教程-廖雪峰</a></li><li><a href="https://github.com/jackfrued/Python-100-Days" target="_blank" rel="noopener">Python-100天从新手到大师</a></li><li><a href="https://www.hongweipeng.com/index.php/series.html" target="_blank" rel="noopener">Python源码阅读</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;ol&gt;
&lt;li&gt;Env &amp;amp; Tools: python(+pip),ipython,Anaconda(+conda),PyCharm&lt;/li&gt;
&lt;li&gt;基础：keywords,comment,input,print,operation,if-else,for,while,try…except,sys.argv,unittest&lt;/li&gt;
&lt;li&gt;基础数据类型: 不可变对象(int,float,str,tuple,) &amp;amp; 可变对象(list,set,dict),垃圾回收机制,类型转换,位运算&lt;/li&gt;
&lt;li&gt;函数: 局部／全局变量，默认／不定长参数，闭包，列表生成式，生成器，迭代器，装饰器，匿名函数，常用内建函数&lt;/li&gt;
&lt;li&gt;类: 类属性／方法／静态方法，实例属性／方法，继承与多态，元类，枚举类，单例模式，内置类属性，定制类&lt;/li&gt;
&lt;li&gt;库：模块与包，导入，自定义库，发布／安装，常用标准库，常用扩展库&lt;/li&gt;
&lt;li&gt;文件IO：读写文件，操作文件／目录&lt;/li&gt;
&lt;li&gt;多任务：进程，线程，协程&lt;/li&gt;
&lt;li&gt;访问数据库：SQLite,MySQL,Redis,MongoDB&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
    
      <category term="Python" scheme="http://sixdegree.github.io/tags/Python/"/>
    
  </entry>
  
</feed>
