<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>SixDegree</title>
  <subtitle>host by chenjin</subtitle>
  <link href="//atom.xml" rel="self"/>
  
  <link href="http://sixdegree.github.io/"/>
  <updated>2016-06-04T08:55:22.107Z</updated>
  <id>http://sixdegree.github.io/</id>
  
  <author>
    <name>Chen Jin</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Hadoop2.x Basic</title>
    <link href="http://sixdegree.github.io/2016/05/25/Hadoop2.x-Basic.html"/>
    <id>http://sixdegree.github.io/2016/05/25/Hadoop2.x-Basic.html</id>
    <published>2016-05-24T16:00:00.000Z</published>
    <updated>2016-06-04T08:55:22.107Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;Hadoop2.x HDFS HA &amp;amp; Federation;&lt;/li&gt;
&lt;li&gt;Hadoop2.x MapReduce on Yarn&lt;/li&gt;
&lt;/ol&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;header-1&quot;&gt;概述&lt;/h2&gt;
&lt;p&gt;Hadoop2中有两个重要的变更：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;DFS的NameNode可以以集群的方式布署，增强了NameNodes的水平扩展能力和高可用性，分别是:HDFS Federation与HA；&lt;/li&gt;
&lt;li&gt;MapReduce将JobTracker中的资源管理及任务生命周期管理（包括定时触发及监控），拆分成两个独立的组件，并更名为YARN（Yet Another Resource Negotiator）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;header-2&quot;&gt;HDFS&lt;/h2&gt;
&lt;h3 id=&quot;header-3&quot;&gt;1.x缺点&lt;/h3&gt;
&lt;p&gt;Namenode problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Only One&lt;/li&gt;
&lt;li&gt;under great memory pressure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;SecondaryNamenode problems:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It’s confusing name&lt;/li&gt;
&lt;li&gt;No up-to-date FSIMAGE file&lt;/li&gt;
&lt;li&gt;No automatic failover&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-4&quot;&gt;2.x改进&lt;/h3&gt;
&lt;p&gt;Muti-Namenode （水平扩展和高可用）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Federation (different namespace)&lt;ul&gt;
&lt;li&gt;多个Namenode，一组Datanode&lt;/li&gt;
&lt;li&gt;使用不同的HDFS目录（即不同的namespace，互不影响）&lt;/li&gt;
&lt;li&gt;应用举例：不用Federation HDFS配置使用不同的Block大小以处理不同的需求&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;HA (same namespace)&lt;ul&gt;
&lt;li&gt;多个Namenode，一组Datanode&lt;/li&gt;
&lt;li&gt;使用相同的HDFS目录（即相同的namespace，只有一个Namenode负责读写）&lt;/li&gt;
&lt;li&gt;只有一个Namenode为Active，对外提供读写服务，其他为StandBy&lt;/li&gt;
&lt;li&gt;Active NN 一旦故障便自动切换到 standby NN（借助Zookeeper完成热切）&lt;/li&gt;
&lt;li&gt;系统通过JournalNodes守护进程使Standby和Active的Namenode保持元数据同步&lt;ul&gt;
&lt;li&gt;Active NN 将修改持久化（写）到JournalNodes&lt;/li&gt;
&lt;li&gt;StandBy NN 从JournalNodes读取修改信息，更新内部元数据&lt;/li&gt;
&lt;li&gt;JournalNodes是轻量级的进程（通过editlog持久化存储），需为奇数个&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;注意：Standby NN也执行namespace状态的checkpoints，所以不要再运行Secondary NN、CheckpointNode、BackupNode&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/25/hdfs.png&quot; alt=&quot;HDFS&quot;&gt;&lt;br&gt;(图片来自 &lt;a href=&quot;http://blog.csdn.net/jiewuyou&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/jiewuyou&lt;/a&gt;)&lt;/p&gt;
&lt;h3 id=&quot;header-5&quot;&gt;HDFS示例&lt;/h3&gt;
&lt;p&gt;Nodes DNS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cluster1 namenode&lt;ul&gt;
&lt;li&gt;masterA.cls1&lt;/li&gt;
&lt;li&gt;masterB.cls1&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;cluster2 namenode&lt;ul&gt;
&lt;li&gt;masterA.cls2&lt;/li&gt;
&lt;li&gt;masterB.cls2&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;datanode&lt;ul&gt;
&lt;li&gt;slave1.cls&lt;/li&gt;
&lt;li&gt;slave2.cls&lt;/li&gt;
&lt;li&gt;slave3.cls&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;zookeeper&lt;ul&gt;
&lt;li&gt;slave1.cls&lt;/li&gt;
&lt;li&gt;slave2.cls&lt;/li&gt;
&lt;li&gt;slave3.cls&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;journalnode&lt;ul&gt;
&lt;li&gt;slave1.cls&lt;/li&gt;
&lt;li&gt;slave2.cls&lt;/li&gt;
&lt;li&gt;slave3.cls&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;header-6&quot;&gt;Configuration&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;hadoop-env.sh (on all nodes)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; export JAVA_HOME=/usr/local/jdk1.8
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Cluster1 (on masterA.cls1,masterB.cls1)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;core-site.sh&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;hdfs://cluster1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hadoop.tmp.dir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;/usr/local/hadoop/tmp&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;ha.zookeeper.quorum&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;slave1.cls:2181,slave2.cls:2181,slave3.cls:2181&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;hdfs-site.xml&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;3&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.nameservices&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;cluster1,cluster2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- journal nodes --&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.shared.edits.dir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
       &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;qjournal://slave1.cls:8485;slave2.cls:8485;slave3.cls:8485/cluster1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.journalnode.edits.dir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;/usr/local/hadoop/tmp/journal&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- Using ssh to switch namenode --&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.ha.fencing.methods&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;sshfence&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.ha.fencing.ssh.private-key-files&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;/root/.ssh/id_rsa&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;

  &lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- Cluster1 --&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.ha.namenodes.cluster1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterA.cls1,masterB.cls1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.cluster1.masterA.cls1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterA.cls1:9000&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.http-address.cluster1.masterA.cls1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterA.cls1:50070&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.cluster1.masterB.cls1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterB.cls1:9000&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.http-address.cluster1.masterB.cls1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterB.cls1:50070&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.ha.automatic-failover.enabled.cluster1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;true&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.client.failover.proxy.provider.cluster1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
       &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- Cluster2 --&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.ha.namenodes.cluster2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterA.cls2,masterB.cls2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.cluster2.masterA.cls2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterA.cls2:9000&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.http-address.cluster2.masterA.cls2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterA.cls2:50070&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.rpc-address.cluster2.masterB.cls2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterB.cls2:9000&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.http-address.cluster2.masterB.cls2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterB.cls2:50070&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.ha.automatic-failover.enabled.cluster2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;true&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.client.failover.proxy.provider.cluster2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Cluster2 (on masterA.cls2,masterB.cls2)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;core-site.sh (copy from cluster1) update:&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt; &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
     &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;fs.defaultFS&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
     &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;hdfs://cluster2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;hdfs-site.xml (copy from cluster1) update:&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
   &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.namenode.shared.edits.dir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;qjournal://slave1.cls:8485;slave2.cls:8485;slave3.cls:8485/cluster2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;slaves (on all nodes)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  slave1.cls
  slave2.cls
  slave3.cls
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&quot;header-7&quot;&gt;Run&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;start zookeeper&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  # slave1.cls,slave2.cls,slave3.cls
  zkServer.sh start
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;start namenode&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # slave1.cls,slave2.cls,slave3.cls
 sbin/hadoop-daemon.sh start journalnode

 # masterA.cls1,masterB.cls1
 bin/hdfs zkfc -formatZK

 # masterA.cls1
 bin/hdfs namenode -format
 sbin/hadoop-daemon.sh start namenode

 # masterB.cls1
 bin/hdfs namenode -bootstrapStandby
 sbin/hadoop-daemon.sh start namenode

 # masterA.cls1,masterB.cls2
 sbin/hadoop-daemon.sh start zkfc
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;start datanode&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # slave1.cls,slave2.cls,slave3.cls
 sbin/hadoop-daemons.sh start datanode
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;header-8&quot;&gt;MapReduce&lt;/h2&gt;
&lt;h3 id=&quot;header-9&quot;&gt;1.x缺点&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;JobTracker under greate pressure&lt;ul&gt;
&lt;li&gt;Job Coordination&lt;/li&gt;
&lt;li&gt;Scheduling&lt;/li&gt;
&lt;li&gt;Resource Management&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Cluster 资源利用率不高 (不同作业需要搭建不同的集群环境)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-10&quot;&gt;2.x改进&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/25/hadoop.png&quot; alt=&quot;Hadoop&quot;&gt;&lt;/p&gt;
&lt;p&gt;引入Yarn&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;JobTracker的功能分离成Yarn的两个单独的组件完成&lt;ul&gt;
&lt;li&gt;ResourceManager 全局管理所有应用程序计算资源的分配&lt;/li&gt;
&lt;li&gt;ApplicationMaster 负责某一应用的任务调度和协调（每个应用一个，例如MapReduce,Storm,Spark等）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Yarn具有通用性，因此整个集群也可作为其他计算框架的管理平台（例如Spark，Storm等）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-11&quot;&gt;Yarn&lt;/h3&gt;
&lt;p&gt;Yarn：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一套资源统一管理和调度的平台&lt;/li&gt;
&lt;li&gt;可管理各种计算框架，包括 MapReduce 、 Spark 、 Strom 等&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/25/yarn.png&quot; alt=&quot;Hadoop&quot;&gt;&lt;/p&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ResourceManager&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;YARN集群的Master，负责管理整个集群的资源分配和作业调度&lt;/li&gt;
&lt;li&gt;接收提交的job，根据job的Context，NodeManager反馈的status，启动分配一个NodeManager的Container作为ApplicationManager&lt;/li&gt;
&lt;li&gt;主要包含两个组件：&lt;ul&gt;
&lt;li&gt;Scheduler 负责将集群资源分配给应用程序&lt;/li&gt;
&lt;li&gt;ApplicationManager 负责接收任务，调度启动每个Job所属的ApplicationMaster，&lt;br&gt;监控重启ApplicationMaster&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;NodeManager&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;YARN集群的Slave，是集群中实际拥有实际资源的工作节点&lt;/li&gt;
&lt;li&gt;负责Container状态的维护，并向RM保持心跳（类似RM在每台机器的上代理）&lt;/li&gt;
&lt;li&gt;注：&lt;ul&gt;
&lt;li&gt;RM可将某个NM上的Container分配给某个Job的AppMstr&lt;/li&gt;
&lt;li&gt;AppMstr将组成Job的多个Task调度到对应的NM上进行执行&lt;/li&gt;
&lt;li&gt;一般DN和NM在同一个节点&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;ApplicationMaster&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;负责申请资源，监控管理任务运行（一个Job生命周期内的所有工作）&lt;/li&gt;
&lt;li&gt;比如:&lt;ul&gt;
&lt;li&gt;运行Task的资源，由AM向RM申请；&lt;/li&gt;
&lt;li&gt;启动/停止NM上某Task的对应的Container，由AM向NM请求来完成&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;是一个可变部分，用户可对不同编程模型写自己的AM实现，让更多类型的编程模型能够跑在此集群中&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Container&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;资源的抽象，Yarn为了作资源隔离而提出的一个框架&lt;ul&gt;
&lt;li&gt;对NodeManager上的资源进行量化，组装成一个个Container，服务于已授权资源的任务&lt;/li&gt;
&lt;li&gt;完成任务后，系统回收资源，供后续任务申请使用&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;资源包括：内存，CPU，硬盘，网络等&lt;/li&gt;
&lt;li&gt;对于资源的表示以内存为单位，比之前以剩余slot数目更合理&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;header-12&quot;&gt;Yarn配置示例&lt;/h3&gt;
&lt;h4 id=&quot;header-13&quot;&gt;Configuration&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;mapred-site.xml&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;mapreduce.framework.name&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;yarn&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;yarn-site.xml&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
       &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;yarn.resourcemanager.hostname&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
       &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;masterA.cls1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
       &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;yarn.nodemanager.aux-services&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
       &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;mapreduce_shuffle&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;header-14&quot;&gt;Run&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;# masterA.cls1
sbin/start-yarn.sh

sbin/stop-yarn.sh
&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      Hadoop2.x Basic Introduce (HDFS+Yarn+MapReduce)
    
    </summary>
    
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>Flume</title>
    <link href="http://sixdegree.github.io/2016/05/20/Flume.html"/>
    <id>http://sixdegree.github.io/2016/05/20/Flume.html</id>
    <published>2016-05-19T16:00:00.000Z</published>
    <updated>2016-06-04T08:35:45.601Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;Flume概述（Agent组件：Source，Channel，Sink）；&lt;/li&gt;
&lt;li&gt;Flume安装；&lt;/li&gt;
&lt;li&gt;Flume使用示例；&lt;/li&gt;
&lt;/ol&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;header-1&quot;&gt;概述&lt;/h2&gt;
&lt;p&gt;Flume 分布式的日志收集系统 &lt;a href=&quot;https://flume.apache.org/FlumeUserGuide.html#setting-up-an-agent&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官网手册&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/20/frame1.png&quot; alt=&quot;Frame 1&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;agent：收集日志发送到目的地（运行在日志收集端的一个Java进程），包括三个核心组件：&lt;ul&gt;
&lt;li&gt;source 收集日志（数据临时存放在channel中）&lt;ul&gt;
&lt;li&gt;可处理各种类型各种格式的日志数据&lt;/li&gt;
&lt;li&gt;例如日志类型：avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy、自定义&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;channel 缓冲数据（数据只有在sink发送成功之后才会被删除）&lt;ul&gt;
&lt;li&gt;例如存放在：memory、jdbc、file、自定义&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;sink 发送日志到目的地&lt;ul&gt;
&lt;li&gt;例如目的地：hdfs、logger、avro、thrift、ipc、file、null、hbase、solr、自定义&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;特殊：interceptor 拦截器（在日志进入到source前，包装清洗过滤event）&lt;ul&gt;
&lt;li&gt;chain形式：可对一个source指定多个拦截器，按先后顺序依次处理&lt;/li&gt;
&lt;li&gt;官方已有的拦截器：Timestamp/Host/Static/Regex Filtering/Regex Extractor/… &lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;event：在整个数据传输过程中，流动的是event&lt;/li&gt;
&lt;li&gt;注意：&lt;ul&gt;
&lt;li&gt;事务保证在event级别&lt;/li&gt;
&lt;li&gt;flume支持多级agent&lt;/li&gt;
&lt;li&gt;flume支持扇入(fan-in)，扇出(fan-out)&lt;br&gt;  &lt;img src=&quot;/2016/05/20/frame2.png&quot; alt=&quot;Frame 2&quot;&gt;&lt;br&gt;  &lt;img src=&quot;/2016/05/20/frame3.png&quot; alt=&quot;Frame 3&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;header-2&quot;&gt;使用示例&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;安装：直接下载解压即可&lt;/li&gt;
&lt;li&gt;&lt;p&gt;配置：在&lt;code&gt;$FLUME_HOME/conf&lt;/code&gt;下添加一个配置文件（例如：&lt;code&gt;flume-conf-test1.properties&lt;/code&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt; # agent1表示代理名称
 agent1.sources=source1
 agent1.sinks=sink1
 agent1.channels=channel1

 # 配置source1
 # &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;. Spooling Directory是监控指定文件夹中新文件的变化
 # 一旦新文件出现，就解析该文件内容，然后写入到channle
 # 写入完成后，标记该文件已完成或者删除该文件
 # &lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;. 添加Timestamp Interceptor
 # 在event的header中添加一个key叫timestamp,value为当前的时间戳
 agent1.sources.source1.&lt;span class=&quot;built_in&quot;&gt;type&lt;/span&gt;=spooldir
 agent1.sources.source1.spoolDir=/home/hadoop/&lt;span class=&quot;built_in&quot;&gt;input&lt;/span&gt;/flume
 agent1.sources.source1.channels=channel1
 agent1.sources.source1.fileHeader = false
 agent1.sources.source1.interceptors = i1
 agent1.sources.source1.interceptors.i1.&lt;span class=&quot;built_in&quot;&gt;type&lt;/span&gt; = timestamp

 # 配置sink1
 agent1.sinks.sink1.&lt;span class=&quot;built_in&quot;&gt;type&lt;/span&gt;=hdfs
 agent1.sinks.sink1.hdfs.path=hdf&lt;span class=&quot;variable&quot;&gt;s:&lt;/span&gt;//cj.storm:&lt;span class=&quot;number&quot;&gt;9000&lt;/span&gt;/output/flume
 agent1.sinks.sink1.hdfs.fileType=DataStream
 agent1.sinks.sink1.hdfs.writeFormat=TEXT
 # agent1.sinks.sink1.hdfs.rollInterval=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;
 # agent1.sinks.sink1.hdfs.rollSize=&lt;span class=&quot;number&quot;&gt;10485760&lt;/span&gt;
 agent1.sinks.sink1.channel=channel1
 agent1.sinks.sink1.hdfs.filePrefix=%Y-%&lt;span class=&quot;keyword&quot;&gt;m&lt;/span&gt;-%d

 # 配置channel1
 agent1.channels.channel1.&lt;span class=&quot;built_in&quot;&gt;type&lt;/span&gt;=&lt;span class=&quot;keyword&quot;&gt;file&lt;/span&gt;
 agent1.channels.channel1.checkpointDir=/home/hadoop/&lt;span class=&quot;built_in&quot;&gt;input&lt;/span&gt;/flume_tmp/checkpoint
 agent1.channels.channel1.dataDirs=/home/hadoop/&lt;span class=&quot;built_in&quot;&gt;input&lt;/span&gt;/flume_tmp/data
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;测试&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # 1. 创建被监控目录
 &amp;gt; mkdir -p /home/hadoop/input/flume

 # 2. 启动flume agent1
 # -n 指定agent名称
 # -c 指定配置文件目录
 # -f 指定配置文件
 &amp;gt; bin/flume-ng agent -n agent1 -c conf -f conf/flume-conf-test1.properties \
 -Dflume.root.logger=DEBUG,console

 # 3. 放入测试文件
 # 4. 查看运行结果
 &amp;gt; hadoop fs -lsr /output/flume
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      Log Collection
    
    </summary>
    
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>Sqoop</title>
    <link href="http://sixdegree.github.io/2016/05/15/Sqoop.html"/>
    <id>http://sixdegree.github.io/2016/05/15/Sqoop.html</id>
    <published>2016-05-14T16:00:00.000Z</published>
    <updated>2016-06-04T08:52:29.031Z</updated>
    
    <content type="html">&lt;p&gt;HDFS数据到关系型数据库的导入导出工具Sqoop简介和基本使用示例&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;header-1&quot;&gt;概述&lt;/h2&gt;
&lt;p&gt;SQOOP – 使用MapReduce实现用于对数据进行导入导出&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Import: 把MySQL、Oracle等数据库中的数据导入到HDFS、Hive、HBase中&lt;/li&gt;
&lt;li&gt;Export: 把HDFS、Hive、HBase中的数据导出到MySQL、Oracle等数据库中&lt;/li&gt;
&lt;li&gt;注意：导入导出的事务是以Mapper任务为单位&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://sqoop.apache.org/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官网&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://sqoop.apache.org/docs/1.4.6/SqoopUserGuide.html#_incremental_imports&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;用户手册&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/15/frame.png&quot; alt=&quot;Export/Import&quot;&gt;&lt;/p&gt;
&lt;h2 id=&quot;header-2&quot;&gt;安装&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;下载解压&lt;/li&gt;
&lt;li&gt;配置环境变量（&lt;code&gt;/etc/profile&lt;/code&gt;）&lt;ul&gt;
&lt;li&gt;SQOOP_HOME&lt;/li&gt;
&lt;li&gt;HADOOP_HOME&lt;/li&gt;
&lt;li&gt;PATH&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;将要使用的JDBC Connector Jar包放入&lt;code&gt;$SQOOP_HOME/lib&lt;/code&gt;下&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;header-3&quot;&gt;使用示例&lt;/h2&gt;
&lt;h3 id=&quot;header-4&quot;&gt;查询&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;list databases&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  sqoop list-databases \
  --connect jdbc:mysql://cj.storm:3306 --username root --password cj123
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;list tables&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  sqoop list-tables \
  --connect jdbc:mysql://cj.storm:3306/hive --username root --password cj123
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;list jobs&lt;pre&gt;&lt;code&gt;  sqoop job --list
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-5&quot;&gt;Import(MySQL=&amp;gt;HDFS)&lt;/h3&gt;
&lt;p&gt;一些参数说明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-m &amp;lt;num&amp;gt;&lt;/code&gt;: 使用的mapper数（注意：对于无主键的表，需要增加参数&lt;code&gt;--split-by xxx&lt;/code&gt; 或 &lt;code&gt;-m 1&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--warehouse-dir &amp;lt;path&amp;gt;&lt;/code&gt;: 指定存放的数据仓库（默认：&lt;code&gt;/user/{USER_NAME}&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--target-dir &amp;lt;path&amp;gt;&lt;/code&gt;: 指定存放的数据路径 （默认：&lt;code&gt;/user/{USER_NAME}/{tablename}&lt;/code&gt;）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--null-string &amp;lt;str&amp;gt;&lt;/code&gt;: 指定用什么代表空字段（默认：NULL）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--hive-import&lt;/code&gt;: 表导入到hive中&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--hive-table &amp;lt;tablename&amp;gt;&lt;/code&gt;: hive table name&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--hive-overwrite&lt;/code&gt;: overwite hive table&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;mysql table =&amp;gt; hdfs file&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # use --warehouse-dir
 # final file: /output/log/part-m-00000
 sqoop import \
 --connect jdbc:mysql://cj.storm:3306/sqoop --username root --password cj123 \
 --table log --fields-terminated-by &#39;,&#39; \
 --warehouse-dir &#39;/output&#39; \
 -m 1

 # use --target-dir &amp;amp; query
 # final file: /output/log_2/part-m-00000
 sqoop import \
 --connect jdbc:mysql://cj.storm:3306/sqoop  --username root --P \
 --query &quot;select * from log where \$CONDITIONS&quot; \
 --target-dir /output/log_2 \
 -m 1  

 # use --target-dir &amp;amp; columns &amp;amp; where
 sqoop import \
 --connect jdbc:mysql://cj.storm:3306/sqoop --username root --password cj123 \
 --table log \
 --columns &quot;ip,status,method&quot; \
 --where &quot;status=&#39;200&#39; and method in (&#39;GET&#39;,&#39;POST&#39;)&quot;  \
 -m 1  \
 --target-dir /output/log_3 \
 --fields-terminated-by &quot;,&quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;mysql table =&amp;gt; hive table&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # use hive-import
 sqoop import 
 --connect jdbc:mysql://cj.storm:3306/hive  --username root --password cj123 
 --table TBLS 
 --fields-terminated-by &#39;\t&#39;  
 --null-string &#39;**&#39;  
 -m 1 
 --hive-import

 # use hive-import &amp;amp; hive-table
 sqoop import \
 --connect jdbc:mysql://cj.storm:3306/hive  --username root --password cj123 \
 --table TBLS \
 --fields-terminated-by &#39;\t&#39; \
 --null-string &#39;**&#39; \
 -m 1 \
 --hive-import \
 --hive-table &#39;tbls_2&#39;

 # check hive table
 hive -e &#39;describe formatted tbls&#39;
 hive -e &#39;describe formatted tbls_2&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;mysql table schema =&amp;gt; hive table schema&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; # just copy table schema (no data)
 sqoop create-hive-table \
 --connect jdbc:mysql://cj.storm:3306/sqoop --username root --password cj123 \
 --table log \
 --hive-table log_sqoop \
 --fields-terminated-by &amp;#39;,&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;header-6&quot;&gt;Job&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;create job:&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; sqoop job \
 --create myjob \
 -- import --connect jdbc:mysql://cj.storm:3306/hive  --username root -P \
 --table TBLS \
 --fields-terminated-by &amp;#39;\t&amp;#39;  \
 --null-string &amp;#39;**&amp;#39; \
 -m 1 \
 --hive-import \
 --hive-table &amp;#39;tbls_4&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;exec job:&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; sqoop job --exec myjob
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看 job:&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; sqoop job --list
 sqoop job --show myjob
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除 job:&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt; sqoop job --delete myjob
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      Sqoop introduction
    
    </summary>
    
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>Hive</title>
    <link href="http://sixdegree.github.io/2016/05/10/Hive.html"/>
    <id>http://sixdegree.github.io/2016/05/10/Hive.html</id>
    <published>2016-05-09T16:00:00.000Z</published>
    <updated>2016-05-31T01:14:41.060Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;Hive概述，安装；&lt;/li&gt;
&lt;li&gt;HiveQL操作；&lt;/li&gt;
&lt;li&gt;Hive的Java客户端操作；&lt;/li&gt;
&lt;/ol&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;header-1&quot;&gt;概述&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;建立在Hadoop基础上的数据仓库，能够管理查询Hadoop中的数据&lt;/li&gt;
&lt;li&gt;本质上，Hive是一个SQL解析引擎，将SQL语句转译成M/R Job，在Hadoop执行&lt;/li&gt;
&lt;li&gt;Hive的表其实就是HDFS的目录，字段即为文件中的列，可以直接在M/R Job里使用这些数据&lt;/li&gt;
&lt;li&gt;在HDFS中的默认存放位置：/user/hive/warehouse（hive-conf.xml的hive.metastore.warehouse.dir属性）&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-2&quot;&gt;系统架构&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/10/frame.png&quot; alt=&quot;Frame&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用户接口&lt;ul&gt;
&lt;li&gt;CLI：Shell命令行&lt;/li&gt;
&lt;li&gt;JDBC/ODBC：Java Connection （与使用传统数据库JDBC的方式类似）&lt;/li&gt;
&lt;li&gt;WebGUI：通过浏览器访问 Hive&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MetaStore&lt;ul&gt;
&lt;li&gt;存储元数据（例如：表名，表属性，列属性，分区属性，数据所在路径等）&lt;/li&gt;
&lt;li&gt;存储在数据库中，目前支持 mysql、derby(默认，内置)&lt;ul&gt;
&lt;li&gt;默认使用内嵌的derby数据库作为存储引擎&lt;/li&gt;
&lt;li&gt;Derby引擎的一次只能打开一个会话&lt;/li&gt;
&lt;li&gt;MySQL等外置存储引擎，可支持多用户同时访问&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Driver&lt;ul&gt;
&lt;li&gt;包含解释器，编译器，优化器，执行器&lt;/li&gt;
&lt;li&gt;完成HQL=&amp;gt;Job，Trigger Exec&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hadoop&lt;ul&gt;
&lt;li&gt;用 HDFS 进行存储&lt;/li&gt;
&lt;li&gt;利用 MapReduce 进行计算&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;注意：大部分的查询由 MapReduce 完成，但有些不是，例如&lt;code&gt;select * from table&lt;/code&gt;（包含&lt;code&gt;*&lt;/code&gt;的查询）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;现在Hive的整体框架，计算引擎不仅仅支持Map/Reduce，并且还支持Tez、Spark等。根&lt;br&gt;据不同的计算引擎又可以使用不同的资源调度和存储系统&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/10/frame-new.png&quot; alt=&quot;Frame New&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;header-3&quot;&gt;数据存储&lt;/h3&gt;
&lt;p&gt;存储结构主要包括：数据库、文件、表、视图&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;使用 HDFS 进行存储，无专门的数据存储格式，也没有为数据建立索引&lt;/li&gt;
&lt;li&gt;用户只需在建表时，指定Hive数据的列分隔符与行分隔符，Hive即可解析数据文件为Table&lt;/li&gt;
&lt;li&gt;默认可以直接加载文本文件（TextFile），也支持SequenceFile &lt;/li&gt;
&lt;li&gt;每一个 Table 在 Hive 中都有一个相应的目录存储数据&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;header-4&quot;&gt;安装&lt;/h2&gt;
&lt;p&gt;Hive可以安装在Hadoop集群中的任何一台机器上&lt;br&gt;metastore支持三种存储模式&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;本地内嵌模式（默认）：元数据保持在Hive内嵌的derby中，只允许一个会话连接&lt;/li&gt;
&lt;li&gt;本地独立模式：元数据保持在本地的一个DB中，允许多会话连接&lt;/li&gt;
&lt;li&gt;&lt;p&gt;远端独立模式：元数据保持在远程的一个DB中，允许多会话连接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;安装Hive：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;下载解压&lt;/li&gt;
&lt;li&gt;设置环境变量（&lt;code&gt;/etc/profile&lt;/code&gt;文件）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;HIVE_HOME&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;HADOOP_HOME&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PATH&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;配置（&lt;code&gt;$HIVE_HOME/conf&lt;/code&gt;目录下）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hive-log4j.properties.template&lt;/code&gt; =&amp;gt; &lt;code&gt;hive-log4j.properties&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hive-default.xml.template&lt;/code&gt; =&amp;gt; &lt;code&gt;hive-site.xml&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hive.metastore.warehouse.dir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;/user/hive/warehouse&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hive.exec.stagingdir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;/tmp/hive/.hive-staging&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hive.exec.scratchdir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;/tmp/hive&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hive.exec.local.scratchdir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;/tmp/hive&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hive.downloaded.resources.dir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;/tmp/hive/${hive.session.id}_resources&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hive.server2.logging.operation.log.location&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;/tmp/hive/operation_logs&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;HDFS上创建和授权目录&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hadoop fs -mkidr /tmp
hadoop fs -chmod g+w /tmp

hadoop fs -mkidr /user/hive/warehouse
hadoop fs -chmod g+w /user/hive/warehouse
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用外部数据库（例如MySQL）作为Hive的metastore：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;安装MySQL&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; rpm -&lt;span class=&quot;keyword&quot;&gt;qa&lt;/span&gt; |&lt;span class=&quot;keyword&quot;&gt;grep&lt;/span&gt; mysql             # 检查mysql
&amp;gt; rpm -&lt;span class=&quot;keyword&quot;&gt;e&lt;/span&gt; --nodeps mysql           # 强力卸载mysql

&amp;gt; rpm -i mysql-server-********    # 安装mysql服务端
&amp;gt; rpm -i mysql-client-********    # 安装mysql客户端

&amp;gt; mysqld_safe &amp;amp;                   # 启动mysql 服务端  
&amp;gt; mysql_secure_installation       # 设置root用户密码
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;mysql 连接权限修改&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; mysql -u root -p
mysql&amp;gt; use mysql;
mysql&amp;gt; select host,user from user;
mysql&amp;gt; grant all privileges on *.* to &#39;root&#39;@&#39;%&#39; identified by &#39;mypassword&#39; with grant option;
mysql&amp;gt; select host,user from user;
mysql&amp;gt; flush privileges;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;添加mysql的jdbc驱动包（置于到&lt;code&gt;$HIVE_HOME/lib&lt;/code&gt;目录下）&lt;/li&gt;
&lt;li&gt;添加配置Hive （&lt;code&gt;$HIVE_HOME/conf/hive-site.xml&lt;/code&gt;）&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionURL&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;jdbc:mysql://cj.storm:3306/hive?createDatabaseIfNotExist=true&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionDriverName&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;com.mysql.jdbc.Driver&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionUserName&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;root&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;javax.jdo.option.ConnectionPassword&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
 &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;admin&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;运行Hive:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;保证Hadoop是启动状态&lt;/li&gt;
&lt;li&gt;设置Hive运行模式&lt;ul&gt;
&lt;li&gt;分为本地与集群两种，可通过&lt;code&gt;mapred.job.tracker&lt;/code&gt;参数设置&lt;/li&gt;
&lt;li&gt;例如：&lt;code&gt;&amp;gt; hive -e &amp;quot;SET mapred.job.tracker=local&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;启动Hive&lt;ul&gt;
&lt;li&gt;启动命令行 &lt;code&gt;&amp;gt; hive --service cli&lt;/code&gt;，同&lt;code&gt;&amp;gt; hive&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;启动Web（port：9999） &lt;code&gt;&amp;gt; hive --service hwi &amp;amp;&lt;/code&gt;，需要另外下载放入&lt;code&gt;hive-hwi&lt;/code&gt;war包&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;验证&lt;ul&gt;
&lt;li&gt;Hive命令&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; hive -help
&amp;gt; hive
hive&amp;gt; show databases;
OK
default
hive&amp;gt; exit;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;header-5&quot;&gt;HiveQL&lt;/h2&gt;
&lt;h3 id=&quot;header-6&quot;&gt;数据库&lt;/h3&gt;
&lt;p&gt;类似传统数据库的DataBase，系统默认使用数据库&lt;code&gt;default&lt;/code&gt;，也可指定&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; hive
hive&amp;gt; create database &amp;lt;数据库名&amp;gt; ;
hive&amp;gt; use &amp;lt;数据库名&amp;gt; ;
...
hive&amp;gt; drop database  &amp;lt;数据库名&amp;gt;;
hive&amp;gt; drop database  &amp;lt;数据库名&amp;gt; cascade;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;header-7&quot;&gt;表&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;查看表：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 查看所有的表
show tables; 
# 支持模糊查询
show tables &amp;#39;*tmp*&amp;#39;; 

# 查看表有哪些分区
show partitions tmp_tb; 

#查看表详情
describe tmp_tb; 
describe formatted tmp_tb;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;修改表结构（alter）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; tmp_tb &lt;span class=&quot;keyword&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;columns&lt;/span&gt; (cols,&lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;);
&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; tmp_tb &lt;span class=&quot;keyword&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;day&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;2016-04-01&#39;&lt;/span&gt;,city=&lt;span class=&quot;string&quot;&gt;&#39;wx&#39;&lt;/span&gt;);
&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; tmp_tb &lt;span class=&quot;keyword&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt; (daytime=&lt;span class=&quot;string&quot;&gt;&#39;2016-05-01&#39;&lt;/span&gt;,city=&lt;span class=&quot;string&quot;&gt;&#39;sz&#39;&lt;/span&gt;);
&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; tmp_tb clustered &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (ip) &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt; buckets;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除表（drop）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;清空表 （truncate）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 无法清空外部表
truncate table table_name;  # 不指定分区，将清空表中的所有分区
truncate table table_name partition (dt=&amp;#39;20080808&amp;#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;视图（view）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;VIEW&lt;/span&gt; v1 &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; t1;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建表&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 创建表
Create [EXTERNAL] TABLE [IF NOT EXISTS] table_name 
  [(col_name data_type, ...)]
  [PARTITIONED BY (col_name data_type, ...)] 
  [
    CLUSTERED BY (col_name, col_name, ...) [SORTED BY (col_name [ASC|DESC], ...)] 
    INTO num_buckets BUCKETS
  ] 
  [ROW FORMAT DELIMITED row_format] 
  [STORED AS file_format] 
  [LOCATION hdfs_path]

# 复制表结构
CREATE [EXTERNAL] TABLE target_table LIKE source_table [LOCATION hdfs_path];
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;EXTERNAL ：标识创建一个外部表&lt;/li&gt;
&lt;li&gt;PARTITIONED By ：分区（每个分区列单独一个目录，分区列本身不会存储在数据文件中）&lt;/li&gt;
&lt;li&gt;CLUSTERED By ：分桶，根据指定列的Hash值切分（一个桶一个数据文件，内容包含桶列）&lt;/li&gt;
&lt;li&gt;ROW FORMAT DELIMITED ：指定数据分割符（默认只认单个字符）&lt;ul&gt;
&lt;li&gt;FIELDS TERMINATED BY&lt;/li&gt;
&lt;li&gt;LINES TERMINATED BY&lt;/li&gt;
&lt;li&gt;COLLECTION ITEMS TERMINATED BY&lt;/li&gt;
&lt;li&gt;MAP KEYS TERMINATED BY&lt;/li&gt;
&lt;li&gt;…&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;STORED AS ：数据存储方式&lt;ul&gt;
&lt;li&gt;TEXTFILE 纯文本，不压缩&lt;/li&gt;
&lt;li&gt;SEQUENCEFILE 序列化，压缩&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;LOCATION ：创建表时就加载数据，指定数据文件所在位置（可选）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加载数据(Load dataset)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;LOAD Cmd：将HDFS文件导入已创建的Hive表（加载时不做检查，查询时检查）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;LOAD&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;DATA&lt;/span&gt; [&lt;span class=&quot;keyword&quot;&gt;LOCAL&lt;/span&gt;] INPATH &lt;span class=&quot;string&quot;&gt;&#39;filepath&#39;&lt;/span&gt; [OVERWRITE] 
&lt;span class=&quot;keyword&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TABLE&lt;/span&gt; tablename
[&lt;span class=&quot;keyword&quot;&gt;PARTITION&lt;/span&gt; (partcol1=val1, partcol2=val2 ...)]
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;!hadoop fs -ls input/hive/stocks_db;
&lt;span class=&quot;keyword&quot;&gt;load&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;data&lt;/span&gt; inpath &lt;span class=&quot;string&quot;&gt;&#39;input/hive/stocks_db&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; stocks;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;CTAS：将Hive查询结果存放入一个新创表，原子级（select失败，table不会创建），目标表不能是分区表和外部表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TABLE&lt;/span&gt; [&lt;span class=&quot;keyword&quot;&gt;IF&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;NOT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;EXISTS&lt;/span&gt;] table_name 
&lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; …
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; stocks_ctas &lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; stocks;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;INSERT…SELECT：将Hive查询结果存入一个已创表&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;INSERT&lt;/span&gt; OVERWRITE|&lt;span class=&quot;keyword&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TABLE&lt;/span&gt; tablename 
[&lt;span class=&quot;keyword&quot;&gt;PARTITION&lt;/span&gt; (partcol1=val1, partcol2=val2 ...)] 
select_statement &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; from_statement
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert into table stocks_ctas select s.* from stocks s;
insert overwrite table stocks_ctas select s.* from stocks s;

# 可以在同一个查询中使用多个insert子句
from stocks_ctas
insert into t1 select id,name
insert into t2 select id,tel
where age&amp;gt;25
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;LOCATION：指定Hive表数据文件位置（注意：不会再移动数据文件到Hive配置的数据仓库中）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;!hadoop fs -ls /user/hive/input/hive/stocks_db;
&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; stocks_loc(...) 
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt;
location &lt;span class=&quot;string&quot;&gt;&#39;/user/hive/input/hive/stocks_db&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;说明：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Hive中有两种性质的表（Table Type）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;managed_table (Hive内部表) &lt;ul&gt;
&lt;li&gt;使用Load data命令插数据时，会将数据文件&lt;code&gt;移动&lt;/code&gt;到数据仓库（由&lt;code&gt;hive-site.xml&lt;/code&gt;配置的&lt;code&gt;hive.metastore.warehouse.dir&lt;/code&gt;指定）&lt;/li&gt;
&lt;li&gt;使用Drop table命令删除表时，元数据（metastore的db中）与对应的数据文件都会被删除&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;external_table (Hive外部表)&lt;ul&gt;
&lt;li&gt;使用Load data命令插数据时，不会将数据文件&lt;code&gt;移动&lt;/code&gt;到数据仓库&lt;/li&gt;
&lt;li&gt;使用Drop table命令删除表时，只有元数据会被删除，实际数据文件不会有影响&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hive中表的数据类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;基本数据类型&lt;ul&gt;
&lt;li&gt;tinyint/smallint/int/bigint&lt;/li&gt;
&lt;li&gt;float/double&lt;/li&gt;
&lt;li&gt;boolean&lt;/li&gt;
&lt;li&gt;string&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;复杂数据类型&lt;ul&gt;
&lt;li&gt;Array/Map/Struct&lt;/li&gt;
&lt;li&gt;没有date/datetime&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;header-8&quot;&gt;分区表&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 使用普通表，会scan整张表，效率低
select * from stocks where symbol=&amp;#39;XYZ&amp;#39; and ymd=&amp;#39;2003-02-01&amp;#39;;

# 使用分区表，会先找到对应分区列目录，效率高
select * from stocks_partition where symbol=&amp;#39;XYZ&amp;#39; and ymd=&amp;#39;2003-02-01&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;分区表（partition table）&lt;br&gt;粗粒度的划分，分区列成了目录（为虚拟列），条件查询时可定位到目录提高效率&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建分区表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; stocks_partition(
  col1 &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  col2 &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  exch_name &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  yr &lt;span class=&quot;built_in&quot;&gt;int&lt;/span&gt;
)
partitioned &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (sym &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;)
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加载数据&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Using &lt;code&gt;insert&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# add partition(sym=B7J) data:
insert into table stocks_partition partition(sym=&#39;B7J&#39;)
select col1,col2,exch_name,yr from stocks where symbol =&#39;B7J&#39;;

# add partition(sym=BB3) data:
insert into table stocks_partition partition(sym=&#39;BB3&#39;)
select col1,col2,exch_name,yr from stocks where symbol =&#39;BB3&#39;;

=&amp;gt; 也合并成一个insert
from stocks
insert into table stocks_partition partition(sym=&#39;B7J&#39;)
select col1,col2,exch_name,yr from stocks where symbol=&#39;B7J&#39;
insert into table stocks_partition partition(sym=&#39;BB3&#39;)
select col1,col2,exch_name,yr from stocks where symbol =&#39;BB3&#39;;

# 注意：如下方式是错误的
insert overwrite table stocks_partition partition(sym=&#39;APPL&#39;)
select col1,col2,exch_name,yr from stocks where symbol=&#39;ZUU&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using &lt;code&gt;location&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# add partition(sym=ZUU) data:
insert overwrite directory &amp;#39;output/hive/stocks-zuu&amp;#39;
select col1,col2,exch_name,yr from stocks where symbol=&amp;#39;ZUU&amp;#39;;

alter table stocks_partition add if not exists partition (sym=&amp;#39;ZUU&amp;#39;) 
location &amp;#39;/output/hive/stocks-zuu&amp;#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;添加删除分区&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; stocks_partition &lt;span class=&quot;keyword&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(sym=&lt;span class=&quot;string&quot;&gt;&#39;ZUU&#39;&lt;/span&gt;);
&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; stocks_partition &lt;span class=&quot;keyword&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(sym=&lt;span class=&quot;string&quot;&gt;&#39;ZUU&#39;&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看表分区 &lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;hive&amp;gt; show partitions stocks_partition
OK
symbol=B7K
symbol=BB3
symbol=ZUU
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;数据查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;selecet * from stocks_partitions where symbol=&amp;#39;XYZ&amp;#39; and ymd=&amp;#39;2003-02-01&amp;#39;;

# 若设置了strict方式，则select的where中一定要包含partition column条件查询
set hive.mapred.mode=strict;
select * from stocks_partitions where ymd=&amp;#39;2003-02-01&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;动态分区&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建动态分区表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; stocks_dynamic_partition(
 col1 &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
 col2 &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;
)
partitioned &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (exch_name &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,yr &lt;span class=&quot;built_in&quot;&gt;int&lt;/span&gt;,sym &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;)
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;启动动态分区&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.dynamic.partition=&lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加载数据（注意：默认动态分区要求至少有一个静态分区）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 如下方式，默认会报错
# SemanticException:dynamic partition strict mode requires at least one static partition column
insert overwrite table stocks_dynamic_partition partition(exch_name,yr,sym)
select col1,col2,exch_name,year(ymd),symbol from stocks;

=&amp;gt; 解决方案1：
set hive.exec.dynamic.partition.mode=nostrict;

=&amp;gt; 解决方案2：
insert overwrite table stocks_dynamic_partition partition(exch_name=&#39;ABCSE&#39;,yr,sym)
select col1,col2,exch_name,year(ymd),symbol from stocks;
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;查看表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;show&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;partitions&lt;/span&gt; stocks_dynamic_partition;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; stocks_dynamic_partition &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; exch_name=&lt;span class=&quot;string&quot;&gt;&#39;ABCSE&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; yr=&lt;span class=&quot;number&quot;&gt;2013&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;注意动态分区的分区数量是有限制的，可根据需要扩大设置（不推荐partition数量过多）：&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.max.dynamic.partitions=&lt;span class=&quot;number&quot;&gt;1000&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.max.dynamic.partitions.pernode=&lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;数据表的目录结构&lt;pre&gt;&lt;code&gt;stocks_dynamic_partition/exch_name=ABCSE/yr=2013/sym=GEL/
stocks_dynamic_partition/exch_name=ABCSE/yr=2013/sym=ZUU/
stocks_dynamic_partition/exch_name=ABCSE/yr=2014/sym=GEL/
...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-9&quot;&gt;桶表&lt;/h3&gt;
&lt;p&gt;桶表(Bucket Table)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;细粒度的划分，桶列仍在数据文件中&lt;/li&gt;
&lt;li&gt;主要应用：&lt;ul&gt;
&lt;li&gt;提高数据抽样效率&lt;/li&gt;
&lt;li&gt;提升某些查询操作效率，例如mapside join&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;创建表&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt; # 必须设置这个数据，hive才会按照你设置的桶的个数去生成数据
 set hive.enforce.bucketing = true;
 create table t4(id int) clustered by(id) into 4 buckets;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt; insert into table t4 select id from t3;      # 追加
 insert overrite table t4 select id from t3;  # 全部重写
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;抽样查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 查询带桶的表(在一部分桶上检索，效率高)
select * from t4 tablesample(bucket 1 out of 4 on id);

# 不带桶的表(会在整个数据集上检索，效率低)
select * from t3 tablesample(bucket 1 out of 4 on id);
select * from t3 tablesample(bucket 1 out of 4 on rand());
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;数据表的目录结构&lt;pre&gt;&lt;code&gt;t4/000000_0
t4/000000_1
t4/000000_2
t4/000000_3
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;分区+分桶：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 创建表
create table if not exists stocks_bucket(
  col1 string,
  col2 string
)
partitioned by (exch_name string,yr string)
clustered by (symbol) into 3 buckets
row format delimited fields terminated by &amp;#39;,&amp;#39; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 设置动态分区和使用桶
set hive.exec.dynamic.partition=true;
set hive.enforce.bucketing = true; 

# 插入数据
insert into table stocks_bucket partition (exch_name=&amp;#39;ABCE&amp;#39;,yr)
select col1,col2,year(ymd) from stocks
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 抽样查询对比
select * from stocks tablesample(bucket 3 out of 5 on symbol) s;        # 低效
select * from stocks_bucket tablesample(bucket 3 out of 5 on symbol) s; # 高效
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 数据表的目录结构
stocks_bucket/exch_name=ABCE/yr=2013
stocks_bucket/exch_name=ABCE/yr=2013/000000_0
stocks_bucket/exch_name=ABCE/yr=2013/000000_1
stocks_bucket/exch_name=ABCE/yr=2013/000000_2
stocks_bucket/exch_name=ABCE/yr=2014
stocks_bucket/exch_name=ABCE/yr=2014/000000_0
stocks_bucket/exch_name=ABCE/yr=2014/000000_1
stocks_bucket/exch_name=ABCE/yr=2014/000000_2
...
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-10&quot;&gt;抽样&lt;/h3&gt;
&lt;p&gt;tablesample 抽样&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tablesample(n precent/rows)&lt;ul&gt;
&lt;li&gt;n precent&lt;/li&gt;
&lt;li&gt;n rows&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;tablesample(nM)&lt;ul&gt;
&lt;li&gt;n兆&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;tablesample(bucket x out of y [on columns])&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;x: 从第几个桶开始抽样（从1开始）&lt;/li&gt;
&lt;li&gt;y: 抽样的桶数（若是分桶表，则必须为总bucket数的倍数或者因子）&lt;/li&gt;
&lt;li&gt;columns: 抽样的列&lt;/li&gt;
&lt;li&gt;注意：&lt;ul&gt;
&lt;li&gt;基于已经分桶的表抽样，查询只会扫描相应桶中的数据&lt;/li&gt;
&lt;li&gt;基于未分桶表的抽样，查询时候需要扫描整表数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;示例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 1. t1 为未分桶表
# 1.1 scan全表，根据col1分为10个桶，从第3个桶中取数据；
select * from t1 tablesample(bucket 3 out of 10 on col1);

# 1.2 scan全表，根据随机数分为10个桶，从第3个桶中取数据；
select * from t1 tablesample(bucket 3 out of 10 on rand());

# 2. t2 为分桶表，有10个桶
# 2.1 直接从第3个桶中取数据
select * from t2 tablesample(bucket 3 out of 10 on col1);

# 2.2 共抽取2(10/5)个桶的数据，从第3个和第8(3+5)个桶中抽取数据
select * from t2 tablesample(bucket 3 out of 5 on col1);

# 2.3 共抽取0.5(10/20)个桶的数据，从第3个桶中抽取一半数据
select * from t2 tablesample(bucket 3 out of 20 on col1);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;例如：&lt;ul&gt;
&lt;li&gt;tablesample(50 precent)&lt;/li&gt;
&lt;li&gt;tablesample(50 rows)&lt;/li&gt;
&lt;li&gt;tablesample(50M)&lt;/li&gt;
&lt;li&gt;tablesample(bucket 3 out of 10)&lt;/li&gt;
&lt;li&gt;tablesample(bucket 3 out of 10 on rand())&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-11&quot;&gt;单表查询&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; [ALL | &lt;span class=&quot;keyword&quot;&gt;DISTINCT&lt;/span&gt;] select_expr, select_expr, ...
  &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; table_reference 
  [&lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; condition] 
  [&lt;span class=&quot;keyword&quot;&gt;GROUP&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; col_list] [&lt;span class=&quot;keyword&quot;&gt;Having&lt;/span&gt; condition]
  [CLUSTER &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; col_list | [&lt;span class=&quot;keyword&quot;&gt;DISTRIBUTE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; col_list] [&lt;span class=&quot;keyword&quot;&gt;SORT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; col_list] | [&lt;span class=&quot;keyword&quot;&gt;ORDER&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; col_list] ]
  [&lt;span class=&quot;keyword&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;built_in&quot;&gt;number&lt;/span&gt;]
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;where：过滤（mapper端）&lt;/li&gt;
&lt;li&gt;group by：局部分组（reducer端），select中可使用一些聚合函数，例如sum，avg，count等&lt;/li&gt;
&lt;li&gt;cluster by：等价于distribute by + sort by ,只是无法指定排序规则（默认asc）&lt;/li&gt;
&lt;li&gt;distribute by：分区（partitioner），按指定字段划分数据到各个reduce/file&lt;/li&gt;
&lt;li&gt;sort by：局部排序（reducer端）&lt;/li&gt;
&lt;li&gt;order by：全局排序，只有一个reducer（数据量很大时慎用）&lt;/li&gt;
&lt;li&gt;limit：减少数据量，传输到reduce端（单机）的数据记录数就减少到n* （map个数）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;加查询结果写入HDFS中&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; overwrite &lt;span class=&quot;keyword&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;directory&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;/home/hive/output/hive/stocks&#39;&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; stocks &lt;span class=&quot;keyword&quot;&gt;distributed&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; symbol &lt;span class=&quot;keyword&quot;&gt;sort&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; symbol &lt;span class=&quot;keyword&quot;&gt;asc&lt;/span&gt;,price_close &lt;span class=&quot;keyword&quot;&gt;desc&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;全局排序 order by&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 无论设置了多少个reducer，这里只会使用一个reducer（数据量很大时效率低）
set mapreduce.job.reduces=3;
select * from stocks order by price_close desc;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;局部排序 sort by&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 每个reducer中排序
set mapreduce.job.reduces=3;
select * from stocks sort by price_close desc;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;分区 distribute/cluster by&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# distribute by 控制某个特定行应该到哪个reducer
# sort by 为每个reducer产生一个排好序的文件
# distribute by + sort by = cluster by
set mapreduce.job.reduces=3;
select * from stocks distributed by symbol sort by symbol asc;
select * from stocks cluster by symbol;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;聚合操作 group by&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; symbol,&lt;span class=&quot;keyword&quot;&gt;count&lt;/span&gt;(*) &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; stocks &lt;span class=&quot;keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; symbol;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Top N查询&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SET&lt;/span&gt; mapred.reduce.tasks = &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; sales &lt;span class=&quot;keyword&quot;&gt;SORT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;BY&lt;/span&gt; amount &lt;span class=&quot;keyword&quot;&gt;DESC&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;LIMIT&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-12&quot;&gt;连接查询&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用Join&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;{inner} join&lt;/code&gt;,&lt;code&gt;{left|right|full} [outer] join&lt;/code&gt;,&lt;code&gt;cross join&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; a.* &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; a &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; b &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; (a.id = b.id &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; a.department = b.department);
&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; a.* &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; a &lt;span class=&quot;keyword&quot;&gt;LEFT&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; b &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; (a.id = b.id &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; a.department = b.department);
&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; a.val, b.val, c.val &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; a &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; b &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; (a.key = b.key1) &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; c &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; (c.key = b.key2);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;特例：&lt;code&gt;LEFT SEMI JOIN&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; a.key, a.value &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; a &lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; a.key &lt;span class=&quot;keyword&quot;&gt;in&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; b.key &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; B);
&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; a.key, a.val &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; a &lt;span class=&quot;keyword&quot;&gt;LEFT&lt;/span&gt; SEMI &lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; b &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; (a.key = b.key);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hive中的Join可分为：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Common Join（Reduce阶段完成join）&lt;ul&gt;
&lt;li&gt;Map阶段：读取源表的数据，以Join on条件中的列为key，以join后所关心的(select或者where中需要用到的)列为value（value中包含Tag，用于标明此value对应哪个表）&lt;/li&gt;
&lt;li&gt;Shuffle阶段：根据key的值进行hash,并将key/value按照hash值推送至不同的reduce中，这样确保两个表中相同的key位于同一个reduce中&lt;/li&gt;
&lt;li&gt;Reduce阶段：根据key的值完成join操作，通过Tag识别不同表中的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Map Join（Map阶段完成join）：通常用于一个很小的表和一个大表进行join的场景&lt;ul&gt;
&lt;li&gt;Local Task（Client端本地执行）：扫描小表，装载到DistributeCache中&lt;/li&gt;
&lt;li&gt;Map Task：读取DistributeCache数据至内存，遍历大表记录，两者进行join，输出结果&lt;/li&gt;
&lt;li&gt;无Reducer Task&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hive中的join操作&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;join操作是在where操作之前执行，即where条件不能起到减少join数据的作用，应尽量在&lt;code&gt;on&lt;/code&gt;中加入约束条件&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; a.val, b.val &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; a 
&lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; b &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; (a.key=b.key)
&lt;span class=&quot;keyword&quot;&gt;WHERE&lt;/span&gt; a.ds=&lt;span class=&quot;string&quot;&gt;&#39;2009-07-07&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; b.ds=&lt;span class=&quot;string&quot;&gt;&#39;2009-07-07&#39;&lt;/span&gt;

=&amp;gt; 优化为：
&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; a.val, b.val &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; a 
&lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; b &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; (a.key=b.key &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; b.ds=&lt;span class=&quot;string&quot;&gt;&#39;2009-07-07&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AND&lt;/span&gt; a.ds=&lt;span class=&quot;string&quot;&gt;&#39;2009-07-07&#39;&lt;/span&gt;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;多表连接，会转换成多个MR Job，但关联条件相同的多表join会自动优化成一个mapreduce job&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 在两个mapred程序中执行join
SELECT a.val, b.val, c.val FROM a 
JOIN b ON (a.key = b.key1) 
JOIN c ON (c.key = b.key2)

# 在一个mapre程序中执行join
SELECT a.val, b.val, c.val FROM a 
JOIN b ON (a.key = b.key1) 
JOIN c ON (c.key = b.key1)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;多表连接，前一个join生成的数据会缓存到内存，通过stream取后一张表数据，应尽量将记录多的表放在后面join，也可使用&lt;code&gt;/*+ STREAMTABLE(table) */&lt;/code&gt;指定将哪个大表stream化&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;/*+ STREAMTABLE(a) */&lt;/span&gt; a.val, b.val, c.val &lt;span class=&quot;keyword&quot;&gt;FROM&lt;/span&gt; a 
&lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; b &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; (a.key = b.key1) 
&lt;span class=&quot;keyword&quot;&gt;JOIN&lt;/span&gt; c &lt;span class=&quot;keyword&quot;&gt;ON&lt;/span&gt; (c.key = b.key1)
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Map Side Join&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;可在查询中使用&lt;code&gt;/*+ mapjoin(table) */&lt;/code&gt; 指定将哪个小表装载到DistributeCache中&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 注意： 这里无法使用a FULL/RIGHT JOIN b
SELECT /*+ MAPJOIN(b) */ a.key, a.value FROM a join b on a.key = b.key;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Auto Map Side Join：系统自动判断使用mapjoin（由参数hive.auto.convert.join决定，默认为true）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# Local Task 中找出符合mapjoin条件的表，装载到DistributeCache中，后续使用map join；若未找到符合条件的表，则使用common join
set hive.auto.convert.join=true;
# 根据参数hive.mapjoin.smalltable.filesize的设置判断mapjoin的表
SELECT a.key, a.value FROM a join b on a.key = b.key;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;与map join相关的hive参数&lt;pre&gt;&lt;code&gt;# hive.join.emit.interval 
# hive.auto.convert.join 
# hive.mapjoin.smalltable.filesize
# hive.mapjoin.size.key  
# hive.mapjoin.cache.numrows
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Sort Map Bucket Map Join：根据join key将各个关联表进行Bucket，提高join效率&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 创建分桶表
create table a_smb(...) clustered by (key) sort by (key) into 10 buckets;
create table b_smb(...) clustered by (key) sort by (key) into 5 buckets;

# 为分桶表加载数据
set hive.enforce.bucketing=true;
insert into tabel a_smb select * from a;
insert into table b_smb select * from b;

# 打开SMB Map Join
set hive.auto.convert.sortmerge.join=true;
set hive.optimize.bucketmapjoin = true; 
set hive.optimize.bucketmapjoin.sortedmerge = true; 

set hive.input.format=org.apache.hadoop.hive.ql.io.BucketizedHiveInputFormat; 

select * from a_smb a join b_sm b on a.key=b.key;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;header-13&quot;&gt;示例&lt;/h2&gt;
&lt;h3 id=&quot;header-14&quot;&gt;示例1：导入Apache log&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;log格式:&lt;pre&gt;&lt;code&gt;127.0.0.1 - frank [10/Oct/2000:13:55:36 -0700] &amp;quot;GET /apache_pb.gif HTTP/1.0&amp;quot; 200 2326
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建表:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;TABLE&lt;/span&gt; apachelog (
host &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,
&lt;span class=&quot;keyword&quot;&gt;identity&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,
username &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,
&lt;span class=&quot;keyword&quot;&gt;time&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,
request &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,
&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,
&lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,
referer &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;,
&lt;span class=&quot;keyword&quot;&gt;agent&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;STRING&lt;/span&gt;)
&lt;span class=&quot;keyword&quot;&gt;ROW&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FORMAT&lt;/span&gt; SERDE &lt;span class=&quot;string&quot;&gt;&#39;org.apache.hadoop.hive.contrib.serde2.RegexSerDe&#39;&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;WITH&lt;/span&gt; SERDEPROPERTIES (
  &lt;span class=&quot;string&quot;&gt;&quot;input.regex&quot;&lt;/span&gt; = &lt;span class=&quot;string&quot;&gt;&quot;([^ ]*) ([^ ]*) ([^ ]*) (-|\\[[^\\]]*\\]) ([^ \&quot;]*|\&quot;[^\&quot;]*\&quot;) (-|[0-9]*) (-|[0-9]*)(?: ([^ \&quot;]*|\&quot;.*\&quot;) ([^ \&quot;]*|\&quot;.*\&quot;))?&quot;&lt;/span&gt;,
  &lt;span class=&quot;string&quot;&gt;&quot;output.format.string&quot;&lt;/span&gt; = &lt;span class=&quot;string&quot;&gt;&quot;%1$s %2$s %3$s %4$s %5$s %6$s %7$s %8$s %9$s&quot;&lt;/span&gt;
)
&lt;span class=&quot;keyword&quot;&gt;STORED&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;AS&lt;/span&gt; TEXTFILE;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;添加jar包到hive的执行环境:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;add jar $HIVE_HOME/lib/hive-contrib-1.2.1.jar
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;加载数据:&lt;pre&gt;&lt;code&gt;# inpath will be deleted!
load data inpath &amp;#39;/input/access_2013_05_31.log&amp;#39; into table apachelog;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;查询:&lt;pre&gt;&lt;code&gt;show tables;
describe formatted apachelog;
select * from apachelog limit 10;
select count(*) from apachelog;
select status,count(*) from apachelog group by status;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/apachelog
/user/hive/warehouse/apachelog/access_2013_05_31.log
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-15&quot;&gt;示例2：创建内部表&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;创建内部表log:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt;(
  ip &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  datetime &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  method &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;
)
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入数据:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert into table log 
select host,time,substring(split(request,&#39; &#39;)[0],2) as method,split(request,&#39; &#39;)[1] as url,status,size from apachelog; 

# 重新过滤掉某些数据（hive中没有delete操作，只能overwrite）
insert overwrite table log 
select * from log where length(method)&amp;lt;7 and method in (&#39;GET&#39;,&#39;POST&#39;,&#39;PUT&#39;,&#39;DELETE&#39;,&#39;OPTION&#39;,&#39;HEAD&#39;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查询:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;describe&lt;/span&gt; formatted &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt;;

&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; mapred.reduce.tasks=&lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; method &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;length&lt;/span&gt;(method)&amp;lt;&lt;span class=&quot;number&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; method;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;,method,&lt;span class=&quot;keyword&quot;&gt;count&lt;/span&gt;(*) &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;group&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;,method;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log
/user/hive/warehouse/log/000000_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-16&quot;&gt;示例3：内部静态分区表&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;创建内部分区表log_partition:（注意分区字段不能包含在建表字段中）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition(
  ip &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  datetime &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;
)
partitioned &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,method &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;)
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入partition数据:（使用insert…select）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;200&#39;&lt;/span&gt;,method=&lt;span class=&quot;string&quot;&gt;&#39;GET&#39;&lt;/span&gt;)
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; ip,datetime,&lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;200&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; method=&lt;span class=&quot;string&quot;&gt;&#39;GET&#39;&lt;/span&gt;;

&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;200&#39;&lt;/span&gt;,method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt;)
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; ip,datetime,&lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;200&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt;

&lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; overwrite &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;301&#39;&lt;/span&gt;,method=&lt;span class=&quot;string&quot;&gt;&#39;GET&#39;&lt;/span&gt;)
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; ip,datetime,&lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;301&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; method=&lt;span class=&quot;string&quot;&gt;&#39;GET&#39;&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; overwrite &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;301&#39;&lt;/span&gt;,method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt;)
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; ip,datetime,&lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;301&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; overwrite &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;400&#39;&lt;/span&gt;,method=&lt;span class=&quot;string&quot;&gt;&#39;GET&#39;&lt;/span&gt;)
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; ip,datetime,&lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;400&#39;&lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; method=&lt;span class=&quot;string&quot;&gt;&#39;GET&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入partition数据:（使用alter…location）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; overwrite &lt;span class=&quot;keyword&quot;&gt;directory&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;/user/hive/warehouse/log_partition/status=400/method=POST&#39;&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; ip,datetime,&lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;400&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt;;

&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition &lt;span class=&quot;keyword&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;400&#39;&lt;/span&gt;,method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt;) 
location &lt;span class=&quot;string&quot;&gt;&#39;/user/hive/warehouse/log_partition/status=400/method=POST&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除partition数据:（注意会删除partition对应的目录和文件）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition &lt;span class=&quot;keyword&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;exists&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;301&#39;&lt;/span&gt;,method=&lt;span class=&quot;string&quot;&gt;&#39;GET&#39;&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;describe&lt;/span&gt; formatted log_partition;
&lt;span class=&quot;keyword&quot;&gt;show&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;partitions&lt;/span&gt; log_partition;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_partition &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;400&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log_partition
/user/hive/warehouse/log_partition/status=200
/user/hive/warehouse/log_partition/status=200/method=GET
/user/hive/warehouse/log_partition/status=200/method=GET/000000_0
/user/hive/warehouse/log_partition/status=301
/user/hive/warehouse/log_partition/status=301/method=POST
/user/hive/warehouse/log_partition/status=301/method=POST/000000_0
/user/hive/warehouse/log_partition/status=400
/user/hive/warehouse/log_partition/status=400/method=GET
/user/hive/warehouse/log_partition/status=400/method=GET/000000_0
/user/hive/warehouse/log_partition/status=400/method=POST
/user/hive/warehouse/log_partition/status=400/method=POST/000000_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-17&quot;&gt;示例4：内部动态分区表&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;创建内部分区表log_dynamic_partition:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_dynamic_partition &lt;span class=&quot;keyword&quot;&gt;like&lt;/span&gt; log_partition;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;打开动态分区:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.dynamic.partition=&lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据:（注意：1. 字段和顺序；2. 第一个为静态partition）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_dynamic_partition &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;200&#39;&lt;/span&gt;,method)
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; ip,datetime,&lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt;,method &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;200&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据:（注意：1. 字段和顺序；2. 所有都为动态partition）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 设置为nostrict模式
set hive.exec.dynamic.partition.mode=nostrict;
# 插入
insert overwrite table log_dynamic_partition partition(status,method)
select ip,datetime,url,size,status,method from log;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;describe&lt;/span&gt; formatted log_dynamic_partition;
&lt;span class=&quot;keyword&quot;&gt;show&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;partitions&lt;/span&gt; log_dynamic_partition;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_dynamic_partition &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;400&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log_dynamic_partition
/user/hive/warehouse/log_dynamic_partition/status=200
/user/hive/warehouse/log_dynamic_partition/status=200/method=GET
/user/hive/warehouse/log_dynamic_partition/status=200/method=GET/000000_0
/user/hive/warehouse/log_dynamic_partition/status=301
/user/hive/warehouse/log_dynamic_partition/status=301/method=GET
/user/hive/warehouse/log_dynamic_partition/status=301/method=GET/000000_0
/user/hive/warehouse/log_dynamic_partition/status=301/method=POST
/user/hive/warehouse/log_dynamic_partition/status=301/method=POST/000000_0
/user/hive/warehouse/log_dynamic_partition/status=400
/user/hive/warehouse/log_dynamic_partition/status=400/method=GET
/user/hive/warehouse/log_dynamic_partition/status=400/method=GET/000000_0
/user/hive/warehouse/log_dynamic_partition/status=400/method=POST
/user/hive/warehouse/log_dynamic_partition/status=400/method=POST/000000_0
...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-18&quot;&gt;示例5：内部表分桶&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;创建分桶表log_bucket: （注意：分桶字段为建表中的字段）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_bucket(
  ip &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  datetime &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  method &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;
)
clustered &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;,method) &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt; buckets
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;打开分桶:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.enforce.bucketing = &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_bucket
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;describe&lt;/span&gt; formatted log_bucket;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_bucket tablesample(bucket &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;);
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; tablesample(bucket &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log_bucket
/user/hive/warehouse/log_bucket/000000_0
/user/hive/warehouse/log_bucket/000001_0
/user/hive/warehouse/log_bucket/000002_0
/user/hive/warehouse/log_bucket/000003_0
/user/hive/warehouse/log_bucket/000004_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-19&quot;&gt;示例6：内部分区分桶表&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;创建分区分桶表log_partition_bucket:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition_bucket(
  ip &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  datetime &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;
)
partitioned &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,method &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;) 
clustered &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (ip) &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt; buckets
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; ;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;打开动态分区和分桶:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.dynamic.partition=&lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.dynamic.partition.mode=nostrict;
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.enforce.bucketing = &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;插入数据:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_partition_bucket &lt;span class=&quot;keyword&quot;&gt;partition&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;,method)
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; ip,datetime,&lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt;,&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;,method &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;describe&lt;/span&gt; formatted log_partition_bucket;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_partition_bucket tablesample(bucket &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/log_partition_bucket
/user/hive/warehouse/log_partition_bucket/status=200
/user/hive/warehouse/log_partition_bucket/status=200/method=GET
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000000_0
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000001_0
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000002_0
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000003_0
/user/hive/warehouse/log_partition_bucket/status=200/method=GET/000004_0
/user/hive/warehouse/log_partition_bucket/status=301
/user/hive/warehouse/log_partition_bucket/status=301/method=GET
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000000_0
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000001_0
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000002_0
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000003_0
/user/hive/warehouse/log_partition_bucket/status=301/method=GET/000004_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000000_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000001_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000002_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000003_0
/user/hive/warehouse/log_partition_bucket/status=301/method=POST/000004_0
...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-20&quot;&gt;示例6：外部表&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;创建外部表log_external:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;external&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_external(
  ip &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  datetime &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  method &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;
)
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; 
location &lt;span class=&quot;string&quot;&gt;&#39;/input/external&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入数据:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# generate file: /input/external/000000_0
insert into table log_external
select * from log where status=&amp;#39;200&amp;#39;;

# generate file: /input/external/000000_0_copy_1
insert into table log_external
select * from log where status=&amp;#39;400&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入数据:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# generate file: /input/log_301/000000_0
insert overwrite directory &amp;#39;/input/log_301&amp;#39;
row format delimited fields terminated by &amp;#39;,&amp;#39;
select * from log where status=&amp;#39;301&amp;#39;; 

# generate file: /input/external/000000_0_copy_2
# delete file: /input/log_301/000000_0
load data inpath &amp;#39;/input/log_301&amp;#39; into table log_external;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;describe&lt;/span&gt; formatted log_external;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_external &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_external &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;400&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_external &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;301&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/input/external/000000_0
/input/external/000000_0_copy_1
/input/external/000000_0_copy_2
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;删除表:（注意：1. 无法使用truncate清空外部表；2. 数据文件不会被删除）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_external;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;重新创建外部表:（不用重新插入数据就有数据可查出了）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;external&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_external(
  ip &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  datetime &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  method &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;
)
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; 
location &lt;span class=&quot;string&quot;&gt;&#39;/input/external&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看表:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;describe&lt;/span&gt; formatted log_external;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_external &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_external &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;400&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; log_external &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;301&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-21&quot;&gt;示例7：外部分区分桶表&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;创建外部分区分桶表log_external_partition:&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;external&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; log_external_partition(
  ip &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  datetime &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,
  &lt;span class=&quot;keyword&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;
)
partitioned &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (&lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;,method &lt;span class=&quot;keyword&quot;&gt;string&lt;/span&gt;)
clustered &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (ip) &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt; buckets 
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt;
location &lt;span class=&quot;string&quot;&gt;&#39;/input/external_partition&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入partition数据: （alter location）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;insert overwrite directory &amp;#39;/input/log_301_GET&amp;#39; 
row format delimited fields terminated by &amp;#39;,&amp;#39;
select ip,datetime,url,size from log where status=&amp;#39;301&amp;#39; and method=&amp;#39;GET&amp;#39;; 

# generate file: /input/log_301_GET/000000_0~000004_0
alter table log_external_partition add partition (status=&amp;#39;301&amp;#39;,method=&amp;#39;GET&amp;#39;) 
location &amp;#39;/input/log_301_GET&amp;#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;插入partition数据:（动态分区）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set hive.exec.dynamic.partition=true;
set hive.exec.dynamic.partition.mode=nostrict;
set hive.enforce.bucketing = true;

# generate file: 
# /input/log_301_GET/000000_0_copy_1
# /input/external_partition/status=xxx/method=yyy/000000_0~000004_0
insert into table log_external_partition partition(status,method)
select ip,datetime,url,size,status,method from log;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;HDFS目录：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/input/log_301_GET
/input/log_301_GET/000000_0
/input/log_301_GET/000000_0_copy_1
/input/log_301_GET/000001_0
/input/log_301_GET/000002_0
/input/log_301_GET/000003_0
/input/log_301_GET/000004_0

/input/external_partition
/input/external_partition/status=200
/input/external_partition/status=200/method=GET
/input/external_partition/status=200/method=GET/000000_0
/input/external_partition/status=200/method=GET/000001_0
/input/external_partition/status=200/method=GET/000002_0
/input/external_partition/status=200/method=GET/000003_0
/input/external_partition/status=200/method=GET/000004_0
/input/external_partition/status=301
/input/external_partition/status=301/method=POST
/input/external_partition/status=301/method=POST/000000_0
/input/external_partition/status=301/method=POST/000001_0
/input/external_partition/status=301/method=POST/000002_0
/input/external_partition/status=301/method=POST/000003_0
/input/external_partition/status=301/method=POST/000004_0
...
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-22&quot;&gt;示例8：全排序&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;使用order by （不管设置几个reducer，最终只使用一个reducer）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;set mapred.reduce.tasks=5;

# 全排序
insert overwrite directory &amp;#39;/input/log_order&amp;#39; 
select ip,size from log order by ip;

# 局部排序
insert overwrite directory &amp;#39;/input/log_distribute&amp;#39; 
select ip,size from log distribute by ip sort by size;

# 全排序（数据量很大时，效率会高些）
insert overwrite directory &amp;#39;/input/log_order_opt&amp;#39;
select * from (select ip,size from log distribute by ip sort by size) s order by ip;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;使用TotalOrderSort&lt;ul&gt;
&lt;li&gt;生成抽样文件&lt;/li&gt;
&lt;li&gt;使用TotalOrderSort&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-23&quot;&gt;示例9：Join&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;创建两张表并插入数据:（crate table as select）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; a_log 
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; 
&lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;200&#39;&lt;/span&gt;;

&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; b_log
&lt;span class=&quot;keyword&quot;&gt;row&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;format&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;delimited&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;fields&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;terminated&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&#39;,&#39;&lt;/span&gt; 
&lt;span class=&quot;keyword&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;status&lt;/span&gt;=&lt;span class=&quot;string&quot;&gt;&#39;301&#39;&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查询: （会自动判断使用mapjoin）&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; a_log a &lt;span class=&quot;keyword&quot;&gt;join&lt;/span&gt; b_log b &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; a.ip=b.ip &lt;span class=&quot;keyword&quot;&gt;where&lt;/span&gt; a.method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; a_log a &lt;span class=&quot;keyword&quot;&gt;join&lt;/span&gt; b_log b &lt;span class=&quot;keyword&quot;&gt;on&lt;/span&gt; a.ip=b.ip &lt;span class=&quot;keyword&quot;&gt;and&lt;/span&gt; a.method=&lt;span class=&quot;string&quot;&gt;&#39;POST&#39;&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;limit&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;HDFS目录:&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/a_log
/user/hive/warehouse/a_log/000000_0
/user/hive/warehouse/b_log
/user/hive/warehouse/b_log/000000_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;创建两张分区表并插入数据:&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; a_log_smb &lt;span class=&quot;keyword&quot;&gt;like&lt;/span&gt; a_log;
&lt;span class=&quot;keyword&quot;&gt;create&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; b_log_smb &lt;span class=&quot;keyword&quot;&gt;like&lt;/span&gt; b_log;

&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; a_log_smb clustered &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (ip) &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt; buckets;
&lt;span class=&quot;keyword&quot;&gt;alter&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;table&lt;/span&gt; b_log_smb clustered &lt;span class=&quot;keyword&quot;&gt;by&lt;/span&gt; (ip) &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt; buckets;

&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; a_log_smb &lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; a_log;
&lt;span class=&quot;keyword&quot;&gt;insert&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;into&lt;/span&gt; b_log_smb &lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; * &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; b_log;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查询:(SMP)&lt;pre&gt;&lt;code&gt;select * from a_log_smb a join b_log_smb b on a.ip=b.ip limit 5;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;HDFS目录：&lt;pre&gt;&lt;code&gt;/user/hive/warehouse/a_log_smb
/user/hive/warehouse/a_log_smb/000000_0
/user/hive/warehouse/a_log_smb/000001_0
/user/hive/warehouse/a_log_smb/000002_0
/user/hive/warehouse/b_log_smb
/user/hive/warehouse/b_log_smb/000000_0
/user/hive/warehouse/b_log_smb/000001_0
/user/hive/warehouse/b_log_smb/000002_0
/user/hive/warehouse/b_log_smb/000003_0
/user/hive/warehouse/b_log_smb/000004_0
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;header-24&quot;&gt;优化策略&lt;/h2&gt;
&lt;p&gt;数据倾斜：由于数据的不均衡原因，导致数据分布不均匀，造成数据大量的集中到一点，造成数据热点&lt;/p&gt;
&lt;p&gt;Hadoop 计算框架特性：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;不怕数据大，怕数据倾斜&lt;/li&gt;
&lt;li&gt;job过多，耗时长（job初始化时间长）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;常用优化手段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少Job数&lt;/li&gt;
&lt;li&gt;并行Job，例如设置：&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 对于同一个SQL产生的JOB,如果不存在依赖的情况下，将会并行启动JOB
set hive.exec.parallel=true;
set hive.exec.parallel.thread.number=16;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;合理设置Mapper和Reducer数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少mapper数：合并小文件&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 100~128M的按照100M分割，&amp;lt;100M合并
set mapred.max.split.size=100000000;
set mapred.min.split.size.per.node=100000000;
set mapred.min.split.size.per.rack=100000000;
set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;增加mapper数：拆分文件（分区，分桶）&lt;/li&gt;
&lt;li&gt;&lt;p&gt;reducer数&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;# 每个reduce任务处理的数据量，默认为1000^3=1G
hive.exec.reducers.bytes.per.reducer

# 每个任务最大的reduce数，默认为999
hive.exec.reducers.max

# 设置reducer数量
mapred.reduce.tasks
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;合理压缩，减少网络传输和I/O压力，例如设置：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; mapred.output.compress = &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;  
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; mapred.output.compression.codec = org.apache.hadoop.io.compress.GzipCodec;  
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; mapred.output.compression.type = &lt;span class=&quot;keyword&quot;&gt;BLOCK&lt;/span&gt;;  
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; mapred.compress.map.output = &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;  
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; mapred.map.output.compression.codec = org.apache.hadoop.io.compress.LzoCodec;  

&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.compress.output = &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;  
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.compress.intermediate = &lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;  
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.intermediate.compression.codec = org.apache.hadoop.io.compress.LzoCodec;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;以SequenceFile保存，节约序列化和反序列化时间&lt;/li&gt;
&lt;li&gt;少用count distinct，例如：&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;select status,count(distinct ip) from log group by status;
=&amp;gt;
select status,count(ip) from (select status,ip from log group by status,ip) a
group by status;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;join优化&lt;ul&gt;
&lt;li&gt;尽量将condition放入join on中&lt;/li&gt;
&lt;li&gt;尽量大表滞后或使用STREAMTABLE(table)标识大表&lt;/li&gt;
&lt;li&gt;使用SMB Map Join&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;合理分区，分桶&lt;/li&gt;
&lt;li&gt;小数据量，尽量使用本地MapReduce，例如设置：&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.mode.local.auto=&lt;span class=&quot;literal&quot;&gt;true&lt;/span&gt;;  
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.mode.local.auto.inputbytes.max=&lt;span class=&quot;number&quot;&gt;50000000&lt;/span&gt;;
&lt;span class=&quot;keyword&quot;&gt;set&lt;/span&gt; hive.exec.mode.local.auto.tasks.max=&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;header-25&quot;&gt;自定义函数&lt;/h2&gt;
&lt;p&gt;查看函数&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;SHOW&lt;/span&gt; FUNCTIONS; 
&lt;span class=&quot;keyword&quot;&gt;DESCRIBE&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;FUNCTION&lt;/span&gt; &amp;lt;function_name&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;自定义函数包括三种UDF、UDAF、UDTF，可直接应用于Select语句&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;UDF：User-Defined-Function&lt;ul&gt;
&lt;li&gt;用户自定义函数（只能实现一进一出的操作）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;extends UDF&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UDAF：User-Defined Aggregation Funcation&lt;ul&gt;
&lt;li&gt;用户自定义聚合函数（可实现多进一出的操作）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;extends UDAF&lt;/code&gt;+ 内部Evaluator&lt;code&gt;implements UDAFEvaluator&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;init 初始化&lt;/li&gt;
&lt;li&gt;iterate 遍历&lt;/li&gt;
&lt;li&gt;terminatePartial 类似Hadoop的Combiner&lt;/li&gt;
&lt;li&gt;merge 合并&lt;/li&gt;
&lt;li&gt;terminate 返回最终的聚集函数结果&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;UDTF：User-Defined Table-Generating Function&lt;ul&gt;
&lt;li&gt;用户自定义表函数（可实现一进多出的操作）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;extends GenericUDTF&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;UDF示例：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;自定义函数&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;import&lt;/span&gt; org.apache.Hadoop.hive.ql.exec.UDF   
&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;Helloword&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;UDF&lt;/span&gt;&lt;/span&gt;{   
&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; String &lt;span class=&quot;title&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt;&lt;/span&gt;{   
    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;hello world!&quot;&lt;/span&gt;;   
}   
&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; String &lt;span class=&quot;title&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String str)&lt;/span&gt;&lt;/span&gt;{   
    &lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;hello world: &quot;&lt;/span&gt; + str;   
}   
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;上传jar包到目标机器&lt;/li&gt;
&lt;li&gt;添加到Hive中&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;# 进入hive客户端，添加jar包
hive&amp;gt; &lt;span class=&quot;built_in&quot;&gt;add&lt;/span&gt; jar udf_helloword.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;创建临时函数&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;hive&amp;gt; create temporary &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;helloword&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;as&lt;/span&gt; &#39;&lt;span class=&quot;title&quot;&gt;com&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;cj&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;hive&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;udf&lt;/span&gt;.&lt;span class=&quot;title&quot;&gt;Helloword&lt;/span&gt;&#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;测试&lt;pre&gt;&lt;code class=&quot;nullsql&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;select&lt;/span&gt; helloword(&lt;span class=&quot;keyword&quot;&gt;name&lt;/span&gt;) &lt;span class=&quot;keyword&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;users&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除临时函数&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;hive&amp;gt; &lt;span class=&quot;keyword&quot;&gt;drop&lt;/span&gt; temporaty &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;helloword&lt;/span&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注：helloworld为临时的函数，所以每次进入hive都需要add jar以及create temporary操作&lt;/p&gt;
&lt;h2 id=&quot;header-26&quot;&gt;Java API&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;启动Hive远程服务&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;&amp;gt; hive --service hiveserver2 &amp;gt;/dev/null  2&amp;gt;/dev/null &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;Java客户端加入依赖包&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.hive&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;hive-jdbc&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;${hive.version}&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;JAVA客户端连接操作代码&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;&lt;span class=&quot;meta&quot;&gt;@Test&lt;/span&gt;
&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;testConnection&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; ClassNotFoundException, SQLException &lt;/span&gt;{
  Class.forName(&lt;span class=&quot;string&quot;&gt;&quot;org.apache.hive.jdbc.HiveDriver&quot;&lt;/span&gt;);
  Connection conn = DriverManager.getConnection(&lt;span class=&quot;string&quot;&gt;&quot;jdbc:hive2://cj.storm:10000/default&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;&quot;&lt;/span&gt;);

  Statement stmt = conn.createStatement();
  String querySQL = &lt;span class=&quot;string&quot;&gt;&quot;select * from log_partition where status=&#39;200&#39; and method=&#39;GET&#39; limit 10&quot;&lt;/span&gt;;
  ResultSet res = stmt.executeQuery(querySQL);
  &lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; (res.next()) {
    System.out.println(res.getString(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) + &lt;span class=&quot;string&quot;&gt;&quot;\t&quot;&lt;/span&gt; + res.getString(&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt;));
  }
  res.close();
  conn.close();
}
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
</content>
    
    <summary type="html">
    
      Hive introduction
    
    </summary>
    
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
  <entry>
    <title>HBase</title>
    <link href="http://sixdegree.github.io/2016/05/05/HBase.html"/>
    <id>http://sixdegree.github.io/2016/05/05/HBase.html</id>
    <published>2016-05-04T16:00:00.000Z</published>
    <updated>2016-05-24T01:45:30.876Z</updated>
    
    <content type="html">&lt;ol&gt;
&lt;li&gt;HBase概述，模型；&lt;/li&gt;
&lt;li&gt;HBase安装，操作；&lt;/li&gt;
&lt;/ol&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h2 id=&quot;header-1&quot;&gt;概述&lt;/h2&gt;
&lt;p&gt;HBase：Hadoop Database&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一种在Hadoop之上的NoSQL 的Key/vale数据库,适合实时查询&lt;/li&gt;
&lt;li&gt;利用Hadoop HDFS作为其文件存储系统&lt;/li&gt;
&lt;li&gt;利用Hadoop MapReduce来处理其海量数据&lt;/li&gt;
&lt;li&gt;利用Zookeeper作为协调工具&lt;/li&gt;
&lt;li&gt;是一个高可靠性、高性能、面向列、可伸缩的分布式存储系统&lt;/li&gt;
&lt;li&gt;适合海量数据(如20PB)的秒级简单查询的数据库&lt;ul&gt;
&lt;li&gt;适合key-value查询&lt;/li&gt;
&lt;li&gt;适合按时间排序top n的场景&lt;/li&gt;
&lt;li&gt;适合大量读写&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-2&quot;&gt;数据模型&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;数据模型&lt;br&gt;  &lt;img src=&quot;/2016/05/05/datamodal.png&quot; alt=&quot;Data Modal&quot;&gt;&lt;br&gt;  &lt;img src=&quot;/2016/05/05/keyvalue.png&quot; alt=&quot;Key Value&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Table:存储管理数据&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RowKey&lt;/code&gt;:行键（类似于关系型数据库中的主键）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ColumnFamily&lt;/code&gt;：列族（定义表时指定），可包含任意多个列（插入记录时动态增加）&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Cell&lt;/code&gt;：单元格，由&lt;code&gt;{rowKey,columnFamily:columnName}&lt;/code&gt;确定的存储单元&lt;ul&gt;
&lt;li&gt;可存储一份数据的多个版本，由&lt;code&gt;Timestamp（时间戳）&lt;/code&gt;属性区分，即数据具有版本特性&lt;/li&gt;
&lt;li&gt;由&lt;code&gt;{rowKey, columnFamily:columnName, version}&lt;/code&gt;可确定某一版的Data&lt;/li&gt;
&lt;li&gt;若不指定时间戳或者版本，默认取最新的数据&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;逻辑数据模型&lt;br&gt;  &lt;img src=&quot;/2016/05/05/logicalmodal.png&quot; alt=&quot;Logical Modal&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;物理数据模型&lt;br&gt;  &lt;img src=&quot;/2016/05/05/physicalmodal.png&quot; alt=&quot;Physical Modal&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;说明：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;存储划分：&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Table&lt;/code&gt;按&lt;code&gt;RowKey&lt;/code&gt;范围&lt;code&gt;[startKey,endKey)&lt;/code&gt;划分成N个&lt;code&gt;Region&lt;/code&gt;&lt;ul&gt;
&lt;li&gt;各个&lt;code&gt;Region&lt;/code&gt;分散存储在不同的&lt;code&gt;RegionServer&lt;/code&gt;（单独的物理机器）中&lt;/li&gt;
&lt;li&gt;这样对表的操作转化为对多台&lt;code&gt;RegionServer&lt;/code&gt;的并行操作&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Region&lt;/code&gt;按&lt;code&gt;ColumnFamily&lt;/code&gt;一对一划分成&lt;code&gt;Store&lt;/code&gt;,每个store包括:&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MemStore&lt;/code&gt; 内存存储 （先，达到阀值后，写入StoreFile）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;StoreFile&lt;/code&gt; 文件存储（对应一个&lt;code&gt;HFile&lt;/code&gt;，存放在Hadoop HDFS）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;存储结构：&lt;ul&gt;
&lt;li&gt;&lt;code&gt;RowKey&lt;/code&gt;,&lt;code&gt;ColumnName&lt;/code&gt;按字典顺序物理存储&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Timestamp&lt;/code&gt;是一个64位整数&lt;/li&gt;
&lt;li&gt;所有数据以&lt;code&gt;byte[]&lt;/code&gt;存储&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/05/region.png&quot; alt=&quot;Region&quot;&gt;&lt;/p&gt;
&lt;h3 id=&quot;header-3&quot;&gt;架构体系&lt;/h3&gt;
&lt;p&gt;主从式结构&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Master（主）：可以启动多个，由Zookeeper的Master Election机制保证总有一个Master运行&lt;ul&gt;
&lt;li&gt;管理RegionServer&lt;/li&gt;
&lt;li&gt;分配Region&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;RegionServer（从）：一个物理节点一个&lt;ul&gt;
&lt;li&gt;存储Region&lt;/li&gt;
&lt;li&gt;响应用户I/O请求，向HDFS文件系统中读写数据&lt;/li&gt;
&lt;li&gt;合并切分Region（StoreFile）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Zookeeper（协调）&lt;ul&gt;
&lt;li&gt;保证集群中只有一个Running Master&lt;ul&gt;
&lt;li&gt;监控RegionServer的状态，实时通知给Master&lt;/li&gt;
&lt;li&gt;存储HBase的Schema（包括有哪些Table，每个Table有哪些ColumnFamily）&lt;/li&gt;
&lt;li&gt;存储Region寻址入口（即&lt;code&gt;-ROOT-&lt;/code&gt;表的location）&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/05/frame1.png&quot; alt=&quot;Frame&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2016/05/05/frame2.png&quot; alt=&quot;Frame&quot;&gt;&lt;/p&gt;
&lt;p&gt;HRegion 进程：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HLog ：预写式日志（所有更新操作先记录进日志，再操作），用于做灾难恢复Failover&lt;/li&gt;
&lt;li&gt;Store ：每个Store存放一个列族&lt;ul&gt;
&lt;li&gt;MemStore 内存存储 （先，达到阀值后，写入StoreFile）&lt;/li&gt;
&lt;li&gt;StoreFile 文件存储（对应一个HFile，存放在Hadoop HDFS）&lt;ul&gt;
&lt;li&gt;每次写入就形成一份单独的&lt;ul&gt;
&lt;li&gt;数量增长到一定阀值：合并StoreFile（合并时会进行版本合并和删除工作）– HDFS适合存储大文件&lt;/li&gt;
&lt;li&gt;大小超过一定阀值：分割当前Region（再由HMaster分配到其他RegionServer）– 实现负载均衡&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;HBase中有两张特殊的Table（&lt;code&gt;-ROOT-&lt;/code&gt;和&lt;code&gt;.META.&lt;/code&gt;）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.META.&lt;/code&gt;：记录了&lt;code&gt;用户表&lt;/code&gt;的Region信息，&lt;code&gt;.META.&lt;/code&gt;表本身可划分成N个regoin&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ROOT-&lt;/code&gt;：记录了&lt;code&gt;.META.&lt;/code&gt;表划分成的N个Region的信息，&lt;code&gt;-ROOT-&lt;/code&gt;本身只有一个，不划分&lt;br&gt;&lt;img src=&quot;/2016/05/05/meta.png&quot; alt=&quot;META&quot;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Client访问HBase上数据数据（并不需要master参与）:&lt;code&gt;zookeeper&lt;/code&gt;=&amp;gt;&lt;code&gt;-ROOT-&lt;/code&gt;表=&amp;gt;&lt;code&gt;.META.&lt;/code&gt;表=&amp;gt;Region位置=&amp;gt;访问&lt;/li&gt;
&lt;li&gt;Client包含访问HBase的接口,可通过维护着一些cache来加快对HBase的访问（比如缓存region的位置信息）&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;header-4&quot;&gt;安装&lt;/h2&gt;
&lt;h3 id=&quot;header-5&quot;&gt;伪分布式&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;下载解压安装包&lt;/li&gt;
&lt;li&gt;设置环境变量（&lt;code&gt;/etc/profile&lt;/code&gt;文件）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;HBASE_HOME&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PATH&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;配置（&lt;code&gt;$HBASE_HOME/conf&lt;/code&gt;目录下）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hbase-env.sh&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;  export JAVA_HOME=/usr/local/jdk
  # 使用HBase内置的Zookeeper
  export HBASE_MANAGES_ZK=true
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hbase-site.xml&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hbase.rootdir&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;hdfs://hadoop0:9000/hbase&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hbase.cluster.distributed&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;true&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hbase.zookeeper.quorum&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;hadoop0&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;dfs.replication&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;启动&lt;ul&gt;
&lt;li&gt;运行Hadoop&lt;/li&gt;
&lt;li&gt;运行HBase: &lt;code&gt;start-hbase.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;验证&lt;ul&gt;
&lt;li&gt;&lt;code&gt;jps&lt;/code&gt; 三个进程：HMaster、HRegionServer、HQuorumPeer&lt;/li&gt;
&lt;li&gt;&lt;code&gt;http://hadoop0:60010&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;header-6&quot;&gt;集群式&lt;/h3&gt;
&lt;p&gt;（在原来的hadoop0上的hbase伪分布基础上进行搭建）&lt;/p&gt;
&lt;p&gt;例如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Master：hadoop0&lt;/li&gt;
&lt;li&gt;RegionServer：hadoop1,hadoop2&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;配置（&lt;code&gt;$HBASE_HOME/conf&lt;/code&gt;目录下）&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hbase-env.sh&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;  export JAVA_HOME=/usr/local/jdk
  # 不使用HBase内置的Zookeeper
  export HBASE_MANAGES_ZK=false
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;hbase-site.xml&lt;/code&gt;&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;  ...
  &lt;span class=&quot;comment&quot;&gt;&amp;lt;!-- 配置Zookeeper监控管理的节点（hostname）--&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;hbase.zookeeper.quorum&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;name&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;hadoop0,hadoop1,hadoop2&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;value&lt;/span&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;property&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;regionservers&lt;/code&gt; （配置RegionServer的hostname）&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt;  hadoop1
  hadoop2
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;复制配置好的hbase到其他节点&lt;pre&gt;&lt;code class=&quot;nullvim&quot;&gt; scp -rp ./hbase `hadoop`@hadoop1:~
 scp -rp ./hbase `hadoop`@hadoop2:~
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;启动&lt;ul&gt;
&lt;li&gt;运行Hadoop&lt;/li&gt;
&lt;li&gt;运行zookeeper&lt;/li&gt;
&lt;li&gt;运行HBase: &lt;code&gt;start-hbase.sh&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;header-7&quot;&gt;操作&lt;/h2&gt;
&lt;p&gt;注意：HBase不能支持where条件、Order by 查询，只支持按照Row key来查询，但是可以通过HBase提供的API进行条件过滤&lt;/p&gt;
&lt;h3 id=&quot;header-8&quot;&gt;Shell Cmd&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;启用HBase Shell命令行&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; hbase shell
  ...
  &amp;gt; quite
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;常用命令&lt;table class=&quot;table&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;命令表达式&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;创建表&lt;/td&gt;
&lt;td&gt;create ‘表名称’, ‘列族名称1’,’列族名称2’,’列族名称N’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;添加记录&lt;/td&gt;
&lt;td&gt;put ‘表名称’, ‘行键’, ‘列族名称:列名称’, ‘值’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;查看记录&lt;/td&gt;
&lt;td&gt;get ‘表名称’, ‘行键’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;查看表中的记录总数&lt;/td&gt;
&lt;td&gt;count ‘表名称’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;删除记录&lt;/td&gt;
&lt;td&gt;delete ‘表名’ ,’行键’ , ‘列名称’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;删除一张表&lt;/td&gt;
&lt;td&gt;先要屏蔽该表，才能对该表进行删除，第一步 disable ‘表名称’ 第二步 drop ‘表名称’&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;查看所有记录&lt;/td&gt;
&lt;td&gt;scan “表名称”&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;查看某个表某个列中所有数据&lt;/td&gt;
&lt;td&gt;scan “表名称” , {COLUMNS=&amp;gt;’列族名称:列名称’}&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;更新记录&lt;/td&gt;
&lt;td&gt;就是重写一遍进行覆盖&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;注意：&lt;ul&gt;
&lt;li&gt;HBase其实没有delete操作，只有insert，以Timestamp区分新旧记录&lt;/li&gt;
&lt;li&gt;为充分利用分布式，可使用reverse key，hash，复合行键等技巧改造行键&lt;/li&gt;
&lt;li&gt;行键打乱后，可更均匀随机的分配到各节点，而不是集中在一个节点&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;操作示例：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;表操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建表&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; create &#39;users&#39;,&#39;user_id&#39;,&#39;address&#39;,&#39;info&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;查看表&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; list
  &amp;gt; describe &#39;users&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;验证表&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; exists &#39;users&#39;
  &amp;gt; is_enabled &#39;users&#39;
  &amp;gt; is_disabled &#39;users&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;删除表&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; disable &#39;users&#39;
  &amp;gt; delete &#39;users&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;记录操作：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;插入&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; put &#39;users&#39;,&#39;xiaoming&#39;,&#39;info:age&#39;,&#39;24&#39;;
  &amp;gt; put &#39;users&#39;,&#39;xiaoming&#39;,&#39;info:birthday&#39;,&#39;1987-06-17&#39;;
  &amp;gt; put &#39;users&#39;,&#39;xiaoming&#39;,&#39;info:company&#39;,&#39;alibaba&#39;;
  &amp;gt; put &#39;users&#39;,&#39;xiaoming&#39;,&#39;address:contry&#39;,&#39;china&#39;;
  &amp;gt; put &#39;users&#39;,&#39;xiaoming&#39;,&#39;address:province&#39;,&#39;zhejiang&#39;;
  &amp;gt; put &#39;users&#39;,&#39;xiaoming&#39;,&#39;address:city&#39;,&#39;hangzhou&#39;;
  &amp;gt; put &#39;users&#39;,&#39;zhangyifei&#39;,&#39;info:birthday&#39;,&#39;1987-4-17&#39;;
  &amp;gt; put &#39;users&#39;,&#39;zhangyifei&#39;,&#39;info:favorite&#39;,&#39;movie&#39;;
  &amp;gt; put &#39;users&#39;,&#39;zhangyifei&#39;,&#39;info:company&#39;,&#39;alibaba&#39;;
  &amp;gt; put &#39;users&#39;,&#39;zhangyifei&#39;,&#39;address:contry&#39;,&#39;china&#39;;
  &amp;gt; put &#39;users&#39;,&#39;zhangyifei&#39;,&#39;address:province&#39;,&#39;guangdong&#39;;
  &amp;gt; put &#39;users&#39;,&#39;zhangyifei&#39;,&#39;address:city&#39;,&#39;jieyang&#39;;
  &amp;gt; put &#39;users&#39;,&#39;zhangyifei&#39;,&#39;address:town&#39;,&#39;xianqiao&#39;;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;查询&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; get &#39;users&#39;,&#39;xiaoming&#39;
  &amp;gt; get &#39;users&#39;,&#39;xiaoming&#39;,&#39;info&#39;
  &amp;gt; get &#39;users&#39;,&#39;xiaoming&#39;,&#39;info:age&#39;

  # 获取单元格数据的版本数据
  &amp;gt; get &#39;users&#39;,&#39;xiaoming&#39;,{COLUMN=&amp;gt;&#39;info:age&#39;,VERSIONS=&amp;gt;1}
  &amp;gt; get &#39;users&#39;,&#39;xiaoming&#39;,{COLUMN=&amp;gt;&#39;info:age&#39;,VERSIONS=&amp;gt;2}
  &amp;gt; get &#39;users&#39;,&#39;xiaoming&#39;,{COLUMN=&amp;gt;&#39;info:age&#39;,VERSIONS=&amp;gt;3}

  # 获取单元格数据的某个版本数据
  &amp;gt; get &#39;users&#39;,&#39;xiaoming&#39;,{COLUMN=&amp;gt;&#39;info:age&#39;,TIMESTAMP=&amp;gt;1364874937056}

  # 全表扫描
  &amp;gt; scan &#39;users&#39;

  # 统计表的行数
  &amp;gt; count &#39;users&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;更新&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  &amp;gt; put &#39;users&#39;,&#39;xiaoming&#39;,&#39;info:age&#39; ,&#39;29&#39;
  &amp;gt; get &#39;users&#39;,&#39;xiaoming&#39;,&#39;info:age&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;删除&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullshell&quot;&gt;  # 删除某列值
  &amp;gt; delete &#39;users&#39;,&#39;xiaoming&#39;,&#39;info:age&#39;

  # 删除整行
  &amp;gt;deleteall &#39;users&#39;,&#39;xiaoming&#39;

  # 清空
  &amp;gt; truncate &#39;users&#39;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;header-9&quot;&gt;Java API&lt;/h3&gt;
&lt;p&gt;依赖包：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.hbase&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;hbase-client&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;${hbase.version}&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用示例：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;Configuration conf = HBaseConfiguration.create();
conf.set(&lt;span class=&quot;string&quot;&gt;&quot;hbase.rootdir&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;hdfs://hadoop0:9000/hbase&quot;&lt;/span&gt;);
&lt;span class=&quot;comment&quot;&gt;//使用eclipse时必须添加这个，否则无法定位&lt;/span&gt;
conf.set(&lt;span class=&quot;string&quot;&gt;&quot;hbase.zookeeper.quorum&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;hadoop0&quot;&lt;/span&gt;);
HBaseAdmin admin = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HBaseAdmin(conf);


String tableName=&lt;span class=&quot;string&quot;&gt;&quot;users&quot;&lt;/span&gt;;
String columnFamily=&lt;span class=&quot;string&quot;&gt;&quot;info&quot;&lt;/span&gt;;

&lt;span class=&quot;comment&quot;&gt;// 1. 创建一张表&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (admin.tableExists(tableName)) {
    System.out.println(&lt;span class=&quot;string&quot;&gt;&quot;table exists!&quot;&lt;/span&gt;);
}&lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;{
    HTableDescriptor tableDesc = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HTableDescriptor(tableName);
    tableDesc.addFamily(&lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HColumnDescriptor(columnFamily));
    admin.createTable(tableDesc);
    System.out.println(&lt;span class=&quot;string&quot;&gt;&quot;create table success!&quot;&lt;/span&gt;);
}

&lt;span class=&quot;comment&quot;&gt;// 2. 添加一条记录&lt;/span&gt;
String rowKey=&lt;span class=&quot;string&quot;&gt;&quot;xiaoming&quot;&lt;/span&gt;;
String column=&lt;span class=&quot;string&quot;&gt;&quot;age&quot;&lt;/span&gt;;
String data=&lt;span class=&quot;string&quot;&gt;&quot;24&quot;&lt;/span&gt;;

HTable table = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; HTable(conf, tableName);
Put p1 = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Put(Bytes.toBytes(rowKey));
p1.add(Bytes.toBytes(columnFamily), Bytes.toBytes(column),     Bytes.toBytes(data));
table.put(p1);
System.out.println(&lt;span class=&quot;string&quot;&gt;&quot;put&#39;&quot;&lt;/span&gt;+rowKey+&lt;span class=&quot;string&quot;&gt;&quot;&#39;,&quot;&lt;/span&gt;+columnFamily+&lt;span class=&quot;string&quot;&gt;&quot;:&quot;&lt;/span&gt;+column+&lt;span class=&quot;string&quot;&gt;&quot;&#39;,&#39;&quot;&lt;/span&gt;+data+&lt;span class=&quot;string&quot;&gt;&quot;&#39;&quot;&lt;/span&gt;);

&lt;span class=&quot;comment&quot;&gt;// 3. 读取一条记录&lt;/span&gt;
Get get = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Get(Bytes.toBytes(rowKey));
Result result = table.get(get);
System.out.println(&lt;span class=&quot;string&quot;&gt;&quot;Get: &quot;&lt;/span&gt;+result);

&lt;span class=&quot;comment&quot;&gt;// 4. 显示所有数据&lt;/span&gt;
Scan scan = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Scan();
ResultScanner scanner = table.getScanner(scan);
&lt;span class=&quot;comment&quot;&gt;/*scan.setStartRow(Bytes.toBytes(&quot;134/&quot;));
scan.setStopRow( Bytes.toBytes(&quot;134:&quot;));
scan.setMaxVersions(1);*/&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (Result res : scanner) {
    System.out.println(&lt;span class=&quot;string&quot;&gt;&quot;Scan: &quot;&lt;/span&gt;+res    );
}
table.close();

&lt;span class=&quot;comment&quot;&gt;// 5. 删除表&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(admin.tableExists(tableName)){
    &lt;span class=&quot;keyword&quot;&gt;try&lt;/span&gt; {
      admin.disableTable(tableName);
      admin.deleteTable(tableName);
    } &lt;span class=&quot;keyword&quot;&gt;catch&lt;/span&gt; (IOException e) {
      e.printStackTrace();
      System.out.println(&lt;span class=&quot;string&quot;&gt;&quot;Delete &quot;&lt;/span&gt;+tableName+&lt;span class=&quot;string&quot;&gt;&quot; 失败&quot;&lt;/span&gt;);
    }
}
admin.close();
System.out.println(&lt;span class=&quot;string&quot;&gt;&quot;Delete &quot;&lt;/span&gt;+tableName+&lt;span class=&quot;string&quot;&gt;&quot; 成功&quot;&lt;/span&gt;);
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;header-10&quot;&gt;结合MapReduce操作&lt;/h3&gt;
&lt;p&gt;Hbase对Mapreduce API进行了扩展，方便Mapreduce任务读写HTable数据&lt;/p&gt;
&lt;table class=&quot;table&quot;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;HBase MapReduce&lt;/th&gt;
&lt;th&gt;Hadoop MapReduce&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;org.apache.hadoop.hbase.mapreduce.TableMapper&lt;/td&gt;
&lt;td&gt;org.apache.hadoop.mapreduce.Mapper&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;org.apache.hadoop.hbase.mapreduce.TableReducer&lt;/td&gt;
&lt;td&gt;org.apache.hadoop.mapreduce.Reducer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;org.apache.hadoop.hbase.mapreduce.TableInputFormat&lt;/td&gt;
&lt;td&gt;org.apache.hadoop.mapreduce.InputFormat&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;org.apache.hadoop.hbase.mapreduce.TableOutputFormat&lt;/td&gt;
&lt;td&gt;org.apache.hadoop.mapreduce.OutputFormat&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;依赖包：&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nullxml&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;org.apache.hbase&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;groupId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;hbase-server&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;artifactId&lt;/span&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;${hbase.version}&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;version&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;dependency&lt;/span&gt;&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用示例1：统计&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String[] args)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{   
    Configuration config = HBaseConfiguration.create(); 
    configuration.set(&lt;span class=&quot;string&quot;&gt;&quot;hbase.zookeeper.quorum&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;hadoop0&quot;&lt;/span&gt;);

    Job job = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Job(config,&lt;span class=&quot;string&quot;&gt;&quot;HBaseTotal&quot;&lt;/span&gt;);  
    job.setJarByClass(TotalOnHBase.class); 

    Scan scan = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Scan();  
    scan.setCaching(&lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;);
    scan.setCacheBlocks(&lt;span class=&quot;keyword&quot;&gt;false&lt;/span&gt;);
    TableMapReduceUtil.initTableMapperJob(&lt;span class=&quot;string&quot;&gt;&quot;access-log&quot;&lt;/span&gt;,scan,MyTableMapper.class,Text.class,IntWritable.class,job);  
    TableMapReduceUtil.initTableReducerJob(&lt;span class=&quot;string&quot;&gt;&quot;total-access&quot;&lt;/span&gt;,MyTableReducer.class,job);  
    job.waitForCompletion(&lt;span class=&quot;keyword&quot;&gt;true&lt;/span&gt;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;MyTableMapper&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;TableMapper&lt;/span&gt;&amp;lt;&lt;span class=&quot;title&quot;&gt;Text&lt;/span&gt;, &lt;span class=&quot;title&quot;&gt;IntWritable&lt;/span&gt;&amp;gt;  &lt;/span&gt;{  
    &lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; IntWritable ONE = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; IntWritable(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;);  
    &lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; Text text = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Text();  
    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(ImmutableBytesWritable row, Result value, Context context)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; IOException, InterruptedException &lt;/span&gt;{  
        String ip = Bytes.toString(row.get()).split(&lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;)[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;];  
        String url = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; String(value.getValue(Bytes.toBytes(&lt;span class=&quot;string&quot;&gt;&quot;info&quot;&lt;/span&gt;), Bytes.toBytes(&lt;span class=&quot;string&quot;&gt;&quot;url&quot;&lt;/span&gt;)));  
        text.set(ip+&lt;span class=&quot;string&quot;&gt;&quot;&amp;amp;&quot;&lt;/span&gt;+url);  
        context.write(text, ONE);  
    }  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;MyTableReducer&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;TableReducer&lt;/span&gt;&amp;lt;&lt;span class=&quot;title&quot;&gt;Text&lt;/span&gt;, &lt;span class=&quot;title&quot;&gt;IntWritable&lt;/span&gt;, &lt;span class=&quot;title&quot;&gt;ImmutableBytesWritable&lt;/span&gt;&amp;gt;  &lt;/span&gt;{  
    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;reduce&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(Text key, Iterable&amp;lt;IntWritable&amp;gt; values, Context context)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; IOException, InterruptedException &lt;/span&gt;{  
        &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; sum = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;  
        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (IntWritable val : values) {  
            sum += val.get();  
        }  

        Put put = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Put(key.getBytes());  
        put.add(Bytes.toBytes(&lt;span class=&quot;string&quot;&gt;&quot;info&quot;&lt;/span&gt;), Bytes.toBytes(&lt;span class=&quot;string&quot;&gt;&quot;count&quot;&lt;/span&gt;), Bytes.toBytes(String.valueOf(sum)));  

        context.write(&lt;span class=&quot;keyword&quot;&gt;null&lt;/span&gt;, put);  
    }  
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;使用示例2：批量导入（&lt;code&gt;TableOutputFormat&lt;/code&gt;,&lt;code&gt;TableReducer&lt;/code&gt;）&lt;/p&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String[] args)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; Exception &lt;/span&gt;{
    &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; Configuration configuration = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Configuration();
    &lt;span class=&quot;comment&quot;&gt;//设置zookeeper&lt;/span&gt;
    configuration.set(&lt;span class=&quot;string&quot;&gt;&quot;hbase.zookeeper.quorum&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;hadoop0&quot;&lt;/span&gt;);
    &lt;span class=&quot;comment&quot;&gt;//设置hbase表名称&lt;/span&gt;
    configuration.set(TableOutputFormat.OUTPUT_TABLE, &lt;span class=&quot;string&quot;&gt;&quot;wlan_log&quot;&lt;/span&gt;);
    &lt;span class=&quot;comment&quot;&gt;//将该值改大，防止hbase超时退出&lt;/span&gt;
    configuration.set(&lt;span class=&quot;string&quot;&gt;&quot;dfs.socket.timeout&quot;&lt;/span&gt;, &lt;span class=&quot;string&quot;&gt;&quot;180000&quot;&lt;/span&gt;);

    &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; Job job = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Job(configuration, &lt;span class=&quot;string&quot;&gt;&quot;HBaseBatchImport&quot;&lt;/span&gt;);
    FileInputFormat.setInputPaths(job, &lt;span class=&quot;string&quot;&gt;&quot;hdfs://hadoop0:9000/input&quot;&lt;/span&gt;);
    job.setInputFormatClass(TextInputFormat.class);
    job.setMapperClass(BatchImportMapper.class);
    job.setMapOutputKeyClass(LongWritable.class);
    job.setMapOutputValueClass(Text.class);
    &lt;span class=&quot;comment&quot;&gt;//BatchImportReducer extends TableReducer&lt;/span&gt;
    job.setReducerClass(BatchImportReducer.class);
    &lt;span class=&quot;comment&quot;&gt;//不再设置输出路径，而是设置输出格式类型&lt;/span&gt;
    job.setOutputFormatClass(TableOutputFormat.class);
    job.waitForCompletion(&lt;span class=&quot;keyword&quot;&gt;true&lt;/span&gt;);
}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;nulljava&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// BatchImportMapper 数据清理，省略...&lt;/span&gt;
&lt;span class=&quot;comment&quot;&gt;// BatchImportReducer 将数据写入HBase&lt;/span&gt;
&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;class&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;BatchImportReducer&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;extends&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;TableReducer&lt;/span&gt;&amp;lt;&lt;span class=&quot;title&quot;&gt;LongWritable&lt;/span&gt;, &lt;span class=&quot;title&quot;&gt;Text&lt;/span&gt;, &lt;span class=&quot;title&quot;&gt;NullWritable&lt;/span&gt;&amp;gt;&lt;/span&gt;{
    &lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;protected&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;reduce&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(LongWritable key, Iterable&amp;lt;Text&amp;gt; values,Context context)&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;throws&lt;/span&gt; IOException ,InterruptedException &lt;/span&gt;{
        &lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (Text text : values) {
            &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; String[] splited = text.toString().split(&lt;span class=&quot;string&quot;&gt;&quot;\t&quot;&lt;/span&gt;);
            &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; Put put = &lt;span class=&quot;keyword&quot;&gt;new&lt;/span&gt; Put(Bytes.toBytes(splited[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;]));
            put.add(Bytes.toBytes(&lt;span class=&quot;string&quot;&gt;&quot;info&quot;&lt;/span&gt;), Bytes.toBytes(&lt;span class=&quot;string&quot;&gt;&quot;age&quot;&lt;/span&gt;), Bytes.toBytes(splited[&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;]));
            &lt;span class=&quot;comment&quot;&gt;//省略其他字段，调用put.add(....)即可&lt;/span&gt;
            context.write(NullWritable.get(), put);
        }
    };
}
&lt;/code&gt;&lt;/pre&gt;
</content>
    
    <summary type="html">
    
      HBase introduction
    
    </summary>
    
    
      <category term="NoSql" scheme="http://sixdegree.github.io/tags/NoSql/"/>
    
      <category term="BigData" scheme="http://sixdegree.github.io/tags/BigData/"/>
    
  </entry>
  
</feed>
